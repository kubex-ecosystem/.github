# LookAtni Code - Gerado automaticamente
# Data: 2025-07-13T23:16:53.748Z
# Fonte: /srv/apps/KUBEX/gdbase/
# Total de arquivos: 160

/// CODE_OF_CONDUCT.md ///
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
discord.gg/CCBJsFHT.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
<https://www.contributor-covenant.org/version/2/0/code_of_conduct.html>.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
<https://www.contributor-covenant.org/faq>. Translations are available at
<https://www.contributor-covenant.org/translations>.

/// NOTICE.md ///
# NOTICE

This software is licensed under the MIT License. Below are additional notes on usage and attribution:

## Attribution Requirement (Optional)

- When distributing or using this software, please provide credit to the original author(s) in one or more of the following ways:
- Retain the copyright notice: `Copyright (c) 2025 Rafael Mori`.
- Include a link to the original project repository or website.

## Acknowledgment

This project was developed with the goal of enhancing usability and providing open access to its features.

For further information about the license and terms of use, please refer to the `LICENSE` file included with this project.

/// README.md ///
#

![GDBASE Banner](docs/assets/top_banner.png)

[![Go](https://img.shields.io/badge/Go-1.19+-00ADD8?logo=go&logoColor=white)](https://go.dev/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/rafa-mori/gdbase/blob/main/LICENSE)
[![Automation](https://img.shields.io/badge/automation-zero%20config-blue)](#features)
[![Releases](https://img.shields.io/github/v/release/rafa-mori/goforge?include_prereleases)](https://github.com/rafa-mori/goforge/releases)
[![Build](https://github.com/rafa-mori/gdbase/actions/workflows/release.yml/badge.svg)](https://github.com/rafa-mori/gdbase/actions/workflows/release.yml)

---

**Modular, scalable, and automatic database management for modern systems.**

---

## **Table of Contents**

1. [About the Project](#about-the-project)
2. [Features](#features)
3. [Installation](#installation)
4. [Usage](#usage)
    - [CLI](#cli)
    - [Project Structure](#project-structure)
    - [Configuration](#configuration)
5. [Roadmap](#roadmap)
6. [Contributing](#contributing)
7. [Contact](#contact)

---

## **About the Project**

**GDBASE** is a database management solution developed in Go, designed to be **modular, scalable, and automatic**. It allows zero-configuration by default, but supports advanced customizations via configuration files. It manages local databases, Docker, and multiple databases simultaneously, making it ideal for distributed systems.

---

## **Features**

‚ú® **Dynamic and automatic configuration**

- Randomly generated passwords stored in the keyring.
- Automatically adjusts for occupied ports.

üóÑÔ∏è **Multi-DB support**

- Redis, RabbitMQ, MongoDB, PostgreSQL, and SQLite ready to use.

üèóÔ∏è **Modular architecture**

- Models follow the `Model ‚Üí Repo ‚Üí Service` pattern.
- Ensures modularity and organization.

üîê **SSH tunnel for external databases**

- `gdbase ssh tunnel` securely connects to remote databases via SSH.

‚öôÔ∏è **Docker orchestration**

- Automatic container generation for portability and easy deployment.

üì° **Monitoring and events**

- Event bus for internal action tracking.

---

## **Installation**

Requirements:

- Go 1.19+
- Docker (for containerized databases)

Clone the repository and build:

```sh
# Clone the repository
git clone https://github.com/rafa-mori/gdbase.git
cd gdbase
go build -o gdbase .
```

---

## **Usage**

### CLI

Start the main server:

```sh
./gdbase start
```

See all available commands:

```sh
./gdbase --help
```

**Main commands:**

| Command      | Function                                             |
|--------------|-----------------------------------------------------|
| `start`      | Initializes `gdbase` and sets up all services       |
| `status`     | Shows status of active databases                    |
| `config`     | Creates a configuration file for customization      |
| `ssh tunnel` | Creates a secure tunnel for external DBs via SSH    |
| `docker`     | Manages Docker containers for databases             |

### Project Structure

The core implementation follows a clear and modular architecture:

```plaintext
./
‚îú‚îÄ‚îÄ cmd
‚îÇ   ‚îú‚îÄ‚îÄ cli
‚îÇ   ‚îú‚îÄ‚îÄ gen_models.go
‚îÇ   ‚îú‚îÄ‚îÄ models.go
‚îÇ   ‚îú‚îÄ‚îÄ main.go
‚îÇ   ‚îú‚îÄ‚îÄ usage.go
‚îÇ   ‚îî‚îÄ‚îÄ wrpr.go
‚îú‚îÄ‚îÄ docs
‚îÇ   ‚îî‚îÄ‚îÄ assets
‚îú‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ go.sum
‚îú‚îÄ‚îÄ internal
‚îÇ   ‚îú‚îÄ‚îÄ events
‚îÇ   ‚îú‚îÄ‚îÄ models
‚îÇ   ‚îî‚îÄ‚îÄ services
‚îú‚îÄ‚îÄ tests
‚îî‚îÄ‚îÄ version
```

---

### Configuration

GDBASE can run without any initial configuration, but supports customization via YAML/JSON files. By default, everything is generated automatically on first use.

Example configuration:

```yaml
postgres:
  host: localhost
  port: 5432
  user: gdbase
  password: secure
redis:
  host: localhost
  port: 6379
```

---

## **Roadmap**

- [x] Dynamic and automatic configuration
- [x] Multi-DB support (Redis, RabbitMQ, MongoDB, PostgreSQL, SQLite)
- [x] Integrated SSH tunnel
- [x] Docker orchestration
- [ ] Plugins for new databases
- [ ] Web dashboard for monitoring

---

## **Contributing**

Contributions are welcome! Feel free to open issues or submit pull requests. See the [Contribution Guide](docs/CONTRIBUTING.md) for more details.

---

## **Contact**

üíå **Developer**:  
[Rafael Mori](mailto:faelmori@gmail.com)  
üíº [Follow me on GitHub](https://github.com/rafa-mori)  
I'm open to collaborations and new ideas. If you found the project interesting, get in touch!

---

**Made with care by the Mori family!** ‚ù§Ô∏è

/// api.go ///
package gdbase

import (
	. "github.com/rafa-mori/gdbase/internal/interfaces"
	t "github.com/rafa-mori/gdbase/internal/types"

	l "github.com/rafa-mori/logz"
)

type PropertyValBase[T any] interface{ IPropertyValBase[T] }
type Property[T any] interface{ IProperty[T] }

func NewProperty[T any](name string, v *T, withMetrics bool, cb func(any) (bool, error)) IProperty[T] {
	return t.NewProperty(name, v, withMetrics, cb)
}

type Channel[T any] interface{ IChannelCtl[T] }
type ChannelBase[T any] interface{ IChannelBase[T] }

func NewChannel[T any](name string, logger l.Logger) IChannelCtl[T] {
	return t.NewChannelCtl[T](name, logger)
}
func NewChannelCtlWithProperty[T any, P IProperty[T]](name string, buffers *int, property P, withMetrics bool, logger l.Logger) IChannelCtl[T] {
	return t.NewChannelCtlWithProperty[T, P](name, buffers, property, withMetrics, logger)
}
func NewChannelBase[T any](name string, buffers int, logger l.Logger) IChannelBase[T] {
	return t.NewChannelBase[T](name, buffers, logger)
}

type Validation[T any] interface{ IValidation[T] }

func NewValidation[T any](name string, v *T, withMetrics bool, cb func(any) (bool, error)) IValidation[T] {
	return t.NewValidation[T]()
}

type ValidationFunc[T any] interface{ IValidationFunc[T] }

func NewValidationFunc[T any](priority int, f func(value *T, args ...any) IValidationResult) IValidationFunc[T] {
	return t.NewValidationFunc[T](priority, f)
}

type ValidationResult interface{ IValidationResult }

func NewValidationResult(isValid bool, message string, metadata map[string]any, err error) IValidationResult {
	return t.NewValidationResult(isValid, message, metadata, err)
}

type Environment interface{ IEnvironment }

func NewEnvironment(envFile string, isConfidential bool, logger l.Logger) (IEnvironment, error) {
	return t.NewEnvironment(envFile, isConfidential, logger)
}

type Mapper[T any] interface{ IMapper[T] }

func NewMapper[T any](object *T, filePath string) IMapper[T] {
	return t.NewMapper[T](object, filePath)
}

type Mutexes interface{ IMutexes }

func NewMutexes() IMutexes { return t.NewMutexes() }

func NewMutexesType() Mutexes { return t.NewMutexesType() }

type Reference interface{ IReference }

func NewReference(name string) IReference { return t.NewReference(name) }

type SignalManager[T chan string] interface{ ISignalManager[T] }

func NewSignalManager[T chan string](signalChan T, logger l.Logger) ISignalManager[T] {
	return t.NewSignalManager[T](signalChan, logger)
}

/// cmd/cli/cmds_ssh.go ///
package cli

import (
	"log"
	"os/exec"
	"strings"

	"github.com/rafa-mori/gdbase/utils"
	"github.com/spf13/cobra"
)

// SshCmdsList retorna uma lista de comandos Cobra relacionados a SSH.
// Retorna um slice de ponteiros para comandos Cobra.
func SshCmds() *cobra.Command {
	rootCmd := &cobra.Command{
		Use:     "ssh",
		Aliases: []string{"s", "ss"},
		Short:   "Configura os utilit√°rios SSH do sistema",
		Long:    "Configura os utilit√°rios SSH do sistema",
	}

	rootCmd.AddCommand(sshTunnelCmd())
	rootCmd.AddCommand(sshTunnelServiceCmd())

	return rootCmd
}

// sshTunnelCmd cria um comando Cobra para configurar um t√∫nel SSH.
// Retorna um ponteiro para o comando Cobra configurado.
func sshTunnelCmd() *cobra.Command {
	var sshUser, sshCert, sshPassword, sshAddress, sshPort string
	var tunnels []string
	var background bool

	rootCmd := &cobra.Command{
		Use:     "tunnel",
		Aliases: []string{"tun", "t"},
		Short:   "Configura um t√∫nel SSH",
		RunE: func(cmd *cobra.Command, args []string) error {
			if background {
				sshCmdRun := exec.Command("kbx", "u", "s", "tunnel-service-background", "--sshUser", sshUser, "--sshCert", sshCert, "--sshPassword", sshPassword, "--sshAddress", sshAddress, "--sshPort", sshPort, "--tunnels", strings.Join(tunnels, ","))
				sshCmdRunErr := sshCmdRun.Start()
				if sshCmdRunErr != nil {
					log.Println("Erro ao iniciar o servi√ßo de t√∫nel SSH:", sshCmdRunErr)
					return nil
				}
				//processReleaseErr := sshCmdRun.Process.Release()
				//if processReleaseErr != nil {
				//	log.Println("Erro ao liberar o processo do servi√ßo de t√∫nel SSH:", processReleaseErr)
				//	return nil
				//}
				log.Println("Servi√ßo de t√∫nel SSH iniciado em segundo plano")
				return nil
			}

			return utils.SshTunnel(sshUser, sshCert, sshPassword, sshAddress, sshPort, tunnels...)
		},
	}

	rootCmd.Flags().BoolVarP(&background, "background", "b", false, "Executar em segundo plano")
	rootCmd.Flags().StringVarP(&sshUser, "login", "l", "", "Usu√°rio SSH")
	rootCmd.Flags().StringVarP(&sshCert, "cert", "i", "", "Certificado SSH")
	rootCmd.Flags().StringVarP(&sshPassword, "secret", "s", "", "Senha SSH")
	rootCmd.Flags().StringVarP(&sshAddress, "host", "t", "", "Endere√ßo SSH")
	rootCmd.Flags().StringVarP(&sshPort, "port", "p", "", "Porta SSH")
	rootCmd.Flags().StringSliceVarP(&tunnels, "tunnels", "L", []string{}, "T√∫neis")

	return rootCmd
}

// sshTunnelServiceCmd cria um comando Cobra para configurar um servi√ßo de t√∫nel SSH em segundo plano.
// Retorna um ponteiro para o comando Cobra configurado.
func sshTunnelServiceCmd() *cobra.Command {
	var sshUser, sshCert, sshPassword, sshAddress, sshPort string
	var tunnels []string
	rootCmd := &cobra.Command{
		Use:    "tunnel-service-background",
		Hidden: true,
		Run: func(cmd *cobra.Command, args []string) {
			_ = utils.SshTunnel(sshUser, sshCert, sshPassword, sshAddress, sshPort, tunnels...)
		},
	}
	rootCmd.Flags().StringVarP(&sshUser, "sshUser", "l", "", "Usu√°rio SSH")
	rootCmd.Flags().StringVarP(&sshCert, "sshCert", "i", "", "Certificado SSH")
	rootCmd.Flags().StringVarP(&sshPassword, "sshPassword", "s", "", "Senha SSH")
	rootCmd.Flags().StringVarP(&sshAddress, "sshAddress", "t", "", "Endere√ßo SSH")
	rootCmd.Flags().StringVarP(&sshPort, "sshPort", "p", "", "Porta SSH")
	rootCmd.Flags().StringSliceVarP(&tunnels, "tunnels", "L", []string{}, "T√∫neis")
	return rootCmd
}

/// cmd/cli/cmds_utils.go ///
package cli

import (
	"github.com/rafa-mori/gdbase/utils/helpers"
	"github.com/spf13/cobra"
)

// SshCmdsList retorna uma lista de comandos Cobra relacionados a SSH.
// Retorna um slice de ponteiros para comandos Cobra.
func UtilsCmds() *cobra.Command {
	uCmd := &cobra.Command{
		Use:     "utils",
		Aliases: []string{"u", "util"},
		Short:   "Configura os utilit√°rios do sistema",
		Long:    "Configura os utilit√°rios do sistema",
	}
	uCmd.AddCommand(installUtilsCmd())
	uCmd.AddCommand(uninstallUtilsCmd())
	return uCmd
}

// sshTunnelServiceCmd cria um comando Cobra para configurar um servi√ßo de t√∫nel SSH em segundo plano.
// Retorna um ponteiro para o comando Cobra configurado.
func installUtilsCmd() *cobra.Command {
	rootCmd := &cobra.Command{
		Use:  "install",
		Long: "Install the bash helpers.",
		Run: func(cmd *cobra.Command, args []string) {
			helpers.InstallBashHelpers()
		},
	}
	return rootCmd
}

// sshTunnelCmd cria um comando Cobra para configurar um t√∫nel SSH.
// Retorna um ponteiro para o comando Cobra configurado.
func uninstallUtilsCmd() *cobra.Command {
	rootCmd := &cobra.Command{
		Use:  "uninstall",
		Long: "Uninstall the bash helpers.",
		Run: func(cmd *cobra.Command, args []string) {
			helpers.UninstallBashHelpers()
		},
	}

	return rootCmd
}

/// cmd/cli/common.go ///
package cli

import (
	"math/rand"
	"os"
	"strings"
)

var banners = []string{
	`
  ______  _______  _______                             
 /      \|       \|       \                            
|  ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\ ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\ ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\ ______   _______  ______  
| ‚ñì‚ñì __\‚ñì‚ñì ‚ñì‚ñì  | ‚ñì‚ñì ‚ñì‚ñì__/ ‚ñì‚ñì|      \ /       \/      \ 
| ‚ñì‚ñì|    \ ‚ñì‚ñì  | ‚ñì‚ñì ‚ñì‚ñì    ‚ñì‚ñì \‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\  ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì  ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\
| ‚ñì‚ñì \‚ñì‚ñì‚ñì‚ñì ‚ñì‚ñì  | ‚ñì‚ñì ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\/      ‚ñì‚ñì\‚ñì‚ñì    \| ‚ñì‚ñì    ‚ñì‚ñì
| ‚ñì‚ñì__| ‚ñì‚ñì ‚ñì‚ñì__/ ‚ñì‚ñì ‚ñì‚ñì__/ ‚ñì‚ñì  ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì_\‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\ ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì
 \‚ñì‚ñì    ‚ñì‚ñì ‚ñì‚ñì    ‚ñì‚ñì ‚ñì‚ñì    ‚ñì‚ñì\‚ñì‚ñì    ‚ñì‚ñì       ‚ñì‚ñì\‚ñì‚ñì     \
  \‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì \‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì \‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì  \‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì\‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì  \‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì`,
}

const Version = "1.0.0"

func GetDescriptions(descriptionArg []string, _ bool) map[string]string {
	var description, banner string
	if descriptionArg != nil {
		if strings.Contains(strings.Join(os.Args[0:], ""), "-h") {
			description = descriptionArg[0]
		} else {
			description = descriptionArg[1]
		}
	} else {
		description = ""
	}
	bannerRandLen := len(banners)
	bannerRandIndex := rand.Intn(bannerRandLen)
	banner = banners[bannerRandIndex]
	return map[string]string{"banner": banner, "description": description}
}

/// cmd/cli/configs.go ///
package cli

import (
	"fmt"
	"github.com/spf13/cobra"
	"github.com/spf13/viper"
)

func configCmd() *cobra.Command {
	var configFile string
	short := "Edit configuration"
	long := "Edit configuration file interactively"

	cmd := &cobra.Command{
		Use:         "config",
		Short:       short,
		Long:        long,
		Annotations: GetDescriptions([]string{short, long}, false),
		RunE: func(cmd *cobra.Command, args []string) error {
			config, err := ReadConfig(configFile)
			if err != nil {
				return err
			}

			updatedConfig, err := EditConfig(config)
			if err != nil {
				return err
			}

			if err := SaveConfig(configFile, updatedConfig); err != nil {
				return err
			}

			fmt.Println("Configuration updated successfully")
			return nil
		},
	}

	cmd.Flags().StringVar(&configFile, "config-file", "config.yaml", "Path to configuration file")
	return cmd
}

func ReadConfig(configFile string) (map[string]interface{}, error) {
	viper.SetConfigFile(configFile)
	if err := viper.ReadInConfig(); err != nil {
		return nil, fmt.Errorf("error reading config file: %v", err)
	}

	var config map[string]interface{}
	if err := viper.Unmarshal(&config); err != nil {
		return nil, fmt.Errorf("error unmarshalling config: %v", err)
	}

	return config, nil
}

func EditConfig(config map[string]interface{}) (map[string]interface{}, error) {
	// Definimos o T√≠tulo do formul√°rio
	//var title = "Editando Configura√ß√£o"
	//
	//// Aqui vamos criar um novo mapa de configura√ß√£o, que ser√° o mapa que ser√° retornado
	//var updatedConfig = make(map[string]string)
	//
	//// Aqui vamos criar as inst√¢ncias vazias das estruturas que comp√µem o formul√°rio
	//// FormFields e FormField
	//var formFields = x.FormFields{}
	//var formField = x.FormField{}
	//
	//// O FormConfig √© a estrutura que serve de funda√ß√£o para o formul√°rio.
	//
	//// Aqui vamos iterar sobre as chaves do mapa de configura√ß√£o, criando nas itera√ß√µes as estruturas
	//// FormConfig, FormFields e FormField, que s√£o as estruturas que representam todos os formul√°rios e campos
	//// que podem ser criados pelo xtui. Ap√≥s a cria√ß√£o das inst√¢ncias, vamos chamar a fun√ß√£o ShowForm, que √©
	//// respons√°vel por exibir o formul√°rio na tela e retornar os valores preenchidos pelo usu√°rio.
	//// As inst√¢ncias ser√£o criadas TODAS de uma v√™z. As estruturas permitem campos aninhados, ent√£o a cria√ß√£o
	//// de formul√°rios e campos √© feita de forma recursiva e uma s√≥ vez.

	return nil, fmt.Errorf("error reading config file: %v", "not implemented")

}

func SaveConfig(configFile string, config map[string]interface{}) error {
	for key, value := range config {
		viper.Set(key, value)
	}

	return viper.WriteConfigAs(configFile)
}

/// cmd/cli/database.go ///
package cli

import (
	"github.com/spf13/cobra"
)

func DatabaseCmd() *cobra.Command {
	var configFile string
	short := "Database management commands for GodoBase"
	long := "Database management commands for GodoBase"
	cmd := &cobra.Command{
		Use:   "database",
		Short: short,
		Long:  long,
		Run: func(cmd *cobra.Command, args []string) {
			err := cmd.Help()
			if err != nil {
				return
			}
		},
	}
	cmd.Flags().StringVar(&configFile, "config-file", "config.yaml", "Path to configuration file")

	cmd.AddCommand(startDatabaseCmd())

	cmd.AddCommand(stopDatabaseCmd())

	cmd.AddCommand(statusDatabaseCmd())

	return cmd
}

func startDatabaseCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "start",
		Short: "Start Database services",
		Long:  "Start Database services",
		Run: func(cmd *cobra.Command, args []string) {
			_ = cmd.Help()
		},
	}
	return cmd
}

func stopDatabaseCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "stop",
		Short: "Stop Docker",
		Long:  "Stop Docker service",
		Run: func(cmd *cobra.Command, args []string) {
			_ = cmd.Help()
		},
	}
	return cmd
}

func statusDatabaseCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "status",
		Short: "Status Docker",
		Long:  "Status Docker service",
		Run: func(cmd *cobra.Command, args []string) {
			_ = cmd.Help()
		},
	}
	return cmd
}

/// cmd/cli/docker.go ///
package cli

import (
	"fmt"

	"github.com/rafa-mori/gdbase/factory"
	s "github.com/rafa-mori/gdbase/internal/services"
	l "github.com/rafa-mori/logz"
	"github.com/spf13/cobra"
)

func DockerCmd() *cobra.Command {
	var configFile string
	short := "Docker management commands for GodoBase"
	long := "Docker management commands for GodoBase"
	cmd := &cobra.Command{
		Use:   "docker",
		Short: short,
		Long:  long,
		Run: func(cmd *cobra.Command, args []string) {
			err := cmd.Help()
			if err != nil {
				return
			}
		},
	}
	cmd.Flags().StringVar(&configFile, "config-file", "config.yaml", "Path to configuration file")

	cmd.AddCommand(startDockerCmd())

	cmd.AddCommand(stopDockerCmd())

	cmd.AddCommand(statusDockerCmd())

	return cmd
}

func startDockerCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "start",
		Short: "Start Docker",
		Long:  "Start Docker service",
		Run: func(cmd *cobra.Command, args []string) {
			dkr, dkrErr := factory.NewDockerService(nil, l.GetLogger("GodoBase"))
			if dkrErr != nil {
				fmt.Printf("Error starting Docker service: %v\n", dkrErr)
				return
			}
			dkrErr = dkr.Initialize()
			if dkrErr != nil {
				fmt.Printf("Error initializing Docker service: %v\n", dkrErr)
				return
			}
			dkrErr = s.SetupDatabaseServices(dkr, nil)
		},
	}
	return cmd
}

func stopDockerCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "stop",
		Short: "Stop Docker",
		Long:  "Stop Docker service",
		Run: func(cmd *cobra.Command, args []string) {
			//dkr, dkrErr := factory.NewDockerService(nil, l.GetLogger("GodoBase"))
			//if dkrErr != nil {
			//	fmt.Printf("Error stopping Docker service: %v\n", dkrErr)
			//	return
			//}
			//dkrErr = dkr
			//if dkrErr != nil {
			//	fmt.Printf("Error stopping Docker service: %v\n", dkrErr)
			//	return
			//}
			return
		},
	}
	return cmd
}

func statusDockerCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "status",
		Short: "Status Docker",
		Long:  "Status Docker service",
		Run: func(cmd *cobra.Command, args []string) {
			//dkr, dkrErr := factory.NewDockerService(nil, l.GetLogger("GodoBase"))
			//if dkrErr != nil {
			//	fmt.Printf("Error getting Docker status: %v\n", dkrErr)
			//	return
			//}
			//dkrErr = dkr.Status()
			//if dkrErr != nil {
			//	fmt.Printf("Error getting Docker status: %v\n", dkrErr)
			//	return
			//}
			_ = cmd.Help()
		},
	}
	return cmd
}

/// cmd/cli/serverdata_types.go ///
package cli

import (
	gl "github.com/rafa-mori/gdbase/logger"
)

type IWebSrvServerData interface {
	GetWebSrvServerData() (WebSrvProcessServer, error)
}
type WebSrvServerData struct {
	Ports      []string       `json:"ports"`
	PubAddress string         `json:"pubAddress"`
	AuthToken  string         `json:"authToken"`
	Uptime     string         `json:"uptime"`
	Processes  []WebSrvServer `json:"processes"`
}

func NewWebSrvServerData(ports []string, pubAddress, authToken, uptime string, processes []WebSrvServer) IWebSrvServerData {
	return &WebSrvServerData{
		Ports:      ports,
		PubAddress: pubAddress,
		AuthToken:  authToken,
		Uptime:     uptime,
		Processes:  processes,
	}
}

func (w *WebSrvServerData) GetWebSrvServerData() (WebSrvProcessServer, error) {
	if w.Ports == nil {
		gl.Log("error", "No ports found")
		return WebSrvProcessServer{}, nil
	}
	if w.PubAddress == "" {
		gl.Log("error", "No public address found")
		return WebSrvProcessServer{}, nil
	}
	if w.AuthToken == "" {
		gl.Log("error", "No auth token found")
		return WebSrvProcessServer{}, nil
	}
	if w.Uptime == "" {
		gl.Log("error", "No uptime found")
		return WebSrvProcessServer{}, nil
	}
	if w.Processes == nil {
		gl.Log("error", "No processes found")
		return WebSrvProcessServer{}, nil
	}
	return WebSrvProcessServer{}, nil
}

/// cmd/cli/webprocess_types.go ///
package cli

type IWebSrvProcessServer interface {
	GetPorts() []string
	GetPubAddress() string
	GetAuthToken() string
	GetUptime() string
	GetProcesses() []WebSrvServer
}
type WebSrvProcessServer struct {
	Ports      []string       `json:"ports"`
	PubAddress string         `json:"pubAddress"`
	AuthToken  string         `json:"authToken"`
	Uptime     string         `json:"uptime"`
	Processes  []WebSrvServer `json:"processes"`
}

func NewWebSrvProcessServer(ports []string, pubAddress, authToken, uptime string, processes []WebSrvServer) IWebSrvProcessServer {
	return WebSrvProcessServer{
		Ports:      ports,
		PubAddress: pubAddress,
		AuthToken:  authToken,
		Uptime:     uptime,
		Processes:  processes,
	}
}

func (w WebSrvProcessServer) GetPorts() []string           { return w.Ports }
func (w WebSrvProcessServer) GetPubAddress() string        { return w.PubAddress }
func (w WebSrvProcessServer) GetAuthToken() string         { return w.AuthToken }
func (w WebSrvProcessServer) GetUptime() string            { return w.Uptime }
func (w WebSrvProcessServer) GetProcesses() []WebSrvServer { return w.Processes }

/// cmd/cli/webserver_types.go ///
package cli

type IWebSrvServer interface {
	GetServerProcessData() ([]IWebSrvServer, error)
	GetServerData() (IWebSrvProcessServer, error)
	GetPorts() []string
	GetPubAddress() string
	GetUptime() string
	GetProcesses() []IWebSrvServer
}
type WebSrvServer struct {
	Pid         int    `json:"pid"`
	Port        string `json:"port"`
	IpVersion   string `json:"ipVersion"`
	BindAddress string `json:"bindAddress"`
	SourcePath  string `json:"sourcePath"`
	Uptime      string `json:"uptime"`
	Processes   []IWebSrvServer
	Ports       []string
}

func NewWebSrvServer(pid int, port, ipVersion, bindAddress, sourcePath, uptime string, processes []IWebSrvServer, ports []string) IWebSrvServer {
	return &WebSrvServer{
		Pid:         pid,
		Port:        port,
		IpVersion:   ipVersion,
		BindAddress: bindAddress,
		SourcePath:  sourcePath,
		Uptime:      uptime,
		Processes:   processes,
		Ports:       ports,
	}
}

func (wss *WebSrvServer) GetServerProcessData() ([]IWebSrvServer, error) {
	return []IWebSrvServer{}, nil
}
func (wss *WebSrvServer) GetServerData() (IWebSrvProcessServer, error) {
	return WebSrvProcessServer{}, nil
}
func (wss *WebSrvServer) GetPorts() []string            { return wss.Ports }
func (wss *WebSrvServer) GetPubAddress() string         { return wss.BindAddress }
func (wss *WebSrvServer) GetUptime() string             { return wss.Uptime }
func (wss *WebSrvServer) GetProcesses() []IWebSrvServer { return wss.Processes }

/// cmd/cli/websrvproc_types.go ///
package cli

type IWebSrvServerProcessData interface {
	GetWevSrvServerProcessData() ([]WebSrvServer, error)
	GetWebSrvServerData() (WebSrvProcessServer, error)
}
type WebSrvServerProcessData struct{}

func NewWebSrvServerProcessData() IWebSrvServerProcessData { return &WebSrvServerProcessData{} }

func (wss *WebSrvServerProcessData) GetWevSrvServerProcessData() ([]WebSrvServer, error) {
	return []WebSrvServer{}, nil
}
func (wss *WebSrvServerProcessData) GetWebSrvServerData() (WebSrvProcessServer, error) {
	return WebSrvProcessServer{}, nil
}

/// cmd/cli/websrvstatus_types.go ///
package cli

import (
	"fmt"

	gl "github.com/rafa-mori/gdbase/logger"
)

type IWebSrvServerStatus interface {
	FollowWebSrvServerStatus(interval int, follow bool, logs bool) error
	NewWebSrvServerProcessData() ([]IWebSrvProcessServer, error)
}
type WebSrvServerStatus struct {
	Interval int
	Follow   bool
	Logs     bool
}

func (wss *WebSrvServerProcessData) FollowWebSrvServerStatus(interval int, follow bool, logs bool) error {
	if interval < 1 {
		gl.Log("error", "Interval must be greater than 0")
		return nil
	}

	process := NewWebSrvServerProcessData()
	procs, err := process.GetWevSrvServerProcessData()
	if err != nil {
		return err
	}
	var processes []IWebSrvServerData
	for _, proc := range procs {
		srvData, srvDataErr := proc.GetServerData()
		if srvDataErr != nil {
			return srvDataErr
		}
		prc := NewWebSrvServerData(proc.Ports, proc.GetPubAddress(), srvData.GetAuthToken(), srvData.GetUptime(), srvData.GetProcesses())
		processes = append(processes, prc)
	}

	if follow {
		for _, prc := range processes {
			if logs {
				prcData, prcDataErr := prc.GetWebSrvServerData()
				if prcDataErr != nil {
					return prcDataErr
				}
				gl.Log("info", fmt.Sprintf("Web Server Process Data - Ports: %v, Pub Address: %v, Auth Token: %v, Uptime: %v, Processes: %v", prcData.Ports, prcData.PubAddress, prcData.AuthToken, prcData.Uptime, prcData.Processes))
			}
		}
	}

	return nil
}
func (wss *WebSrvServerProcessData) NewWebSrvServerProcessData() ([]IWebSrvProcessServer, error) {
	return []IWebSrvProcessServer{}, nil
}

/// cmd/gen_models.go ///
package main

import (
	"database/sql"
	"fmt"
	"io"
	"os"
	"strings"
	"text/template"

	is "github.com/rafa-mori/gdbase/internal/services"
	gl "github.com/rafa-mori/gdbase/logger"
	t "github.com/rafa-mori/gdbase/types"
	l "github.com/rafa-mori/logz"
	_ "gorm.io/driver/mysql"
	_ "gorm.io/driver/postgres"
	_ "gorm.io/driver/sqlite"
	"gorm.io/gorm"
)

type Column struct {
	Name string
	Type string
}

// GenUser gera os modelos de usu√°rio a partir do banco de dados
func Main() {
	// Inicializa o banco de dados
	_, dbSql, err := initDB()
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao inicializar o banco de dados: %v", err))
		return
	}
	defer dbSql.Close()

	// Consulta para obter estrutura das tabelas
	rows, err := dbSql.Query(`
        SELECT table_name, column_name, data_type
        FROM information_schema.columns
        WHERE table_schema = 'public';
    `)

	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao executar consulta: %v", err))
		return
	}

	defer rows.Close()

	tables := make(map[string][]Column)

	for rows.Next() {
		var tableName, columnName, dataType string
		if err := rows.Scan(&tableName, &columnName, &dataType); err != nil {
			gl.Log("fatal", fmt.Sprintf("Erro ao escanear linha: %v", err))
			return
		}
		tables[tableName] = append(tables[tableName], Column{Name: titleCase(columnName), Type: mapSQLType(dataType)})
	}

	// Gerar c√≥digo Go a partir da estrutura
	generateGoModels(tables)
}

// Fun√ß√£o para colocar t√≠tulo no nome dos campos
func titleCase(s string) string {
	if len(s) == 0 {
		return s
	}
	return string(s[0]-32) + s[1:]
}

func initDB() (*gorm.DB, *sql.DB, error) {
	dbConfig := t.NewDBConfigWithFilePath("GoBE-DB", "/home/user/.kubex/gdbase/config/config.json")
	if dbConfig == nil {
		gl.Log("fatal", "Erro ao carregar configura√ß√£o do banco de dados")
		return nil, nil, fmt.Errorf("erro ao carregar configura√ß√£o do banco de dados")
	}
	// Inicializa o banco de dados
	// Cria√ß√£o do servi√ßo de banco de dados
	dbService, err := is.NewDatabaseService(dbConfig, l.GetLogger("gen_models"))
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao criar servi√ßo de banco de dados: %v", err))
		return nil, nil, err
	}
	// Inicializa√ß√£o do servi√ßo de banco de dados
	err = dbService.Initialize()
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao inicializar servi√ßo de banco de dados: %v", err))
		return nil, nil, err
	}
	// Configura√ß√£o do banco de dados
	db, err := dbService.GetDB()
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao obter banco de dados: %v", err))
		return nil, nil, err
	}
	// Conex√£o com o banco de dados
	dbSql, err := db.DB()
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao obter conex√£o com o banco de dados: %v", err))
		return nil, nil, err
	}
	//defer dbSql.Close()

	if err := dbSql.Ping(); err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao conectar ao banco de dados: %v", err))
		return nil, nil, err
	}
	fmt.Println("Conex√£o com o banco de dados estabelecida com sucesso!")

	return db, dbSql, nil
}

// Gera structs Go dinamicamente
func generateGoModels(tables map[string][]Column) {
	modelTemplate := `package main

{{range $table, $columns := .}}
type {{$table | title}} struct {
	{{range $columns}}
		{{.Name}} {{.Type}} ` + "`" + `json:"{{.Name}}" yaml:"{{.Name}}" xml:"{{.Name}}"` + "`" + `{{end}}
}
{{end}}
`

	file, err := os.Create("models.go")
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao criar arquivo: %v", err))
		return
	}
	defer file.Close()

	tmpl, err := template.New("models").
		Funcs(template.FuncMap{"title": titleCase}).
		Parse(modelTemplate)
	// Option("missingkey=zero") para evitar erro de chave ausente
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao criar template: %v", err))
		return
	}

	writer := io.Writer(file)
	if err = tmpl.Execute(writer, tables); err != nil {
		gl.Log("fatal", fmt.Sprintf("Erro ao executar template: %v", err))
		return
	}
	file.Sync()
	fmt.Println("Arquivo models.go gerado com sucesso!")
}

// Mapeia tipos SQL para Go
func mapSQLType(sqlType string) string {
	switch strings.ToLower(sqlType) {
	case "integer":
		return "int"
	case "numeric":
		return "float64"
	case "text", "varchar", "character varying":
		return "string"
	case "timestamp", "timestamp without time zone":
		return "time.Time"
	case "boolean":
		return "bool"
	default:
		return "any"
	}
}

/// cmd/main.go ///
// go:generate go run github.com/rafa-mori/gdbase/internalmodels/user GenUser
package main

import (
	"fmt"

	gl "github.com/rafa-mori/gdbase/logger"
)

func main() {
	if err := RegX().Execute(); err != nil {
		gl.Log("error", fmt.Sprintf("Error: %v", err))
	}
}

/// cmd/models.go ///
package main

import "time"

type Audit_events struct {
	Entity_type string    `json:"Entity_type" yaml:"Entity_type" xml:"Entity_type"`
	User_id     string    `json:"User_id" yaml:"User_id" xml:"User_id"`
	Changes     any       `json:"Changes" yaml:"Changes" xml:"Changes"`
	Action      string    `json:"Action" yaml:"Action" xml:"Action"`
	Id          any       `json:"Id" yaml:"Id" xml:"Id"`
	Entity_id   any       `json:"Entity_id" yaml:"Entity_id" xml:"Entity_id"`
	Created_at  time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
}

type Customers struct {
	City               string    `json:"City" yaml:"City" xml:"City"`
	Phone              string    `json:"Phone" yaml:"Phone" xml:"Phone"`
	Code               string    `json:"Code" yaml:"Code" xml:"Code"`
	Created_at         time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Id                 any       `json:"Id" yaml:"Id" xml:"Id"`
	Last_sync_at       time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
	Name               string    `json:"Name" yaml:"Name" xml:"Name"`
	Email              string    `json:"Email" yaml:"Email" xml:"Email"`
	Address            string    `json:"Address" yaml:"Address" xml:"Address"`
	Last_purchase_date time.Time `json:"Last_purchase_date" yaml:"Last_purchase_date" xml:"Last_purchase_date"`
	Is_active          bool      `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
	Document           string    `json:"Document" yaml:"Document" xml:"Document"`
	Updated_at         time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	Payment_terms      string    `json:"Payment_terms" yaml:"Payment_terms" xml:"Payment_terms"`
	State              string    `json:"State" yaml:"State" xml:"State"`
	Postal_code        string    `json:"Postal_code" yaml:"Postal_code" xml:"Postal_code"`
	External_id        string    `json:"External_id" yaml:"External_id" xml:"External_id"`
	Country            string    `json:"Country" yaml:"Country" xml:"Country"`
	Credit_limit       float64   `json:"Credit_limit" yaml:"Credit_limit" xml:"Credit_limit"`
}

type Inventory struct {
	Expiration_date time.Time `json:"Expiration_date" yaml:"Expiration_date" xml:"Expiration_date"`
	Lot_control     string    `json:"Lot_control" yaml:"Lot_control" xml:"Lot_control"`
	Location_code   string    `json:"Location_code" yaml:"Location_code" xml:"Location_code"`
	Product_id      any       `json:"Product_id" yaml:"Product_id" xml:"Product_id"`
	Last_sync_at    time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
	Created_at      time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Minimum_level   float64   `json:"Minimum_level" yaml:"Minimum_level" xml:"Minimum_level"`
	Last_count_date time.Time `json:"Last_count_date" yaml:"Last_count_date" xml:"Last_count_date"`
	Maximum_level   float64   `json:"Maximum_level" yaml:"Maximum_level" xml:"Maximum_level"`
	Is_active       bool      `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
	Quantity        float64   `json:"Quantity" yaml:"Quantity" xml:"Quantity"`
	Id              any       `json:"Id" yaml:"Id" xml:"Id"`
	Warehouse_id    any       `json:"Warehouse_id" yaml:"Warehouse_id" xml:"Warehouse_id"`
	Updated_at      time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	Status          any       `json:"Status" yaml:"Status" xml:"Status"`
	Reorder_point   float64   `json:"Reorder_point" yaml:"Reorder_point" xml:"Reorder_point"`
}

type Inventory_movements struct {
	Quantity           float64   `json:"Quantity" yaml:"Quantity" xml:"Quantity"`
	Movement_type      string    `json:"Movement_type" yaml:"Movement_type" xml:"Movement_type"`
	Previous_quantity  float64   `json:"Previous_quantity" yaml:"Previous_quantity" xml:"Previous_quantity"`
	Reference_document string    `json:"Reference_document" yaml:"Reference_document" xml:"Reference_document"`
	Inventory_id       any       `json:"Inventory_id" yaml:"Inventory_id" xml:"Inventory_id"`
	Id                 any       `json:"Id" yaml:"Id" xml:"Id"`
	Product_id         any       `json:"Product_id" yaml:"Product_id" xml:"Product_id"`
	External_id        string    `json:"External_id" yaml:"External_id" xml:"External_id"`
	Created_by         string    `json:"Created_by" yaml:"Created_by" xml:"Created_by"`
	Reason             string    `json:"Reason" yaml:"Reason" xml:"Reason"`
	Created_at         time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Warehouse_id       any       `json:"Warehouse_id" yaml:"Warehouse_id" xml:"Warehouse_id"`
	Last_sync_at       time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
}

type Order_items struct {
	Suggestion_reason string    `json:"Suggestion_reason" yaml:"Suggestion_reason" xml:"Suggestion_reason"`
	Quantity          float64   `json:"Quantity" yaml:"Quantity" xml:"Quantity"`
	Last_sync_at      time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
	Is_suggested      bool      `json:"Is_suggested" yaml:"Is_suggested" xml:"Is_suggested"`
	Updated_at        time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	External_id       string    `json:"External_id" yaml:"External_id" xml:"External_id"`
	Order_id          any       `json:"Order_id" yaml:"Order_id" xml:"Order_id"`
	Created_at        time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Discount          float64   `json:"Discount" yaml:"Discount" xml:"Discount"`
	Product_id        any       `json:"Product_id" yaml:"Product_id" xml:"Product_id"`
	Id                any       `json:"Id" yaml:"Id" xml:"Id"`
	Unit_price        float64   `json:"Unit_price" yaml:"Unit_price" xml:"Unit_price"`
	Total             float64   `json:"Total" yaml:"Total" xml:"Total"`
}

type Orders struct {
	Prediction_id              any       `json:"Prediction_id" yaml:"Prediction_id" xml:"Prediction_id"`
	Id                         any       `json:"Id" yaml:"Id" xml:"Id"`
	Shipping_amount            float64   `json:"Shipping_amount" yaml:"Shipping_amount" xml:"Shipping_amount"`
	Priority                   int       `json:"Priority" yaml:"Priority" xml:"Priority"`
	Customer_id                any       `json:"Customer_id" yaml:"Customer_id" xml:"Customer_id"`
	Shipping_address           string    `json:"Shipping_address" yaml:"Shipping_address" xml:"Shipping_address"`
	Estimated_delivery_date    time.Time `json:"Estimated_delivery_date" yaml:"Estimated_delivery_date" xml:"Estimated_delivery_date"`
	Order_number               string    `json:"Order_number" yaml:"Order_number" xml:"Order_number"`
	Discount_amount            float64   `json:"Discount_amount" yaml:"Discount_amount" xml:"Discount_amount"`
	Actual_delivery_date       time.Time `json:"Actual_delivery_date" yaml:"Actual_delivery_date" xml:"Actual_delivery_date"`
	Order_date                 time.Time `json:"Order_date" yaml:"Order_date" xml:"Order_date"`
	Total_amount               float64   `json:"Total_amount" yaml:"Total_amount" xml:"Total_amount"`
	Status                     any       `json:"Status" yaml:"Status" xml:"Status"`
	Last_sync_at               time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
	Tax_amount                 float64   `json:"Tax_amount" yaml:"Tax_amount" xml:"Tax_amount"`
	Expected_margin            float64   `json:"Expected_margin" yaml:"Expected_margin" xml:"Expected_margin"`
	Created_at                 time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Updated_at                 time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	Is_automatically_generated bool      `json:"Is_automatically_generated" yaml:"Is_automatically_generated" xml:"Is_automatically_generated"`
	Payment_method             string    `json:"Payment_method" yaml:"Payment_method" xml:"Payment_method"`
	Notes                      string    `json:"Notes" yaml:"Notes" xml:"Notes"`
	External_id                string    `json:"External_id" yaml:"External_id" xml:"External_id"`
	Payment_status             any       `json:"Payment_status" yaml:"Payment_status" xml:"Payment_status"`
	Final_amount               float64   `json:"Final_amount" yaml:"Final_amount" xml:"Final_amount"`
}

type Prediction_daily_data struct {
	Prediction_id    any       `json:"Prediction_id" yaml:"Prediction_id" xml:"Prediction_id"`
	Predicted_stock  float64   `json:"Predicted_stock" yaml:"Predicted_stock" xml:"Predicted_stock"`
	Created_at       time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Lower_bound      float64   `json:"Lower_bound" yaml:"Lower_bound" xml:"Lower_bound"`
	Predicted_demand float64   `json:"Predicted_demand" yaml:"Predicted_demand" xml:"Predicted_demand"`
	Id               any       `json:"Id" yaml:"Id" xml:"Id"`
	Day_date         any       `json:"Day_date" yaml:"Day_date" xml:"Day_date"`
	Upper_bound      float64   `json:"Upper_bound" yaml:"Upper_bound" xml:"Upper_bound"`
}

type Products struct {
	Is_active           bool      `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
	Width               float64   `json:"Width" yaml:"Width" xml:"Width"`
	Max_stock_threshold int       `json:"Max_stock_threshold" yaml:"Max_stock_threshold" xml:"Max_stock_threshold"`
	Name                string    `json:"Name" yaml:"Name" xml:"Name"`
	Search_vector       any       `json:"Search_vector" yaml:"Search_vector" xml:"Search_vector"`
	Shelf_life_days     int       `json:"Shelf_life_days" yaml:"Shelf_life_days" xml:"Shelf_life_days"`
	Min_stock_threshold int       `json:"Min_stock_threshold" yaml:"Min_stock_threshold" xml:"Min_stock_threshold"`
	Weight              float64   `json:"Weight" yaml:"Weight" xml:"Weight"`
	Updated_at          time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	Length              float64   `json:"Length" yaml:"Length" xml:"Length"`
	Cost                float64   `json:"Cost" yaml:"Cost" xml:"Cost"`
	Last_sync_at        time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
	External_id         string    `json:"External_id" yaml:"External_id" xml:"External_id"`
	Created_at          time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Barcode             string    `json:"Barcode" yaml:"Barcode" xml:"Barcode"`
	Lead_time_days      int       `json:"Lead_time_days" yaml:"Lead_time_days" xml:"Lead_time_days"`
	Id                  any       `json:"Id" yaml:"Id" xml:"Id"`
	Reorder_point       int       `json:"Reorder_point" yaml:"Reorder_point" xml:"Reorder_point"`
	Sku                 string    `json:"Sku" yaml:"Sku" xml:"Sku"`
	Height              float64   `json:"Height" yaml:"Height" xml:"Height"`
	Price               float64   `json:"Price" yaml:"Price" xml:"Price"`
	Category            string    `json:"Category" yaml:"Category" xml:"Category"`
	Manufacturer        string    `json:"Manufacturer" yaml:"Manufacturer" xml:"Manufacturer"`
	Description         string    `json:"Description" yaml:"Description" xml:"Description"`
}

type Stock_predictions struct {
	Prediction_date            time.Time `json:"Prediction_date" yaml:"Prediction_date" xml:"Prediction_date"`
	Confidence_level           any       `json:"Confidence_level" yaml:"Confidence_level" xml:"Confidence_level"`
	Warehouse_id               any       `json:"Warehouse_id" yaml:"Warehouse_id" xml:"Warehouse_id"`
	Id                         any       `json:"Id" yaml:"Id" xml:"Id"`
	Current_level              float64   `json:"Current_level" yaml:"Current_level" xml:"Current_level"`
	Days_until_stockout        int       `json:"Days_until_stockout" yaml:"Days_until_stockout" xml:"Days_until_stockout"`
	Suggested_reorder_quantity float64   `json:"Suggested_reorder_quantity" yaml:"Suggested_reorder_quantity" xml:"Suggested_reorder_quantity"`
	Predicted_level            float64   `json:"Predicted_level" yaml:"Predicted_level" xml:"Predicted_level"`
	Updated_at                 time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	Prediction_horizon_days    int       `json:"Prediction_horizon_days" yaml:"Prediction_horizon_days" xml:"Prediction_horizon_days"`
	Product_id                 any       `json:"Product_id" yaml:"Product_id" xml:"Product_id"`
	Created_at                 time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
}

type Sync_config struct {
	Is_active             bool      `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
	Entity_name           string    `json:"Entity_name" yaml:"Entity_name" xml:"Entity_name"`
	Created_at            time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Last_sync_timestamp   time.Time `json:"Last_sync_timestamp" yaml:"Last_sync_timestamp" xml:"Last_sync_timestamp"`
	Id                    int       `json:"Id" yaml:"Id" xml:"Id"`
	Sync_interval_minutes int       `json:"Sync_interval_minutes" yaml:"Sync_interval_minutes" xml:"Sync_interval_minutes"`
	Error_count           int       `json:"Error_count" yaml:"Error_count" xml:"Error_count"`
	Updated_at            time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
}

type Sync_logs struct {
	Records_processed int       `json:"Records_processed" yaml:"Records_processed" xml:"Records_processed"`
	Records_updated   int       `json:"Records_updated" yaml:"Records_updated" xml:"Records_updated"`
	Records_created   int       `json:"Records_created" yaml:"Records_created" xml:"Records_created"`
	Records_failed    int       `json:"Records_failed" yaml:"Records_failed" xml:"Records_failed"`
	Start_time        time.Time `json:"Start_time" yaml:"Start_time" xml:"Start_time"`
	Id                int       `json:"Id" yaml:"Id" xml:"Id"`
	End_time          time.Time `json:"End_time" yaml:"End_time" xml:"End_time"`
	Entity_name       string    `json:"Entity_name" yaml:"Entity_name" xml:"Entity_name"`
	Error_message     string    `json:"Error_message" yaml:"Error_message" xml:"Error_message"`
	Created_at        time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Status            string    `json:"Status" yaml:"Status" xml:"Status"`
}

type Temp_inventory struct {
	Updated_at      time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	Warehouse_id    any       `json:"Warehouse_id" yaml:"Warehouse_id" xml:"Warehouse_id"`
	Reorder_point   float64   `json:"Reorder_point" yaml:"Reorder_point" xml:"Reorder_point"`
	Status          any       `json:"Status" yaml:"Status" xml:"Status"`
	Quantity        float64   `json:"Quantity" yaml:"Quantity" xml:"Quantity"`
	Id              any       `json:"Id" yaml:"Id" xml:"Id"`
	Maximum_level   float64   `json:"Maximum_level" yaml:"Maximum_level" xml:"Maximum_level"`
	Last_count_date time.Time `json:"Last_count_date" yaml:"Last_count_date" xml:"Last_count_date"`
	Last_sync_at    time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
	Minimum_level   float64   `json:"Minimum_level" yaml:"Minimum_level" xml:"Minimum_level"`
	Created_at      time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Expiration_date time.Time `json:"Expiration_date" yaml:"Expiration_date" xml:"Expiration_date"`
	Product_id      any       `json:"Product_id" yaml:"Product_id" xml:"Product_id"`
	Location_code   string    `json:"Location_code" yaml:"Location_code" xml:"Location_code"`
	Lot_control     string    `json:"Lot_control" yaml:"Lot_control" xml:"Lot_control"`
}

type User_preferences struct {
	Updated_at       time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	Preference_value string    `json:"Preference_value" yaml:"Preference_value" xml:"Preference_value"`
	Id               any       `json:"Id" yaml:"Id" xml:"Id"`
	Preference_key   string    `json:"Preference_key" yaml:"Preference_key" xml:"Preference_key"`
	User_id          string    `json:"User_id" yaml:"User_id" xml:"User_id"`
	Created_at       time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
}

type Users struct {
	Name       string    `json:"Name" yaml:"Name" xml:"Name"`
	Email      string    `json:"Email" yaml:"Email" xml:"Email"`
	Role_id    int       `json:"Role_id" yaml:"Role_id" xml:"Role_id"`
	Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Username   string    `json:"Username" yaml:"Username" xml:"Username"`
	Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	Active     bool      `json:"Active" yaml:"Active" xml:"Active"`
	Password   string    `json:"Password" yaml:"Password" xml:"Password"`
	Id         any       `json:"Id" yaml:"Id" xml:"Id"`
}

type Warehouses struct {
	Last_sync_at time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
	Address      string    `json:"Address" yaml:"Address" xml:"Address"`
	Created_at   time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
	Updated_at   time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
	Is_active    bool      `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
	External_id  string    `json:"External_id" yaml:"External_id" xml:"External_id"`
	Code         string    `json:"Code" yaml:"Code" xml:"Code"`
	Postal_code  string    `json:"Postal_code" yaml:"Postal_code" xml:"Postal_code"`
	State        string    `json:"State" yaml:"State" xml:"State"`
	Name         string    `json:"Name" yaml:"Name" xml:"Name"`
	Id           any       `json:"Id" yaml:"Id" xml:"Id"`
	City         string    `json:"City" yaml:"City" xml:"City"`
	Country      string    `json:"Country" yaml:"Country" xml:"Country"`
}

/// cmd/usage.go ///
package main

import (
	"github.com/fatih/color"
	"github.com/spf13/cobra"
)

func colorYellow(s string) string {
	return color.New(color.FgYellow).SprintFunc()(s)
}
func colorGreen(s string) string {
	return color.New(color.FgGreen).SprintFunc()(s)
}
func colorBlue(s string) string {
	return color.New(color.FgBlue).SprintFunc()(s)
}
func colorRed(s string) string {
	return color.New(color.FgRed).SprintFunc()(s)
}
func colorHelp(s string) string {
	return color.New(color.FgCyan).SprintFunc()(s)
}
func hasServiceCommands(cmds []*cobra.Command) bool {
	for _, cmd := range cmds {
		if cmd.Annotations["service"] == "true" {
			return true
		}
	}
	return false
}
func hasModuleCommands(cmds []*cobra.Command) bool {
	for _, cmd := range cmds {
		if cmd.Annotations["service"] != "true" {
			return true
		}
	}
	return false
}
func setUsageDefinition(cmd *cobra.Command) {
	cobra.AddTemplateFunc("colorYellow", colorYellow)
	cobra.AddTemplateFunc("colorGreen", colorGreen)
	cobra.AddTemplateFunc("colorRed", colorRed)
	cobra.AddTemplateFunc("colorBlue", colorBlue)
	cobra.AddTemplateFunc("colorHelp", colorHelp)
	cobra.AddTemplateFunc("hasServiceCommands", hasServiceCommands)
	cobra.AddTemplateFunc("hasModuleCommands", hasModuleCommands)

	// Altera o template de uso do cobra
	cmd.SetUsageTemplate(cliUsageTemplate)
}

var cliUsageTemplate = `{{- if index .Annotations "banner" }}{{colorBlue (index .Annotations "banner")}}{{end}}{{- if (index .Annotations "description") }}
{{index .Annotations "description"}}
{{- end }}

{{colorYellow "Usage:"}}{{if .Runnable}}
  {{.UseLine}}{{end}}{{if .HasAvailableSubCommands}}
  {{.CommandPath}} [command] [args]{{end}}{{if gt (len .Aliases) 0}}

{{colorYellow "Aliases:"}}
  {{.NameAndAliases}}{{end}}{{if .HasExample}}

{{colorYellow "Example:"}}
  {{.Example}}{{end}}{{if .HasAvailableSubCommands}}
{{colorYellow "Available Commands:"}}{{range .Commands}}{{if (or .IsAvailableCommand (eq .Name "help"))}}
  {{colorGreen (rpad .Name .NamePadding) }} {{.Short}}{{end}}{{end}}{{end}}{{if .HasAvailableLocalFlags}}

{{colorYellow "Flags:"}}
{{.LocalFlags.FlagUsages | trimTrailingWhitespaces | colorHelp}}{{end}}{{if .HasAvailableInheritedFlags}}

{{colorYellow "Global Options:"}}
  {{.InheritedFlags.FlagUsages | trimTrailingWhitespaces | colorHelp}}{{end}}{{if .HasHelpSubCommands}}

{{colorYellow "Additional help topics:"}}
{{range .Commands}}{{if .IsHelpCommand}}
  {{colorGreen (rpad .CommandPath .CommandPathPadding) }} {{.Short}}{{end}}{{end}}{{end}}{{if .HasSubCommands}}

{{colorYellow (printf "Use \"%s [command] --help\" for more information about a command." .CommandPath)}}{{end}}
`

/// cmd/wrpr.go ///
package main

import (
	"fmt"
	"os"
	"strings"

	"github.com/rafa-mori/gdbase/cmd/cli"
	gl "github.com/rafa-mori/gdbase/logger"
	"github.com/rafa-mori/gdbase/version"
	"github.com/spf13/cobra"
)

type GDBase struct {
	parentCmdName string
	printBanner   bool
	certPath      string
	keyPath       string
	configPath    string
}

func (m *GDBase) Alias() string {
	return ""
}
func (m *GDBase) ShortDescription() string {
	return "GDBase: GKBX Database and Docker manager/service. "
}
func (m *GDBase) LongDescription() string {
	return `GDBase: Is a tool to manage GKBX database and Docker services. It provides many DB flavors like MySQL, PostgreSQL, MongoDB, Redis, etc. It also provides Docker services like Docker Swarm, Docker Compose, etc. It is a command line tool that can be used to manage GKBX database and Docker services.`
}
func (m *GDBase) Usage() string {
	return "gdbase [command] [args]"
}
func (m *GDBase) Examples() []string {
	return []string{"gdbase [command] [args]", "gdbase database user auth'", "gdbase db roles list"}
}
func (m *GDBase) Active() bool {
	return true
}
func (m *GDBase) Module() string {
	return "gdbase"
}
func (m *GDBase) Execute() error {
	dbChanData := make(chan interface{})
	defer close(dbChanData)

	if spyderErr := m.Command().Execute(); spyderErr != nil {
		gl.Log("error", spyderErr.Error())
		return spyderErr
	} else {
		return nil
	}
}
func (m *GDBase) Command() *cobra.Command {
	cmd := &cobra.Command{
		Use: m.Module(),
		//Aliases:     []string{m.Alias(), "w", "wb", "webServer", "http"},
		Example:     m.concatenateExamples(),
		Annotations: m.getDescriptions(nil, true),
		Version:     version.GetVersion(),
		Run: func(cmd *cobra.Command, args []string) {
			_ = cmd.Help()
		},
	}

	cmd.AddCommand(version.CliCommand())

	cmd.AddCommand(cli.DockerCmd())

	cmd.AddCommand(cli.DatabaseCmd())

	cmd.AddCommand(cli.UtilsCmds())

	cmd.AddCommand(cli.SshCmds())

	setUsageDefinition(cmd)

	for _, c := range cmd.Commands() {
		setUsageDefinition(c)
		if !strings.Contains(strings.Join(os.Args, " "), c.Use) {
			if c.Short == "" {
				c.Short = c.Annotations["description"]
			}
		}
	}

	return cmd
}
func (m *GDBase) preRunEMethod(cmd *cobra.Command, args []string) error {
	gl.Log("debug", fmt.Sprintf("PreRunE: %s", cmd.Name()))

	return nil
}
func (m *GDBase) getDescriptions(descriptionArg []string, _ bool) map[string]string {
	return cli.GetDescriptions(descriptionArg, m.printBanner)
}
func (m *GDBase) SetParentCmdName(rtCmd string) {
	m.parentCmdName = rtCmd
}
func (m *GDBase) concatenateExamples() string {
	examples := ""
	rtCmd := m.parentCmdName
	if rtCmd != "" {
		rtCmd = rtCmd + " "
	}
	for _, example := range m.Examples() {
		examples += rtCmd + example + "\n  "
	}
	return examples
}

func RegX() *GDBase {
	var configPath = os.Getenv("GODOBASE_CONFIGFILE")
	var keyPath = os.Getenv("GODOBASE_KEYFILE")
	var certPath = os.Getenv("GODOBASE_CERTFILE")
	var printBannerV = os.Getenv("GODOBASE_PRINTBANNER")
	if printBannerV == "" {
		printBannerV = "true"
	}

	return &GDBase{
		configPath:  configPath,
		keyPath:     keyPath,
		certPath:    certPath,
		printBanner: strings.ToLower(printBannerV) == "true",
	}
}

/// docs/CONTRIBUTING.md ///
# **Contributing to GoSpider**

Thank you for your interest in contributing to **[GoSpider](https://github.com/rafa-mori/gospider)**! We are excited to have you as part of our community. This guide will help you get started and contribute effectively to the project.

---

## **How to Contribute**

There are several ways to contribute to [GoSpider](https://github.com/rafa-mori/gospider):

1. **Report Issues**
   - Found bugs or issues in the code? Open an issue detailing the problem.
   - Include as much information as possible: steps to reproduce the issue, logs, Go version used, etc.

2. **Suggest Improvements**
   - Have an idea to improve the project? Share your suggestion by opening an issue with the `enhancement` tag.

3. **Submit Pull Requests**
   - Want to fix a bug or implement something new? Submit a pull request with your changes.

4. **Test and Review Code**
   - Help review pull requests from other contributors.
   - Run existing tests and validate if the proposed changes keep the system functional.

---

## **Getting Started**

### 1. **Clone the Repository**
```bash
git clone https://github.com/rafa-mori/gospider.git
cd gospider
```

### 2. **Set Up the Environment**
Make sure you have Go installed:

You can install Go using one of the following methods:

- [A super easy way to install Go](https://github.com/rafa-mori/go-installer)
  ```shell
    curl -sSfL 'https://raw.githubusercontent.com/rafa-mori/go-installer/refs/heads/main/go.sh' | bash
  ```

- [Convencional way to download Go](https://go.dev/dl/)

### 3. **Install Dependencies**
```bash
# Download the necessary packages
go mod download
```

### 4. **Run Tests**
Before making changes, run the existing tests:
```bash
go test ./...
```

---

## **Creating a Pull Request**

### **1. Fork the Repository**
Create a fork of the project to your own GitHub.

### **2. Create a New Branch**
```bash
git checkout -b your-feature
```

### **3. Make Changes**
Make sure to follow the project's code conventions and best practices.

### **4. Add Tests (if applicable)**
Include test cases to validate the added functionality.

### **5. Run Tests**
Ensure all changes and tests are working:
```bash
go test ./...
```

### **6. Commit and Push**
```bash
git add .
git commit -m "Brief description of the change"
git push origin your-feature
```

### **7. Open the Pull Request**
Go to the original repository on GitHub and open a pull request explaining your changes.

---

## **Code Standards**

### **Code Style**
This project follows Go's code conventions. Some recommendations:
- Use `gofmt` to format the code:
```bash
gofmt -w .
```

- Name variables and functions clearly and descriptively.
- Break down long functions into smaller parts whenever possible.

### **Commits**
Commits should be clear and descriptive. Examples:
- `fix: fix bug in notification logic`
- `feat: add support for Slack notifier`

---

## **Best Practices**

1. **Be Respectful and Welcoming**  
   This is an open-source project for everyone. Respect other contributors and collaborate constructively.

2. **Document Your Changes**  
   Update the `README.md` or documentation, if necessary, to include your changes.

3. **Add Tests When Possible**  
   Ensure any new functionality is accompanied by tests.

4. **Be Clear in Issue Reports**  
   When opening an issue, be detailed and provide as much context as possible.

---

## **Where to Get Help**

If you need assistance, feel free to:
- Open an issue with the `question` tag.
- Contact me via the email or LinkedIn listed in the `README.md`.

---

## **Our Commitment**

We commit to reviewing pull requests and issues as quickly as possible. We value your contribution and appreciate the time dedicated to the project!

/// docs/README.pt-BR.md ///
#

![GDBASE Banner](/docs/assets/top_banner.png)

[![Go](https://img.shields.io/badge/Go-1.19+-00ADD8?logo=go&logoColor=white)](https://go.dev/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/rafa-mori/gdbase/blob/main/LICENSE)
[![Automation](https://img.shields.io/badge/automation-zero%20config-blue)](#features)
[![Releases](https://img.shields.io/github/v/release/rafa-mori/goforge?include_prereleases)](https://github.com/rafa-mori/goforge/releases)
[![Build](https://github.com/rafa-mori/gdbase/actions/workflows/release.yml/badge.svg)](https://github.com/rafa-mori/gdbase/actions/workflows/release.yml)

---

**Gerenciamento de bancos de dados modular, escal√°vel e autom√°tico para sistemas modernos.**

---

## **Table of Contents**

1. [About the Project](#about-the-project)
2. [Features](#features)
3. [Installation](#installation)
4. [Usage](#usage)
    - [CLI](#cli)
    - [Project Structure](#project-structure)
    - [Configuration](#configuration)
5. [Roadmap](#roadmap)
6. [Contributing](#contributing)
7. [Contact](#contact)

---

## **About the Project**

**GDBASE** √© uma solu√ß√£o de gerenciamento de bancos de dados desenvolvida em Go, projetada para ser **modular, escal√°vel e autom√°tica**. Permite configura√ß√£o zero, mas suporta customiza√ß√µes avan√ßadas via arquivos de configura√ß√£o. Gerencia bancos locais, Docker e m√∫ltiplos bancos simultaneamente, ideal para sistemas distribu√≠dos.

---

## **Features**

‚ú® **Configura√ß√£o din√¢mica e autom√°tica**

- Senhas geradas rand√¥micamente e armazenadas no keyring.
- Portas ocupadas ajustadas automaticamente.

üóÑÔ∏è **Compat√≠vel com m√∫ltiplos DBs**

- Redis, RabbitMQ, MongoDB, PostgreSQL e SQLite prontos para uso.

üèóÔ∏è **Arquitetura modular**

- Models seguem padr√£o `Model ‚Üí Repo ‚Üí Service`.
- Modularidade e organiza√ß√£o garantidas.

üîê **T√∫nel SSH para bancos externos**

- `gdbase ssh tunnel` conecta bancos remotos via SSH com seguran√ßa.

‚öôÔ∏è **Orquestra√ß√£o via Docker**

- Gera√ß√£o autom√°tica de containers para portabilidade e f√°cil implanta√ß√£o.

üì° **Monitoramento e eventos**

- Event bus para rastreamento interno de a√ß√µes.

---

## **Installation**

Requisitos:

- Go 1.19+
- Docker (para bancos em container)

Clone o reposit√≥rio e compile:

```sh
# Clone o reposit√≥rio
git clone https://github.com/rafa-mori/gdbase.git
cd gdbase
go build -o gdbase .
```

---

## **Usage**

### CLI

Inicie o servidor principal:

```sh
./gdbase start
```

Veja todos os comandos dispon√≠veis:

```sh
./gdbase --help
```

**Principais comandos:**

| Comando      | Fun√ß√£o                                             |
|--------------|----------------------------------------------------|
| `start`      | Inicializa `gdbase` e configura todos os servi√ßos  |
| `status`     | Exibe status dos bancos de dados ativos            |
| `config`     | Cria um arquivo de configura√ß√£o para customiza√ß√£o  |
| `ssh tunnel` | Cria um t√∫nel seguro para bancos externos via SSH  |
| `docker`     | Gerencia containers Docker para bancos de dados    |

### Project Structure

A implementa√ß√£o central segue uma arquitetura clara e modular:

```plaintext
./
‚îú‚îÄ‚îÄ cmd
‚îÇ   ‚îú‚îÄ‚îÄ cli
‚îÇ   ‚îú‚îÄ‚îÄ gen_models.go
‚îÇ   ‚îú‚îÄ‚îÄ models.go
‚îÇ   ‚îú‚îÄ‚îÄ main.go
‚îÇ   ‚îú‚îÄ‚îÄ usage.go
‚îÇ   ‚îî‚îÄ‚îÄ wrpr.go
‚îú‚îÄ‚îÄ docs
‚îÇ   ‚îî‚îÄ‚îÄ assets
‚îú‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ go.sum
‚îú‚îÄ‚îÄ internal
‚îÇ   ‚îú‚îÄ‚îÄ events
‚îÇ   ‚îú‚îÄ‚îÄ models
‚îÇ   ‚îî‚îÄ‚îÄ services
‚îú‚îÄ‚îÄ tests
‚îî‚îÄ‚îÄ version
```

---

### Configuration

O GDBASE pode rodar sem configura√ß√£o inicial, mas aceita customiza√ß√£o via arquivos YAML/JSON. Por padr√£o, tudo √© gerado automaticamente no primeiro uso.

Exemplo de configura√ß√£o:

```yaml
postgres:
  host: localhost
  port: 5432
  user: gdbase
  password: secure
redis:
  host: localhost
  port: 6379
```

---

## **Roadmap**

- [x] Configura√ß√£o din√¢mica e autom√°tica
- [x] Suporte a m√∫ltiplos bancos (Redis, RabbitMQ, MongoDB, PostgreSQL, SQLite)
- [x] T√∫nel SSH integrado
- [x] Orquestra√ß√£o via Docker
- [ ] Plugins para novos bancos
- [ ] Dashboard web para monitoramento

---

## **Contributing**

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues ou enviar pull requests. Veja o [Guia de Contribui√ß√£o](docs/CONTRIBUTING.md) para mais detalhes.

---

## **Contact**

üíå **Developer**:  
[Rafael Mori](mailto:rafa-mori@gmail.com)  
üíº [Follow me on GitHub](https://github.com/rafa-mori)  
Estou aberto a colabora√ß√µes e novas ideias. Se achou o projeto interessante, entre em contato!

---

**Made with care by the Mori family!** ‚ù§Ô∏è

/// factory/broker.go ///
package factory

import (
	"log"

	"github.com/rafa-mori/gdbase/internal/services"
	"github.com/streadway/amqp"
)

type Broker = services.BrokerImpl
type BrokerInfo = services.BrokerInfoLock
type BrokerManager = services.BrokerManager

func NewBrokerService(verbose bool, port string) (*Broker, error) { return services.NewBroker(verbose) }
func NewBrokerManager() *BrokerManager                            { return services.NewBrokerManager() }
func NewBrokerInfo(port string) *BrokerInfo                       { return services.NewBrokerInfo("", port) }

func PublishMessage(queueName string, message string) error {
	conn, err := amqp.Dial("amqp://guest:guest@localhost:5672/")
	if err != nil {
		log.Printf("Erro ao conectar ao RabbitMQ: %s", err)
		return err
	}
	defer conn.Close()

	ch, err := conn.Channel()
	if err != nil {
		log.Printf("Erro ao abrir um canal: %s", err)
		return err
	}
	defer ch.Close()

	q, err := ch.QueueDeclare(
		queueName,
		false,
		false,
		false,
		false,
		nil,
	)
	if err != nil {
		log.Printf("Erro ao declarar a fila: %s", err)
		return err
	}

	err = ch.Publish(
		"",
		q.Name,
		false,
		false,
		amqp.Publishing{
			ContentType: "text/plain",
			Body:        []byte(message),
		},
	)
	if err != nil {
		log.Printf("Erro ao publicar a mensagem: %s", err)
		return err
	}

	log.Printf("Mensagem publicada na fila %s: %s", queueName, message)
	return nil
}

/// factory/crypto_service.go ///
package factory

import (
	crp "github.com/rafa-mori/gdbase/internal/security/crypto"
	krs "github.com/rafa-mori/gdbase/internal/security/external"
	sci "github.com/rafa-mori/gdbase/internal/security/interfaces"
)

type CryptoService = sci.ICryptoService
type KeyringService = sci.IKeyringService

func NewCryptoService() CryptoService {
	return crp.NewCryptoService()
}

func NewKeyringService(keyringServiceName, keyringServicePath string) KeyringService {
	return krs.NewKeyringService(keyringServiceName, keyringServicePath)
}

/// factory/database.go ///
package factory

import (
	l "github.com/rafa-mori/logz"
	dbAbs "github.com/rafa-mori/gdbase/internal/services"
	t "github.com/rafa-mori/gdbase/types"
)

type DBConfig = t.DBConfig

type DBService = t.IDBService
type IDBConfig = t.DBConfig

func NewDatabaseService(config *t.DBConfig, logger l.Logger) (DBService, error) {
	return dbAbs.NewDatabaseService(config, logger)
}

func SetupDatabaseServices(d dbAbs.IDockerService, config *t.DBConfig) error {
	return dbAbs.SetupDatabaseServices(d, config)
}

/// factory/docker.go ///
package factory

import (
	dkrs "github.com/rafa-mori/gdbase/internal/services"
	t "github.com/rafa-mori/gdbase/types"
	l "github.com/rafa-mori/logz"
)

type DockerSrv interface {
	dkrs.IDockerService
}

func NewDockerService(config *t.DBConfig, logger l.Logger) (DockerSrv, error) {
	return dkrs.NewDockerService(config, logger)
}

/// factory/models/auth.go ///
package models

type AuthRequestDTO struct {
	Username string `json:"username"`
	Password string `json:"password"`
}

/// factory/models/clients.go ///
package models

import (
	m "github.com/rafa-mori/gdbase/internal/models/clients"
	"gorm.io/gorm"
)

type ClientModel = m.ClientDetailed
type ClientService = m.IClientService
type ClientRepo = m.IClientRepo

func NewClientService(clientRepo ClientRepo) ClientService {
	return m.NewClientService(clientRepo)
}

func NewClientRepo(db *gorm.DB) ClientRepo {
	return m.NewClientRepo(db)
}

/// factory/models/cron.go ///
package models

import (
	"context"
	"errors"

	m "github.com/rafa-mori/gdbase/internal/models/cron"
	"gorm.io/gorm"
)

type CronJobType = m.CronJob
type CronJobModel = m.CronJob
type CronJobService = m.ICronJobService
type CronJobRepo = m.ICronJobRepo

func NewCronJobService(cronJobRepo CronJobRepo) CronJobService {
	return m.NewCronJobService(cronJobRepo)
}
func NewCronJobRepo(ctx context.Context, db *gorm.DB) CronJobRepo {
	return m.NewCronJobRepo(ctx, db)
}
func NewCronJob(ctx context.Context, cron *CronJobModel, restrict bool) (*CronJobModel, error) {
	if cn, ok := m.NewCronJob(ctx, cron, restrict).(*CronJobModel); ok {
		return cn, nil
	}
	return nil, errors.New("failed to create cron job")
}

/// factory/models/products.go ///
package models

import (
	m "github.com/rafa-mori/gdbase/internal/models/products"
	"gorm.io/gorm"
)

type ProductModel = m.Product
type ProductService = m.IProductService
type ProductRepo = m.IProductRepo

func NewProductService(productRepo ProductRepo) ProductService {
	return m.NewProductService(productRepo)
}

func NewProductRepo(db *gorm.DB) ProductRepo {
	return m.NewProductRepo(db)
}

/// factory/models/user.go ///
package models

import (
	m "github.com/rafa-mori/gdbase/internal/models/users"
	"gorm.io/gorm"
)

type UserModelType = m.UserModel
type UserModel = m.IUser
type UserService = m.IUserService
type UserRepo = m.IUserRepo

func NewUserService(userRepo UserRepo) UserService {
	return m.NewUserService(userRepo)
}

func NewUserRepo(db *gorm.DB) UserRepo {
	return m.NewUserRepo(db)
}

func NewUserModel(username, name, email string) UserModel {
	return &m.UserModel{
		Username: username,
		Name:     name,
		Email:    email,
		Password: "",
		Active:   true,
	}
}

/// factory/models/webhooks.go ///
package models

import (
	m "github.com/rafa-mori/gdbase/internal/models/webhooks"
	"gorm.io/gorm"
)

type Webhook = m.IWebhook
type WebhookService = m.IWebhookService
type WebhookRepo = m.IWebhookRepo

// Define RegisterWebhookRequest here if it does not exist in the imported package
type RegisterWebhookRequest struct {
	// Add appropriate fields here, for example:
	FullUrl string `json:"fullUrl"`
	Event   string `json:"event"`
	Status  string `json:"status"`
}

// Define WebhookResponse here if it does not exist in the imported package
type WebhookResponse struct {
	ID      uint   `json:"id"`
	FullUrl string `json:"fullUrl"`
	Event   string `json:"event"`
	Status  string `json:"status"`
}

func NewWebhookService(webhookRepo WebhookRepo) WebhookService {
	return m.NewWebhookService(webhookRepo)
}

func NewWebhookRepo(db *gorm.DB) WebhookRepo {
	return m.NewWebhookRepo(db)
}

func NewWebhookModel(fullUrl, event, status string) Webhook {
	return m.NewWebhook(fullUrl, event, status)
}

/// gdbase.go ///
package gdbase

/// internal/events/dispatcher.go ///
package events

/// internal/events/event.go ///
package events

/// internal/events/event_bus.go ///
package events

import "sync"

type EventBus struct {
	events map[string]map[string][]func(...any)
	mutex  sync.Mutex
}

func NewEventBus() *EventBus {
	return &EventBus{
		events: make(map[string]map[string][]func(...any)),
	}
}

// Adiciona eventos
func (e *EventBus) On(name, event string, callback func(...any)) {
	e.mutex.Lock()
	defer e.mutex.Unlock()

	if e.events[name] == nil {
		e.events[name] = make(map[string][]func(...any))
	}

	e.events[name][event] = append(e.events[name][event], callback)
}

// Dispara eventos
func (e *EventBus) Emit(name, event string, args ...any) {
	e.mutex.Lock()
	defer e.mutex.Unlock()

	if callbacks, ok := e.events[name][event]; ok {
		for _, cb := range callbacks {
			go cb(args...)
		}
	}
}

/// internal/events/screenning.go ///
package events

/// internal/globals/defaults.go ///
package globals

import (
	"fmt"
	"os"

	crp "github.com/rafa-mori/gdbase/internal/security/crypto"
	krs "github.com/rafa-mori/gdbase/internal/security/external"
	gl "github.com/rafa-mori/gdbase/logger"
)

var (
	KubexKeyringName = "kubex"
	KubexKeyringKey  string
)

func init() {
	var err error
	if KubexKeyringKey == "" {
		KubexKeyringKey, err = GetOrGenPasswordKeyringPass(KubexKeyringName)
		if err != nil {
			gl.Log("fatal", fmt.Sprintf("Error initializing keyring: %v", err))
		}
	}
}

const (
	KeyringService            = "kubex"
	DefaultGoBEKeyPath        = "$HOME/.kubex/gobe/gobe-key.pem"
	DefaultGoBECertPath       = "$HOME/.kubex/gobe/gobe-cert.pem"
	DefaultGodoBaseConfigPath = "$HOME/.kubex/gdbase/config/config.json"
	DefaultVolumesDir         = "$HOME/.kubex/volumes"
	DefaultRedisVolume        = "$HOME/.kubex/volumes/redis"
	DefaultPostgresVolume     = "$HOME/.kubex/volumes/postgresql"
	DefaultMongoVolume        = "$HOME/.kubex/volumes/mongo"
	DefaultRabbitMQVolume     = "$HOME/.kubex/volumes/rabbitmq"
)

type GenericRepo interface {
	Create(u interface{}) (interface{}, error)
	FindOne(where ...interface{}) (interface{}, error)
	FindAll(where ...interface{}) ([]interface{}, error)
	Update(u interface{}) (interface{}, error)
	Delete(id uint) error
}
type Certificate struct {
}
type Docker struct{}
type FileSystem struct {
}
type Cache struct {
	Enabled          bool   `json:"enabled"`
	Setup            bool   `json:"setup"`
	CacheDir         string `json:"cache_dir"`
	SetupFlagPath    string `json:"setup_flag_path"`
	DepsFlagPath     string `json:"deps_flag_path"`
	ServicesFlagPath string `json:"services_flag_path"`
	VaultFlagPath    string `json:"vault_flag_path"`
}
type ValidationError struct {
	Field   string
	Message string
}

func (v *ValidationError) Error() string {
	return v.Message
}
func (v *ValidationError) FieldError() map[string]string {
	return map[string]string{v.Field: v.Message}
}
func (v *ValidationError) FieldsError() map[string]string {
	return map[string]string{v.Field: v.Message}
}
func (v *ValidationError) ErrorOrNil() error {
	return v
}

var (
	ErrUsernameRequired = &ValidationError{Field: "username", Message: "Username is required"}
	ErrPasswordRequired = &ValidationError{Field: "password", Message: "Password is required"}
	ErrEmailRequired    = &ValidationError{Field: "email", Message: "Email is required"}
	ErrDBNotProvided    = &ValidationError{Field: "db", Message: "Database not provided"}
	ErrModelNotFound    = &ValidationError{Field: "model", Message: "Model not found"}
)

// GetOrGenPasswordKeyringPass retrieves the password from the keyring or generates a new one if it doesn't exist
// It uses the keyring service name to store and retrieve the password
// These methods aren't exposed to the outside world, only accessible through the package main logic
func GetOrGenPasswordKeyringPass(name string) (string, error) {
	// Try to retrieve the password from the keyring
	krPass, krPassErr := krs.NewKeyringService(KeyringService, fmt.Sprintf("gobe-%s", name)).RetrievePassword()
	if krPassErr != nil && krPassErr == os.ErrNotExist {
		gl.Log("debug", fmt.Sprintf("Key found for %s", name))
		// If the error is "keyring: item not found", generate a new key
		gl.Log("debug", fmt.Sprintf("Key not found, generating new key for %s", name))
		krPassKey, krPassKeyErr := crp.NewCryptoServiceType().GenerateKey()
		if krPassKeyErr != nil {
			gl.Log("error", fmt.Sprintf("Error generating key: %v", krPassKeyErr))
			return "", krPassKeyErr
		}
		krPass = string(krPassKey)

		// Store the password in the keyring and return the encoded password
		return storeKeyringPassword(name, []byte(krPass))
	} else if krPassErr != nil {
		gl.Log("error", fmt.Sprintf("Error retrieving key: %v", krPassErr))
		return "", krPassErr
	}

	if !crp.IsBase64String(krPass) {
		krPass = crp.NewCryptoService().EncodeBase64([]byte(krPass))
	}

	return krPass, nil
}

// storeKeyringPassword stores the password in the keyring
// It will check if data is encoded, if so, will decode, store and then
// encode again or encode for the first time, returning always a portable data for
// the caller/logic outside this package be able to use it better and safer
// This method is not exposed to the outside world, only accessible through the package main logic
func storeKeyringPassword(name string, pass []byte) (string, error) {
	cryptoService := crp.NewCryptoServiceType()
	// Will decode if encoded, but only if the password is not empty, not nil and not ENCODED
	copyPass := make([]byte, len(pass))
	copy(copyPass, pass)

	var decodedPass []byte
	if crp.IsBase64String(string(copyPass)) {
		var decodeErr error
		// Will decode if encoded, but only if the password is not empty, not nil and not ENCODED
		decodedPass, decodeErr = cryptoService.DecodeIfEncoded(copyPass)
		if decodeErr != nil {
			gl.Log("error", fmt.Sprintf("Error decoding password: %v", decodeErr))
			return "", decodeErr
		}
	} else {
		decodedPass = copyPass
	}

	// Store the password in the keyring decoded to avoid storing the encoded password
	// locally are much better for security keep binary static and encoded to handle with transport
	// integration and other utilities
	storeErr := krs.NewKeyringService(KeyringService, fmt.Sprintf("gobe-%s", name)).StorePassword(string(decodedPass))
	if storeErr != nil {
		gl.Log("error", fmt.Sprintf("Error storing key: %v", storeErr))
		return "", storeErr
	}

	// Handle with logging here for getOrGenPasswordKeyringPass output
	encodedPass, encodeErr := cryptoService.EncodeIfDecoded(decodedPass)
	if encodeErr != nil {
		gl.Log("error", fmt.Sprintf("Error encoding password: %v", encodeErr))
		return "", encodeErr
	}

	// Return the encoded password to be used by the caller/logic outside this package
	return encodedPass, nil
}

/// internal/interfaces/channels.go ///
package interfaces

import (
	"github.com/google/uuid"
	"reflect"
)

type IChannelBase[T any] interface {
	IMutexes

	GetName() string                 // The name of the channel.
	GetChannel() (any, reflect.Type) // The channel for the value. Main channel for this struct.
	GetType() reflect.Type           // The type of the channel.
	GetBuffers() int                 // The number of buffers for the channel.

	SetName(name string) string       // Set the name of the channel.
	SetChannel(reflect.Type, int) any // The channel for the value. Main channel for this struct.
	SetBuffers(buffers int) int       // The number of buffers for the channel.

	Close() error // Close the channel.
	Clear() error // Clear the channel.
}

type IChannelCtl[T any] interface {
	IMutexes

	// Structure management

	GetID() uuid.UUID
	GetName() string
	SetName(name string) string

	// Property query

	GetProperty() IProperty[T]

	// SubChannels management

	GetSubChannels() map[string]interface{}
	SetSubChannels(channels map[string]interface{}) map[string]interface{}

	GetSubChannelByName(name string) (any, reflect.Type, bool)
	SetSubChannelByName(name string, channel any) (any, error)

	GetSubChannelTypeByName(name string) (reflect.Type, bool)

	GetSubChannelBuffersByName(name string) (int, bool)
	SetSubChannelBuffersByName(name string, buffers int) (int, error)

	// Main channel management

	GetMainChannel() any
	SetMainChannel(channel chan T) chan T
	GetMainChannelType() reflect.Type

	GetHasMetrics() bool
	SetHasMetrics(hasMetrics bool) bool
	GetBufferSize() int
	SetBufferSize(size int) int

	Close() error

	// Chainable methods

	WithProperty(property IProperty[T]) IChannelCtl[T]
	WithChannel(channel chan T) IChannelCtl[T]
	WithBufferSize(size int) IChannelCtl[T]
	WithMetrics(metrics bool) IChannelCtl[T]
}

/// internal/interfaces/environment.go ///
package interfaces

import "context"

type IEnvironment interface {
	Mu() IMutexes
	CpuCount() int
	MemTotal() int
	Hostname() string
	Os() string
	Kernel() string
	LoadEnvFile(watchFunc func(ctx context.Context, chanCbArg chan any) <-chan any) error
	GetEnvFilePath() string
	Getenv(key string) string
	Setenv(key, value string) error
	GetEnvCache() map[string]string
	ParseEnvVar(s string) (string, string)
	LoadEnvFromShell() error
	MemAvailable() int
	GetShellName(s string) (string, int)
	BackupEnvFile() error
	EncryptEnvFile() error
	DecryptEnvFile() (string, error)
	EncryptEnv(value string) (string, error)
	DecryptEnv(encryptedValue string) (string, error)
	IsEncrypted(envFile string) bool
	IsEncryptedValue(value string) bool
	EnableEnvFileEncryption() error
	DisableEnvFileEncryption() error
}

/// internal/interfaces/gobemin.go ///
package interfaces

import (
	"net/http"

	l "github.com/rafa-mori/logz"
)

type IGoBE interface {
	StartGoBE()
	HandleValidate(w http.ResponseWriter, r *http.Request)
	HandleContact(w http.ResponseWriter, r *http.Request)
	RateLimit(w http.ResponseWriter, r *http.Request) bool
	Initialize() error
	GetLogFilePath() string
	GetConfigFilePath() string
	GetLogger() l.Logger
	Mu() IMutexes
	GetReference() IReference
	Environment() IEnvironment
}

/// internal/interfaces/mapper.go ///
package interfaces

// IMapper is a generic interface for serializing and deserializing objects of type T.
type IMapper[T any] interface {
	// SerializeToFile serializes an object of type T to a file in the specified format.
	SerializeToFile(format string)
	// DeserializeFromFile deserializes an object of type T from a file in the specified format.
	DeserializeFromFile(format string) (*T, error)
	// Serialize converts an object of type T to a byte array in the specified format.
	Serialize(format string) ([]byte, error)
	// Deserialize converts a byte array in the specified format to an object of type T.
	Deserialize(data []byte, format string) (*T, error)
}

/// internal/interfaces/mutexes.go ///
package interfaces

import "time"

type IMutexes interface {
	MuLock()
	MuUnlock()
	MuRLock()
	MuRUnlock()
	MuTryLock() bool
	MuTryRLock() bool

	MuWaitCond()
	MuSignalCond()
	MuBroadcastCond()

	GetMuSharedCtx() any
	SetMuSharedCtx(ctx any)
	GetMuSharedCtxValidate() func(any) (bool, error)
	SetMuSharedCtxValidate(validate func(any) (bool, error))
	MuWaitCondWithTimeout(timeout time.Duration) bool

	MuAdd(delta int)
	MuDone()
	MuWait()
}

/// internal/interfaces/property.go ///
package interfaces

import (
	l "github.com/rafa-mori/logz"
	"github.com/google/uuid"
)

// IProperty is an interface that defines the methods for a property.
type IProperty[T any] interface {
	GetName() string
	GetValue() T
	SetValue(v *T)
	GetReference() (uuid.UUID, string)
	Prop() IPropertyValBase[T]
	GetLogger() l.Logger
	Serialize(format, filePath string) ([]byte, error)
	Deserialize(data []byte, format, filePath string) error
	SaveToFile(filePath string, format string) error
	LoadFromFile(filename, format string) error
	// Telemetry() *ITelemetry
}

/// internal/interfaces/property_base.go ///
package interfaces

import (
	"github.com/google/uuid"
	l "github.com/rafa-mori/logz"
	"reflect"
)

// IPropertyValBase is an interface that defines the methods for a property value.
type IPropertyValBase[T any] interface {
	GetLogger() l.Logger
	GetID() uuid.UUID
	GetName() string
	Value() *T
	StartCtl() <-chan string
	Type() reflect.Type
	Get(async bool) any
	Set(t *T) bool
	Clear() bool
	IsNil() bool
	Serialize(format, filePath string) ([]byte, error)
	Deserialize(data []byte, format, filePath string) error
}

/// internal/interfaces/reference.go ///
package interfaces

import "github.com/google/uuid"

type IReference interface {
	GetID() uuid.UUID
	GetName() string
	SetName(name string)
	String() string
}

/// internal/interfaces/request_tracer.go ///
package interfaces

import "time"

type IRequestsTracer interface {
	GetIP() string
	GetPort() string
	GetLastUserAgent() string
	GetUserAgents() []string
	GetEndpoint() string
	GetMethod() string
	GetTimeList() []time.Time
	GetCount() int
	GetError() error
	GetMutexes() IMutexes
	IsValid() bool
	GetOldFilePath() string

	GetFilePath() string
	SetFilePath(filePath string)
	GetMapper() IMapper[IRequestsTracer]
	SetMapper(mapper IMapper[IRequestsTracer])
	GetRequestWindow() time.Duration
	SetRequestWindow(window time.Duration)
	GetRequestLimit() int
	SetRequestLimit(limit int)
	Mu() IMutexes
}

/// internal/interfaces/signal_manager.go ///
package interfaces

type ISignalManager[T chan string] interface {
	ListenForSignals() error
	StopListening()
}

/// internal/interfaces/user.go ///
package interfaces

type User interface {
	GetID() string
	GetName() string
	GetUsername() string
	GetEmail() string
	GetRoleID() uint
	GetPhone() string
	GetDocument() string
	GetAddress() string
	GetCity() string
	GetState() string
	GetCountry() string
	GetZip() string
	GetBirth() string
	GetAvatar() string
	GetPicture() string
	GetActive() bool
	SetName(name string)
	SetUsername(username string)
	SetPassword(password string) error
	SetEmail(email string)
	SetRoleID(roleID uint)
	SetPhone(phone string)
	SetDocument(document string)
	SetAddress(address string)
	SetCity(city string)
	SetState(state string)
	SetCountry(country string)
	SetZip(zip string)
	SetBirth(birth string)
	SetAvatar(avatar string)
	SetPicture(picture string)
	SetActive(active bool)
	CheckPasswordHash(password string) bool
	Sanitize()
	Validate() error

	getUserObj() *User
}

/// internal/interfaces/user_repo.go ///
package interfaces

import xtt "github.com/rafa-mori/xtui/types"

type IUserRepo interface {
	Create(u User) (User, error)
	FindOne(where ...interface{}) (User, error)
	FindAll(where ...interface{}) ([]User, error)
	Update(u User) (User, error)
	Delete(id string) error
	Close() error
	List(where ...interface{}) (xtt.TableDataHandler, error)
}

/// internal/interfaces/validation.go ///
package interfaces

type IValidation[T any] interface {
	CheckIfWillValidate() bool
	Validate(value *T, args ...any) IValidationResult
	AddValidator(validator IValidationFunc[T]) error
	RemoveValidator(priority int) error
	GetValidator(priority int) (any, error)
	GetValidators() map[int]IValidationFunc[T]
	GetResults() map[int]IValidationResult
	ClearResults()
	IsValid() bool
}

/// internal/interfaces/validation_func.go ///
package interfaces

type IValidationFunc[T any] interface {
	GetPriority() int
	SetPriority(priority int)
	GetFunction() func(value *T, args ...any) IValidationResult
	SetFunction(function func(value *T, args ...any) IValidationResult)
	GetResult() IValidationResult
	SetResult(result IValidationResult)
}

/// internal/interfaces/validation_result.go ///
package interfaces

import "github.com/google/uuid"

type IValidationResult interface {
	String() string
	GetID() uuid.UUID
	GetName() string
	GetIsValid() bool
	GetMessage() string
	GetError() error
	GetMetadata(key string) (any, bool)
	SetMetadata(key string, value any)
	GetAllMetadataKeys() []string
}

/// internal/models/auth.go ///
package models

// User represents an authenticated user
// Equivalent to the User interface in TypeScript
import "time"

type User struct {
	ID          string     `json:"id"`
	Name        string     `json:"name"`
	Email       string     `json:"email"`
	Role        UserRole   `json:"role"`
	Permissions []string   `json:"permissions,omitempty"`
	PhotoURL    *string    `json:"photoUrl,omitempty"`
	Region      *string    `json:"region,omitempty"`
	LastLogin   *time.Time `json:"lastLogin,omitempty"`
}

// UserRole represents the roles a user can have
type UserRole string

const (
	Admin      UserRole = "admin"
	Backoffice UserRole = "backoffice"
	Supervisor UserRole = "supervisor"
	Seller     UserRole = "seller"
)

// Permission represents the permissions a user can have
type Permission string

const (
	// System Administration
	ManageSystemSettings Permission = "manage_system_settings"
	ManageUsers          Permission = "manage_users"
	ManageRoles          Permission = "manage_roles"
	ViewSystemLogs       Permission = "view_system_logs"

	// Master Data Management
	ManageAllProducts Permission = "manage_all_products"
	ManagePrices      Permission = "manage_prices"
	ManageAllClients  Permission = "manage_all_clients"
	ManageCategories  Permission = "manage_categories"

	// Orders and Sales
	ManageAllOrders Permission = "manage_all_orders"
	CreateOrders    Permission = "create_orders"
	ApproveOrders   Permission = "approve_orders"
	CancelOrders    Permission = "cancel_orders"
	EditOrders      Permission = "edit_orders"

	// Commissions
	ManageCommissionRules Permission = "manage_commission_rules"
	ProcessCommissions    Permission = "process_commissions"
	ViewAllCommissions    Permission = "view_all_commissions"

	// Reports and Analysis
	ViewAllReports Permission = "view_all_reports"
	ExportReports  Permission = "export_reports"
)

// UserRolePermissions maps roles to their permissions
var UserRolePermissions = map[UserRole][]Permission{
	Admin: {
		ManageSystemSettings,
		ManageUsers,
		ManageRoles,
		ViewSystemLogs,
		ManageAllProducts,
		ManagePrices,
		ManageAllClients,
		ManageCategories,
		ManageAllOrders,
		CreateOrders,
		ApproveOrders,
		CancelOrders,
		EditOrders,
		ManageCommissionRules,
		ProcessCommissions,
		ViewAllCommissions,
		ViewAllReports,
		ExportReports,
	},
	Backoffice: {
		ManageAllProducts,
		ManagePrices,
		ManageAllClients,
		ManageCategories,
		ManageAllOrders,
		CreateOrders,
		ApproveOrders,
		CancelOrders,
		EditOrders,
		ProcessCommissions,
		ViewAllCommissions,
		ViewAllReports,
		ExportReports,
	},
	Supervisor: {
		ViewAllReports,
		CreateOrders,
	},
	Seller: {
		CreateOrders,
	},
}

/// internal/models/clients/client_model.go ///
package clients

import (
	"time"

	t "github.com/rafa-mori/gdbase/internal/types"
)

// ClientStatus represents the status of a client
type ClientStatus string

const (
	Active   ClientStatus = "ACTIVE"
	Inactive ClientStatus = "INACTIVE"
	Pending  ClientStatus = "PENDING"
	Blocked  ClientStatus = "BLOCKED"
	Archived ClientStatus = "ARCHIVED"
)

// ClientType represents the type of a client
type ClientType string

const (
	Individual ClientType = "individual"
	Company    ClientType = "company"
)

// IClientContact interface for ClientContact
// IClientContact defines methods for manipulating ClientContact fields
//
//go:generate mockgen -destination=../../mocks/mock_client_contact.go -package=mocks . IClientContact
type IClientContact interface {
	GetPhone() *string
	SetPhone(phone *string)
	GetMobilePhone() *string
	SetMobilePhone(mobilePhone *string)
	GetEmail() *string
	SetEmail(email *string)
	GetContactName() *string
	SetContactName(contactName *string)
}

// ClientContact represents the contact information of a client
type ClientContact struct {
	Phone       *string `json:"phone,omitempty" xml:"phone,omitempty" yaml:"phone,omitempty" gorm:"column:phone"`
	MobilePhone *string `json:"mobilePhone,omitempty" xml:"mobilePhone,omitempty" yaml:"mobilePhone,omitempty" gorm:"column:mobile_phone"`
	Email       *string `json:"email,omitempty" xml:"email,omitempty" yaml:"email,omitempty" gorm:"column:email"`
	ContactName *string `json:"contactName,omitempty" xml:"contactName,omitempty" yaml:"contactName,omitempty" gorm:"column:contact_name"`
}

func (c *ClientContact) GetPhone() *string        { return c.Phone }
func (c *ClientContact) SetPhone(phone *string)   { c.Phone = phone }
func (c *ClientContact) GetMobilePhone() *string  { return c.MobilePhone }
func (c *ClientContact) SetMobilePhone(m *string) { c.MobilePhone = m }
func (c *ClientContact) GetEmail() *string        { return c.Email }
func (c *ClientContact) SetEmail(email *string)   { c.Email = email }
func (c *ClientContact) GetContactName() *string  { return c.ContactName }
func (c *ClientContact) SetContactName(n *string) { c.ContactName = n }

// IArchiveInfo interface for ArchiveInfo
type IArchiveInfo interface {
	GetArchivedAt() time.Time
	SetArchivedAt(t time.Time)
	GetArchivedBy() string
	SetArchivedBy(by string)
	GetReason() string
	SetReason(reason string)
}

// ArchiveInfo represents archival information of a client
type ArchiveInfo struct {
	ArchivedAt time.Time `json:"archivedAt" xml:"archivedAt" yaml:"archivedAt" gorm:"column:archived_at"`
	ArchivedBy string    `json:"archivedBy" xml:"archivedBy" yaml:"archivedBy" gorm:"column:archived_by"`
	Reason     string    `json:"reason" xml:"reason" yaml:"reason" gorm:"column:reason"`
}

func (a *ArchiveInfo) GetArchivedAt() time.Time  { return a.ArchivedAt }
func (a *ArchiveInfo) SetArchivedAt(t time.Time) { a.ArchivedAt = t }
func (a *ArchiveInfo) GetArchivedBy() string     { return a.ArchivedBy }
func (a *ArchiveInfo) SetArchivedBy(by string)   { a.ArchivedBy = by }
func (a *ArchiveInfo) GetReason() string         { return a.Reason }
func (a *ArchiveInfo) SetReason(reason string)   { a.Reason = reason }

// IClientDetailed interface for ClientDetailed
type IClientDetailed interface {
	TableName() string
	GetID() string
	SetID(id string)
	GetCode() *string
	SetCode(code *string)
	GetTradingName() *string
	SetTradingName(name *string)
	GetDocumentType() ClientType
	SetDocumentType(t ClientType)
	GetContact() IClientContact
	SetContact(contact IClientContact)
	GetMainAddress() t.IAddress
	SetMainAddress(addr t.IAddress)
	GetAddresses() []t.IAddress
	SetAddresses(addrs []t.IAddress)
	GetStatus() ClientStatus
	SetStatus(status ClientStatus)
	GetCreditLimit() *float64
	SetCreditLimit(limit *float64)
	GetPaymentTerms() *string
	SetPaymentTerms(terms *string)
	GetNotes() *string
	SetNotes(notes *string)
	GetTotalOrders() *int
	SetTotalOrders(total *int)
	GetTotalSpent() *float64
	SetTotalSpent(spent *float64)
	GetLastOrderDate() *time.Time
	SetLastOrderDate(date *time.Time)
	GetArchiveInfo() IArchiveInfo
	SetArchiveInfo(info IArchiveInfo)
}

// ClientDetailed represents a detailed client structure
type ClientDetailed struct {
	ID            string        `json:"id" xml:"id" yaml:"id" gorm:"column:id;primaryKey"`
	Code          *string       `json:"code,omitempty" xml:"code,omitempty" yaml:"code,omitempty" gorm:"column:code"`
	TradingName   *string       `json:"tradingName,omitempty" xml:"tradingName,omitempty" yaml:"tradingName,omitempty" gorm:"column:trading_name"`
	DocumentType  ClientType    `json:"documentType" xml:"documentType" yaml:"documentType" gorm:"column:document_type"`
	Contact       ClientContact `json:"contact" xml:"contact" yaml:"contact" gorm:"embedded;embeddedPrefix:contact_"`
	MainAddress   t.Address     `json:"mainAddress" xml:"mainAddress" yaml:"mainAddress" gorm:"embedded;embeddedPrefix:main_address_"`
	Addresses     []t.Address   `json:"addresses" xml:"addresses" yaml:"addresses" gorm:"-"`
	Status        ClientStatus  `json:"status" xml:"status" yaml:"status" gorm:"column:status"`
	CreditLimit   *float64      `json:"creditLimit,omitempty" xml:"creditLimit,omitempty" yaml:"creditLimit,omitempty" gorm:"column:credit_limit"`
	PaymentTerms  *string       `json:"paymentTerms,omitempty" xml:"paymentTerms,omitempty" yaml:"paymentTerms,omitempty" gorm:"column:payment_terms"`
	Notes         *string       `json:"notes,omitempty" xml:"notes,omitempty" yaml:"notes,omitempty" gorm:"column:notes"`
	TotalOrders   *int          `json:"totalOrders,omitempty" xml:"totalOrders,omitempty" yaml:"totalOrders,omitempty" gorm:"column:total_orders"`
	TotalSpent    *float64      `json:"totalSpent,omitempty" xml:"totalSpent,omitempty" yaml:"totalSpent,omitempty" gorm:"column:total_spent"`
	LastOrderDate *time.Time    `json:"lastOrderDate,omitempty" xml:"lastOrderDate,omitempty" yaml:"lastOrderDate,omitempty" gorm:"column:last_order_date"`
	ArchiveInfo   *ArchiveInfo  `json:"archiveInfo,omitempty" xml:"archiveInfo,omitempty" yaml:"archiveInfo,omitempty" gorm:"embedded;embeddedPrefix:archive_"`
	CreatedAt     time.Time     `json:"createdAt" xml:"createdAt" yaml:"createdAt" gorm:"column:created_at"`
	UpdatedAt     time.Time     `json:"updatedAt" xml:"updatedAt" yaml:"updatedAt" gorm:"column:updated_at"`
	LastSync      time.Time     `json:"lastSync" xml:"lastSync" yaml:"lastSync" gorm:"column:last_sync"`
}

func (c *ClientDetailed) TableName() string            { return "clients" }
func (c *ClientDetailed) GetID() string                { return c.ID }
func (c *ClientDetailed) SetID(id string)              { c.ID = id }
func (c *ClientDetailed) GetCode() *string             { return c.Code }
func (c *ClientDetailed) SetCode(code *string)         { c.Code = code }
func (c *ClientDetailed) GetTradingName() *string      { return c.TradingName }
func (c *ClientDetailed) SetTradingName(name *string)  { c.TradingName = name }
func (c *ClientDetailed) GetDocumentType() ClientType  { return c.DocumentType }
func (c *ClientDetailed) SetDocumentType(t ClientType) { c.DocumentType = t }
func (c *ClientDetailed) GetContact() IClientContact   { return &c.Contact }
func (c *ClientDetailed) SetContact(contact IClientContact) {
	if v, ok := contact.(*ClientContact); ok {
		c.Contact = *v
	}
}
func (c *ClientDetailed) GetMainAddress() t.IAddress { return &c.MainAddress }
func (c *ClientDetailed) SetMainAddress(addr t.IAddress) {
	if v, ok := addr.(*t.Address); ok {
		c.MainAddress = *v
	}
}
func (c *ClientDetailed) GetAddresses() []t.IAddress {
	addrs := make([]t.IAddress, len(c.Addresses))
	for i := range c.Addresses {
		addrs[i] = &c.Addresses[i]
	}
	return addrs
}
func (c *ClientDetailed) SetAddresses(addrs []t.IAddress) {
	c.Addresses = make([]t.Address, len(addrs))
	for i, a := range addrs {
		if v, ok := a.(*t.Address); ok {
			c.Addresses[i] = *v
		}
	}
}
func (c *ClientDetailed) GetStatus() ClientStatus          { return c.Status }
func (c *ClientDetailed) SetStatus(status ClientStatus)    { c.Status = status }
func (c *ClientDetailed) GetCreditLimit() *float64         { return c.CreditLimit }
func (c *ClientDetailed) SetCreditLimit(limit *float64)    { c.CreditLimit = limit }
func (c *ClientDetailed) GetPaymentTerms() *string         { return c.PaymentTerms }
func (c *ClientDetailed) SetPaymentTerms(terms *string)    { c.PaymentTerms = terms }
func (c *ClientDetailed) GetNotes() *string                { return c.Notes }
func (c *ClientDetailed) SetNotes(notes *string)           { c.Notes = notes }
func (c *ClientDetailed) GetTotalOrders() *int             { return c.TotalOrders }
func (c *ClientDetailed) SetTotalOrders(total *int)        { c.TotalOrders = total }
func (c *ClientDetailed) GetTotalSpent() *float64          { return c.TotalSpent }
func (c *ClientDetailed) SetTotalSpent(spent *float64)     { c.TotalSpent = spent }
func (c *ClientDetailed) GetLastOrderDate() *time.Time     { return c.LastOrderDate }
func (c *ClientDetailed) SetLastOrderDate(date *time.Time) { c.LastOrderDate = date }
func (c *ClientDetailed) GetArchiveInfo() IArchiveInfo     { return c.ArchiveInfo }
func (c *ClientDetailed) SetArchiveInfo(info IArchiveInfo) {
	if v, ok := info.(*ArchiveInfo); ok {
		c.ArchiveInfo = v
	}
}

// ClientResponse represents a paginated response of clients
type ClientResponse struct {
	Data       []ClientDetailed `json:"data" xml:"data" yaml:"data" gorm:"-"`
	Total      int              `json:"total" xml:"total" yaml:"total" gorm:"-"`
	TotalPages int              `json:"totalPages" xml:"totalPages" yaml:"totalPages" gorm:"-"`
	Page       int              `json:"page" xml:"page" yaml:"page" gorm:"-"`
	Limit      int              `json:"limit" xml:"limit" yaml:"limit" gorm:"-"`
}

// ClientSortField represents the fields by which clients can be sorted
type ClientSortField string

const (
	Name        ClientSortField = "name"
	Document    ClientSortField = "document"
	CreatedAt   ClientSortField = "createdAt"
	UpdatedAt   ClientSortField = "updatedAt"
	City        ClientSortField = "city"
	CreditLimit ClientSortField = "creditLimit"
	Status      ClientSortField = "status"
)

// SortDirection represents the direction of sorting
type SortDirection string

const (
	Asc  SortDirection = "asc"
	Desc SortDirection = "desc"
)

// ClientFilterParams represents the parameters for filtering clients
type ClientFilterParams struct {
	Name            *string          `json:"name,omitempty"`
	Document        *string          `json:"document,omitempty"`
	Email           *string          `json:"email,omitempty"`
	Phone           *string          `json:"phone,omitempty"`
	Status          *ClientStatus    `json:"status,omitempty"`
	IncludeArchived bool             `json:"includeArchived"`
	SortBy          *ClientSortField `json:"sortBy,omitempty"`
	SortDirection   *SortDirection   `json:"sortDirection,omitempty"`
}

// ArchiveClientDTO represents the data for archiving a client
type ArchiveClientDTO struct {
	Reason     string `json:"reason"`
	ArchivedBy string `json:"archivedBy"`
}

// CreateClientDTO represents the data for creating a client
type CreateClientDTO struct {
	Code         *string       `json:"code,omitempty"`
	TradingName  *string       `json:"tradingName,omitempty"`
	DocumentType ClientType    `json:"documentType"`
	Contact      ClientContact `json:"contact"`
	MainAddress  t.Address     `json:"mainAddress"`
	Addresses    []t.Address   `json:"addresses"`
	Status       ClientStatus  `json:"status"`
	CreditLimit  *float64      `json:"creditLimit,omitempty"`
	PaymentTerms *string       `json:"paymentTerms,omitempty"`
	Notes        *string       `json:"notes,omitempty"`
}

// UpdateClientDTO represents the data for updating a client
type UpdateClientDTO struct {
	Code         *string        `json:"code,omitempty"`
	TradingName  *string        `json:"tradingName,omitempty"`
	DocumentType *ClientType    `json:"documentType,omitempty"`
	Contact      *ClientContact `json:"contact,omitempty"`
	MainAddress  *t.Address     `json:"mainAddress,omitempty"`
	Addresses    *[]t.Address   `json:"addresses,omitempty"`
	Status       *ClientStatus  `json:"status,omitempty"`
	CreditLimit  *float64       `json:"creditLimit,omitempty"`
	PaymentTerms *string        `json:"paymentTerms,omitempty"`
	Notes        *string        `json:"notes,omitempty"`
}

// PaginationParams represents pagination parameters
type PaginationParams struct {
	Page  int `json:"page"`
	Limit int `json:"limit"`
}

// PaginatedClientResult represents a paginated result of clients
type PaginatedClientResult struct {
	Data       []ClientDetailed `json:"data"`
	Total      int              `json:"total"`
	Page       int              `json:"page"`
	Limit      int              `json:"limit"`
	TotalPages int              `json:"totalPages"`
}

/// internal/models/clients/clients_repo.go ///
package clients

import (
	"fmt"

	gl "github.com/rafa-mori/gdbase/logger"
	"gorm.io/gorm"
)

// IClientRepo define o contrato do reposit√≥rio para clientes.
type IClientRepo interface {
	// Cria um novo cliente e retorna o objeto criado.
	Create(client *ClientDetailed) (*ClientDetailed, error)
	// Busca um cliente usando uma condi√ß√£o gen√©rica (Ex.: "id = ?", id).
	FindOne(query interface{}, args ...interface{}) (*ClientDetailed, error)
	// Busca todos os clientes que satisfa√ßam determinada condi√ß√£o.
	FindAll(query interface{}, args ...interface{}) ([]*ClientDetailed, error)
	// Atualiza os dados de um cliente.
	Update(client *ClientDetailed) (*ClientDetailed, error)
	// Exclui um cliente com base no ID.
	Delete(id string) error
	// Fecha a conex√£o com o banco de dados.
	Close() error
	// Lista os clientes em um formato de tabela simples ou outro formato que desejar.
	List(query interface{}, args ...interface{}) (interface{}, error)
}

// ClientRepo √© a implementa√ß√£o de IClientRepo usando GORM.
type ClientRepo struct {
	db *gorm.DB
}

// NewClientRepo cria uma nova inst√¢ncia de ClientRepo.
func NewClientRepo(db *gorm.DB) IClientRepo {
	if db == nil {
		gl.Log("error", "ClientRepo: gorm DB is nil")
		return nil
	}
	return &ClientRepo{db: db}
}

func (cr *ClientRepo) Create(client *ClientDetailed) (*ClientDetailed, error) {
	if client == nil {
		return nil, fmt.Errorf("ClientRepo: client is nil")
	}
	err := cr.db.Create(client).Error
	if err != nil {
		return nil, fmt.Errorf("ClientRepo: failed to create client: %w", err)
	}
	return client, nil
}

func (cr *ClientRepo) FindOne(query interface{}, args ...interface{}) (*ClientDetailed, error) {
	var client ClientDetailed
	err := cr.db.Where(query, args...).First(&client).Error
	if err != nil {
		return nil, fmt.Errorf("ClientRepo: failed to find client: %w", err)
	}
	return &client, nil
}

func (cr *ClientRepo) FindAll(query interface{}, args ...interface{}) ([]*ClientDetailed, error) {
	var clients []*ClientDetailed
	err := cr.db.Where(query, args...).Find(&clients).Error
	if err != nil {
		return nil, fmt.Errorf("ClientRepo: failed to find clients: %w", err)
	}
	return clients, nil
}

func (cr *ClientRepo) Update(client *ClientDetailed) (*ClientDetailed, error) {
	if client == nil {
		return nil, fmt.Errorf("ClientRepo: client is nil")
	}
	err := cr.db.Save(client).Error
	if err != nil {
		return nil, fmt.Errorf("ClientRepo: failed to update client: %w", err)
	}
	return client, nil
}

func (cr *ClientRepo) Delete(id string) error {
	err := cr.db.Delete(&ClientDetailed{}, id).Error
	if err != nil {
		return fmt.Errorf("ClientRepo: failed to delete client: %w", err)
	}
	return nil
}

func (cr *ClientRepo) Close() error {
	sqlDB, err := cr.db.DB()
	if err != nil {
		return err
	}
	return sqlDB.Close()
}

func (cr *ClientRepo) List(query interface{}, args ...interface{}) (interface{}, error) {
	var clients []ClientDetailed
	err := cr.db.Where(query, args...).Find(&clients).Error
	if err != nil {
		return nil, fmt.Errorf("ClientRepo: failed to list clients: %w", err)
	}
	// Aqui, por exemplo, podemos construir uma estrutura de tabela simples
	tableRows := [][]string{}
	for i, client := range clients {
		row := []string{
			fmt.Sprintf("%d", i+1),
			client.ID,
			// Supondo que TradingName seja opcional; usamos uma fun√ß√£o inline para tratar o nil
			func() string {
				if client.TradingName != nil {
					return *client.TradingName
				}
				return ""
			}(),
			string(client.Status), // status √© do tipo ClientStatus (string)
		}
		tableRows = append(tableRows, row)
	}
	return tableRows, nil
}

/// internal/models/clients/clients_service.go ///
package clients

import (
	"errors"
	"fmt"
)

// IClientService define os m√©todos dispon√≠veis para gerenciar clientes.
type IClientService interface {
	// Cria um cliente.
	CreateClient(client *ClientDetailed) (*ClientDetailed, error)
	// Obt√©m um cliente pelo ID.
	GetClientByID(id string) (*ClientDetailed, error)
	// Atualiza um cliente.
	UpdateClient(client *ClientDetailed) (*ClientDetailed, error)
	// Exclui um cliente pelo ID.
	DeleteClient(id string) error
	// Lista todos os clientes.
	ListClients() ([]*ClientDetailed, error)
}

// ClientService √© a implementa√ß√£o de IClientService.
type ClientService struct {
	repo IClientRepo
}

// NewClientService cria uma nova inst√¢ncia de ClientService.
func NewClientService(repo IClientRepo) IClientService {
	return &ClientService{repo: repo}
}

func (cs *ClientService) CreateClient(client *ClientDetailed) (*ClientDetailed, error) {
	if client == nil {
		return nil, errors.New("ClientService: client is nil")
	}
	// Aqui voc√™ pode adicionar valida√ß√µes espec√≠ficas do dom√≠nio.
	if client.ID == "" {
		return nil, errors.New("ClientService: client ID is empty")
	}
	createdClient, err := cs.repo.Create(client)
	if err != nil {
		return nil, fmt.Errorf("ClientService: error creating client: %w", err)
	}
	return createdClient, nil
}

func (cs *ClientService) GetClientByID(id string) (*ClientDetailed, error) {
	client, err := cs.repo.FindOne("id = ?", id)
	if err != nil {
		return nil, fmt.Errorf("ClientService: error fetching client: %w", err)
	}
	return client, nil
}

func (cs *ClientService) UpdateClient(client *ClientDetailed) (*ClientDetailed, error) {
	updatedClient, err := cs.repo.Update(client)
	if err != nil {
		return nil, fmt.Errorf("ClientService: error updating client: %w", err)
	}
	return updatedClient, nil
}

func (cs *ClientService) DeleteClient(id string) error {
	err := cs.repo.Delete(id)
	if err != nil {
		return fmt.Errorf("ClientService: error deleting client: %w", err)
	}
	return nil
}

func (cs *ClientService) ListClients() ([]*ClientDetailed, error) {
	clients, err := cs.repo.FindAll("1 = 1")
	if err != nil {
		return nil, fmt.Errorf("ClientService: error listing clients: %w", err)
	}
	return clients, nil
}

/// internal/models/cron/common.go ///
package cron

import (
	"context"
	"errors"
	"fmt"
	"math/rand"
	"reflect"
	"time"

	"github.com/google/uuid"

	t "github.com/rafa-mori/gdbase/internal/types"
	gl "github.com/rafa-mori/gdbase/logger"
	l "github.com/rafa-mori/logz"
)

type ICronJobValidation interface {
	ValidateCronJobProperties(ctx context.Context, cron *CronJob, restrict bool) (*CronJob, error)
	ValidateCronJobRestrict(field any) error
}
type CronModelValidation struct {
	*t.Mutexes
	Logger        l.Logger
	defaultValues map[string]any
}

func NewCronModelValidation(ctx context.Context, logger l.Logger, debug bool) ICronJobValidation {
	if logger == nil {
		logger = l.GetLogger("CronModelValidation")
	}
	if debug {
		gl.SetDebug(true)
	}
	return &CronModelValidation{
		Mutexes: t.NewMutexesType(),
		Logger:  logger,
		defaultValues: map[string]any{
			"RetryInterval":    func() int { return rand.Intn(10) + 1 }(),
			"CreatedAt":        time.Now(),
			"UserID":           uuid.Nil,
			"Retries":          0,
			"ExecTimeout":      30,
			"MaxRetries":       3,
			"MaxExecutionTime": 150,
			"IsRecurring":      false,
			"IsActive":         true,
			"CronType":         "cron",
			"CronExpression":   "2 * * * *",
			"Command":          "echo 'Hello, World!'",
			"Method":           "GET",
		},
	}
}
func (cv *CronModelValidation) IsValidField(field any) bool {
	if field == nil {
		gl.LogObjLogger(cv, "warn", fmt.Sprintf("Field is nil: %v", field))
		return false
	}
	if reflect.TypeOf(field).Kind() == reflect.Ptr {
		gl.LogObjLogger(cv, "warn", fmt.Sprintf("Field is a pointer: %v", field))
		return false
	}
	if vl := reflect.ValueOf(field); !vl.IsValid() || !vl.IsNil() || vl.IsZero() {
		gl.LogObjLogger(cv, "warn", fmt.Sprintf("Field is not valid: %v", field))
		return false
	}
	return true
}
func (cv *CronModelValidation) GetValueOrDefault(ctx context.Context, name string, field any) any {
	// If the field is not valid, search for a default value
	if defaultValue, ok := cv.defaultValues[name]; ok {
		gl.LogObjLogger(cv, "notice", fmt.Sprintf("Field %s is not valid, using default value: %v", name, defaultValue))
		return defaultValue
	}
	// If no default value is found, return the original field
	return field // If the field is valid, return the field itself
}
func (cv *CronModelValidation) ValidateCronJobRestrict(field any) error {
	if !cv.IsValidField(field) {
		gl.LogObjLogger(cv, "warn", fmt.Sprintf("Field is not valid: %v", field))
		return errors.New("field is not valid")
	}
	switch v := field.(type) {
	case string:
		if v == "" {
			gl.LogObjLogger(cv, "warn", fmt.Sprintf("Field is empty: %v", field))
			return errors.New("field cannot be empty")
		}
	case int:
		if v <= 0 {
			gl.LogObjLogger(cv, "warn", fmt.Sprintf("Field is not positive: %v", field))
			return errors.New("field must be positive")
		}
	case uuid.UUID:
		if v == uuid.Nil {
			gl.LogObjLogger(cv, "warn", fmt.Sprintf("Field is not a valid UUID: %v", field))
			return errors.New("field must be a valid UUID")
		}
	}
	return nil
}
func (cv *CronModelValidation) ValidateCronJobProperties(ctx context.Context, cron *CronJob, restrict bool) (*CronJob, error) {
	// Check if the cron job is nil
	if cron == nil {
		gl.LogObjLogger(cv, "error", "Cron job cannot be nil")
		return nil, errors.New("cron job cannot be nil")
	}

	// Get the values of the cron job struct
	val := reflect.ValueOf(cron).Elem()

	// Iterate over the fields of the struct
	for i := 0; i < val.NumField(); i++ {

		// Get the field name
		name := val.Type().Field(i)

		// Get the field value
		value := val.Field(i)

		// If it is a restricted validation, check the field value
		if restrict {
			err := cv.ValidateCronJobRestrict(value.Interface())
			if err != nil {
				gl.LogObjLogger(cv, "warn", fmt.Sprintf("Field is not valid: %v", value.Interface()))
				return nil, err
			}
		}

		// Set the field value back to the struct
		value.Set(reflect.ValueOf(cv.GetValueOrDefault(ctx, name.Name, value.Interface())))
	}

	// Lock the mutex to restore the values back to the struct
	cv.MuLock()
	defer cv.MuUnlock()

	gl.LogObjLogger(cv, "info", fmt.Sprintf("Cron job properties validated: %v", cron))

	// return the cron job with the validated and defaulted values
	return cron, nil
}

/// internal/models/cron/cronjob_model.go ///
package cron

import (
	"context"
	"time"

	l "github.com/rafa-mori/logz"
	"github.com/google/uuid"
	t "github.com/rafa-mori/gdbase/types"

	jobqueue "github.com/rafa-mori/gdbase/internal/models/job_queue"

	gl "github.com/rafa-mori/gdbase/logger"
)

type ICronJobModel interface {
	TableName() string
	PrimaryKey() string
	GetID() uuid.UUID
	SetID(id uuid.UUID)
	GetCreatedAt() time.Time
	SetCreatedAt(createdAt time.Time)
	GetUpdatedAt() *time.Time
	SetUpdatedAt(updatedAt *time.Time)
	GetCreatedBy() uuid.UUID
	SetCreatedBy(createdBy uuid.UUID)
	GetUpdatedBy() uuid.UUID
	SetUpdatedBy(updatedBy uuid.UUID)
	GetLastExecutedAt() *time.Time
	SetLastExecutedAt(lastExecutedAt *time.Time)
	GetLastExecutedBy() uuid.UUID
	SetLastExecutedBy(lastExecutedBy uuid.UUID)
	GetUserID() uuid.UUID
	SetUserID(userID uuid.UUID)
	CronJobObject() *CronJob
}

type CronJob struct {
	ID             uuid.UUID `json:"id" gorm:"type:uuid;primary_key,default:uuid_generate_v4()" binding:"-"`
	UserID         uuid.UUID `json:"user_id" gorm:"type:uuid;references:users(id)" binding:"omitempty"`
	CreatedBy      uuid.UUID `json:"created_by" gorm:"type:uuid;references:users(id)" binding:"omitempty"`
	UpdatedBy      uuid.UUID `json:"updated_by" gorm:"type:uuid;references:users(id),omitempty" binding:"omitempty"`
	LastExecutedBy uuid.UUID `json:"last_executed_by" gorm:"type:uuid;references:users(id),omitempty" binding:"omitempty"`

	Name           string `json:"name" gorm:"type:varchar(255);not null" binding:"required"`
	Description    string `json:"description" gorm:"type:text" binding:"omitempty"`
	CronType       string `json:"cron_type" gorm:"type:enum('cron', 'interval');default:'cron'" binding:"omitempty"`
	CronExpression string `json:"cron_expression" gorm:"type:text;default:'2 * * * *'" binding:"omitempty"`
	Command        string `json:"command" gorm:"type:text"`                                // ajustar para que n√£o seja obrigat√≥rio, mas revisar a l√≥gica de execu√ß√£o antes
	Method         string `json:"method" gorm:"type:enum('GET', 'POST', 'PUT', 'DELETE')"` // ajustar para que n√£o seja obrigat√≥rio, mas revisar a l√≥gica de execu√ß√£o antes
	APIEndpoint    string `json:"api_endpoint" gorm:"type:varchar(255)"`
	LastRunStatus  string `json:"last_run_status" gorm:"type:enum('success', 'failure', 'pending');default:'pending'" binding:"omitempty"`
	LastRunMessage string `json:"last_run_message" gorm:"type:text" binding:"omitempty"`

	Retries          int `json:"retries" gorm:"default:0" binding:"omitempty"`
	ExecTimeout      int `json:"exec_timeout" gorm:"default:30" binding:"omitempty"`
	MaxRetries       int `json:"max_retries" gorm:"default:3" binding:"omitempty"`
	RetryInterval    int `json:"retry_interval" gorm:"default:10" binding:"omitempty"`
	MaxExecutionTime int `json:"max_execution_time" gorm:"default:300" binding:"omitempty"`

	IsRecurring bool `json:"is_recurring" gorm:"default:false" binding:"omitempty"`
	IsActive    bool `json:"is_active" gorm:"default:true" binding:"omitempty"`

	StartsAt  time.Time `json:"starts_at" gorm:"default:now()" binding:"omitempty"`
	CreatedAt time.Time `json:"created_at" gorm:"default:now()" binding:"omitempty"`

	EndsAt         *time.Time `json:"ends_at" binding:"omitempty"`
	LastRunTime    *time.Time `json:"last_run_time" binding:"omitempty"`
	UpdatedAt      *time.Time `json:"updated_at" gorm:"default:now()" binding:"omitempty"`
	LastExecutedAt *time.Time `json:"last_executed_at" binding:"omitempty"`

	Payload t.JsonB `json:"payload" binding:"omitempty"`
	Headers t.JsonB `json:"headers" binding:"omitempty"`

	Metadata t.JsonB `json:"metadata" binding:"omitempty"`
}

func NewCronJob(ctx context.Context, cron *CronJob, restrict bool) ICronJobModel {
	if cron == nil {
		cron = &CronJob{}
	}
	cv := NewCronModelValidation(ctx, l.GetLogger(""), false)
	cronV, err := cv.ValidateCronJobProperties(ctx, cron, restrict)
	if err != nil {
		gl.Log("error", "Failed to validate cron job properties")
		return nil
	}
	if cronV == nil {
		gl.Log("error", "Cron job is nil after validation")
		return nil
	}
	return cronV
}

func (c *CronJob) TableName() string                           { return "cron_jobs" }
func (c *CronJob) PrimaryKey() string                          { return "id" }
func (c *CronJob) GetID() uuid.UUID                            { return c.ID }
func (c *CronJob) SetID(id uuid.UUID)                          { c.ID = id }
func (c *CronJob) GetCreatedAt() time.Time                     { return c.CreatedAt }
func (c *CronJob) SetCreatedAt(createdAt time.Time)            { c.CreatedAt = createdAt }
func (c *CronJob) GetUpdatedAt() *time.Time                    { return c.UpdatedAt }
func (c *CronJob) SetUpdatedAt(updatedAt *time.Time)           { c.UpdatedAt = updatedAt }
func (c *CronJob) GetCreatedBy() uuid.UUID                     { return c.CreatedBy }
func (c *CronJob) SetCreatedBy(createdBy uuid.UUID)            { c.CreatedBy = createdBy }
func (c *CronJob) GetUpdatedBy() uuid.UUID                     { return c.UpdatedBy }
func (c *CronJob) SetUpdatedBy(updatedBy uuid.UUID)            { c.UpdatedBy = updatedBy }
func (c *CronJob) GetLastExecutedAt() *time.Time               { return c.LastExecutedAt }
func (c *CronJob) SetLastExecutedAt(lastExecutedAt *time.Time) { c.LastExecutedAt = lastExecutedAt }
func (c *CronJob) GetLastExecutedBy() uuid.UUID                { return c.LastExecutedBy }
func (c *CronJob) SetLastExecutedBy(lastExecutedBy uuid.UUID)  { c.LastExecutedBy = lastExecutedBy }
func (c *CronJob) GetUserID() uuid.UUID                        { return c.UserID }
func (c *CronJob) SetUserID(userID uuid.UUID)                  { c.UserID = userID }

// Add a method to enqueue a job into the JobQueue
func (c *CronJob) EnqueueJob(ctx context.Context, jobQueueService jobqueue.IJobQueueService) error {
	job := &jobqueue.JobQueue{
		CronJobID:      c.ID,
		Status:         "pending",
		ScheduledAt:    time.Now(),
		ExecutionTime:  time.Now().Add(time.Duration(c.ExecTimeout) * time.Second),
		JobType:        "cron",
		JobExpression:  c.CronExpression,
		JobCommand:     c.Command,
		JobMethod:      c.Method,
		JobAPIEndpoint: c.APIEndpoint,
		JobPayload:     c.Payload,
		JobHeaders:     c.Headers,
		JobRetries:     c.Retries,
		JobTimeout:     c.ExecTimeout,
		UserID:         c.UserID,
		CreatedBy:      c.CreatedBy,
		UpdatedBy:      c.UpdatedBy,
	}
	_, err := jobQueueService.CreateJob(ctx, job)
	return err
}

// LogExecutionDetails logs execution details into the ExecutionLog using the provided service.
func (c *CronJob) LogExecutionDetails(ctx context.Context, service jobqueue.IExecutionLogService, details jobqueue.ExecutionLog) error {
	return service.CreateLog(ctx, details)
}

// PrepareForSave ensures all required fields are set before saving a CronJob.
func (c *CronJob) PrepareForSave(ctx context.Context, defaultUserID uuid.UUID) {
	if c.UserID == uuid.Nil {
		c.UserID = defaultUserID
	}
	if c.CreatedBy == uuid.Nil {
		c.CreatedBy = defaultUserID
	}
	if c.UpdatedBy == uuid.Nil {
		c.UpdatedBy = defaultUserID
	}
	if c.LastExecutedBy == uuid.Nil {
		c.LastExecutedBy = defaultUserID
	}
}

func (c *CronJob) CronJobObject() *CronJob { return c }

/// internal/models/cron/cronjob_repo.go ///
package cron

import (
	"context"
	"time"

	"github.com/google/uuid"
	"gorm.io/gorm"
)

type ICronJobRepo interface {
	Create(ctx context.Context, job *CronJob) (*CronJob, error)
	FindByID(ctx context.Context, id uuid.UUID) (*CronJob, error)
	FindAll(ctx context.Context) ([]*CronJob, error)
	Update(ctx context.Context, job *CronJob) (*CronJob, error)
	Delete(ctx context.Context, id uuid.UUID) error
}

type CronJobRepo struct {
	DB *gorm.DB
}

func NewCronJobRepo(ctx context.Context, db *gorm.DB) ICronJobRepo {
	return &CronJobRepo{DB: db}
}

func (r *CronJobRepo) Create(ctx context.Context, job *CronJob) (*CronJob, error) {
	userID, ok := ctx.Value("userID").(uuid.UUID)
	if !ok {
		return nil, gorm.ErrRecordNotFound
	}
	job.CreatedAt = time.Now()
	job.UserID = userID
	job.CreatedBy = userID
	job.UpdatedBy = userID
	job.LastExecutedBy = userID
	job.UpdatedAt = &job.CreatedAt
	job.LastExecutedAt = nil
	job.LastRunTime = nil
	if job.LastRunStatus == "" {
		job.LastRunStatus = "pending"
	}
	if job.ID == uuid.Nil {
		var err error
		job.ID, err = uuid.NewRandom()
		if err != nil {
			return nil, err
		}
	}
	if err := r.DB.WithContext(ctx).Create(job).Error; err != nil {
		return nil, err
	}
	return job, nil
}

func (r *CronJobRepo) FindByID(ctx context.Context, id uuid.UUID) (*CronJob, error) {
	var job CronJob
	if err := r.DB.WithContext(ctx).First(&job, "id = ?", id).Error; err != nil {
		return nil, err
	}
	return &job, nil
}

func (r *CronJobRepo) FindAll(ctx context.Context) ([]*CronJob, error) {
	var jobs []*CronJob
	if err := r.DB.WithContext(ctx).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}

func (r *CronJobRepo) Update(ctx context.Context, job *CronJob) (*CronJob, error) {
	if err := r.DB.WithContext(ctx).Save(job).Error; err != nil {
		return nil, err
	}
	return job, nil
}

func (r *CronJobRepo) Delete(ctx context.Context, id uuid.UUID) error {
	if err := r.DB.WithContext(ctx).Delete(&CronJob{}, "id = ?", id).Error; err != nil {
		return err
	}
	return nil
}

/// internal/models/cron/cronjob_service.go ///
package cron

import (
	"context"
	"errors"
	"fmt"
	"log"
	"strings"
	"time"

	"github.com/google/uuid"
	jobqueue "github.com/rafa-mori/gdbase/internal/models/job_queue"
	gl "github.com/rafa-mori/gdbase/logger"
	"github.com/streadway/amqp"
)

type ICronJobService interface {
	CreateCronJob(ctx context.Context, job *CronJob) (*CronJob, error)
	GetCronJobByID(ctx context.Context, id uuid.UUID) (*CronJob, error)
	ListCronJobs(ctx context.Context) ([]*CronJob, error)
	UpdateCronJob(ctx context.Context, job *CronJob) (*CronJob, error)
	DeleteCronJob(ctx context.Context, id uuid.UUID) error
	EnableCronJob(ctx context.Context, id uuid.UUID) error
	DisableCronJob(ctx context.Context, id uuid.UUID) error
	ExecuteCronJobManually(ctx context.Context, id uuid.UUID) error
	ListActiveCronJobs(ctx context.Context) ([]*CronJob, error)
	RescheduleCronJob(ctx context.Context, id uuid.UUID, newExpression string) error
	ValidateCronExpression(ctx context.Context, expression string) error
	GetJobQueue(ctx context.Context) ([]jobqueue.JobQueue, error)
	ReprocessFailedJobs(ctx context.Context) error
	GetExecutionLogs(ctx context.Context, cronJobID uuid.UUID) ([]jobqueue.ExecutionLog, error)
}

type CronJobService struct {
	Repo ICronJobRepo
}

func NewCronJobService(repo ICronJobRepo) ICronJobService {
	return &CronJobService{Repo: repo}
}

func (s *CronJobService) publishToRabbitMQ(ctx context.Context, queueName string, message string) error {
	conn, err := amqp.Dial("amqp://guest:guest@localhost:5672/")
	if err != nil {
		log.Printf("Failed to connect to RabbitMQ: %s", err)
		return err
	}
	defer conn.Close()

	ch, err := conn.Channel()
	if err != nil {
		log.Printf("Failed to open a channel: %s", err)
		return err
	}
	defer ch.Close()

	q, err := ch.QueueDeclare(
		queueName,
		false,
		false,
		false,
		false,
		nil,
	)
	if err != nil {
		log.Printf("Failed to declare a queue: %s", err)
		return err
	}

	err = ch.Publish(
		"",
		q.Name,
		false,
		false,
		amqp.Publishing{
			ContentType: "text/plain",
			Body:        []byte(message),
		},
	)
	if err != nil {
		log.Printf("Failed to publish a message: %s", err)
		return err
	}

	log.Printf("Message published to queue %s: %s", queueName, message)
	return nil
}

func (s *CronJobService) CreateCronJob(ctx context.Context, job *CronJob) (*CronJob, error) {
	if job.Name == "" {
		return nil, errors.New("job name is required")
	}

	artifact := NewCronJob(ctx, job, false).CronJobObject()
	if artifact == nil {
		gl.Log("error", "Failed to create cron job object")
		return nil, errors.New("failed to create cron job object")
	}

	createdJob, err := s.Repo.Create(ctx, artifact)
	if err != nil {
		return nil, err
	}

	// Publish to RabbitMQ
	if err := s.publishToRabbitMQ(ctx, "cronjob_events", "CronJob Created: "+createdJob.ID.String()); err != nil {
		log.Printf("Failed to publish create event: %s", err)
	}

	return createdJob, nil
}

func (s *CronJobService) GetCronJobByID(ctx context.Context, id uuid.UUID) (*CronJob, error) {
	return s.Repo.FindByID(ctx, id)
}

func (s *CronJobService) ListCronJobs(ctx context.Context) ([]*CronJob, error) {
	return s.Repo.FindAll(ctx)
}

func (s *CronJobService) UpdateCronJob(ctx context.Context, job *CronJob) (*CronJob, error) {
	if job.ID == uuid.Nil {
		return nil, errors.New("job ID is required")
	}
	updatedJob, err := s.Repo.Update(ctx, job)
	if err != nil {
		return nil, err
	}

	// Publish to RabbitMQ
	if err := s.publishToRabbitMQ(ctx, "cronjob_events", "CronJob Updated: "+updatedJob.ID.String()); err != nil {
		log.Printf("Failed to publish update event: %s", err)
	}

	return updatedJob, nil
}

func (s *CronJobService) DeleteCronJob(ctx context.Context, id uuid.UUID) error {
	if id == uuid.Nil {
		return errors.New("job ID is required")
	}
	if err := s.Repo.Delete(ctx, id); err != nil {
		return err
	}

	// Publish to RabbitMQ
	if err := s.publishToRabbitMQ(ctx, "cronjob_events", "CronJob Deleted: "+id.String()); err != nil {
		log.Printf("Failed to publish delete event: %s", err)
	}

	return nil
}

func (s *CronJobService) EnableCronJob(ctx context.Context, id uuid.UUID) error {
	job, err := s.Repo.FindByID(ctx, id)
	if err != nil {
		return err
	}
	job.IsActive = true
	_, err = s.Repo.Update(ctx, job)
	return err
}

func (s *CronJobService) DisableCronJob(ctx context.Context, id uuid.UUID) error {
	job, err := s.Repo.FindByID(ctx, id)
	if err != nil {
		return err
	}
	job.IsActive = false
	_, err = s.Repo.Update(ctx, job)
	return err
}

func (s *CronJobService) ExecuteCronJobManually(ctx context.Context, id uuid.UUID) error {
	job, err := s.Repo.FindByID(ctx, id)
	if err != nil {
		return err
	}
	// Simulate execution logic here (e.g., log execution or trigger a worker)
	job.LastRunStatus = "success"
	now := time.Now().UTC()
	job.LastRunTime = &now
	_, err = s.Repo.Update(ctx, job)
	return err
}

func (s *CronJobService) ListActiveCronJobs(ctx context.Context) ([]*CronJob, error) {
	cronList, err := s.Repo.FindAll(ctx)
	if err != nil {
		return nil, err
	}
	var activeCronJobs []*CronJob
	for _, job := range cronList {
		if job.IsActive {
			activeCronJobs = append(activeCronJobs, job)
		}
	}
	return activeCronJobs, nil
}

func (s *CronJobService) RescheduleCronJob(ctx context.Context, id uuid.UUID, newExpression string) error {
	job, err := s.Repo.FindByID(ctx, id)
	if err != nil {
		return err
	}
	job.CronExpression = newExpression
	_, err = s.Repo.Update(ctx, job)
	return err
}

func (s *CronJobService) ValidateCronExpression(ctx context.Context, expression string) error {
	expression = strings.TrimSpace(expression)
	if expression == "" {
		return errors.New("cron expression cannot be empty")
	}
	// Implement cron expression validation logic here.
	// For example, you can use a library like "github.com/robfig/cron/v3" to validate the expression.
	// _, err := cron.ParseStandard(expression)
	return fmt.Errorf("cron expression '%s' is not valid", expression)
}

// GetJobQueue retrieves the current state of the job queue.
func (s *CronJobService) GetJobQueue(ctx context.Context) ([]jobqueue.JobQueue, error) {
	// Implement logic to fetch the job queue from the repository.
	return nil, errors.New("not implemented")
}

// ReprocessFailedJobs reprocesses all failed jobs in the queue.
func (s *CronJobService) ReprocessFailedJobs(ctx context.Context) error {
	// Implement logic to reprocess failed jobs.
	return errors.New("not implemented")
}

// GetExecutionLogs retrieves execution logs for a specific cron job.
func (s *CronJobService) GetExecutionLogs(ctx context.Context, cronJobID uuid.UUID) ([]jobqueue.ExecutionLog, error) {
	// Implement logic to fetch execution logs from the repository.
	return nil, errors.New("not implemented")
}

// SaveCronJob ensures all required fields are set and saves the CronJob.
func (s *CronJobService) SaveCronJob(ctx context.Context, job *CronJob, defaultUserID uuid.UUID) error {
	// Preencher campos automaticamente
	job.PrepareForSave(ctx, defaultUserID)

	// Salvar no reposit√≥rio usando o m√©todo Update
	_, err := s.Repo.Update(ctx, job)
	return err
}

/// internal/models/dsts.go ///
package models

import (
	"fmt"
	"reflect"

	"github.com/goccy/go-json"
	ci "github.com/rafa-mori/gdbase/internal/interfaces"
)

type Model interface {
	ci.IReference // Aqui tem nome e ID (uuid)
	Validate() error
}

var ModelList = make([]interface{}, 0) /*{
	//&UserImpl{},
	//&Product{},
	//&CustomerImpl{},
	//&Order{},
})*/
var ModelRegistryMap = map[reflect.Type]any{
	//strings.ToLower("User"):     reflect.TypeOf(UserImpl{}),
	//strings.ToLower("Product"):  reflect.TypeOf(Product{}),
	//strings.ToLower("Customer"): reflect.TypeOf(CustomerImpl{}),
	//strings.ToLower("Order"):    reflect.TypeOf(Order{}),
	//strings.ToLower("Ping"):     reflect.TypeOf(PingImpl{}),
}

type ModelRegistryImpl[T Model] struct {
	Dt *T     `json:"data"`
	St []byte `json:"status"`
}
type ModelRegistryInterface interface {
	GetType() reflect.Type
	FromModel(model interface{}) ModelRegistryInterface
	FromSerialized(data []byte) (ModelRegistryInterface, error)
	ToModel() interface{}
}

func (m *ModelRegistryImpl[T]) GetType() reflect.Type { return reflect.TypeFor[T]() }

func (m *ModelRegistryImpl[T]) FromModel(model interface{}) ModelRegistryInterface {
	if model == nil {
		return nil
	}
	// Ficou assim para evitar o loop de importa√ß√£o, ta lind√£o!
	md, ok := model.(*T)
	if ok {
		vl := reflect.ValueOf(md)
		if !vl.IsValid() || vl.IsNil() {
			return nil
		}
		if (*md).Validate() != nil {
			return nil
		}

		// Agora s√£o ponteiros pro mesmo valor?
		// Se n√£o for um ponteiro, cria um novo ponteiro
		m.Dt = md
		m.St, _ = json.Marshal(m.Dt)
	}
	if m.Dt == nil {
		return nil
	}
	// Verifica se o tipo do modelo est√° registrado
	if _, ok := ModelRegistryMap[reflect.TypeOf(m.Dt)]; !ok {
		return nil
	}
	return m
}
func (m *ModelRegistryImpl[T]) FromSerialized(data []byte) (ModelRegistryInterface, error) {
	var mdr ModelRegistryImpl[T]
	if err := json.Unmarshal(data, &mdr); err != nil {
		return nil, err
	}
	// Retorna o tipo que est√° impl√≠cito na estrutura pelo generic T
	// Assim n√£o √© preciso armazenar o tipo do modelo
	// Verifica se o tipo do modelo est√° registrado
	if _, ok := ModelRegistryMap[mdr.GetType()]; !ok {
		return nil, fmt.Errorf("model %s not found", mdr.GetType())
	}
	return &mdr, nil
}
func (m *ModelRegistryImpl[T]) ToModel() interface{} {
	if model, ok := ModelRegistryMap[m.GetType()]; ok {
		// Verifica se est√° nulo o objeto e se existe de fato no map.
		// Se n√£o existir, retorna nil
		if model != nil {
			return model
		}
	}
	return nil
}

func RegisterModel(modelType reflect.Type) error {
	// Ferrou porque n√£o tem mais como guardar o nome.. rsrs
	if _, exists := ModelRegistryMap[modelType]; exists {
		return fmt.Errorf("model %s j√° registrado", modelType.String())
	}
	// O map armazena valores pelo tipo do modelo, ent√£o como estamos s√≥
	// registrando o tipo, n√£o precisamos guardar valor. O nome est√° impl√≠cito
	// na interface Model. S√≥ implementar l√°. rsrs
	ModelRegistryMap[modelType] = nil
	return nil
}
func NewModelRegistry[T Model]() ModelRegistryInterface {
	return &ModelRegistryImpl[T]{}
}
func NewModelRegistryFromModel[T Model](model interface{}) ModelRegistryInterface {
	mr := ModelRegistryImpl[T]{}
	return mr.FromModel(model)
}
func NewModelRegistryFromSerialized[T Model](data []byte) (ModelRegistryInterface, error) {
	mr := ModelRegistryImpl[T]{}
	return mr.FromSerialized(data)
}

/// internal/models/dsts_test.go ///
package models

import (
	"errors"
	"reflect"
	"testing"

	"github.com/goccy/go-json"
	"github.com/google/uuid"
	typ "github.com/rafa-mori/gdbase/internal/types"
	"github.com/stretchr/testify/assert"
)

// Mock implementation of the Model interface
type MockModel struct {
	*typ.Reference
	ID    uuid.UUID
	Valid bool
}

func (m *MockModel) GetID() uuid.UUID {
	return m.ID
}

func (m *MockModel) Validate() error {
	if m.Valid {
		return nil
	}
	return errors.New("validation failed")
}

func TestFromModel(t *testing.T) {
	// Register the MockModel type
	mockModelType := reflect.TypeOf(&MockModel{})
	err := RegisterModel(mockModelType)
	assert.NoError(t, err)

	t.Run("Valid Model", func(t *testing.T) {
		validModel := &MockModel{ID: uuid.New(), Valid: true, Reference: typ.NewReference("123").GetReference()}

		// O tipo generic √© sempre uma interface referindo ao Model,
		// Ent√£o √© sempre um ponteiro.
		registry := NewModelRegistry[Model]()
		result := registry.FromModel(validModel)

		assert.NotNil(t, result)

		vl := reflect.ValueOf(result)
		assert.Equal(t, reflect.Ptr, vl.Kind())
		assert.Equal(t, reflect.TypeOf(validModel), vl.Type())
		if reConverted, ok := vl.Interface().(*MockModel); ok {
			// Type assertion successful
			assert.Equal(t, validModel.GetID(), reConverted.GetID())
			assert.NoError(t, reConverted.Validate())
		} else {
			// Type assertion failed
			t.Errorf("Expected type *MockModel, got %T", result)
		}

	})

	t.Run("Nil Model", func(t *testing.T) {
		// a quest√£o √© o MockModel n√£o est√° implementando o Model,
		// ent√£o n√£o √© poss√≠vel fazer o type assertion.
		// O tipo generic √© sempre uma interface referindo ao Model,
		// Ent√£o √© sempre um ponteiro.
		registry := NewModelRegistry[*MockModel]()
		result := registry.FromModel(nil)

		assert.Nil(t, result)
	})

	t.Run("Invalid Model", func(t *testing.T) {
		invalidModel := &MockModel{ID: uuid.New(), Valid: false}
		registry := NewModelRegistry[*MockModel]()
		result := registry.FromModel(invalidModel)

		assert.Nil(t, result)
	})

	t.Run("Unregistered Model", func(t *testing.T) {
		unregisteredModel := &struct {
			ID string
		}{ID: "456"}
		registry := NewModelRegistry[*MockModel]()
		result := registry.FromModel(unregisteredModel)

		assert.Nil(t, result)
	})
}

func TestSerialization(t *testing.T) {
	t.Run("Serialize and Deserialize Valid Model", func(t *testing.T) {
		validModel := &MockModel{ID: uuid.New(), Valid: true, Reference: typ.NewReference("123").GetReference()}
		registry := NewModelRegistry[*MockModel]()
		registry.FromModel(validModel)

		// Serialize
		data, err := json.Marshal(registry)
		assert.NoError(t, err)

		// Deserialize
		deserializedRegistry, err := NewModelRegistryFromSerialized[*MockModel](data)
		assert.NoError(t, err)

		// Convert back to model
		deserializedModel := deserializedRegistry.ToModel().(*MockModel)
		assert.Equal(t, validModel.GetID(), deserializedModel.GetID())
		assert.NoError(t, deserializedModel.Validate())
	})
}

/// internal/models/job_queue/job_queue.go ///
package jobqueue

import (
	"context"
	"time"

	"github.com/google/uuid"
	t "github.com/rafa-mori/gdbase/types"
)

type IJobQueue interface {
	TableName() string
	GetID() uuid.UUID
	SetID(id uuid.UUID)
	GetCronJobID() uuid.UUID
	SetCronJobID(cronJobID uuid.UUID)
	GetStatus() string
	SetStatus(status string)
	GetScheduledAt() time.Time
	SetScheduledAt(scheduledAt time.Time)
	GetExecutionTime() time.Time
	SetExecutionTime(executionTime time.Time)
	GetErrorMessage() string
	SetErrorMessage(errorMessage string)
	GetRetryCount() int
	SetRetryCount(retryCount int)
	GetNextRunTime() time.Time
	SetNextRunTime(nextRunTime time.Time)
	GetCreatedAt() time.Time
	SetCreatedAt(createdAt time.Time)
	GetUpdatedAt() time.Time
	SetUpdatedAt(updatedAt time.Time)
	GetMetadata() string
	SetMetadata(metadata string)
	GetUserID() uuid.UUID
	SetUserID(userID uuid.UUID)
	GetCreatedBy() uuid.UUID
	SetCreatedBy(createdBy uuid.UUID)
	GetUpdatedBy() uuid.UUID
	SetUpdatedBy(updatedBy uuid.UUID)
	GetLastExecutedBy() uuid.UUID
	SetLastExecutedBy(lastExecutedBy uuid.UUID)
	GetJobType() string
	SetJobType(jobType string)
	GetJobExpression() string
	SetJobExpression(jobExpression string)
	GetJobCommand() string
	SetJobCommand(jobCommand string)
	GetJobMethod() string
	SetJobMethod(jobMethod string)
	GetJobAPIEndpoint() string
	SetJobAPIEndpoint(jobAPIEndpoint string)
	GetJobPayload() string
	SetJobPayload(jobPayload string)
	GetJobHeaders() string
	SetJobHeaders(jobHeaders string)
	GetJobRetries() int
	SetJobRetries(jobRetries int)
	GetJobTimeout() int
	SetJobTimeout(jobTimeout int)
}

type JobQueue struct {
	ID             uuid.UUID `json:"id" xml:"id" yaml:"id" gorm:"column:id;primaryKey;type:uuid;default:uuid_generate_v4()"`
	Code           int       `json:"code" xml:"code" yaml:"code" gorm:"column:code;primaryKey;autoIncrement"`
	CronJobID      uuid.UUID `json:"cronjob_id" xml:"cronjob_id" yaml:"cronjob_id" gorm:"column:cronjob_id"`
	Status         string    `json:"status" xml:"status" yaml:"status" gorm:"column:status;default:'PENDING'"`
	ScheduledAt    time.Time `json:"scheduled_time" xml:"scheduled_time" yaml:"scheduled_time" gorm:"column:scheduled_time;default:now()"`
	ExecutionTime  time.Time `json:"execution_time" xml:"execution_time" yaml:"execution_time" gorm:"column:execution_time"`
	ErrorMessage   string    `json:"error_message" xml:"error_message" yaml:"error_message" gorm:"column:error_message;default:null"`
	RetryCount     int       `json:"retry_count" xml:"retry_count" yaml:"retry_count" gorm:"column:retry_count;default:0"`
	NextRunTime    time.Time `json:"next_run_time" xml:"next_run_time" yaml:"next_run_time" gorm:"column:next_run_time"`
	CreatedAt      time.Time `json:"created_at" xml:"created_at" yaml:"created_at" gorm:"column:created_at;default:now()"`
	UpdatedAt      time.Time `json:"updated_at" xml:"updated_at" yaml:"updated_at" gorm:"column:updated_at;default:now()"`
	Metadata       string    `json:"metadata" xml:"metadata" yaml:"metadata" gorm:"column:metadata;default:null"`
	UserID         uuid.UUID `json:"user_id" xml:"user_id" yaml:"user_id" gorm:"column:user_id;references:users(id)"`
	CreatedBy      uuid.UUID `json:"created_by" xml:"created_by" yaml:"created_by" gorm:"column:created_by;references:users(id)"`
	UpdatedBy      uuid.UUID `json:"updated_by" xml:"updated_by" yaml:"updated_by" gorm:"column:updated_by;references:users(id)"`
	LastExecutedBy uuid.UUID `json:"last_executed_by" xml:"last_executed_by" yaml:"last_executed_by" gorm:"column:last_executed_by;references:users(id)"`
	JobType        string    `json:"job_type" xml:"job_type" yaml:"job_type" gorm:"column:job_type;default:'cron'"`
	JobExpression  string    `json:"job_expression" xml:"job_expression" yaml:"job_expression" gorm:"column:job_expression;default:'2 * * * *'"`
	JobCommand     string    `json:"job_command" xml:"job_command" yaml:"job_command" gorm:"column:job_command"`
	JobMethod      string    `json:"job_method" xml:"job_method" yaml:"job_method" gorm:"column:job_method"`
	JobAPIEndpoint string    `json:"job_api_endpoint" xml:"job_api_endpoint" yaml:"job_api_endpoint" gorm:"column:job_api_endpoint"`
	JobPayload     t.JsonB   `json:"job_payload" xml:"job_payload" yaml:"job_payload" gorm:"column:job_payload"`
	JobHeaders     t.JsonB   `json:"job_headers" xml:"job_headers" yaml:"job_headers" gorm:"column:job_headers"`
	JobRetries     int       `json:"job_retries" xml:"job_retries" yaml:"job_retries" gorm:"column:job_retries;default:0"`
	JobTimeout     int       `json:"job_timeout" xml:"job_timeout" yaml:"job_timeout" gorm:"column:job_timeout;default:0"`
}

func (j *JobQueue) TableName() string                          { return "job_queue" }
func (j *JobQueue) GetID() uuid.UUID                           { return j.ID }
func (j *JobQueue) GetCode() int                               { return j.Code }
func (j *JobQueue) SetCode(code int)                           { j.Code = code }
func (j *JobQueue) SetID(id uuid.UUID)                         { j.ID = id }
func (j *JobQueue) GetCronJobID() uuid.UUID                    { return j.CronJobID }
func (j *JobQueue) SetCronJobID(cronJobID uuid.UUID)           { j.CronJobID = cronJobID }
func (j *JobQueue) GetStatus() string                          { return j.Status }
func (j *JobQueue) SetStatus(status string)                    { j.Status = status }
func (j *JobQueue) GetScheduledAt() time.Time                  { return j.ScheduledAt }
func (j *JobQueue) SetScheduledAt(scheduledAt time.Time)       { j.ScheduledAt = scheduledAt }
func (j *JobQueue) GetExecutionTime() time.Time                { return j.ExecutionTime }
func (j *JobQueue) SetExecutionTime(executionTime time.Time)   { j.ExecutionTime = executionTime }
func (j *JobQueue) GetErrorMessage() string                    { return j.ErrorMessage }
func (j *JobQueue) SetErrorMessage(errorMessage string)        { j.ErrorMessage = errorMessage }
func (j *JobQueue) GetRetryCount() int                         { return j.RetryCount }
func (j *JobQueue) SetRetryCount(retryCount int)               { j.RetryCount = retryCount }
func (j *JobQueue) GetNextRunTime() time.Time                  { return j.NextRunTime }
func (j *JobQueue) SetNextRunTime(nextRunTime time.Time)       { j.NextRunTime = nextRunTime }
func (j *JobQueue) GetCreatedAt() time.Time                    { return j.CreatedAt }
func (j *JobQueue) SetCreatedAt(createdAt time.Time)           { j.CreatedAt = createdAt }
func (j *JobQueue) GetUpdatedAt() time.Time                    { return j.UpdatedAt }
func (j *JobQueue) SetUpdatedAt(updatedAt time.Time)           { j.UpdatedAt = updatedAt }
func (j *JobQueue) GetMetadata() string                        { return j.Metadata }
func (j *JobQueue) SetMetadata(metadata string)                { j.Metadata = metadata }
func (j *JobQueue) GetUserID() uuid.UUID                       { return j.UserID }
func (j *JobQueue) SetUserID(userID uuid.UUID)                 { j.UserID = userID }
func (j *JobQueue) GetCreatedBy() uuid.UUID                    { return j.CreatedBy }
func (j *JobQueue) SetCreatedBy(createdBy uuid.UUID)           { j.CreatedBy = createdBy }
func (j *JobQueue) GetUpdatedBy() uuid.UUID                    { return j.UpdatedBy }
func (j *JobQueue) SetUpdatedBy(updatedBy uuid.UUID)           { j.UpdatedBy = updatedBy }
func (j *JobQueue) GetLastExecutedBy() uuid.UUID               { return j.LastExecutedBy }
func (j *JobQueue) SetLastExecutedBy(lastExecutedBy uuid.UUID) { j.LastExecutedBy = lastExecutedBy }
func (j *JobQueue) GetJobType() string                         { return j.JobType }
func (j *JobQueue) SetJobType(jobType string)                  { j.JobType = jobType }
func (j *JobQueue) GetJobExpression() string                   { return j.JobExpression }
func (j *JobQueue) SetJobExpression(jobExpression string)      { j.JobExpression = jobExpression }
func (j *JobQueue) GetJobCommand() string                      { return j.JobCommand }
func (j *JobQueue) SetJobCommand(jobCommand string)            { j.JobCommand = jobCommand }
func (j *JobQueue) GetJobMethod() string                       { return j.JobMethod }
func (j *JobQueue) SetJobMethod(jobMethod string)              { j.JobMethod = jobMethod }
func (j *JobQueue) GetJobAPIEndpoint() string                  { return j.JobAPIEndpoint }
func (j *JobQueue) SetJobAPIEndpoint(jobAPIEndpoint string)    { j.JobAPIEndpoint = jobAPIEndpoint }
func (j *JobQueue) GetJobPayload() t.JsonB                     { return j.JobPayload }
func (j *JobQueue) SetJobPayload(jobPayload t.JsonB)           { j.JobPayload = jobPayload }
func (j *JobQueue) GetJobHeaders() t.JsonB                     { return j.JobHeaders }
func (j *JobQueue) SetJobHeaders(jobHeaders t.JsonB)           { j.JobHeaders = jobHeaders }
func (j *JobQueue) GetJobRetries() int                         { return j.JobRetries }
func (j *JobQueue) SetJobRetries(jobRetries int)               { j.JobRetries = jobRetries }
func (j *JobQueue) GetJobTimeout() int                         { return j.JobTimeout }
func (j *JobQueue) SetJobTimeout(jobTimeout int)               { j.JobTimeout = jobTimeout }

type IExecutionLog interface {
	TableName() string
	GetID() uuid.UUID
	SetID(id uuid.UUID)
	GetCronJobID() uuid.UUID
	SetCronJobID(cronJobID uuid.UUID)
	GetExecutionTime() time.Time
	SetExecutionTime(executionTime time.Time)
	GetStatus() uuid.UUID
	SetStatus(status uuid.UUID)
	GetOutput() uuid.UUID
	SetOutput(output uuid.UUID)
	GetErrorMessage() uuid.UUID
	SetErrorMessage(errorMessage uuid.UUID)
	GetRetryCount() int
	SetRetryCount(retryCount int)
	GetCreatedAt() time.Time
	SetCreatedAt(createdAt time.Time)
	GetUpdatedAt() time.Time
	SetUpdatedAt(updatedAt time.Time)
	GetUserID() uuid.UUID
	SetUserID(userID uuid.UUID)
	GetCreatedBy() uuid.UUID
	SetCreatedBy(createdBy uuid.UUID)
	GetUpdatedBy() uuid.UUID
	SetUpdatedBy(updatedBy uuid.UUID)
	GetMetadata() string
	SetMetadata(metadata string)
}

type ExecutionLog struct {
	ID            uuid.UUID `json:"id" xml:"id" yaml:"id" gorm:"column:id;primaryKey;type:uuid;default:uuid_generate_v4()"`
	CronJobID     uuid.UUID `json:"cronjob_id" xml:"cronjob_id" yaml:"cronjob_id" gorm:"column:cronjob_id;type:uuid;references:CronJob(id)"`
	ExecutionTime time.Time `json:"execution_time" xml:"execution_time" yaml:"execution_time" gorm:"column:execution_time;default:now()"`
	Status        string    `json:"status" xml:"status" yaml:"status" gorm:"column:status;default:'PENDING'"`
	Output        string    `json:"output" xml:"output" yaml:"output" gorm:"column:output;default:null"`
	ErrorMessage  string    `json:"error_message" xml:"error_message" yaml:"error_message" gorm:"column:error_message;default:null"`
	RetryCount    int       `json:"retry_count" xml:"retry_count" yaml:"retry_count" gorm:"column:retry_count;default:0"`
	CreatedAt     time.Time `json:"created_at" xml:"created_at" yaml:"created_at" gorm:"column:created_at;default:now()"`
	UpdatedAt     time.Time `json:"updated_at" xml:"updated_at" yaml:"updated_at" gorm:"column:updated_at;default:now()"`
	UserID        uuid.UUID `json:"user_id" xml:"user_id" yaml:"user_id" gorm:"column:user_id;type:uuid;references:users(id)"`
	CreatedBy     uuid.UUID `json:"created_by" xml:"created_by" yaml:"created_by" gorm:"column:created_by;type:uuid;references:users(id)"`
	UpdatedBy     uuid.UUID `json:"updated_by" xml:"updated_by" yaml:"updated_by" gorm:"column:updated_by;type:uuid;references:users(id)"`
	Metadata      string    `json:"metadata" xml:"metadata" yaml:"metadata" gorm:"column:metadata;type:jsonb"`
}

func (e *ExecutionLog) TableName() string                        { return "execution_logs" }
func (e *ExecutionLog) GetID() uuid.UUID                         { return e.ID }
func (e *ExecutionLog) SetID(id uuid.UUID)                       { e.ID = id }
func (e *ExecutionLog) GetCronJobID() uuid.UUID                  { return e.CronJobID }
func (e *ExecutionLog) SetCronJobID(cronJobID uuid.UUID)         { e.CronJobID = cronJobID }
func (e *ExecutionLog) GetExecutionTime() time.Time              { return e.ExecutionTime }
func (e *ExecutionLog) SetExecutionTime(executionTime time.Time) { e.ExecutionTime = executionTime }
func (e *ExecutionLog) GetStatus() string                        { return e.Status }
func (e *ExecutionLog) SetStatus(status string)                  { e.Status = status }
func (e *ExecutionLog) GetOutput() string                        { return e.Output }
func (e *ExecutionLog) SetOutput(output string)                  { e.Output = output }
func (e *ExecutionLog) GetErrorMessage() string                  { return e.ErrorMessage }
func (e *ExecutionLog) SetErrorMessage(errorMessage string)      { e.ErrorMessage = errorMessage }
func (e *ExecutionLog) GetRetryCount() int                       { return e.RetryCount }
func (e *ExecutionLog) SetRetryCount(retryCount int)             { e.RetryCount = retryCount }
func (e *ExecutionLog) GetCreatedAt() time.Time                  { return e.CreatedAt }
func (e *ExecutionLog) SetCreatedAt(createdAt time.Time)         { e.CreatedAt = createdAt }
func (e *ExecutionLog) GetUpdatedAt() time.Time                  { return e.UpdatedAt }
func (e *ExecutionLog) SetUpdatedAt(updatedAt time.Time)         { e.UpdatedAt = updatedAt }
func (e *ExecutionLog) GetUserID() uuid.UUID                     { return e.UserID }
func (e *ExecutionLog) SetUserID(userID uuid.UUID)               { e.UserID = userID }
func (e *ExecutionLog) GetCreatedBy() uuid.UUID                  { return e.CreatedBy }
func (e *ExecutionLog) SetCreatedBy(createdBy uuid.UUID)         { e.CreatedBy = createdBy }
func (e *ExecutionLog) GetUpdatedBy() uuid.UUID                  { return e.UpdatedBy }
func (e *ExecutionLog) SetUpdatedBy(updatedBy uuid.UUID)         { e.UpdatedBy = updatedBy }
func (e *ExecutionLog) GetMetadata() string                      { return e.Metadata }
func (e *ExecutionLog) SetMetadata(metadata string)              { e.Metadata = metadata }

// IExecutionLogService defines the interface for execution log services.
type IExecutionLogService interface {
	CreateLog(ctx context.Context, log ExecutionLog) error
}

/// internal/models/job_queue/job_repo.go ///
package jobqueue

import (
	"context"
	"errors"
	"time"

	"github.com/google/uuid"
	"gorm.io/gorm"
)

type IJobQueueRepo interface {
	Create(ctx context.Context, job *JobQueue) (*JobQueue, error)
	FindByID(ctx context.Context, id uuid.UUID) (*JobQueue, error)
	FindAll(ctx context.Context) ([]*JobQueue, error)
	Update(ctx context.Context, job *JobQueue) (*JobQueue, error)
	Delete(ctx context.Context, id uuid.UUID) error
	FindByStatus(ctx context.Context, status string) ([]*JobQueue, error)
	FindByUserID(ctx context.Context, userID uuid.UUID) ([]*JobQueue, error)
	FindByType(ctx context.Context, jobType string) ([]*JobQueue, error)
	FindByCreatedAt(ctx context.Context, createdAt time.Time) ([]*JobQueue, error)
	FindByUpdatedAt(ctx context.Context, updatedAt time.Time) ([]*JobQueue, error)
	FindByCreatedBy(ctx context.Context, createdBy uuid.UUID) ([]*JobQueue, error)
	FindByUpdatedBy(ctx context.Context, updatedBy uuid.UUID) ([]*JobQueue, error)
	FindByLastExecutedAt(ctx context.Context, lastExecutedAt time.Time) ([]*JobQueue, error)
	FindByLastExecutedBy(ctx context.Context, lastExecutedBy uuid.UUID) ([]*JobQueue, error)
	FindByStatusAndUserID(ctx context.Context, status string, userID uuid.UUID) ([]*JobQueue, error)
	FindByStatusAndType(ctx context.Context, status string, jobType string) ([]*JobQueue, error)
	FindByStatusAndCreatedAt(ctx context.Context, status string, createdAt time.Time) ([]*JobQueue, error)
	FindByStatusAndUpdatedAt(ctx context.Context, status string, updatedAt time.Time) ([]*JobQueue, error)
	FindByStatusAndCreatedBy(ctx context.Context, status string, createdBy uuid.UUID) ([]*JobQueue, error)
	FindByStatusAndUpdatedBy(ctx context.Context, status string, updatedBy uuid.UUID) ([]*JobQueue, error)

	FindByStatusAndLastExecutedAt(ctx context.Context, status string, lastExecutedAt time.Time) ([]*JobQueue, error)
	FindByStatusAndLastExecutedBy(ctx context.Context, status string, lastExecutedBy uuid.UUID) ([]*JobQueue, error)
	FindByUserIDAndType(ctx context.Context, userID uuid.UUID, jobType string) ([]*JobQueue, error)
	FindByUserIDAndCreatedAt(ctx context.Context, userID uuid.UUID, createdAt time.Time) ([]*JobQueue, error)
	FindByUserIDAndCreatedBy(ctx context.Context, userID uuid.UUID, createdBy uuid.UUID) ([]*JobQueue, error)
	FindByUserIDAndUpdatedAt(ctx context.Context, userID uuid.UUID, updatedAt time.Time) ([]*JobQueue, error)
	FindByUserIDAndUpdatedBy(ctx context.Context, userID uuid.UUID, updatedBy uuid.UUID) ([]*JobQueue, error)
	FindByUserIDAndLastExecutedAt(ctx context.Context, userID uuid.UUID, lastExecutedAt time.Time) ([]*JobQueue, error)
	FindByUserIDAndLastExecutedBy(ctx context.Context, userID uuid.UUID, lastExecutedBy uuid.UUID) ([]*JobQueue, error)

	ExecuteJobManually(ctx context.Context, jobID uuid.UUID) error
	RetryFailedJob(ctx context.Context, jobID uuid.UUID) error
	RescheduleJob(ctx context.Context, jobID uuid.UUID, newSchedule time.Time) error
	ValidateJobSchedule(ctx context.Context, schedule string) error
}

type JobQueueRepository struct {
	db *gorm.DB
}

func NewJobQueueRepository(db *gorm.DB) IJobQueueRepo {
	return &JobQueueRepository{db: db}
}

// Implement repository methods here
func (repo *JobQueueRepository) Create(ctx context.Context, job *JobQueue) (*JobQueue, error) {
	if err := repo.db.Create(job).Error; err != nil {
		return nil, err
	}
	return job, nil
}
func (repo *JobQueueRepository) FindByID(ctx context.Context, id uuid.UUID) (*JobQueue, error) {
	var job JobQueue
	if err := repo.db.First(&job, "id = ?", id).Error; err != nil {
		return nil, err
	}
	return &job, nil
}
func (repo *JobQueueRepository) FindAll(ctx context.Context) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) Update(ctx context.Context, job *JobQueue) (*JobQueue, error) {
	if err := repo.db.Save(job).Error; err != nil {
		return nil, err
	}
	return job, nil
}
func (repo *JobQueueRepository) Delete(ctx context.Context, id uuid.UUID) error {
	if err := repo.db.Delete(&JobQueue{}, "id = ?", id).Error; err != nil {
		return err
	}
	return nil
}
func (repo *JobQueueRepository) FindByStatus(ctx context.Context, status string) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("status = ?", status).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUserID(ctx context.Context, userID uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("user_id = ?", userID).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByType(ctx context.Context, jobType string) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("type = ?", jobType).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByCreatedAt(ctx context.Context, createdAt time.Time) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("created_at = ?", createdAt).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUpdatedAt(ctx context.Context, updatedAt time.Time) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("updated_at = ?", updatedAt).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByCreatedBy(ctx context.Context, createdBy uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("created_by = ?", createdBy).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUpdatedBy(ctx context.Context, updatedBy uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("updated_by = ?", updatedBy).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByLastExecutedAt(ctx context.Context, lastExecutedAt time.Time) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("last_executed_at = ?", lastExecutedAt).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByLastExecutedBy(ctx context.Context, lastExecutedBy uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("last_executed_by = ?", lastExecutedBy).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByStatusAndUserID(ctx context.Context, status string, userID uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("status = ? AND user_id = ?", status, userID).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByStatusAndType(ctx context.Context, status string, jobType string) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("status = ? AND type = ?", status, jobType).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByStatusAndCreatedAt(ctx context.Context, status string, createdAt time.Time) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("status = ? AND created_at = ?", status, createdAt).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByStatusAndCreatedBy(ctx context.Context, status string, createdBy uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("status = ? AND created_by = ?", status, createdBy).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByStatusAndUpdatedAt(ctx context.Context, status string, updatedAt time.Time) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("status = ? AND updated_at = ?", status, updatedAt).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByStatusAndUpdatedBy(ctx context.Context, status string, updatedBy uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("status = ? AND updated_by = ?", status, updatedBy).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByStatusAndLastExecutedAt(ctx context.Context, status string, lastExecutedAt time.Time) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("status = ? AND last_executed_at = ?", status, lastExecutedAt).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByStatusAndLastExecutedBy(ctx context.Context, status string, lastExecutedBy uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("status = ? AND last_executed_by = ?", status, lastExecutedBy).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUserIDAndType(ctx context.Context, userID uuid.UUID, jobType string) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("user_id = ? AND type = ?", userID, jobType).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUserIDAndCreatedAt(ctx context.Context, userID uuid.UUID, createdAt time.Time) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("user_id = ? AND created_at = ?", userID, createdAt).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUserIDAndCreatedBy(ctx context.Context, userID uuid.UUID, createdBy uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("user_id = ? AND created_by = ?", userID, createdBy).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUserIDAndUpdatedAt(ctx context.Context, userID uuid.UUID, updatedAt time.Time) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("user_id = ? AND updated_at = ?", userID, updatedAt).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUserIDAndUpdatedBy(ctx context.Context, userID uuid.UUID, updatedBy uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("user_id = ? AND updated_by = ?", userID, updatedBy).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUserIDAndLastExecutedAt(ctx context.Context, userID uuid.UUID, lastExecutedAt time.Time) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("user_id = ? AND last_executed_at = ?", userID, lastExecutedAt).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) FindByUserIDAndLastExecutedBy(ctx context.Context, userID uuid.UUID, lastExecutedBy uuid.UUID) ([]*JobQueue, error) {
	var jobs []*JobQueue
	if err := repo.db.Where("user_id = ? AND last_executed_by = ?", userID, lastExecutedBy).Find(&jobs).Error; err != nil {
		return nil, err
	}
	return jobs, nil
}
func (repo *JobQueueRepository) ExecuteJobManually(ctx context.Context, jobID uuid.UUID) error {
	var job JobQueue
	if err := repo.db.First(&job, "id = ?", jobID).Error; err != nil {
		return err
	}
	job.Status = "executing"
	if err := repo.db.Save(&job).Error; err != nil {
		return err
	}
	// Execute the job logic here
	return nil
}
func (repo *JobQueueRepository) RetryFailedJob(ctx context.Context, jobID uuid.UUID) error {
	var job JobQueue
	if err := repo.db.First(&job, "id = ?", jobID).Error; err != nil {
		return err
	}
	job.Status = "retrying"
	if err := repo.db.Save(&job).Error; err != nil {
		return err
	}
	// Retry the job logic here
	return nil
}
func (repo *JobQueueRepository) RescheduleJob(ctx context.Context, jobID uuid.UUID, newSchedule time.Time) error {
	var job JobQueue
	if err := repo.db.First(&job, "id = ?", jobID).Error; err != nil {
		return err
	}
	job.ScheduledAt = newSchedule
	if err := repo.db.Save(&job).Error; err != nil {
		return err
	}
	return nil
}
func (repo *JobQueueRepository) ValidateJobSchedule(ctx context.Context, schedule string) error {
	if schedule == "" {
		return errors.New("schedule cannot be empty")
	}
	// Add your validation logic here
	return nil
}

/// internal/models/job_queue/job_service.go ///
package jobqueue

import (
	"context"
	"errors"
	"time"

	"github.com/google/uuid"
)

type IJobQueueService interface {
	CreateJob(ctx context.Context, job *JobQueue) (*JobQueue, error)
	GetJobByID(ctx context.Context, id uuid.UUID) (*JobQueue, error)
	ListJobs(ctx context.Context) ([]*JobQueue, error)
	UpdateJob(ctx context.Context, job *JobQueue) (*JobQueue, error)
	DeleteJob(ctx context.Context, id uuid.UUID) error
	ListJobsByStatus(ctx context.Context, status string) ([]*JobQueue, error)
	ListJobsByUserID(ctx context.Context, userID uuid.UUID) ([]*JobQueue, error)
	ExecuteJobManually(ctx context.Context, id uuid.UUID) error
	ValidateJobSchedule(ctx context.Context, schedule string) error
	ListJobsByType(ctx context.Context, jobType string) ([]*JobQueue, error)
	ListJobsByCreatedAt(ctx context.Context, createdAt time.Time) ([]*JobQueue, error)
}
type JobQueueService struct{ Repo IJobQueueRepo }

func NewJobQueueService(repo IJobQueueRepo) IJobQueueService { return &JobQueueService{Repo: repo} }

func (s *JobQueueService) CreateJob(ctx context.Context, job *JobQueue) (*JobQueue, error) {
	if job == nil {
		return nil, errors.New("job cannot be nil")
	}
	if job.ID == uuid.Nil {
		return nil, errors.New("job ID cannot be empty")
	}
	if job.UserID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	if job.Status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	return s.Repo.Create(ctx, job)
}
func (s *JobQueueService) GetJobByID(ctx context.Context, id uuid.UUID) (*JobQueue, error) {
	if id == uuid.Nil {
		return nil, errors.New("job ID cannot be empty")
	}
	return s.Repo.FindByID(ctx, id)
}
func (s *JobQueueService) ListJobs(ctx context.Context) ([]*JobQueue, error) {
	return s.Repo.FindAll(ctx)
}

func (s *JobQueueService) UpdateJob(ctx context.Context, job *JobQueue) (*JobQueue, error) {
	if job == nil {
		return nil, errors.New("job cannot be nil")
	}
	if job.ID == uuid.Nil {
		return nil, errors.New("job ID cannot be empty")
	}
	return s.Repo.Update(ctx, job)
}
func (s *JobQueueService) DeleteJob(ctx context.Context, id uuid.UUID) error {
	if id == uuid.Nil {
		return errors.New("job ID cannot be empty")
	}
	return s.Repo.Delete(ctx, id)
}
func (s *JobQueueService) ListJobsByStatus(ctx context.Context, status string) ([]*JobQueue, error) {
	if status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	return s.Repo.FindByStatus(ctx, status)
}
func (s *JobQueueService) ListJobsByUserID(ctx context.Context, userID uuid.UUID) ([]*JobQueue, error) {
	if userID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	return s.Repo.FindByUserID(ctx, userID)
}
func (s *JobQueueService) ExecuteJobManually(ctx context.Context, id uuid.UUID) error {
	if id == uuid.Nil {
		return errors.New("job ID cannot be empty")
	}
	return s.Repo.ExecuteJobManually(ctx, id)
}
func (s *JobQueueService) RescheduleJob(ctx context.Context, id uuid.UUID, newSchedule time.Time) error {
	if id == uuid.Nil {
		return errors.New("job ID cannot be empty")
	}
	return s.Repo.RescheduleJob(ctx, id, newSchedule)
}
func (s *JobQueueService) ValidateJobSchedule(ctx context.Context, schedule string) error {
	if schedule == "" {
		return errors.New("schedule cannot be empty")
	}
	// Add your validation logic here
	return nil
}
func (s *JobQueueService) ListJobsByType(ctx context.Context, jobType string) ([]*JobQueue, error) {
	if jobType == "" {
		return nil, errors.New("job type cannot be empty")
	}
	return s.Repo.FindByType(ctx, jobType)
}
func (s *JobQueueService) ListJobsByCreatedAt(ctx context.Context, createdAt time.Time) ([]*JobQueue, error) {
	if createdAt.IsZero() {
		return nil, errors.New("created at cannot be empty")
	}
	return s.Repo.FindByCreatedAt(ctx, createdAt)
}
func (s *JobQueueService) ListJobsByCreatedBy(ctx context.Context, createdBy uuid.UUID) ([]*JobQueue, error) {
	if createdBy == uuid.Nil {
		return nil, errors.New("created by cannot be empty")
	}
	return s.Repo.FindByCreatedBy(ctx, createdBy)
}
func (s *JobQueueService) ListJobsByUpdatedAt(ctx context.Context, updatedAt time.Time) ([]*JobQueue, error) {
	if updatedAt.IsZero() {
		return nil, errors.New("updated at cannot be empty")
	}
	return s.Repo.FindByUpdatedAt(ctx, updatedAt)
}
func (s *JobQueueService) ListJobsByUpdatedBy(ctx context.Context, updatedBy uuid.UUID) ([]*JobQueue, error) {
	if updatedBy == uuid.Nil {
		return nil, errors.New("updated by cannot be empty")
	}
	return s.Repo.FindByUpdatedBy(ctx, updatedBy)
}
func (s *JobQueueService) ListJobsByLastExecutedAt(ctx context.Context, lastExecutedAt time.Time) ([]*JobQueue, error) {
	if lastExecutedAt.IsZero() {
		return nil, errors.New("last executed at cannot be empty")
	}
	return s.Repo.FindByLastExecutedAt(ctx, lastExecutedAt)
}
func (s *JobQueueService) ListJobsByLastExecutedBy(ctx context.Context, lastExecutedBy uuid.UUID) ([]*JobQueue, error) {
	if lastExecutedBy == uuid.Nil {
		return nil, errors.New("last executed by cannot be empty")
	}
	return s.Repo.FindByLastExecutedBy(ctx, lastExecutedBy)
}
func (s *JobQueueService) ListJobsByStatusAndUserID(ctx context.Context, status string, userID uuid.UUID) ([]*JobQueue, error) {
	if status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	if userID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	return s.Repo.FindByStatusAndUserID(ctx, status, userID)
}
func (s *JobQueueService) ListJobsByStatusAndType(ctx context.Context, status string, jobType string) ([]*JobQueue, error) {
	if status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	if jobType == "" {
		return nil, errors.New("job type cannot be empty")
	}
	return s.Repo.FindByStatusAndType(ctx, status, jobType)
}
func (s *JobQueueService) ListJobsByStatusAndCreatedAt(ctx context.Context, status string, createdAt time.Time) ([]*JobQueue, error) {
	if status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	if createdAt.IsZero() {
		return nil, errors.New("created at cannot be empty")
	}
	return s.Repo.FindByStatusAndCreatedAt(ctx, status, createdAt)
}
func (s *JobQueueService) ListJobsByStatusAndCreatedBy(ctx context.Context, status string, createdBy uuid.UUID) ([]*JobQueue, error) {
	if status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	if createdBy == uuid.Nil {
		return nil, errors.New("created by cannot be empty")
	}
	return s.Repo.FindByStatusAndCreatedBy(ctx, status, createdBy)
}
func (s *JobQueueService) ListJobsByStatusAndUpdatedAt(ctx context.Context, status string, updatedAt time.Time) ([]*JobQueue, error) {
	if status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	if updatedAt.IsZero() {
		return nil, errors.New("updated at cannot be empty")
	}
	return s.Repo.FindByStatusAndUpdatedAt(ctx, status, updatedAt)
}
func (s *JobQueueService) ListJobsByStatusAndUpdatedBy(ctx context.Context, status string, updatedBy uuid.UUID) ([]*JobQueue, error) {
	if status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	if updatedBy == uuid.Nil {
		return nil, errors.New("updated by cannot be empty")
	}
	return s.Repo.FindByStatusAndUpdatedBy(ctx, status, updatedBy)
}
func (s *JobQueueService) ListJobsByStatusAndLastExecutedAt(ctx context.Context, status string, lastExecutedAt time.Time) ([]*JobQueue, error) {
	if status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	if lastExecutedAt.IsZero() {
		return nil, errors.New("last executed at cannot be empty")
	}
	return s.Repo.FindByStatusAndLastExecutedAt(ctx, status, lastExecutedAt)
}
func (s *JobQueueService) ListJobsByStatusAndLastExecutedBy(ctx context.Context, status string, lastExecutedBy uuid.UUID) ([]*JobQueue, error) {
	if status == "" {
		return nil, errors.New("job status cannot be empty")
	}
	if lastExecutedBy == uuid.Nil {
		return nil, errors.New("last executed by cannot be empty")
	}
	return s.Repo.FindByStatusAndLastExecutedBy(ctx, status, lastExecutedBy)
}
func (s *JobQueueService) ListJobsByUserIDAndType(ctx context.Context, userID uuid.UUID, jobType string) ([]*JobQueue, error) {
	if userID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	if jobType == "" {
		return nil, errors.New("job type cannot be empty")
	}
	return s.Repo.FindByUserIDAndType(ctx, userID, jobType)
}
func (s *JobQueueService) ListJobsByUserIDAndCreatedAt(ctx context.Context, userID uuid.UUID, createdAt time.Time) ([]*JobQueue, error) {
	if userID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	if createdAt.IsZero() {
		return nil, errors.New("created at cannot be empty")
	}
	return s.Repo.FindByUserIDAndCreatedAt(ctx, userID, createdAt)
}
func (s *JobQueueService) ListJobsByUserIDAndCreatedBy(ctx context.Context, userID uuid.UUID, createdBy uuid.UUID) ([]*JobQueue, error) {
	if userID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	if createdBy == uuid.Nil {
		return nil, errors.New("created by cannot be empty")
	}
	return s.Repo.FindByUserIDAndCreatedBy(ctx, userID, createdBy)
}
func (s *JobQueueService) ListJobsByUserIDAndUpdatedAt(ctx context.Context, userID uuid.UUID, updatedAt time.Time) ([]*JobQueue, error) {
	if userID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	if updatedAt.IsZero() {
		return nil, errors.New("updated at cannot be empty")
	}
	return s.Repo.FindByUserIDAndUpdatedAt(ctx, userID, updatedAt)
}
func (s *JobQueueService) ListJobsByUserIDAndUpdatedBy(ctx context.Context, userID uuid.UUID, updatedBy uuid.UUID) ([]*JobQueue, error) {
	if userID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	if updatedBy == uuid.Nil {
		return nil, errors.New("updated by cannot be empty")
	}
	return s.Repo.FindByUserIDAndUpdatedBy(ctx, userID, updatedBy)
}
func (s *JobQueueService) ListJobsByUserIDAndLastExecutedAt(ctx context.Context, userID uuid.UUID, lastExecutedAt time.Time) ([]*JobQueue, error) {
	if userID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	if lastExecutedAt.IsZero() {
		return nil, errors.New("last executed at cannot be empty")
	}
	return s.Repo.FindByUserIDAndLastExecutedAt(ctx, userID, lastExecutedAt)
}
func (s *JobQueueService) ListJobsByUserIDAndLastExecutedBy(ctx context.Context, userID uuid.UUID, lastExecutedBy uuid.UUID) ([]*JobQueue, error) {
	if userID == uuid.Nil {
		return nil, errors.New("user ID cannot be empty")
	}
	if lastExecutedBy == uuid.Nil {
		return nil, errors.New("last executed by cannot be empty")
	}
	return s.Repo.FindByUserIDAndLastExecutedBy(ctx, userID, lastExecutedBy)
}

/// internal/models/notification/notification_model.go ///
package notification

import (
	"time"
)

type INotification interface {
	TableName() string
	GetID() int
	GetTitle() string
	GetMessage() string
	GetScheduledAt() time.Time
	GetChannel() string
	GetStatus() string
}

// Model: Notification define a estrutura b√°sica de uma notifica√ß√£o.
type Notification struct {
	ID          int       `json:"id" xml:"id" yaml:"id" gorm:"column:id;primaryKey;autoIncrement"`
	Title       string    `json:"title" xml:"title" yaml:"title" gorm:"column:title"`
	Message     string    `json:"message" xml:"message" yaml:"message" gorm:"column:message"`
	ScheduledAt time.Time `json:"scheduled_at" xml:"scheduled_at" yaml:"scheduled_at" gorm:"column:scheduled_at"`
	Channel     string    `json:"channel" xml:"channel" yaml:"channel" gorm:"column:channel"`
	Status      string    `json:"status" xml:"status" yaml:"status" gorm:"column:status"`
}

func (n *Notification) TableName() string                    { return "notifications" }
func (n *Notification) GetID() int                           { return n.ID }
func (n *Notification) GetTitle() string                     { return n.Title }
func (n *Notification) GetMessage() string                   { return n.Message }
func (n *Notification) GetScheduledAt() time.Time            { return n.ScheduledAt }
func (n *Notification) GetChannel() string                   { return n.Channel }
func (n *Notification) GetStatus() string                    { return n.Status }
func (n *Notification) SetID(id int)                         { n.ID = id }
func (n *Notification) SetTitle(title string)                { n.Title = title }
func (n *Notification) SetMessage(message string)            { n.Message = message }
func (n *Notification) SetScheduledAt(scheduledAt time.Time) { n.ScheduledAt = scheduledAt }
func (n *Notification) SetChannel(channel string)            { n.Channel = channel }
func (n *Notification) SetStatus(status string)              { n.Status = status }

/// internal/models/notification/notification_repo.go ///
package notification

import (
	"errors"
	"sync"
)

// MemoryNotificationRepo √© uma implementa√ß√£o em mem√≥ria do reposit√≥rio.
type MemoryNotificationRepo struct {
	mu            sync.Mutex
	notifications []Notification
	nextID        int
}

// Repository: Interface de persist√™ncia de notifica√ß√µes.
type NotificationRepo interface {
	Create(notification Notification) (Notification, error)
	GetAll() ([]Notification, error)
	Delete(id int) error
}

func NewMemoryNotificationRepo() *MemoryNotificationRepo {
	return &MemoryNotificationRepo{
		notifications: make([]Notification, 0),
		nextID:        1,
	}
}

func (repo *MemoryNotificationRepo) Create(notification Notification) (Notification, error) {
	repo.mu.Lock()
	defer repo.mu.Unlock()
	notification.ID = repo.nextID
	repo.nextID++
	repo.notifications = append(repo.notifications, notification)
	return notification, nil
}

func (repo *MemoryNotificationRepo) GetAll() ([]Notification, error) {
	repo.mu.Lock()
	defer repo.mu.Unlock()
	return repo.notifications, nil
}

func (repo *MemoryNotificationRepo) Delete(id int) error {
	repo.mu.Lock()
	defer repo.mu.Unlock()
	for i, notif := range repo.notifications {
		if notif.ID == id {
			repo.notifications = append(repo.notifications[:i], repo.notifications[i+1:]...)
			return nil
		}
	}
	return errors.New("notifica√ß√£o n√£o encontrada")
}

/// internal/models/notification/notification_service.go ///
package notification

import (
	"bytes"
	"encoding/json"
	"errors"
	"fmt"
	"net/http"
	"time"

	gl "github.com/rafa-mori/gdbase/logger"
)

// Service: NotificationService encapsula a l√≥gica de neg√≥cio e envio.
type NotificationService struct {
	repo NotificationRepo
}

func NewNotificationService(repo NotificationRepo) *NotificationService {
	return &NotificationService{repo: repo}
}

// CreateNotification cria a notifica√ß√£o, define status e, se necess√°rio, processa o envio.
func (s *NotificationService) CreateNotification(notification Notification) (Notification, error) {
	notification.Status = "pendente"
	created, err := s.repo.Create(notification)
	if err != nil {
		return Notification{}, err
	}
	// Se a data agendada j√° passou ou √© igual ao momento atual, envia instantaneamente.
	if created.ScheduledAt.Before(time.Now()) || created.ScheduledAt.Equal(time.Now()) {
		// Executa o processamento em uma goroutine para n√£o bloquear o endpoint.
		go s.ProcessNotification(created)
	}
	return created, nil
}

// ProcessNotification decide qual fun√ß√£o de envio utilizar conforme o canal.
func (s *NotificationService) ProcessNotification(notification Notification) error {
	var err error
	switch notification.Channel {
	case "email":
		err = s.sendEmail(notification)
	case "whatsapp":
		err = s.sendWhatsApp(notification)
	case "push":
		err = s.sendPush(notification)
	default:
		err = errors.New("canal desconhecido")
	}
	if err == nil {
		notification.Status = "enviado"
		fmt.Printf("Notifica√ß√£o ID %d enviada com sucesso via %s\n", notification.ID, notification.Channel)
	} else {
		notification.Status = "erro"
		fmt.Printf("Erro ao enviar notifica√ß√£o ID %d: %v\n", notification.ID, err)
	}
	// Em um cen√°rio real, voc√™ atualizaria o status no banco aqui.
	return err
}

// Fun√ß√£o simulada para envio de e-mail.
func (s *NotificationService) sendEmail(notification Notification) error {
	gl.Log("info", "Enviando Email")
	fmt.Printf("Enviando Email: %s - %s\n", notification.Title, notification.Message)
	return nil
}

// Fun√ß√£o simulada para envio de notifica√ß√£o push.
func (s *NotificationService) sendPush(notification Notification) error {
	gl.Log("info", "Enviando Push Notification")
	fmt.Printf("Enviando Push Notification: %s - %s\n", notification.Title, notification.Message)
	return nil
}

// Fun√ß√£o para envio de mensagem via WhatsApp usando a WhatsApp Cloud API real.
func (s *NotificationService) sendWhatsApp(notification Notification) error {
	// Placeholders para dados sens√≠veis ‚Äì substitua pelos seus dados reais.
	const (
		phoneNumberID   = "YOUR_PHONE_NUMBER_ID"   // Seu ID do n√∫mero do WhatsApp Business
		accessToken     = "YOUR_ACCESS_TOKEN"      // Token de acesso gerado para a WhatsApp Cloud API
		recipientNumber = "RECIPIENT_PHONE_NUMBER" // N√∫mero do destinat√°rio no formato internacional (ex.: "5511999999999")
	)

	// Monta o endpoint concatenando o ID e o token.
	endpoint := "https://graph.facebook.com/v15.0/" + phoneNumberID + "/messages?access_token=" + accessToken

	// Constr√≥i o payload para enviar uma mensagem de texto via WhatsApp.
	payload := map[string]interface{}{
		"messaging_product": "whatsapp",
		"to":                recipientNumber,
		"type":              "text",
		"text": map[string]interface{}{
			"body": notification.Message, // Utiliza a mensagem definida na notifica√ß√£o.
		},
	}

	// Serializa o payload para JSON.
	jsonPayload, err := json.Marshal(payload)
	if err != nil {
		gl.Log("error", "Erro ao gerar payload JSON")
		return fmt.Errorf("erro ao gerar payload JSON: %v", err)
	}

	// Cria a requisi√ß√£o POST.
	req, err := http.NewRequest("POST", endpoint, bytes.NewBuffer(jsonPayload))
	if err != nil {
		gl.Log("error", "Erro ao criar requisi√ß√£o HTTP")
		return fmt.Errorf("erro ao criar requisi√ß√£o HTTP: %v", err)
	}
	req.Header.Set("Content-Type", "application/json")

	// Configura o client HTTP com timeout.
	client := &http.Client{Timeout: 10 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		gl.Log("error", "Erro ao enviar requisi√ß√£o HTTP")
		return fmt.Errorf("erro na requisi√ß√£o HTTP: %v", err)
	}
	defer resp.Body.Close()

	// Verifica se a resposta indica sucesso.
	if resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusCreated {
		gl.Log("error", "Erro ao enviar mensagem via WhatsApp")
		return fmt.Errorf("falha no envio via WhatsApp, status code: %d", resp.StatusCode)
	}

	// Se necess√°rio, voc√™ pode ler a resposta para maiores detalhes.
	// body, _ := ioutil.ReadAll(resp.Body)
	// fmt.Printf("Resposta do WhatsApp: %s\n", string(body))

	return nil
}

/// internal/models/orders/order_model.go ///
package orders

import (
	"time"

	t "github.com/rafa-mori/gdbase/internal/types"
)

// PaymentMethod represents the payment methods available for an order
type PaymentMethod string

const (
	Cash       PaymentMethod = "cash"
	Credit     PaymentMethod = "credit"
	CreditCard PaymentMethod = "credit_card"
	BankSlip   PaymentMethod = "bank_slip"
	Transfer   PaymentMethod = "transfer"
)

// OrderStatus representa os status poss√≠veis de um pedido
// (alinhar com enum do TypeScript/SQL)
type OrderStatus string

const (
	OrderStatusDraft     OrderStatus = "DRAFT"
	OrderStatusCreated   OrderStatus = "CREATED"
	OrderStatusApproved  OrderStatus = "APPROVED"
	OrderStatusShipped   OrderStatus = "SHIPPED"
	OrderStatusDelivered OrderStatus = "DELIVERED"
	OrderStatusCanceled  OrderStatus = "CANCELED"
)

// Address represents an address associated with an order
type Address struct {
	Street     string  `json:"street" xml:"street" yaml:"street" gorm:"column:street"`
	Number     string  `json:"number" xml:"number" yaml:"number" gorm:"column:number"`
	Complement *string `json:"complement,omitempty" xml:"complement,omitempty" yaml:"complement,omitempty" gorm:"column:complement"`
	District   string  `json:"district" xml:"district" yaml:"district" gorm:"column:district"`
	City       string  `json:"city" xml:"city" yaml:"city" gorm:"column:city"`
	State      string  `json:"state" xml:"state" yaml:"state" gorm:"column:state"`
	ZipCode    string  `json:"zipCode" xml:"zipCode" yaml:"zipCode" gorm:"column:zip_code"`
	IsDefault  bool    `json:"isDefault" xml:"isDefault" yaml:"isDefault" gorm:"column:is_default"`
	Type       string  `json:"type" xml:"type" yaml:"type" gorm:"column:type"`
}

// IOrderItem define a interface para manipula√ß√£o de itens do pedido
type IOrderItem interface {
	TableName() string
	GetID() string
	GetProductID() string
	GetQuantity() int
	GetUnitPrice() t.Money
	GetDiscount() t.Money
	GetTotal() t.Money
	GetNotes() *string

	SetProductID(string)
	SetQuantity(int)
	SetUnitPrice(t.Money)
	SetDiscount(t.Money)
	SetTotal(t.Money)
	SetNotes(*string)
}

// OrderItem represents an item in an order
type OrderItem struct {
	ID        string  `json:"id" xml:"id" yaml:"id" gorm:"column:id"`
	ProductID string  `json:"productId" xml:"productId" yaml:"productId" gorm:"column:product_id"`
	Quantity  int     `json:"quantity" xml:"quantity" yaml:"quantity" gorm:"column:quantity"`
	UnitPrice t.Money `json:"unitPrice" xml:"unitPrice" yaml:"unitPrice" gorm:"column:unit_price"`
	Discount  t.Money `json:"discount" xml:"discount" yaml:"discount" gorm:"column:discount"`
	Total     t.Money `json:"total" xml:"total" yaml:"total" gorm:"column:total"`
	Notes     *string `json:"notes,omitempty" xml:"notes,omitempty" yaml:"notes,omitempty" gorm:"column:notes"`
}

// M√©todos de IOrderItem
func (oi *OrderItem) TableName() string      { return "order_items" }
func (oi *OrderItem) GetID() string          { return oi.ID }
func (oi *OrderItem) GetProductID() string   { return oi.ProductID }
func (oi *OrderItem) GetQuantity() int       { return oi.Quantity }
func (oi *OrderItem) GetUnitPrice() t.Money  { return oi.UnitPrice }
func (oi *OrderItem) GetDiscount() t.Money   { return oi.Discount }
func (oi *OrderItem) GetTotal() t.Money      { return oi.Total }
func (oi *OrderItem) GetNotes() *string      { return oi.Notes }
func (oi *OrderItem) SetProductID(v string)  { oi.ProductID = v }
func (oi *OrderItem) SetQuantity(v int)      { oi.Quantity = v }
func (oi *OrderItem) SetUnitPrice(v t.Money) { oi.UnitPrice = v }
func (oi *OrderItem) SetDiscount(v t.Money)  { oi.Discount = v }
func (oi *OrderItem) SetTotal(v t.Money)     { oi.Total = v }
func (oi *OrderItem) SetNotes(v *string)     { oi.Notes = v }

// IOrder define a interface para manipula√ß√£o de pedidos
type IOrder interface {
	TableName() string
	GetID() string
	GetCode() *string
	GetClientID() string
	GetUserID() string
	GetItems() []IOrderItem
	GetSubtotal() t.Money
	GetDiscountValue() t.Money
	GetDiscountPercentage() float64
	GetShippingValue() t.Money
	GetTotal() t.Money
	GetStatus() OrderStatus
	GetPayments() []OrderPayment
	GetNotes() *string
	GetShippingAddress() *Address
	GetDeliveryDate() *time.Time
	GetSyncStatus() string
	GetSyncErrorMessage() *string
	GetCreatedAt() time.Time
	GetUpdatedAt() time.Time
	GetSyncedAt() *time.Time

	SetCode(*string)
	SetClientID(string)
	SetUserID(string)
	SetItems([]IOrderItem)
	SetSubtotal(t.Money)
	SetDiscountValue(t.Money)
	SetDiscountPercentage(float64)
	SetShippingValue(t.Money)
	SetTotal(t.Money)
	SetStatus(OrderStatus)
	SetPayments([]OrderPayment)
	SetNotes(*string)
	SetShippingAddress(*Address)
	SetDeliveryDate(*time.Time)
	SetSyncStatus(string)
	SetSyncErrorMessage(*string)
	SetCreatedAt(time.Time)
	SetUpdatedAt(time.Time)
	SetSyncedAt(*time.Time)
}

// OrderPayment represents a payment for an order
type OrderPayment struct {
	Method       PaymentMethod `json:"method" xml:"method" yaml:"method" gorm:"column:method"`
	Installments int           `json:"installments" xml:"installments" yaml:"installments" gorm:"column:installments"`
	DueDate      time.Time     `json:"dueDate" xml:"dueDate" yaml:"dueDate" gorm:"column:due_date"`
	Value        t.Money       `json:"value" xml:"value" yaml:"value" gorm:"column:value"`
}

// Order represents a complete order
type Order struct {
	ID                 string         `json:"id" xml:"id" yaml:"id" gorm:"column:id;primaryKey"`
	Code               *string        `json:"code,omitempty" xml:"code,omitempty" yaml:"code,omitempty" gorm:"column:code"`
	ClientID           string         `json:"clientId" xml:"clientId" yaml:"clientId" gorm:"column:client_id"`
	UserID             string         `json:"userId" xml:"userId" yaml:"userId" gorm:"column:user_id"`
	Items              []OrderItem    `json:"items" xml:"items" yaml:"items" gorm:"-"`
	Subtotal           t.Money        `json:"subtotal" xml:"subtotal" yaml:"subtotal" gorm:"column:subtotal"`
	DiscountValue      t.Money        `json:"discountValue" xml:"discountValue" yaml:"discountValue" gorm:"column:discount_value"`
	DiscountPercentage float64        `json:"discountPercentage" xml:"discountPercentage" yaml:"discountPercentage" gorm:"column:discount_percentage"`
	ShippingValue      t.Money        `json:"shippingValue" xml:"shippingValue" yaml:"shippingValue" gorm:"column:shipping_value"`
	Total              t.Money        `json:"total" xml:"total" yaml:"total" gorm:"column:total"`
	Status             OrderStatus    `json:"status" xml:"status" yaml:"status" gorm:"column:status"`
	Payments           []OrderPayment `json:"payments" xml:"payments" yaml:"payments" gorm:"-"`
	Notes              *string        `json:"notes,omitempty" xml:"notes,omitempty" yaml:"notes,omitempty" gorm:"column:notes"`
	ShippingAddress    *Address       `json:"shippingAddress,omitempty" xml:"shippingAddress,omitempty" yaml:"shippingAddress,omitempty" gorm:"-"`
	DeliveryDate       *time.Time     `json:"deliveryDate,omitempty" xml:"deliveryDate,omitempty" yaml:"deliveryDate,omitempty" gorm:"column:delivery_date"`
	SyncStatus         string         `json:"syncStatus" xml:"syncStatus" yaml:"syncStatus" gorm:"column:sync_status"`
	SyncErrorMessage   *string        `json:"syncErrorMessage,omitempty" xml:"syncErrorMessage,omitempty" yaml:"syncErrorMessage,omitempty" gorm:"column:sync_error_message"`
	CreatedAt          time.Time      `json:"createdAt" xml:"createdAt" yaml:"createdAt" gorm:"column:created_at"`
	UpdatedAt          time.Time      `json:"updatedAt" xml:"updatedAt" yaml:"updatedAt" gorm:"column:updated_at"`
	SyncedAt           *time.Time     `json:"syncedAt,omitempty" xml:"syncedAt,omitempty" yaml:"syncedAt,omitempty" gorm:"column:synced_at"`
}

// M√©todos de IOrder
func (o *Order) TableName() string   { return "orders" }
func (o *Order) GetID() string       { return o.ID }
func (o *Order) GetCode() *string    { return o.Code }
func (o *Order) GetClientID() string { return o.ClientID }
func (o *Order) GetUserID() string   { return o.UserID }
func (o *Order) GetItems() []IOrderItem {
	items := make([]IOrderItem, len(o.Items))
	for i := range o.Items {
		items[i] = &o.Items[i]
	}
	return items
}
func (o *Order) GetSubtotal() t.Money           { return o.Subtotal }
func (o *Order) GetDiscountValue() t.Money      { return o.DiscountValue }
func (o *Order) GetDiscountPercentage() float64 { return o.DiscountPercentage }
func (o *Order) GetShippingValue() t.Money      { return o.ShippingValue }
func (o *Order) GetTotal() t.Money              { return o.Total }
func (o *Order) GetStatus() OrderStatus         { return o.Status }
func (o *Order) GetPayments() []OrderPayment    { return o.Payments }
func (o *Order) GetNotes() *string              { return o.Notes }
func (o *Order) GetShippingAddress() *Address   { return o.ShippingAddress }
func (o *Order) GetDeliveryDate() *time.Time    { return o.DeliveryDate }
func (o *Order) GetSyncStatus() string          { return o.SyncStatus }
func (o *Order) GetSyncErrorMessage() *string   { return o.SyncErrorMessage }
func (o *Order) GetCreatedAt() time.Time        { return o.CreatedAt }
func (o *Order) GetUpdatedAt() time.Time        { return o.UpdatedAt }
func (o *Order) GetSyncedAt() *time.Time        { return o.SyncedAt }
func (o *Order) SetCode(v *string)              { o.Code = v }
func (o *Order) SetClientID(v string)           { o.ClientID = v }
func (o *Order) SetUserID(v string)             { o.UserID = v }
func (o *Order) SetItems(v []IOrderItem) {
	items := make([]OrderItem, len(v))
	for i, item := range v {
		if oi, ok := item.(*OrderItem); ok {
			items[i] = *oi
		}
	}
	o.Items = items
}
func (o *Order) SetSubtotal(v t.Money)           { o.Subtotal = v }
func (o *Order) SetDiscountValue(v t.Money)      { o.DiscountValue = v }
func (o *Order) SetDiscountPercentage(v float64) { o.DiscountPercentage = v }
func (o *Order) SetShippingValue(v t.Money)      { o.ShippingValue = v }
func (o *Order) SetTotal(v t.Money)              { o.Total = v }
func (o *Order) SetStatus(v OrderStatus)         { o.Status = v }
func (o *Order) SetPayments(v []OrderPayment)    { o.Payments = v }
func (o *Order) SetNotes(v *string)              { o.Notes = v }
func (o *Order) SetShippingAddress(v *Address)   { o.ShippingAddress = v }
func (o *Order) SetDeliveryDate(v *time.Time)    { o.DeliveryDate = v }
func (o *Order) SetSyncStatus(v string)          { o.SyncStatus = v }
func (o *Order) SetSyncErrorMessage(v *string)   { o.SyncErrorMessage = v }
func (o *Order) SetCreatedAt(v time.Time)        { o.CreatedAt = v }
func (o *Order) SetUpdatedAt(v time.Time)        { o.UpdatedAt = v }
func (o *Order) SetSyncedAt(v *time.Time)        { o.SyncedAt = v }

// OrderDraft represents a draft version of an order
type OrderDraft struct {
	ClientID          string      `json:"clientId" xml:"clientId" yaml:"clientId" gorm:"-"`
	Items             []OrderItem `json:"items" xml:"items" yaml:"items" gorm:"-"`
	Notes             *string     `json:"notes,omitempty" xml:"notes,omitempty" yaml:"notes,omitempty" gorm:"-"`
	DeliveryDate      *time.Time  `json:"deliveryDate,omitempty" xml:"deliveryDate,omitempty" yaml:"deliveryDate,omitempty" gorm:"-"`
	PaymentMethod     *string     `json:"paymentMethod,omitempty" xml:"paymentMethod,omitempty" yaml:"paymentMethod,omitempty" gorm:"-"`
	Installments      *int        `json:"installments,omitempty" xml:"installments,omitempty" yaml:"installments,omitempty" gorm:"-"`
	ShippingAddressID *string     `json:"shippingAddressId,omitempty" xml:"shippingAddressId,omitempty" yaml:"shippingAddressId,omitempty" gorm:"-"`
}

/// internal/models/orders/order_repo.go ///
package orders

import (
	"fmt"

	"gorm.io/gorm"
)

// Adiciona importa√ß√£o expl√≠cita do model Order

type IOrderRepo interface {
	Create(o *Order) (*Order, error)
	FindOne(where ...interface{}) (*Order, error)
	FindAll(where ...interface{}) ([]*Order, error)
	Update(o *Order) (*Order, error)
	Delete(id string) error
	Close() error
}

type OrderRepo struct {
	g *gorm.DB
}

func NewOrderRepo(db *gorm.DB) IOrderRepo {
	if db == nil {
		return nil
	}
	return &OrderRepo{db}
}

func (or *OrderRepo) Create(o *Order) (*Order, error) {
	if o == nil {
		return nil, fmt.Errorf("OrderRepo: Order is nil")
	}
	err := or.g.Create(o).Error
	if err != nil {
		return nil, fmt.Errorf("OrderRepo: failed to create Order: %w", err)
	}
	return o, nil
}

func (or *OrderRepo) FindOne(where ...interface{}) (*Order, error) {
	var o Order
	err := or.g.Where(where[0], where[1:]...).First(&o).Error
	if err != nil {
		return nil, fmt.Errorf("OrderRepo: failed to find Order: %w", err)
	}
	return &o, nil
}

func (or *OrderRepo) FindAll(where ...interface{}) ([]*Order, error) {
	var os []*Order
	err := or.g.Where(where[0], where[1:]...).Find(&os).Error
	if err != nil {
		return nil, fmt.Errorf("OrderRepo: failed to find all orders: %w", err)
	}
	return os, nil
}

func (or *OrderRepo) Update(o *Order) (*Order, error) {
	if o == nil {
		return nil, fmt.Errorf("OrderRepo: Order is nil")
	}
	err := or.g.Save(o).Error
	if err != nil {
		return nil, fmt.Errorf("OrderRepo: failed to update Order: %w", err)
	}
	return o, nil
}

func (or *OrderRepo) Delete(id string) error {
	err := or.g.Delete(&Order{}, id).Error
	if err != nil {
		return fmt.Errorf("OrderRepo: failed to delete Order: %w", err)
	}
	return nil
}

func (or *OrderRepo) Close() error {
	sqlDB, err := or.g.DB()
	if err != nil {
		return err
	}
	return sqlDB.Close()
}

/// internal/models/orders/order_service.go ///
package orders

import (
	"errors"
	"fmt"
)

type IOrderService interface {
	CreateOrder(order *Order) (*Order, error)
	GetOrderByID(id string) (*Order, error)
	UpdateOrder(order *Order) (*Order, error)
	DeleteOrder(id string) error
	ListOrders() ([]*Order, error)
}

type OrderService struct {
	repo IOrderRepo
}

func NewOrderService(repo IOrderRepo) IOrderService {
	return &OrderService{repo: repo}
}

func (os *OrderService) CreateOrder(order *Order) (*Order, error) {
	if order.ClientID == "" || order.UserID == "" || len(order.Items) == 0 {
		return nil, errors.New("missing required fields")
	}
	createdOrder, err := os.repo.Create(order)
	if err != nil {
		return nil, fmt.Errorf("error creating order: %w", err)
	}
	return createdOrder, nil
}

func (os *OrderService) GetOrderByID(id string) (*Order, error) {
	order, err := os.repo.FindOne("id = ?", id)
	if err != nil {
		return nil, fmt.Errorf("error fetching order: %w", err)
	}
	return order, nil
}

func (os *OrderService) UpdateOrder(order *Order) (*Order, error) {
	updatedOrder, err := os.repo.Update(order)
	if err != nil {
		return nil, fmt.Errorf("error updating order: %w", err)
	}
	return updatedOrder, nil
}

func (os *OrderService) DeleteOrder(id string) error {
	err := os.repo.Delete(id)
	if err != nil {
		return fmt.Errorf("error deleting order: %w", err)
	}
	return nil
}

func (os *OrderService) ListOrders() ([]*Order, error) {
	orders, err := os.repo.FindAll("status != ?", "cancelled")
	if err != nil {
		return nil, fmt.Errorf("error listing orders: %w", err)
	}
	return orders, nil
}

/// internal/models/orders/order_status.go ///
package orders

// OrderStatusEnum represents the possible statuses of an order
type OrderStatusEnum string

const (
	Draft      OrderStatusEnum = "draft"
	Pending    OrderStatusEnum = "pending"
	Approved   OrderStatusEnum = "approved"
	Processing OrderStatusEnum = "processing"
	Shipped    OrderStatusEnum = "shipped"
	Delivered  OrderStatusEnum = "delivered"
	Cancelled  OrderStatusEnum = "cancelled"
	Rejected   OrderStatusEnum = "rejected"
	Returned   OrderStatusEnum = "returned"
)

// OrderStatusLabels maps order statuses to user-friendly labels
var OrderStatusLabels = map[OrderStatusEnum]string{
	Draft:      "Rascunho",
	Pending:    "Pendente",
	Approved:   "Aprovado",
	Processing: "Em processamento",
	Shipped:    "Enviado",
	Delivered:  "Entregue",
	Cancelled:  "Cancelado",
	Rejected:   "Rejeitado",
	Returned:   "Devolvido",
}

// OrderStatusColors maps order statuses to their corresponding colors
var OrderStatusColors = map[OrderStatusEnum]string{
	Draft:      "gray",
	Pending:    "yellow",
	Approved:   "blue",
	Processing: "purple",
	Shipped:    "indigo",
	Delivered:  "green",
	Cancelled:  "red",
	Rejected:   "pink",
	Returned:   "orange",
}

/// internal/models/products/product_model.go ///
package products

import (
	"time"

	t "github.com/rafa-mori/gdbase/internal/types"
)

// PriceTable represents a product's price table
type PriceTable struct {
	ID    string   `json:"id" xml:"id" yaml:"id" gorm:"column:id"`
	Name  string   `json:"name" xml:"name" yaml:"name" gorm:"column:name"`
	Price *t.Money `json:"price" xml:"price" yaml:"price" gorm:"column:price"`
}

// IPriceTable interface for abstraction
type IPriceTable interface {
	TableName() string
	GetID() string
	SetID(id string)
	GetName() string
	SetName(name string)
	GetPrice() *t.Money
	SetPrice(price *t.Money)
}

func (p *PriceTable) TableName() string       { return "price_tables" }
func (p *PriceTable) GetID() string           { return p.ID }
func (p *PriceTable) SetID(id string)         { p.ID = id }
func (p *PriceTable) GetName() string         { return p.Name }
func (p *PriceTable) SetName(name string)     { p.Name = name }
func (p *PriceTable) GetPrice() *t.Money      { return p.Price }
func (p *PriceTable) SetPrice(price *t.Money) { p.Price = price }

// ProductCategory represents a product category
type ProductCategory struct {
	ID       string  `json:"id" xml:"id" yaml:"id" gorm:"column:id"`
	Name     string  `json:"name" xml:"name" yaml:"name" gorm:"column:name"`
	ParentID *string `json:"parentId,omitempty" xml:"parentId,omitempty" yaml:"parentId,omitempty" gorm:"column:parent_id"`
}

// IProductCategory interface for abstraction
//
//go:generate mockgen -destination=../../mocks/mock_product_category.go -package=mocks . IProductCategory
type IProductCategory interface {
	TableName() string
	GetID() string
	SetID(id string)
	GetName() string
	SetName(name string)
	GetParentID() *string
	SetParentID(parentID *string)
}

func (c *ProductCategory) TableName() string       { return "product_categories" }
func (c *ProductCategory) GetID() string           { return c.ID }
func (c *ProductCategory) SetID(id string)         { c.ID = id }
func (c *ProductCategory) GetName() string         { return c.Name }
func (c *ProductCategory) SetName(name string)     { c.Name = name }
func (c *ProductCategory) GetParentID() *string    { return c.ParentID }
func (c *ProductCategory) SetParentID(pid *string) { c.ParentID = pid }

// Product represents a product
type Product struct {
	ID                    string           `json:"id" xml:"id" yaml:"id" gorm:"column:id;primaryKey"`
	Code                  string           `json:"code" xml:"code" yaml:"code" gorm:"column:code"`
	SKU                   string           `json:"sku" xml:"sku" yaml:"sku" gorm:"column:sku"`
	EAN                   *string          `json:"ean,omitempty" xml:"ean,omitempty" yaml:"ean,omitempty" gorm:"column:ean"`
	Name                  string           `json:"name" xml:"name" yaml:"name" gorm:"column:name"`
	Description           string           `json:"description" xml:"description" yaml:"description" gorm:"column:description"`
	ImageURL              *string          `json:"imageUrl,omitempty" xml:"imageUrl,omitempty" yaml:"imageUrl,omitempty" gorm:"column:image_url"`
	Unit                  string           `json:"unit" xml:"unit" yaml:"unit" gorm:"column:unit"`
	Weight                *float64         `json:"weight,omitempty" xml:"weight,omitempty" yaml:"weight,omitempty" gorm:"column:weight"`
	Dimensions            *Dimensions      `json:"dimensions,omitempty" xml:"dimensions,omitempty" yaml:"dimensions,omitempty" gorm:"embedded;embeddedPrefix:dimensions_"`
	CategoryID            string           `json:"categoryId" xml:"categoryId" yaml:"categoryId" gorm:"column:category_id"`
	Category              *ProductCategory `json:"category,omitempty" xml:"category,omitempty" yaml:"category,omitempty" gorm:"foreignKey:CategoryID"`
	PriceTables           []PriceTable     `json:"priceTables" xml:"priceTables" yaml:"priceTables" gorm:"-"`
	Stock                 Stock            `json:"stock" xml:"stock" yaml:"stock" gorm:"embedded;embeddedPrefix:stock_"`
	MinOrderQuantity      *int             `json:"minOrderQuantity,omitempty" xml:"minOrderQuantity,omitempty" yaml:"minOrderQuantity,omitempty" gorm:"column:min_order_quantity"`
	MultipleOrderQuantity *int             `json:"multipleOrderQuantity,omitempty" xml:"multipleOrderQuantity,omitempty" yaml:"multipleOrderQuantity,omitempty" gorm:"column:multiple_order_quantity"`
	IsActive              bool             `json:"isActive" xml:"isActive" yaml:"isActive" gorm:"column:is_active"`
	CreatedAt             time.Time        `json:"createdAt" xml:"createdAt" yaml:"createdAt" gorm:"column:created_at"`
	UpdatedAt             time.Time        `json:"updatedAt" xml:"updatedAt" yaml:"updatedAt" gorm:"column:updated_at"`
}

// IProduct interface for abstraction
type IProduct interface {
	TableName() string
	GetID() string
	SetID(id string)
	GetCode() string
	SetCode(code string)
	GetSKU() string
	SetSKU(sku string)
	GetEAN() *string
	SetEAN(ean *string)
	GetName() string
	SetName(name string)
	GetDescription() string
	SetDescription(desc string)
	GetImageURL() *string
	SetImageURL(url *string)
	GetUnit() string
	SetUnit(unit string)
	GetWeight() *float64
	SetWeight(weight *float64)
	GetDimensions() IDimensions
	SetDimensions(dim IDimensions)
	GetCategoryID() string
	SetCategoryID(id string)
	GetCategory() IProductCategory
	SetCategory(cat IProductCategory)
	GetPriceTables() []IPriceTable
	SetPriceTables(tables []IPriceTable)
	GetStock() IStock
	SetStock(stock IStock)
	GetMinOrderQuantity() *int
	SetMinOrderQuantity(qty *int)
	GetMultipleOrderQuantity() *int
	SetMultipleOrderQuantity(qty *int)
	GetIsActive() bool
	SetIsActive(active bool)
	GetCreatedAt() time.Time
	SetCreatedAt(t time.Time)
	GetUpdatedAt() time.Time
	SetUpdatedAt(t time.Time)
}

func (p *Product) TableName() string          { return "products" }
func (p *Product) GetID() string              { return p.ID }
func (p *Product) SetID(id string)            { p.ID = id }
func (p *Product) GetCode() string            { return p.Code }
func (p *Product) SetCode(code string)        { p.Code = code }
func (p *Product) GetSKU() string             { return p.SKU }
func (p *Product) SetSKU(sku string)          { p.SKU = sku }
func (p *Product) GetEAN() *string            { return p.EAN }
func (p *Product) SetEAN(ean *string)         { p.EAN = ean }
func (p *Product) GetName() string            { return p.Name }
func (p *Product) SetName(name string)        { p.Name = name }
func (p *Product) GetDescription() string     { return p.Description }
func (p *Product) SetDescription(desc string) { p.Description = desc }
func (p *Product) GetImageURL() *string       { return p.ImageURL }
func (p *Product) SetImageURL(url *string)    { p.ImageURL = url }
func (p *Product) GetUnit() string            { return p.Unit }
func (p *Product) SetUnit(unit string)        { p.Unit = unit }
func (p *Product) GetWeight() *float64        { return p.Weight }
func (p *Product) SetWeight(weight *float64)  { p.Weight = weight }
func (p *Product) GetDimensions() IDimensions { return p.Dimensions }
func (p *Product) SetDimensions(dim IDimensions) {
	if v, ok := dim.(*Dimensions); ok {
		p.Dimensions = v
	}
}
func (p *Product) GetCategoryID() string         { return p.CategoryID }
func (p *Product) SetCategoryID(id string)       { p.CategoryID = id }
func (p *Product) GetCategory() IProductCategory { return p.Category }
func (p *Product) SetCategory(cat IProductCategory) {
	if v, ok := cat.(*ProductCategory); ok {
		p.Category = v
	}
}
func (p *Product) GetPriceTables() []IPriceTable {
	tables := make([]IPriceTable, len(p.PriceTables))
	for i := range p.PriceTables {
		tables[i] = &p.PriceTables[i]
	}
	return tables
}
func (p *Product) SetPriceTables(tables []IPriceTable) {
	p.PriceTables = make([]PriceTable, len(tables))
	for i, t := range tables {
		if v, ok := t.(*PriceTable); ok {
			p.PriceTables[i] = *v
		}
	}
}
func (p *Product) GetStock() IStock { return &p.Stock }
func (p *Product) SetStock(stock IStock) {
	if v, ok := stock.(*Stock); ok {
		p.Stock = *v
	}
}
func (p *Product) GetMinOrderQuantity() *int         { return p.MinOrderQuantity }
func (p *Product) SetMinOrderQuantity(qty *int)      { p.MinOrderQuantity = qty }
func (p *Product) GetMultipleOrderQuantity() *int    { return p.MultipleOrderQuantity }
func (p *Product) SetMultipleOrderQuantity(qty *int) { p.MultipleOrderQuantity = qty }
func (p *Product) GetIsActive() bool                 { return p.IsActive }
func (p *Product) SetIsActive(active bool)           { p.IsActive = active }
func (p *Product) GetCreatedAt() time.Time           { return p.CreatedAt }
func (p *Product) SetCreatedAt(t time.Time)          { p.CreatedAt = t }
func (p *Product) GetUpdatedAt() time.Time           { return p.UpdatedAt }
func (p *Product) SetUpdatedAt(t time.Time)          { p.UpdatedAt = t }

// Dimensions represents the dimensions of a product
type Dimensions struct {
	Length float64 `json:"length" xml:"length" yaml:"length" gorm:"column:length"`
	Width  float64 `json:"width" xml:"width" yaml:"width" gorm:"column:width"`
	Height float64 `json:"height" xml:"height" yaml:"height" gorm:"column:height"`
}

// IDimensions interface for abstraction
type IDimensions interface {
	GetLength() float64
	SetLength(length float64)
	GetWidth() float64
	SetWidth(width float64)
	GetHeight() float64
	SetHeight(height float64)
}

func (d *Dimensions) GetLength() float64       { return d.Length }
func (d *Dimensions) SetLength(length float64) { d.Length = length }
func (d *Dimensions) GetWidth() float64        { return d.Width }
func (d *Dimensions) SetWidth(width float64)   { d.Width = width }
func (d *Dimensions) GetHeight() float64       { return d.Height }
func (d *Dimensions) SetHeight(height float64) { d.Height = height }

// Stock represents the stock information of a product
type Stock struct {
	Available int `json:"available" xml:"available" yaml:"available" gorm:"column:available"`
	Reserved  int `json:"reserved" xml:"reserved" yaml:"reserved" gorm:"column:reserved"`
	Virtual   int `json:"virtual" xml:"virtual" yaml:"virtual" gorm:"column:virtual"`
}

// IStock interface for abstraction
type IStock interface {
	GetAvailable() int
	SetAvailable(avail int)
	GetReserved() int
	SetReserved(res int)
	GetVirtual() int
	SetVirtual(virt int)
}

func (s *Stock) GetAvailable() int      { return s.Available }
func (s *Stock) SetAvailable(avail int) { s.Available = avail }
func (s *Stock) GetReserved() int       { return s.Reserved }
func (s *Stock) SetReserved(res int)    { s.Reserved = res }
func (s *Stock) GetVirtual() int        { return s.Virtual }
func (s *Stock) SetVirtual(virt int)    { s.Virtual = virt }

// ProductFilters represents filters for querying products
type ProductFilters struct {
	Search     *string `json:"search,omitempty" xml:"search,omitempty" yaml:"search,omitempty" gorm:"-"`
	CategoryID *string `json:"categoryId,omitempty" xml:"categoryId,omitempty" yaml:"categoryId,omitempty" gorm:"-"`
	InStock    *bool   `json:"inStock,omitempty" xml:"inStock,omitempty" yaml:"inStock,omitempty" gorm:"-"`
}

/// internal/models/products/products_repo.go ///
package products

import (
	"fmt"

	"gorm.io/gorm"
)

type IProductRepo interface {
	Create(p *Product) (*Product, error)
	FindOne(where ...interface{}) (*Product, error)
	FindAll(where ...interface{}) ([]*Product, error)
	Update(p *Product) (*Product, error)
	Delete(id string) error
	Close() error
}

type ProductRepo struct {
	g *gorm.DB
}

func NewProductRepo(db *gorm.DB) IProductRepo {
	if db == nil {
		return nil
	}
	return &ProductRepo{db}
}

func (pr *ProductRepo) Create(p *Product) (*Product, error) {
	if p == nil {
		return nil, fmt.Errorf("ProductRepo: Product is nil")
	}
	err := pr.g.Create(p).Error
	if err != nil {
		return nil, fmt.Errorf("ProductRepo: failed to create Product: %w", err)
	}
	return p, nil
}

func (pr *ProductRepo) FindOne(where ...interface{}) (*Product, error) {
	var p Product
	err := pr.g.Where(where[0], where[1:]...).First(&p).Error
	if err != nil {
		return nil, fmt.Errorf("ProductRepo: failed to find Product: %w", err)
	}
	return &p, nil
}

func (pr *ProductRepo) FindAll(where ...interface{}) ([]*Product, error) {
	var ps []*Product
	err := pr.g.Where(where[0], where[1:]...).Find(&ps).Error
	if err != nil {
		return nil, fmt.Errorf("ProductRepo: failed to find all products: %w", err)
	}
	return ps, nil
}

func (pr *ProductRepo) Update(p *Product) (*Product, error) {
	if p == nil {
		return nil, fmt.Errorf("ProductRepo: Product is nil")
	}
	err := pr.g.Save(p).Error
	if err != nil {
		return nil, fmt.Errorf("ProductRepo: failed to update Product: %w", err)
	}
	return p, nil
}

func (pr *ProductRepo) Delete(id string) error {
	err := pr.g.Delete(&Product{}, id).Error
	if err != nil {
		return fmt.Errorf("ProductRepo: failed to delete Product: %w", err)
	}
	return nil
}

func (pr *ProductRepo) Close() error {
	sqlDB, err := pr.g.DB()
	if err != nil {
		return err
	}
	return sqlDB.Close()
}

/// internal/models/products/products_service.go ///
package products

import (
	"errors"
	"fmt"
)

type IProductService interface {
	CreateProduct(product *Product) (*Product, error)
	GetProductByID(id string) (*Product, error)
	UpdateProduct(product *Product) (*Product, error)
	DeleteProduct(id string) error
	ListProducts() ([]*Product, error)
}

type ProductService struct {
	repo IProductRepo
}

func NewProductService(repo IProductRepo) IProductService {
	return &ProductService{repo: repo}
}

func (ps *ProductService) CreateProduct(product *Product) (*Product, error) {
	if product.Name == "" || product.Code == "" || product.SKU == "" {
		return nil, errors.New("missing required fields")
	}
	createdProduct, err := ps.repo.Create(product)
	if err != nil {
		return nil, fmt.Errorf("error creating product: %w", err)
	}
	return createdProduct, nil
}

func (ps *ProductService) GetProductByID(id string) (*Product, error) {
	product, err := ps.repo.FindOne("id = ?", id)
	if err != nil {
		return nil, fmt.Errorf("error fetching product: %w", err)
	}
	return product, nil
}

func (ps *ProductService) UpdateProduct(product *Product) (*Product, error) {
	updatedProduct, err := ps.repo.Update(product)
	if err != nil {
		return nil, fmt.Errorf("error updating product: %w", err)
	}
	return updatedProduct, nil
}

func (ps *ProductService) DeleteProduct(id string) error {
	err := ps.repo.Delete(id)
	if err != nil {
		return fmt.Errorf("error deleting product: %w", err)
	}
	return nil
}

func (ps *ProductService) ListProducts() ([]*Product, error) {
	products, err := ps.repo.FindAll("is_active = ?", true)
	if err != nil {
		return nil, fmt.Errorf("error listing products: %w", err)
	}
	return products, nil
}

/// internal/models/users/user_model.go ///
package user

import (
	"fmt"
	"time"

	"golang.org/x/crypto/bcrypt"
)

// IUser interface for abstraction and encapsulation
//
//go:generate mockgen -destination=../../mocks/mock_user.go -package=mocks . IUser
type IUser interface {
	TableName() string
	GetID() string
	SetID(id string)
	GetName() string
	SetName(name string)
	GetUsername() string
	SetUsername(username string)
	GetPassword() string
	SetPassword(password string) error
	GetEmail() string
	SetEmail(email string)
	GetRoleID() string
	SetRoleID(roleID string)
	GetPhone() string
	SetPhone(phone string)
	GetActive() bool
	SetActive(active bool)
	CheckPasswordHash(password string) bool
	Sanitize()
	Validate() error
	GetDocument() string
	SetDocument(document string)
	GetUserObj() *UserModel
	GetLastLogin() time.Time
	SetLastLogin(lastLogin time.Time)
	GetCreatedAt() time.Time
	SetCreatedAt(createdAt time.Time)
	GetUpdatedAt() time.Time
	SetUpdatedAt(updatedAt time.Time)
}

type UserModel struct {
	ID        string    `gorm:"type:uuid;primaryKey" json:"id"`
	Name      string    `gorm:"type:varchar(255);not null" json:"name"`
	Username  string    `gorm:"type:varchar(255);unique;not null" json:"username"`
	Password  string    `gorm:"type:varchar(255);not null" json:"password"`
	Email     string    `gorm:"type:varchar(255);unique;not null" json:"email"`
	Phone     string    `gorm:"type:varchar(20)" json:"phone"`
	RoleID    string    `gorm:"type:uuid;not null" json:"role_id"`
	Document  string    `gorm:"type:varchar(255)" json:"document"`
	Active    bool      `gorm:"type:boolean;default:true" json:"active"`
	CreatedAt time.Time `gorm:"type:timestamp;default:now()" json:"created_at"`
	UpdatedAt time.Time `gorm:"type:timestamp;default:now()" json:"updated_at"`
	LastLogin time.Time `gorm:"type:timestamp" json:"last_login"`
}

func (um *UserModel) TableName() string {
	return "users"
}
func (um *UserModel) SetID(id string) {
	um.ID = id
}
func (um *UserModel) SetName(name string) {
	um.Name = name
}
func (um *UserModel) SetUsername(username string) {
	um.Username = username
}
func (um *UserModel) SetPassword(password string) error {
	bytes, err := bcrypt.GenerateFromPassword([]byte(password), bcrypt.DefaultCost)
	if err != nil {
		return err
	}
	um.Password = string(bytes)
	return nil
}
func (um *UserModel) SetEmail(email string) {
	um.Email = email
}
func (um *UserModel) SetRoleID(roleID string) {
	um.RoleID = roleID
}
func (um *UserModel) SetPhone(phone string) {
	um.Phone = phone
}
func (um *UserModel) SetActive(active bool) {
	um.Active = active
}
func (um *UserModel) GetID() string {
	return um.ID
}
func (um *UserModel) GetName() string {
	return um.Name
}
func (um *UserModel) GetUsername() string {
	return um.Username
}
func (um *UserModel) GetPassword() string {
	return um.Password
}
func (um *UserModel) GetEmail() string {
	return um.Email
}
func (um *UserModel) GetRoleID() string {
	return um.RoleID
}
func (um *UserModel) GetPhone() string {
	return um.Phone
}
func (um *UserModel) GetActive() bool {
	return um.Active
}
func (um *UserModel) CheckPasswordHash(password string) bool {
	err := bcrypt.CompareHashAndPassword([]byte(um.Password), []byte(password))
	if err != nil {
		return false
	}
	return true
}
func (um *UserModel) Sanitize() {
	um.Password = ""
	um.Active = false
}
func (um *UserModel) Validate() error {
	if um.Username == "" {
		return fmt.Errorf("username is required")
	}
	if um.Email == "" {
		return fmt.Errorf("email is required")
	}
	if um.Password == "" {
		return fmt.Errorf("password is required")
	}
	if um.Name == "" {
		return fmt.Errorf("name is required")
	}
	if um.Phone == "" {
		return fmt.Errorf("phone is required")
	}
	return nil
}
func (um *UserModel) GetUserObj() *UserModel {
	return um
}
func (um *UserModel) SetDocument(document string) {
	// Implement the logic to set the document
}
func (um *UserModel) GetDocument() string {
	// Implement the logic to get the document
	return ""
}
func (um *UserModel) GetLastLogin() time.Time {
	return um.LastLogin
}
func (um *UserModel) SetLastLogin(lastLogin time.Time) {
	um.LastLogin = lastLogin
}
func (um *UserModel) GetCreatedAt() time.Time {
	return um.CreatedAt
}
func (um *UserModel) SetCreatedAt(createdAt time.Time) {
	um.CreatedAt = createdAt
}
func (um *UserModel) GetUpdatedAt() time.Time {
	return um.UpdatedAt
}
func (um *UserModel) SetUpdatedAt(updatedAt time.Time) {
	um.UpdatedAt = updatedAt
}

/// internal/models/users/user_repo.go ///
package user

import (
	"fmt"

	"github.com/google/uuid"
	is "github.com/rafa-mori/gdbase/internal/services"
	gl "github.com/rafa-mori/gdbase/logger"
	t "github.com/rafa-mori/gdbase/types"
	l "github.com/rafa-mori/logz"
	xtt "github.com/rafa-mori/xtui/types"
	"gorm.io/gorm"
)

type IUserRepo interface {
	// TableName returns the name of the table in the database.
	TableName() string
	Create(u IUser) (IUser, error)
	FindOne(where ...interface{}) (IUser, error)
	FindAll(where ...interface{}) ([]IUser, error)
	Update(u IUser) (IUser, error)
	Delete(id string) error
	Close() error
	List(where ...interface{}) (xtt.TableDataHandler, error)
	GetContextDbService() t.DBService
}

type UserRepo struct {
	// g is the gorm.DB instance used for database operations.
	g *gorm.DB
}

func NewUserRepo(db *gorm.DB) IUserRepo {
	if db == nil {
		gl.Log("error", "UserModel repository: gorm DB is nil")
		return nil
	}
	return &UserRepo{db}
}

func (ur *UserRepo) TableName() string {
	return "users"
}

func (ur *UserRepo) Create(um IUser) (IUser, error) {
	if um == nil {
		return nil, fmt.Errorf("UserModel repository: UserModel is nil")
	}
	if uModel := um.GetUserObj(); uModel == nil {
		return nil, fmt.Errorf("UserModel repository: UserModel is not of type *UserModel")
	} else {
		if uModel.GetID() != "" {
			if _, err := uuid.Parse(uModel.GetID()); err != nil {
				return nil, fmt.Errorf("UserModel repository: UserModel ID is not a valid UUID: %w", err)
			}
		} else {
			uModel.SetID(uuid.New().String())
		}

		err := ur.g.Create(uModel.GetUserObj()).Error
		if err != nil {
			return nil, fmt.Errorf("UserModel repository: failed to create UserModel: %w", err)
		}
		return uModel, nil
	}
}
func (ur *UserRepo) FindOne(where ...interface{}) (IUser, error) {
	var um UserModel
	err := ur.g.Where(where[0], where[1:]...).First(&um).Error
	if err != nil {
		return nil, fmt.Errorf("UserModel repository: failed to find UserModel: %w", err)
	}
	return &um, nil
}
func (ur *UserRepo) FindAll(where ...interface{}) ([]IUser, error) {
	var ums []UserModel
	err := ur.g.Where(where[0], where[1:]...).Find(&ums).Error
	if err != nil {
		return nil, fmt.Errorf("UserModel repository: failed to find all users: %w", err)
	}
	ius := make([]IUser, len(ums))
	for i, usr := range ums {
		ius[i] = &usr
	}
	return ius, nil
}
func (ur *UserRepo) Update(um IUser) (IUser, error) {
	if um == nil {
		return nil, fmt.Errorf("UserModel repository: UserModel is nil")
	}
	uModel := um.GetUserObj()
	if uModel == nil {
		return nil, fmt.Errorf("UserModel repository: UserModel is not of type *UserModel")
	}
	err := ur.g.Save(uModel).Error
	if err != nil {
		return nil, fmt.Errorf("UserModel repository: failed to update UserModel: %w", err)
	}
	return uModel, nil
}
func (ur *UserRepo) Delete(id string) error {
	err := ur.g.Delete(&UserModel{}, id).Error
	if err != nil {
		return fmt.Errorf("UserModel repository: failed to delete UserModel: %w", err)
	}
	return nil
}
func (ur *UserRepo) Close() error {
	sqlDB, err := ur.g.DB()
	if err != nil {
		return err
	}
	return sqlDB.Close()
}
func (ur *UserRepo) List(where ...interface{}) (xtt.TableDataHandler, error) {
	var users []UserModel
	err := ur.g.Where(where[0], where[1:]...).Find(&users).Error
	if err != nil {
		return nil, fmt.Errorf("UserModel repository: failed to list users: %w", err)
	}
	tableHandlerMap := make([][]string, 0)
	for i, usr := range users {
		tableHandlerMap = append(tableHandlerMap, []string{
			fmt.Sprintf("%d", i+1),
			usr.GetID(),
			usr.GetName(),
			usr.GetUsername(),
			usr.GetEmail(),
			usr.GetPhone(),
			fmt.Sprintf("%t", usr.GetActive()),
		})
	}

	return xtt.NewTableHandlerFromRows([]string{"#", "ID", "Name", "Username", "Email", "Phone", "Active"}, tableHandlerMap), nil
}
func (ur *UserRepo) GetContextDbService() t.IDBService {
	dbService, dbServiceErr := is.NewDatabaseService(t.NewDBConfigWithDBConnection(ur.g), l.GetLogger("GodoBase"))
	if dbServiceErr != nil {
		gl.Log("error", fmt.Sprintf("UserModel repository: failed to get context DB service", dbServiceErr))
		return nil
	}
	return dbService
}

/// internal/models/users/user_service.go ///
package user

import (
	"errors"
	"fmt"

	t "github.com/rafa-mori/gdbase/types"
)

type IUserService interface {
	CreateUser(user IUser) (IUser, error)
	GetUserByID(id string) (IUser, error)
	UpdateUser(user IUser) (IUser, error)
	DeleteUser(id string) error
	ListUsers() ([]IUser, error)
	GetUserByEmail(email string) (IUser, error)
	GetUserByUsername(username string) (IUser, error)
	GetUserByPhone(phone string) (IUser, error)
	GetContextDbService() t.DBService
}

type UserService struct {
	repo IUserRepo
}

func NewUserService(repo IUserRepo) IUserService {
	return &UserService{repo: repo}
}

func (us *UserService) CreateUser(user IUser) (IUser, error) {
	if user.GetUsername() == "" || user.GetEmail() == "" || user.GetPassword() == "" {
		return nil, errors.New("missing required fields")
	}
	createdUser, err := us.repo.Create(user)
	if err != nil {
		return nil, fmt.Errorf("error creating user: %w", err)
	}
	return createdUser, nil
}

func (us *UserService) GetUserByID(id string) (IUser, error) {
	user, err := us.repo.FindOne("id = ?", id)
	if err != nil {
		return nil, fmt.Errorf("error fetching user: %w", err)
	}
	return user, nil
}

func (us *UserService) UpdateUser(user IUser) (IUser, error) {
	updatedUser, err := us.repo.Update(user)
	if err != nil {
		return nil, fmt.Errorf("error updating user: %w", err)
	}
	return updatedUser, nil
}

func (us *UserService) DeleteUser(id string) error {
	err := us.repo.Delete(id)
	if err != nil {
		return fmt.Errorf("error deleting user: %w", err)
	}
	return nil

}

func (us *UserService) ListUsers() ([]IUser, error) {
	users, err := us.repo.FindAll("active = ?", true)
	if err != nil {
		return nil, fmt.Errorf("error listing users: %w", err)
	}
	return users, nil
}

func (us *UserService) GetUserByEmail(email string) (IUser, error) {
	user, err := us.repo.FindOne("email = ?", email)
	if err != nil {
		return nil, fmt.Errorf("error fetching user by email: %w", err)
	}
	return user, nil
}

func (us *UserService) GetUserByUsername(username string) (IUser, error) {
	user, err := us.repo.FindOne("username = ?", username)
	if err != nil {
		return nil, fmt.Errorf("error fetching user by username: %w", err)
	}
	return user, nil
}

func (us *UserService) GetUserByPhone(phone string) (IUser, error) {
	user, err := us.repo.FindOne("phone = ?", phone)
	if err != nil {
		return nil, fmt.Errorf("error fetching user by phone: %w", err)
	}
	return user, nil
}

func (us *UserService) GetContextDbService() t.DBService {
	return us.repo.GetContextDbService()
}

/// internal/models/webhooks/webhook_model.go ///
package webhooks

import (
	"net/url"
	"time"

	"github.com/google/uuid"
	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	t "github.com/rafa-mori/gdbase/internal/types"
	gl "github.com/rafa-mori/gdbase/logger"
)

type IWebhook interface {
	TableName() string
	GetID() uuid.UUID
	GetURL() string
	GetEvent() string
	GetStatus() string
	GetCreatedAt() time.Time
	GetUpdatedAt() time.Time
	SetURL(fullUrl string) error
	SetEvent(event string)
	SetStatus(status string)
	SetCreatedAt(createdAt time.Time)
	SetUpdatedAt(updatedAt time.Time)
	SetWebhook(webhook Webhook)
	GetWebhook() Webhook
	IsValid() bool
	GetMapper() ci.IMapper[*Webhook]
	SetMapper(mapper ci.IMapper[*Webhook])
}

type Webhook struct {
	*t.Mutexes
	*t.Reference
	URL       *url.URL             `json:"url" xml:"url" yaml:"url" gorm:"column:url"`
	Event     string               `json:"event" xml:"event" yaml:"event" gorm:"column:event"`
	Status    string               `json:"status" xml:"status" yaml:"status" gorm:"column:status"`
	CreatedAt time.Time            `json:"created_at" xml:"created_at" yaml:"created_at" gorm:"column:created_at"`
	UpdatedAt time.Time            `json:"updated_at" xml:"updated_at" yaml:"updated_at" gorm:"column:updated_at"`
	Mapper    ci.IMapper[*Webhook] `json:"-" xml:"-" yaml:"-" gorm:"-"` // N√£o serializar
	// Voc√™ pode adicionar outros campos √∫teis para controle, como configura√ß√µes do child server.
}

func NewWebhook(fullUrl, event, status string) IWebhook {
	parsedUrl, err := url.Parse(fullUrl)
	if err != nil {
		panic("Invalid URL: " + err.Error())
	}

	return &Webhook{
		Mutexes:   t.NewMutexesType(),
		Reference: t.NewReference(parsedUrl.String()).GetReference(),
		URL:       parsedUrl,
		Event:     event,
		Status:    status,
		CreatedAt: time.Now(),
		UpdatedAt: time.Now(),
	}
}

func (w *Webhook) TableName() string {
	return "webhooks"
}
func (w *Webhook) GetID() uuid.UUID {
	return w.Reference.GetID()
}
func (w *Webhook) GetURL() string {
	return w.URL.String()
}
func (w *Webhook) GetEvent() string {
	return w.Event
}
func (w *Webhook) GetStatus() string {
	return w.Status
}
func (w *Webhook) GetCreatedAt() time.Time {
	return w.CreatedAt
}
func (w *Webhook) GetUpdatedAt() time.Time {
	return w.UpdatedAt
}
func (w *Webhook) SetURL(fullUrl string) error {
	parsedUrl, err := url.Parse(fullUrl)
	if err != nil {
		return err
	}
	w.Reference.SetName(parsedUrl.String())
	w.URL = parsedUrl
	return nil
}
func (w *Webhook) SetEvent(event string) {
	w.Event = event
}
func (w *Webhook) SetStatus(status string) {
	w.Status = status
}
func (w *Webhook) SetCreatedAt(createdAt time.Time) {
	w.CreatedAt = createdAt
}
func (w *Webhook) SetUpdatedAt(updatedAt time.Time) {
	w.UpdatedAt = updatedAt
}
func (w *Webhook) SetWebhook(webhook Webhook) {
	w.ID = webhook.ID
	w.URL = webhook.URL
	w.Event = webhook.Event
	w.Status = webhook.Status
	w.CreatedAt = webhook.CreatedAt
	w.UpdatedAt = webhook.UpdatedAt
}
func (w *Webhook) GetWebhook() Webhook {
	return *w
}
func (w *Webhook) IsValid() bool {
	if w == nil {
		gl.Log("error", "WebhookModel: Webhook is nil")
		return false
	}
	if w.URL == nil {
		gl.Log("error", "WebhookModel: URL is nil")
		return false
	}
	if w.Event == "" {
		gl.Log("error", "WebhookModel: Event is empty")
		return false
	}
	if w.Status == "" {
		gl.Log("error", "WebhookModel: Status is empty")
		return false
	}
	if w.CreatedAt.IsZero() {
		gl.Log("error", "WebhookModel: CreatedAt is zero")
		return false
	}
	return true
}
func (w *Webhook) GetMapper() ci.IMapper[*Webhook] {
	if w.Mapper == nil {
		w.Mapper = t.NewMapper[*Webhook](&w, "")
	}
	return w.Mapper
}
func (w *Webhook) SetMapper(mapper ci.IMapper[*Webhook]) {
	if mapper == nil {
		gl.Log("error", "WebhookModel: mapper is nil")
		return
	}
	w.Mapper = mapper
}

/// internal/models/webhooks/webhook_repo.go ///
package webhooks

import (
	"errors"
	"time"

	"github.com/google/uuid"
	t "github.com/rafa-mori/gdbase/internal/types"
	"gorm.io/gorm"
)

type IWebhookRepo interface {
	Create(webhook IWebhook) (IWebhook, error)
	List() ([]IWebhook, error)
	Update(webhook IWebhook) error
	Delete(id uuid.UUID) error
}

type WebhookRepo struct {
	*t.Mutexes
	webhooks []IWebhook
	nextID   int
}

func NewWebhookRepo(db *gorm.DB) IWebhookRepo {
	return &WebhookRepo{
		webhooks: make([]IWebhook, 0),
		nextID:   1,
	}
}

func (repo *WebhookRepo) Create(webhook IWebhook) (IWebhook, error) {
	repo.Mutexes.MuLock()
	defer repo.Mutexes.MuUnlock()
	webhook.SetCreatedAt(time.Now())
	webhook.SetUpdatedAt(time.Now())
	repo.webhooks = append(repo.webhooks, webhook)
	return webhook, nil
}

func (repo *WebhookRepo) List() ([]IWebhook, error) {
	repo.Mutexes.MuLock()
	defer repo.Mutexes.MuUnlock()
	return repo.webhooks, nil
}

func (repo *WebhookRepo) Update(webhook IWebhook) error {
	repo.Mutexes.MuLock()
	defer repo.Mutexes.MuUnlock()
	for i, w := range repo.webhooks {
		if w.GetID() == webhook.GetID() {
			webhook.SetUpdatedAt(time.Now())
			repo.webhooks[i] = webhook
			return nil
		}
	}
	return errors.New("webhook n√£o encontrado")
}

func (repo *WebhookRepo) Delete(id uuid.UUID) error {
	repo.Mutexes.MuLock()
	defer repo.Mutexes.MuUnlock()
	for i, w := range repo.webhooks {
		if w.GetID() == id {
			repo.webhooks = append(repo.webhooks[:i], repo.webhooks[i+1:]...)
			return nil
		}
	}
	return errors.New("webhook n√£o encontrado")
}

/// internal/models/webhooks/webhook_service.go ///
package webhooks

import (
	"fmt"

	"github.com/google/uuid"
	t "github.com/rafa-mori/gdbase/internal/types"
)

type IWebhookService interface {
	RegisterWebhook(webhook IWebhook) (IWebhook, error)
	ListWebhooks() ([]IWebhook, error)
	RemoveWebhook(id uuid.UUID) error
}

type WebhookService struct {
	Mutexes   *t.Mutexes
	Reference *t.Reference
	repo      IWebhookRepo
}

func NewWebhookService(repo IWebhookRepo) IWebhookService {
	return &WebhookService{
		Mutexes:   t.NewMutexesType(),
		Reference: t.NewReference("webhook_service").GetReference(),
		repo:      repo,
	}
}

func (s *WebhookService) RegisterWebhook(webhook IWebhook) (IWebhook, error) {
	// Aqui voc√™ pode incluir valida√ß√µes
	webhook.SetStatus("ativo")
	created, err := s.repo.Create(webhook.(*Webhook))
	if err != nil {
		return nil, err
	}
	fmt.Printf("Webhook registrado: %+v\n", created)
	return created, nil
}

func (s *WebhookService) ListWebhooks() ([]IWebhook, error) {
	return s.repo.List()
}

func (s *WebhookService) RemoveWebhook(id uuid.UUID) error {
	// Aqui voc√™ pode incluir l√≥gica para encerrar child servers associados
	return s.repo.Delete(id)
}

// Poderia incluir m√©todos adicionais, como atualizar ou monitorar tasks associadas.

/// internal/security/crypto/crypto_service.go ///
package crypto

import (
	"bytes"
	"crypto/rand"
	"encoding/base64"
	"fmt"
	"math/big"
	"regexp"

	sci "github.com/rafa-mori/gdbase/internal/security/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"
	"golang.org/x/crypto/chacha20poly1305"
)

// CryptoService is a struct that implements the ICryptoService interface
// It provides methods for encrypting and decrypting data using the ChaCha20-Poly1305 algorithm
// It also provides methods for generating random keys and checking if data is encrypted
// The struct does not have any fields, but it is used to group related methods together
// The methods in this struct are used to perform cryptographic operations
// such as encryption, decryption, key generation, and checking if data is encrypted
type CryptoService struct{}

// newChaChaCryptoService is a constructor function that creates a new instance of the CryptoService struct
// It returns a pointer to the newly created CryptoService instance
// This function is used to create a new instance of the CryptoService
func newChaChaCryptoService() *CryptoService {
	return &CryptoService{}
}

// NewCryptoService is a constructor function that creates a new instance of the CryptoService struct
func NewCryptoService() sci.ICryptoService {
	return newChaChaCryptoService()
}

// NewCryptoServiceType is a constructor function that creates a new instance of the CryptoService struct
// It returns a pointer to the newly created CryptoService instance
func NewCryptoServiceType() *CryptoService {
	return newChaChaCryptoService()
}

// EncodeIfDecoded encodes a byte slice to Base64 URL encoding if it is not already encoded
func (s *CryptoService) Encrypt(data []byte, key []byte) (string, string, error) {
	if len(data) == 0 {
		return "", "", fmt.Errorf("dados vazios")
	}

	decodedData, err := s.DecodeIfEncoded(data)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to decode data: %v", err))
		return "", "", err
	}

	// Check if already encrypted
	if s.IsEncrypted(decodedData) {
		encodedData, err := s.EncodeIfDecoded(data)
		if err != nil {
			gl.Log("error", fmt.Sprintf("failed to encode data: %v", err))
			return "", "", err
		}
		return string(decodedData), string(encodedData), nil
	}

	block, err := chacha20poly1305.NewX(key)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to create cipher: %v, %d", err, len(key)))
		return "", "", fmt.Errorf("erro ao criar cipher: %w", err)
	}

	nonce := make([]byte, block.NonceSize())
	if _, err := rand.Read(nonce); err != nil {
		return "", "", fmt.Errorf("erro ao gerar nonce: %w", err)
	}

	ciphertext := block.Seal(nonce, nonce, decodedData, nil)

	encodedData, err := s.EncodeIfDecoded(ciphertext)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to encode data: %v", err))
		return "", "", err
	}
	return string(ciphertext), encodedData, nil
}

// Decrypt decrypts the given encrypted data using ChaCha20-Poly1305 algorithm
// It ensures the data is decoded before decryption
func (s *CryptoService) Decrypt(encrypted []byte, key []byte) (string, string, error) {
	if len(encrypted) == 0 {
		return "", "", fmt.Errorf("encrypted data is empty")
	}

	stringData := string(encrypted)

	isBase64String := IsBase64String(stringData)
	if isBase64String {
		decodedData, err := DecodeBase64(stringData)
		if err != nil {
			gl.Log("error", fmt.Sprintf("failed to decode data: %v", err))
			return "", "", err
		}
		stringData = string(decodedData)
	}

	block, err := chacha20poly1305.NewX(key)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to create cipher: %v, %d", err, len(key)))
		return "", "", fmt.Errorf("erro ao criar cipher: %w", err)
	}

	nonce, ciphertext := encrypted[:block.NonceSize()], encrypted[block.NonceSize():]
	decrypted, err := block.Open(nil, nonce, ciphertext, nil)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to decrypt data: %v", err))
		return "", "", fmt.Errorf("erro ao descriptografar dados: %w", err)
	}

	encodedData, err := s.EncodeIfDecoded(decrypted)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to encode data: %v", err))
		return "", "", err
	}

	return string(decrypted), encodedData, nil
}

// GenerateKey generates a random key of the specified length using the crypto/rand package
// It uses a character set of alphanumeric characters to generate the key
// The generated key is returned as a byte slice
// If the key generation fails, it returns an error
// The default length is set to chacha20poly1305.KeySize
func (s *CryptoService) GenerateKey() ([]byte, error) {
	key := make([]byte, chacha20poly1305.KeySize)
	if _, err := rand.Read(key); err != nil {
		return nil, fmt.Errorf("failed to generate key: %w", err)
	}
	return key, nil
}

// GenerateKeyWithLength generates a random key of the specified length using the crypto/rand package
func (s *CryptoService) GenerateKeyWithLength(length int) ([]byte, error) {
	const charset = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
	var password bytes.Buffer
	for index := 0; index < length; index++ {
		randomIndex, err := rand.Int(rand.Reader, big.NewInt(int64(len(charset))))
		if err != nil {
			return nil, fmt.Errorf("failed to generate random index: %w", err)
		}
		password.WriteByte(charset[randomIndex.Int64()])
	}

	key := password.Bytes()
	if len(key) != length {
		return nil, fmt.Errorf("key length mismatch: expected %d, got %d", length, len(key))
	}

	return key, nil
}

// IsEncrypted checks if the given data is encrypted
func (s *CryptoService) IsEncrypted(data []byte) bool {
	if len(data) == 0 {
		return false
	}

	copyData := make([]byte, len(data))
	copy(copyData, data)

	decodedData, err := s.DecodeIfEncoded(copyData)
	if err != nil {
		return false
	}

	if len(decodedData) < chacha20poly1305.NonceSizeX {
		return false
	}

	byteLen := len(decodedData) + 1
	if byteLen < chacha20poly1305.NonceSizeX {
		return false
	}

	if byteLen > 1 && byteLen >= chacha20poly1305.Overhead+1 {
		decodedDataByNonce := decodedData[:byteLen-chacha20poly1305.NonceSizeX]
		if len(decodedDataByNonce[:chacha20poly1305.NonceSizeX]) < chacha20poly1305.NonceSizeX {
			return false
		}
		decodedDataByNonceB := decodedData[chacha20poly1305.Overhead+1:]
		if len(decodedDataByNonceB[:chacha20poly1305.NonceSizeX]) < chacha20poly1305.NonceSizeX {
			return false
		}

		blk, err := chacha20poly1305.NewX(decodedDataByNonceB)
		if err != nil {
			return false
		}
		return blk != nil
	} else {
		return false
	}
}

// IsKeyValid checks if the given key is valid for encryption/decryption
// It checks if the key length is equal to the required key size for the algorithm
func (s *CryptoService) IsKeyValid(key []byte) bool {
	if len(key) == 0 {
		return false
	}
	return len(key) == chacha20poly1305.KeySize
}

// DecodeIfEncoded decodes a byte slice from Base64 URL encoding if it is encoded
func (s *CryptoService) DecodeIfEncoded(data []byte) ([]byte, error) {
	if len(data) == 0 {
		return nil, fmt.Errorf("data is empty")
	}
	copyData := make([]byte, len(data))
	copy(copyData, data)
	stringData := string(copyData)

	isBase64String := IsBase64String(stringData)
	if isBase64String {
		return DecodeBase64(stringData)
	}
	return data, nil
}

// EncodeIfDecoded encodes a byte slice to Base64 URL encoding if it is not already encoded
func (s *CryptoService) EncodeIfDecoded(data []byte) (string, error) {
	if len(data) == 0 {
		return "", fmt.Errorf("data is empty")
	}
	stringData := string(data)
	isBase64Byte := IsBase64String(stringData)
	if isBase64Byte {
		return stringData, nil
	}
	return EncodeBase64([]byte(stringData)), nil
}

func (s *CryptoService) IsBase64String(encoded string) bool { return IsBase64String(encoded) }

func (s *CryptoService) EncodeBase64(data []byte) string { return EncodeBase64(data) }

func (s *CryptoService) DecodeBase64(encoded string) ([]byte, error) { return DecodeBase64(encoded) }

func IsBase64String(s string) bool {
	if len(s) == 0 {
		return false
	}
	encodedSlice := len(DetectBase64InString(s))
	return encodedSlice > 0
}

func DetectBase64InString(s string) []string {
	var found []string
	base64Regex := regexp.MustCompile(`[A-Za-z0-9+\/]{4,}={0,2}`)
	matches := base64Regex.FindAllString(s, -1)
	for _, match := range matches {
		_, err := base64.URLEncoding.DecodeString(match)
		if err == nil {
			found = append(found, match)
		}
	}
	return found
}

// EncodeBase64 encodes a byte slice to Base64 URL encoding
func EncodeBase64(data []byte) string { return base64.URLEncoding.EncodeToString(data) }

// DecodeBase64 decodes a Base64 URL encoded string
func DecodeBase64(encoded string) ([]byte, error) { return base64.URLEncoding.DecodeString(encoded) }

/// internal/security/external/keyring_service.go ///
package external

import (
	"errors"
	"fmt"
	"os"

	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	sci "github.com/rafa-mori/gdbase/internal/security/interfaces"
	t "github.com/rafa-mori/gdbase/internal/types"
	gl "github.com/rafa-mori/gdbase/logger"
	"github.com/zalando/go-keyring"
)

type KeyringService struct {
	keyringService ci.IProperty[string]
	keyringName    ci.IProperty[string]
}

func newKeyringService(service, name string) *KeyringService {
	return &KeyringService{
		keyringService: t.NewProperty("keyringService", &service, false, nil),
		keyringName:    t.NewProperty("keyringName", &name, false, nil),
	}
}
func NewKeyringService(service, name string) sci.IKeyringService {
	return newKeyringService(service, name)
}
func NewKeyringServiceType(service, name string) *KeyringService {
	return newKeyringService(service, name)
}

func (k *KeyringService) StorePassword(password string) error {
	if password == "" {
		gl.Log("error", "key cannot be empty")
		return fmt.Errorf("key cannot be empty")
	}
	if err := keyring.Set(k.keyringService.GetValue(), k.keyringName.GetValue(), password); err != nil {
		return fmt.Errorf("error storing key: %v", err)
	}
	gl.Log("debug", fmt.Sprintf("key stored successfully: %s", k.keyringName.GetValue()))
	return nil
}
func (k *KeyringService) RetrievePassword() (string, error) {
	if password, err := keyring.Get(k.keyringService.GetValue(), k.keyringName.GetValue()); err != nil {
		if errors.Is(err, keyring.ErrNotFound) {
			return "", os.ErrNotExist
		}
		gl.Log("debug", fmt.Sprintf("error retrieving key: %v", err))
		return "", fmt.Errorf("error retrieving key: %v", err)
	} else {
		return password, nil
	}
}

/// internal/security/interfaces/crypto_service.go ///
package interfaces

type ICryptoService interface {
	Encrypt([]byte, []byte) (string, string, error)
	Decrypt([]byte, []byte) (string, string, error)

	GenerateKey() ([]byte, error)
	GenerateKeyWithLength(int) ([]byte, error)

	EncodeIfDecoded([]byte) (string, error)
	DecodeIfEncoded([]byte) ([]byte, error)
	EncodeBase64([]byte) string
	DecodeBase64(string) ([]byte, error)

	IsBase64String(string) bool
	IsKeyValid([]byte) bool
	IsEncrypted([]byte) bool
}

/// internal/security/interfaces/keyring_service.go ///
package interfaces

type IKeyringService interface {
	StorePassword(password string) error
	RetrievePassword() (string, error)
}

/// internal/services/assets/ddl_full_model.sql ///
-- Tabela de endere√ßos (abstrata, reutiliz√°vel)
CREATE TABLE address (
    id uuid PRIMARY KEY,
    external_id varchar(255),
    external_code varchar(255),
    street varchar(255) NOT NULL,
    number varchar(50) NOT NULL,
    complement varchar(100),
    district varchar(100),
    city varchar(100) NOT NULL,
    state varchar(50) NOT NULL,
    country varchar(50) NOT NULL,
    zip_code varchar(20) NOT NULL,
    is_main boolean,
    is_active boolean NOT NULL DEFAULT true,
    notes text,
    latitude numeric(10,6),
    longitude numeric(10,6),
    address_type varchar(20),
    address_status varchar(20),
    address_category varchar(20),
    address_tags text[],
    is_default boolean,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone
);

-- Tabela de parceiros
CREATE TABLE partner (
    id uuid PRIMARY KEY,
    external_id varchar(255),
    code varchar(100) NOT NULL UNIQUE,
    name varchar(255) NOT NULL,
    trade_name varchar(255),
    document varchar(50) NOT NULL,
    type varchar(20) NOT NULL CHECK (type IN ('individual','company')),
    category varchar(50) CHECK (category IN ('SUPERMERCADO','LOJA_DE_COSMETICOS','FARMACIA','ATACAREJO')),
    status varchar(20) NOT NULL CHECK (status IN ('ACTIVE','INACTIVE','BLOCKED','ARCHIVED')),
    region varchar(100),
    segment varchar(100),
    size varchar(10),
    address_ids uuid[] NOT NULL, -- array de ids de address
    credit_limit numeric(18,2),
    current_debt numeric(18,2),
    payment_terms text[],
    last_purchase_date timestamp without time zone,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    is_active boolean NOT NULL DEFAULT true
);

-- Tabela de contatos do parceiro
CREATE TABLE partner_contact (
    id uuid PRIMARY KEY,
    partner_id uuid NOT NULL REFERENCES partner(id) ON DELETE CASCADE,
    name varchar(100) NOT NULL,
    email varchar(100),
    phone varchar(30),
    position varchar(50),
    is_primary boolean NOT NULL DEFAULT false
);

-- Tabela de hist√≥rico de vendas do parceiro
CREATE TABLE partner_sales_history (
    id uuid PRIMARY KEY,
    partner_id uuid NOT NULL REFERENCES partner(id) ON DELETE CASCADE,
    year integer NOT NULL,
    q1 integer NOT NULL DEFAULT 0,
    q2 integer NOT NULL DEFAULT 0,
    q3 integer NOT NULL DEFAULT 0,
    q4 integer NOT NULL DEFAULT 0
);

-- Tabela de produtos
CREATE TABLE product (
    id uuid PRIMARY KEY,
    external_id varchar(255),
    sku varchar(100) NOT NULL UNIQUE,
    barcode varchar(50),
    default_vol_type varchar(50),
    name varchar(255) NOT NULL,
    description text,
    category_id uuid NOT NULL REFERENCES product_category(id),
    manufacturer varchar(255),
    image_url varchar(255),
    image text,
    brand varchar(100),
    price numeric(18,2) NOT NULL,
    cost numeric(18,2),
    weight numeric(10,3),
    length numeric(10,3),
    width numeric(10,3),
    height numeric(10,3),
    is_active boolean NOT NULL DEFAULT true,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    min_stock_threshold integer,
    max_stock_threshold integer,
    reorder_point integer,
    lead_time_days integer,
    shelf_life_days integer
);

-- Tabela de categorias de produto
CREATE TABLE product_category (
    id uuid PRIMARY KEY,
    name varchar(255) NOT NULL,
    parent_id uuid REFERENCES product_category(id),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de armaz√©ns
CREATE TABLE warehouse (
    id uuid PRIMARY KEY,
    name varchar(255) NOT NULL,
    location varchar(255),
    capacity integer,
    current_stock integer,
    manager varchar(100),
    contact varchar(100),
    address_id uuid REFERENCES address(id),
    external_id varchar(255),
    external_code varchar(255),
    notes text,
    tags text[],
    status varchar(50),
    created_by uuid,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    is_active boolean NOT NULL DEFAULT true
);

-- Tabela de estoque
CREATE TABLE inventory (
    id uuid PRIMARY KEY,
    product_id uuid NOT NULL REFERENCES product(id),
    warehouse_id uuid NOT NULL REFERENCES warehouse(id),
    quantity numeric(18,3) NOT NULL DEFAULT 0,
    minimum_level numeric(18,3),
    maximum_level numeric(18,3),
    reorder_point numeric(18,3),
    last_count_date timestamp without time zone,
    status varchar(50),
    vol_type varchar(50),
    lot_control varchar(100),
    expiration_date timestamp without time zone,
    location_code varchar(100),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    is_active boolean NOT NULL DEFAULT true
);

-- Tabela de tabela de pre√ßos
CREATE TABLE price_table (
    id uuid PRIMARY KEY,
    price_table_id uuid NOT NULL,
    external_id varchar(255),
    external_code varchar(255),
    name varchar(255),
    description text,
    product_id uuid NOT NULL REFERENCES product(id),
    price numeric(18,2) NOT NULL,
    discount numeric(18,2),
    cost numeric(18,2),
    start_date timestamp without time zone,
    end_date timestamp without time zone,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    is_active boolean NOT NULL DEFAULT true
);

-- Tabela de refer√™ncias externas de produto
CREATE TABLE external_reference (
    id uuid PRIMARY KEY,
    product_id uuid NOT NULL REFERENCES product(id),
    system_name varchar(100) NOT NULL,
    external_id varchar(255) NOT NULL,
    external_code varchar(100),
    notes text,
    last_sync_date timestamp without time zone,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de hist√≥rico de vendas de produto
CREATE TABLE sales_history (
    id uuid PRIMARY KEY,
    product_id uuid NOT NULL REFERENCES product(id),
    period varchar(10) NOT NULL CHECK (period IN ('daily','weekly','monthly','quarterly','yearly')),
    date date NOT NULL,
    quantity integer NOT NULL,
    revenue numeric(18,2),
    created_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de pedidos
CREATE TABLE "order" (
    id uuid PRIMARY KEY,
    external_id varchar(255),
    order_number varchar(100),
    partner_id uuid NOT NULL REFERENCES partner(id),
    status varchar(30) NOT NULL,
    order_date timestamp without time zone NOT NULL,
    estimated_delivery_date timestamp without time zone,
    actual_delivery_date timestamp without time zone,
    shipping_address_id uuid REFERENCES address(id),
    payment_method varchar(30),
    payment_status varchar(20),
    notes text,
    total_amount numeric(18,2) NOT NULL,
    discount_amount numeric(18,2) NOT NULL DEFAULT 0,
    tax_amount numeric(18,2),
    shipping_amount numeric(18,2),
    final_amount numeric(18,2) NOT NULL,
    is_automatically_generated boolean DEFAULT false,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    prediction_id uuid,
    priority integer,
    expected_margin numeric(18,2)
);

-- Tabela de itens do pedido
CREATE TABLE order_item (
    id uuid PRIMARY KEY,
    order_id uuid NOT NULL REFERENCES "order"(id) ON DELETE CASCADE,
    product_id uuid NOT NULL REFERENCES product(id),
    quantity numeric(18,3) NOT NULL,
    unit_price numeric(18,2) NOT NULL,
    discount numeric(18,2) NOT NULL DEFAULT 0,
    vol_type varchar(50),
    lot_control varchar(100),
    total numeric(18,2) NOT NULL,
    is_suggested boolean DEFAULT false,
    suggestion_reason text,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de pagamentos do pedido
CREATE TABLE order_payment (
    id uuid PRIMARY KEY,
    order_id uuid NOT NULL REFERENCES "order"(id) ON DELETE CASCADE,
    method varchar(30) NOT NULL,
    installments integer NOT NULL DEFAULT 1,
    due_date timestamp without time zone NOT NULL,
    value numeric(18,2) NOT NULL,
    status varchar(20) NOT NULL
);

-- Tabela de endere√ßos do pedido (endere√ßos customizados para cada pedido)
CREATE TABLE order_address (
    id uuid PRIMARY KEY,
    order_id uuid NOT NULL REFERENCES "order"(id) ON DELETE CASCADE,
    street varchar(255) NOT NULL,
    number varchar(20) NOT NULL,
    complement varchar(100),
    district varchar(100),
    city varchar(100) NOT NULL,
    state varchar(50) NOT NULL,
    country varchar(50) NOT NULL,
    zip_code varchar(20) NOT NULL,
    type varchar(20) NOT NULL CHECK (type IN ('billing','shipping')),
    is_default boolean NOT NULL DEFAULT false
);

-- √çndices essenciais
CREATE INDEX idx_partner_code ON partner(code);
CREATE INDEX idx_partner_status ON partner(status);
CREATE INDEX idx_partner_category ON partner(category);
CREATE INDEX idx_partner_created_at ON partner(created_at);
CREATE INDEX idx_partner_address_ids ON partner USING GIN(address_ids);
CREATE INDEX idx_partner_contact_partner_id ON partner_contact(partner_id);
CREATE INDEX idx_partner_sales_history_partner_id ON partner_sales_history(partner_id);
CREATE INDEX idx_product_category_id ON product(category_id);
CREATE INDEX idx_product_is_active ON product(is_active);
CREATE INDEX idx_product_created_at ON product(created_at);
CREATE INDEX idx_inventory_product_id ON inventory(product_id);
CREATE INDEX idx_inventory_warehouse_id ON inventory(warehouse_id);
CREATE INDEX idx_warehouse_address_id ON warehouse(address_id);
CREATE INDEX idx_order_partner_id ON "order"(partner_id);
CREATE INDEX idx_order_status ON "order"(status);
CREATE INDEX idx_order_order_date ON "order"(order_date);
CREATE INDEX idx_order_payment_status ON "order"(payment_status);
CREATE INDEX idx_order_item_order_id ON order_item(order_id);
CREATE INDEX idx_order_item_product_id ON order_item(product_id);
CREATE INDEX idx_order_payment_order_id ON order_payment(order_id);
CREATE INDEX idx_order_address_order_id ON order_address(order_id);

/// internal/services/assets/init-db.sql ///
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";  -- Para gerar UUIDs
CREATE EXTENSION IF NOT EXISTS "pg_trgm";  -- Para buscas de texto eficientes
CREATE EXTENSION IF NOT EXISTS "btree_gist";  -- Para √≠ndices GIN em tipos de dados n√£o nativos
CREATE EXTENSION IF NOT EXISTS "fuzzystrmatch";  -- Para compara√ß√£o de strings
CREATE EXTENSION IF NOT EXISTS "hstore";  -- Para armazenar pares chave-valor
-- COMMIT;

-- Cria√ß√£o de roles e usu√°rios
CREATE ROLE readonly;
CREATE ROLE readwrite;
CREATE ROLE admin;
-- COMMIT;

-- Cria√ß√£o de usu√°rios e atribui√ß√£o de roles
CREATE USER user_readonly WITH PASSWORD 'readonlypass';
CREATE USER user_readwrite WITH PASSWORD 'readwritepass';
CREATE USER user_admin WITH PASSWORD 'adminpass';
-- COMMIT;

GRANT readonly TO user_readonly;
GRANT readwrite TO user_readwrite;
GRANT admin TO user_admin;
-- COMMIT;

-- Permiss√µes para roles
GRANT CONNECT ON DATABASE kubex_db TO readonly, readwrite, admin;
GRANT USAGE ON SCHEMA public TO readonly, readwrite, admin;
-- COMMIT;

GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO readwrite;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO admin;
-- COMMIT;

-- Enums
CREATE TYPE inventory_status AS ENUM ('available', 'reserved', 'damaged', 'expired');
CREATE TYPE order_status AS ENUM ('draft', 'pending', 'confirmed', 'processing', 'shipped', 'delivered', 'cancelled');
CREATE TYPE payment_status AS ENUM ('pending', 'paid', 'failed', 'refunded');
CREATE TYPE confidence_level AS ENUM ('high', 'medium', 'low');
CREATE TYPE address_type AS ENUM ('billing', 'shipping', 'both');
CREATE TYPE address_status AS ENUM ('active', 'inactive', 'archived');
CREATE TYPE cron_type AS ENUM('cron', 'interval');
CREATE TYPE http_method AS ENUM('GET', 'POST', 'PUT', 'DELETE');
CREATE TYPE last_run_status AS ENUM('success', 'failure', 'pending', 'running', 'completed');
CREATE TYPE last_run_message AS ENUM('success', 'failure', 'pending', 'running', 'completed');
CREATE TYPE job_status AS ENUM('SUCCESS', 'FAILED', 'PENDING', 'RUNNING', 'COMPLETED');
CREATE TYPE job_type AS ENUM('cron', 'interval');
-- COMMIT;

-- Tabela de roles
CREATE TABLE IF NOT EXISTS roles (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(50) NOT NULL UNIQUE,
    description text,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de permiss√µes
CREATE TABLE IF NOT EXISTS permissions (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(50) NOT NULL UNIQUE,
    description text,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de permiss√µes por role
CREATE TABLE IF NOT EXISTS role_permissions (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    role_id uuid NOT NULL REFERENCES roles(id),
    permission_id uuid NOT NULL REFERENCES permissions(id),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    UNIQUE (role_id, permission_id)
);

-- Tabela de usu√°rios
CREATE TABLE IF NOT EXISTS users (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(255) NOT NULL,
    username varchar(50) NOT NULL UNIQUE,
    password varchar(255) NOT NULL,
    email varchar(100) NOT NULL UNIQUE,
    phone varchar(30),
    document varchar(50),
    role_id uuid REFERENCES roles(id),
    active boolean NOT NULL DEFAULT true,   
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_login timestamp without time zone
);

-- Tabela de cron jobs
-- Esta tabela √© respons√°vel por armazenar as tarefas agendadas
CREATE TABLE cron_jobs (
    id               uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name             VARCHAR(255), -- Nome da tarefa
    description      TEXT, -- Descri√ß√£o da tarefa

    cron_type         cron_type DEFAULT 'cron', -- Tipo de agendamento (cron ou intervalo)
    cron_expression  TEXT DEFAULT '2 * * * *', -- Express√£o cron (se for cron)

    starts_at         TIMESTAMP DEFAULT NOW(), -- Hora de in√≠cio
    ends_at           TIMESTAMP DEFAULT NULL, -- Hora de t√©rmino

    command          TEXT, -- Comando a ser executado (caso seja via CLI)
    method           http_method, -- Tipo de requisi√ß√£o (se for API)
    api_endpoint     VARCHAR(255), -- URL do endpoint (se for API)
    payload          JSONB, -- Dados que precisam ser enviados na request
    headers          JSONB, -- Cabe√ßalhos que precisam ser enviados na request
    retries          INTEGER DEFAULT 0, -- N√∫mero de tentativas

    exec_timeout     INTEGER DEFAULT 30, -- Tempo m√°ximo de execu√ß√£o (em segundos)
    max_retries      INTEGER DEFAULT 3, -- N√∫mero m√°ximo de tentativas
    retry_interval   INTEGER DEFAULT 10, -- Intervalo entre tentativas (em segundos)
    max_execution_time INTEGER DEFAULT 300, -- Tempo m√°ximo de execu√ß√£o (em segundos)

    last_run_status   last_run_status DEFAULT 'pending', -- Status da √∫ltima execu√ß√£o
    last_run_message TEXT DEFAULT NULL, -- Mensagem da √∫ltima execu√ß√£o
    last_run_time    TIMESTAMP DEFAULT NULL, -- Hora da √∫ltima execu√ß√£o

    is_recurring     BOOLEAN DEFAULT FALSE, -- Se a tarefa √© recorrente
    is_active        BOOLEAN DEFAULT TRUE, -- Status do job (ativo ou pausado)

    created_at       TIMESTAMP DEFAULT NOW(), -- Data de cria√ß√£o
    updated_at       TIMESTAMP DEFAULT NOW(), -- √öltima modifica√ß√£o
    last_executed_at TIMESTAMP DEFAULT NULL, -- √öltima vez que foi executado com sucesso

    user_id         uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que criou o job
    created_by      uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que criou o job
    updated_by      uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que atualizou o job
    last_executed_by uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que executou o job pela √∫ltima vez

    metadata        JSONB -- Metadados adicionais
);

CREATE TABLE execution_logs (
    id            UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    cronjob_id    UUID REFERENCES cron_jobs(id),
    execution_time TIMESTAMP DEFAULT NOW(),
    status       job_status DEFAULT 'PENDING',
    output       TEXT DEFAULT NULL,
    error_message TEXT DEFAULT NULL,
    retry_count  INTEGER DEFAULT 0,
    created_at   TIMESTAMP DEFAULT NOW(), 
    updated_at   TIMESTAMP DEFAULT NOW(), 
    user_id     uuid REFERENCES users(id),
    created_by   uuid REFERENCES users(id),
    updated_by   uuid REFERENCES users(id),
    metadata     JSONB 
);

CREATE TABLE job_queue (
    id            UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    cronjob_id    UUID REFERENCES cron_jobs(id),
    status        job_status DEFAULT 'PENDING', 
    scheduled_time TIMESTAMP DEFAULT NOW(),
    execution_time TIMESTAMP DEFAULT NULL,
    error_message TEXT DEFAULT NULL,
    retry_count   INTEGER DEFAULT 0,
    next_run_time TIMESTAMP DEFAULT NULL, 
    created_at    TIMESTAMP DEFAULT NOW(),
    updated_at    TIMESTAMP DEFAULT NOW(),
    metadata      JSONB DEFAULT NULL,
    user_id      uuid REFERENCES users(id), 
    created_by    uuid REFERENCES users(id),
    updated_by    uuid REFERENCES users(id),
    last_executed_by uuid REFERENCES users(id),
    job_type       job_type DEFAULT 'cron',
    job_expression TEXT DEFAULT '2 * * * *',
    job_command   TEXT,
    job_method    http_method,
    job_api_endpoint VARCHAR(255),
    job_payload   JSONB,
    job_headers   JSONB,
    job_retries   INTEGER DEFAULT 0,
    job_timeout   INTEGER DEFAULT 0
);


-- COMMIT;

-- Tabela de endere√ßos (abstrata, reutiliz√°vel)
CREATE TABLE IF NOT EXISTS addresses (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    external_id varchar(255),
    external_code varchar(255),
    street varchar(255) NOT NULL,
    number varchar(50) NOT NULL,
    complement varchar(100),
    district varchar(100),
    city varchar(100) NOT NULL,
    state varchar(50) NOT NULL,
    country varchar(50) NOT NULL,
    zip_code varchar(20) NOT NULL,
    is_main boolean,
    is_active boolean NOT NULL DEFAULT true,
    notes text,
    latitude numeric(10,6),
    longitude numeric(10,6),
    address_type varchar(20),
    address_status varchar(20),
    address_category varchar(20),
    address_tags text[],
    is_default boolean,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone
);
-- COMMIT;

-- Tabela de logs de auditoria
CREATE TABLE IF NOT EXISTS audit_logs (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id uuid REFERENCES users(id),
    action varchar(50) NOT NULL,
    entity_type varchar(50) NOT NULL,
    entity_id uuid NOT NULL,
    changes jsonb,
    created_at timestamp without time zone NOT NULL DEFAULT now()
);
-- COMMIT;

-- Tabela de logs de erro
CREATE TABLE IF NOT EXISTS error_logs (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    error_message text NOT NULL,
    stack_trace text,
    created_at timestamp without time zone NOT NULL DEFAULT now()
);
-- COMMIT;

-- Tabela de logs de acesso
CREATE TABLE IF NOT EXISTS access_logs (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id uuid REFERENCES users(id),
    action varchar(50) NOT NULL,
    ip_address varchar(50),
    user_agent text,
    created_at timestamp without time zone NOT NULL DEFAULT now()
);
-- COMMIT;

-- Tabela de categorias de produto
CREATE TABLE IF NOT EXISTS product_category (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(255) NOT NULL,
    parent_id uuid REFERENCES product_category(id),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de produtos
CREATE TABLE IF NOT EXISTS products (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    external_id varchar(255),
    sku varchar(100) NOT NULL UNIQUE,
    barcode varchar(50),
    default_vol_type varchar(50),
    name varchar(255) NOT NULL,
    description text,
    category_id uuid NOT NULL REFERENCES product_category(id),
    manufacturer varchar(255),
    image_url varchar(255),
    image text,
    brand varchar(100),
    price numeric(18,2) NOT NULL,
    cost numeric(18,2),
    weight numeric(10,3),
    length numeric(10,3),
    width numeric(10,3),
    height numeric(10,3),
    is_active boolean NOT NULL DEFAULT true,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    min_stock_threshold integer,
    max_stock_threshold integer,
    reorder_point integer,
    lead_time_days integer,
    shelf_life_days integer,
    search_vector tsvector
);

-- COMMIT;

-- √çndices para produtos
CREATE INDEX IF NOT EXISTS idx_product_sku ON products(sku);
CREATE INDEX IF NOT EXISTS idx_product_barcode ON products(barcode);
CREATE INDEX IF NOT EXISTS idx_product_name ON products(name);
CREATE INDEX IF NOT EXISTS idx_product_category_id ON products(category_id);
CREATE INDEX IF NOT EXISTS idx_product_manufacturer ON products(manufacturer);
CREATE INDEX IF NOT EXISTS idx_product_search_vector ON products USING GIN(search_vector);
-- COMMIT;

-- Trigger para atualizar o campo search_vector
CREATE OR REPLACE FUNCTION update_product_search_vector() RETURNS TRIGGER AS $$
BEGIN
    NEW.search_vector :=
        setweight(to_tsvector('portuguese', COALESCE(NEW.name, '')), 'A') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.sku, '')), 'A') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.barcode, '')), 'A') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.description, '')), 'C') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.brand, '')), 'B') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.manufacturer, '')), 'B');
    RETURN NEW;
END
$$ LANGUAGE plpgsql;
-- COMMIT;

DROP TRIGGER IF EXISTS trigger_update_product_search_vector ON products;
CREATE TRIGGER trigger_update_product_search_vector
    BEFORE INSERT OR UPDATE ON products
    FOR EACH ROW EXECUTE FUNCTION update_product_search_vector();
-- COMMIT;

-- Tabela de parceiros
CREATE TABLE IF NOT EXISTS partners (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    external_id varchar(255),
    code varchar(100) NOT NULL UNIQUE,
    name varchar(255) NOT NULL,
    trade_name varchar(255),
    document varchar(50) NOT NULL,
    type varchar(20) NOT NULL CHECK (type IN ('individual','company')),
    category varchar(50) CHECK (category IN ('SUPERMERCADO','LOJA_DE_COSMETICOS','FARMACIA','ATACAREJO')),
    status varchar(20) NOT NULL CHECK (status IN ('ACTIVE','INACTIVE','BLOCKED','ARCHIVED')),
    region varchar(100),
    segment varchar(100),
    size varchar(10),
    address_ids uuid[] NOT NULL,
    credit_limit numeric(18,2),
    current_debt numeric(18,2),
    payment_terms text[],
    last_purchase_date timestamp without time zone,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    is_active boolean NOT NULL DEFAULT true
);

-- Tabela de contatos do parceiro
CREATE TABLE IF NOT EXISTS partner_contact (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    partner_id uuid NOT NULL REFERENCES partners(id) ON DELETE CASCADE,
    name varchar(100) NOT NULL,
    email varchar(100),
    phone varchar(30),
    position varchar(50),
    is_primary boolean NOT NULL DEFAULT false
);

-- Tabela de hist√≥rico de vendas do parceiro
CREATE TABLE IF NOT EXISTS partner_sales_history (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    partner_id uuid NOT NULL REFERENCES partners(id) ON DELETE CASCADE,
    year integer NOT NULL,
    q1 integer NOT NULL DEFAULT 0,
    q2 integer NOT NULL DEFAULT 0,
    q3 integer NOT NULL DEFAULT 0,
    q4 integer NOT NULL DEFAULT 0
);
-- COMMIT;

-- Tabela de armaz√©ns
CREATE TABLE IF NOT EXISTS warehouses (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(255) NOT NULL,
    location varchar(255),
    capacity integer,
    current_stock integer,
    manager varchar(100),
    contact varchar(100),
    address_id uuid REFERENCES addresses(id),
    external_id varchar(255),
    external_code varchar(255),
    notes text,
    tags text[],
    status varchar(50),
    created_by uuid REFERENCES users(id),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_by uuid REFERENCES users(id),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    is_active boolean NOT NULL DEFAULT true
);

-- Tabela de estoque
CREATE TABLE IF NOT EXISTS inventory (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    product_id uuid NOT NULL REFERENCES products(id),
    warehouse_id uuid NOT NULL REFERENCES warehouses(id),
    quantity numeric(18,3) NOT NULL DEFAULT 0,
    minimum_level numeric(18,3),
    maximum_level numeric(18,3),
    reorder_point numeric(18,3),
    last_count_date timestamp without time zone,
    status varchar(50),
    vol_type varchar(50),
    lot_control varchar(100),
    expiration_date timestamp without time zone,
    location_code varchar(100),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    is_active boolean NOT NULL DEFAULT true
);
-- COMMIT;

-- Tabela de previs√µes de estoque
CREATE TABLE IF NOT EXISTS stock_predictions (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    product_id uuid NOT NULL REFERENCES products(id) ON DELETE CASCADE,
    warehouse_id uuid NOT NULL REFERENCES warehouses(id) ON DELETE CASCADE,
    current_level NUMERIC(18,3) NOT NULL,
    predicted_level NUMERIC(18,3) NOT NULL,
    days_until_stockout INTEGER,
    confidence_level VARCHAR(10) CHECK (confidence_level IN ('high','medium','low')) NOT NULL,
    suggested_reorder_quantity NUMERIC(18,3),
    prediction_date TIMESTAMP NOT NULL DEFAULT NOW(),
    prediction_horizon_days INTEGER NOT NULL DEFAULT 30,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    CONSTRAINT unique_prediction UNIQUE (product_id, warehouse_id, prediction_date, prediction_horizon_days)
);
-- COMMIT;

-- Tabela de pedidos
-- CREATE TABLE IF NOT EXISTS orders (
--     id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
--     external_id varchar(255),
--     order_number varchar(100),
--     partner_id uuid NOT NULL REFERENCES partners(id),
--     status varchar(30) NOT NULL,
--     order_date timestamp without time zone NOT NULL,
--     estimated_delivery_date timestamp without time zone,
--     actual_delivery_date timestamp without time zone,
--     shipping_address_id uuid REFERENCES addresses(id),
--     payment_method varchar(30),
--     payment_status varchar(20),
--     notes text,
--     total_amount numeric(18,2) NOT NULL,
--     discount_amount numeric(18,2) NOT NULL DEFAULT 0,
--     tax_amount numeric(18,2),
--     shipping_amount numeric(18,2),
--     final_amount numeric(18,2) NOT NULL,
--     is_automatically_generated boolean DEFAULT false,
--     created_at timestamp without time zone NOT NULL DEFAULT now(),
--     updated_at timestamp without time zone NOT NULL DEFAULT now(),
--     last_sync_at timestamp without time zone,
--     --prediction_id uuid REFERENCES stock_predictions(id),
--     priority integer, 
--     expected_margin numeric(18,2)
-- );
-- COMMIT;

-- Tabela de configura√ß√µes de sincroniza√ß√£o
CREATE TABLE IF NOT EXISTS sync_config (
    id SERIAL PRIMARY KEY,
    entity_name VARCHAR(100) NOT NULL,
    last_sync_timestamp TIMESTAMP NOT NULL DEFAULT NOW(),
    sync_interval_minutes INTEGER NOT NULL DEFAULT 60,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    error_count INTEGER NOT NULL DEFAULT 0,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Tabela de logs de sincroniza√ß√£o
CREATE TABLE IF NOT EXISTS sync_logs (
    id SERIAL PRIMARY KEY,
    entity_name VARCHAR(100) NOT NULL,
    start_time TIMESTAMP NOT NULL,
    end_time TIMESTAMP,
    status VARCHAR(50) NOT NULL,
    records_processed INTEGER,
    records_created INTEGER,
    records_updated INTEGER,
    records_failed INTEGER,
    error_message TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);
-- COMMIT;

-- Tabela de dados de previs√£o di√°ria (para armazenar s√©ries temporais)
CREATE TABLE IF NOT EXISTS prediction_daily_data (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    --prediction_id uuid NOT NULL REFERENCES stock_predictions(id) ON DELETE CASCADE,
    day_date DATE NOT NULL,
    predicted_demand NUMERIC(18,3) NOT NULL,
    predicted_stock NUMERIC(18,3) NOT NULL,
    lower_bound NUMERIC(18,3),
    upper_bound NUMERIC(18,3),
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
    -- CONSTRAINT unique_prediction_day UNIQUE (prediction_id, day_date)
);

-- Tabela de configura√ß√µes de usu√°rios
CREATE TABLE IF NOT EXISTS user_preferences (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id uuid NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    preference_type VARCHAR(50) NOT NULL CHECK (preference_type IN ('notification', 'theme', 'language')),
    preference_value_type VARCHAR(50) NOT NULL CHECK (preference_value_type IN ('string', 'boolean', 'integer', 'float')),
    preference_key VARCHAR(100) NOT NULL,
    preference_value TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    CONSTRAINT unique_user_preference UNIQUE (user_id, preference_key)
);

-- Tabela de eventos de auditoria
CREATE TABLE IF NOT EXISTS audit_events (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    entity_type VARCHAR(100) NOT NULL,
    entity_id uuid NOT NULL,
    action VARCHAR(50) NOT NULL, -- create, update, delete
    user_id uuid NOT NULL REFERENCES users(id),
    changes JSONB,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);
-- COMMIT;

-- Tabela de tokens de sess√£o
CREATE TABLE IF NOT EXISTS refresh_tokens (
    id SERIAL PRIMARY KEY,
    user_id uuid NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    token_id varchar(255) NOT NULL UNIQUE,
    expires_at timestamp without time zone NOT NULL,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);
-- COMMIT;

-- √çndices para tabelas auxiliares
CREATE INDEX IF NOT EXISTS idx_sync_logs_entity_name ON sync_logs(entity_name);
-- CREATE INDEX IF NOT EXISTS idx_stock_predictions_product_id ON stock_predictions(product_id);
-- CREATE INDEX IF NOT EXISTS idx_stock_predictions_warehouse_id ON stock_predictions(warehouse_id);
-- CREATE INDEX IF NOT EXISTS idx_stock_predictions_days_until_stockout ON stock_predictions(days_until_stockout);
-- CREATE INDEX IF NOT EXISTS idx_stock_predictions_confidence_level ON stock_predictions(confidence_level);
-- CREATE INDEX IF NOT EXISTS idx_prediction_daily_data_prediction_id ON prediction_daily_data(prediction_id);
-- CREATE INDEX IF NOT EXISTS idx_prediction_daily_data_day_date ON prediction_daily_data(day_date);
CREATE INDEX IF NOT EXISTS idx_user_preferences_user_id ON user_preferences(user_id);
CREATE INDEX IF NOT EXISTS idx_audit_events_entity_type_id ON audit_events(entity_type, entity_id);
CREATE INDEX IF NOT EXISTS idx_audit_events_created_at ON audit_events(created_at);
CREATE INDEX IF NOT EXISTS idx_audit_events_user_id ON audit_events(user_id);
-- COMMIT;

-- Artefatos b√°sicos iniciais
INSERT INTO product_category (id, name, created_at, updated_at) VALUES (uuid_generate_v4(), 'Default', now(), now()) ON CONFLICT DO NOTHING;
INSERT INTO addresses (id, street, number, city, state, country, zip_code, is_active, created_at, updated_at) VALUES (uuid_generate_v4(), 'Rua Exemplo', '100', 'Cidade', 'UF', 'Brasil', '00000-000', true, now(), now()) ON CONFLICT DO NOTHING;
INSERT INTO partners (id, code, name, document, type, status, address_ids, is_active, created_at, updated_at) VALUES (uuid_generate_v4(), 'P0001', 'Parceiro Exemplo', '00.000.000/0001-00', 'company', 'ACTIVE', ARRAY[(SELECT id FROM addresses LIMIT 1)], true, now(), now()) ON CONFLICT DO NOTHING;
INSERT INTO warehouses (id, name, address_id, is_active, created_at, updated_at) VALUES (uuid_generate_v4(), 'Armaz√©m Central', (SELECT id FROM addresses LIMIT 1), true, now(), now()) ON CONFLICT DO NOTHING;
-- COMMIT;


-- Inserting default roles
INSERT INTO roles (id, name, description, created_at, updated_at) VALUES
(uuid_generate_v4(), 'admin', 'Administrator with full access', now(), now()),
(uuid_generate_v4(), 'editor', 'Editor with modification permissions', now(), now()),
(uuid_generate_v4(), 'viewer', 'User with read-only access', now(), now());

-- Inserting default permissions
INSERT INTO permissions (id, name, description, created_at, updated_at) VALUES
(uuid_generate_v4(), 'user_create', 'Permission to create users', now(), now()),
(uuid_generate_v4(), 'user_edit', 'Permission to edit users', now(), now()),
(uuid_generate_v4(), 'user_delete', 'Permission to delete users', now(), now()),
(uuid_generate_v4(), 'post_create', 'Permission to create posts', now(), now()),
(uuid_generate_v4(), 'post_edit', 'Permission to edit posts', now(), now()),
(uuid_generate_v4(), 'post_delete', 'Permission to delete posts', now(), now());

-- Associating permissions with roles
INSERT INTO role_permissions (id, role_id, permission_id, created_at, updated_at) VALUES
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'user_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'user_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'user_delete'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'post_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'post_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'post_delete'), now(), now());

INSERT INTO role_permissions (id, role_id, permission_id, created_at, updated_at) VALUES
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'editor'), (SELECT id FROM permissions WHERE name = 'post_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'editor'), (SELECT id FROM permissions WHERE name = 'post_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'editor'), (SELECT id FROM permissions WHERE name = 'post_delete'), now(), now());

INSERT INTO role_permissions (id, role_id, permission_id, created_at, updated_at) VALUES
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'user_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'user_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'user_delete'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'post_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'post_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'post_delete'), now(), now());

-- Criando um usu√°rio de exemplo
INSERT INTO "users" ("id","name","username","password","email","phone","role_id","document","active","created_at","updated_at","last_login") 
VALUES (
    uuid_generate_v4(),
    'Test User',
    'testUser',
    '$2a$10$24gpz0aVeuDarfmgwZlZoeJufrxAVKUsw5MjpfHlFN576I.gz.oSW',
    'abcdef',
    '9898989898',
    CASE WHEN (SELECT id FROM roles WHERE name = 'admin') IS NOT NULL THEN
        (SELECT id FROM roles WHERE name = 'admin') 
    ELSE
        (SELECT id FROM roles WHERE name = 'editor')
    END,
    '22CBCA1346796431',
    true,
    now(),
    now(),
    now()
)
ON CONFLICT ("username") DO UPDATE
SET "name" = 'TestUser',
    "email" = 'abcdef@test.com',
    "phone" = '9898989898',
    "role_id" = CAST('06ccc24a-4385-4f66-b528-5f8098c8e22d' as uuid),
    "document" = '22CBCA1346796431',
    "active" = true,
    "updated_at" = now()
RETURNING id;

COMMIT;

/// internal/services/assets/init-db.txt ///
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";  -- Para gerar UUIDs
CREATE EXTENSION IF NOT EXISTS "pg_trgm";  -- Para buscas de texto eficientes
CREATE EXTENSION IF NOT EXISTS "btree_gist";  -- Para √≠ndices GIN em tipos de dados n√£o nativos
CREATE EXTENSION IF NOT EXISTS "fuzzystrmatch";  -- Para compara√ß√£o de strings
CREATE EXTENSION IF NOT EXISTS "hstore";  -- Para armazenar pares chave-valor
-- COMMIT;

-- Cria√ß√£o de roles e usu√°rios
CREATE ROLE readonly;
CREATE ROLE readwrite;
CREATE ROLE admin;
-- COMMIT;

-- Cria√ß√£o de usu√°rios e atribui√ß√£o de roles
CREATE USER user_readonly WITH PASSWORD 'readonlypass';
CREATE USER user_readwrite WITH PASSWORD 'readwritepass';
CREATE USER user_admin WITH PASSWORD 'adminpass';
-- COMMIT;

GRANT readonly TO user_readonly;
GRANT readwrite TO user_readwrite;
GRANT admin TO user_admin;
-- COMMIT;

-- Permiss√µes para roles
GRANT CONNECT ON DATABASE kubex_db TO readonly, readwrite, admin;
GRANT USAGE ON SCHEMA public TO readonly, readwrite, admin;
-- COMMIT;

GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO readwrite;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO admin;
-- COMMIT;

-- Enums
CREATE TYPE inventory_status AS ENUM ('available', 'reserved', 'damaged', 'expired');
CREATE TYPE order_status AS ENUM ('draft', 'pending', 'confirmed', 'processing', 'shipped', 'delivered', 'cancelled');
CREATE TYPE payment_status AS ENUM ('pending', 'paid', 'failed', 'refunded');
CREATE TYPE confidence_level AS ENUM ('high', 'medium', 'low');
CREATE TYPE address_type AS ENUM ('billing', 'shipping', 'both');
CREATE TYPE address_status AS ENUM ('active', 'inactive', 'archived');
CREATE TYPE cron_type AS ENUM('cron', 'interval');
CREATE TYPE http_method AS ENUM('GET', 'POST', 'PUT', 'DELETE');
CREATE TYPE last_run_status AS ENUM('success', 'failure', 'pending', 'running', 'completed');
CREATE TYPE last_run_message AS ENUM('success', 'failure', 'pending', 'running', 'completed');
CREATE TYPE job_status AS ENUM('SUCCESS', 'FAILED', 'PENDING', 'RUNNING', 'COMPLETED');
CREATE TYPE job_type AS ENUM('cron', 'interval');
-- COMMIT;

-- Tabela de roles
CREATE TABLE IF NOT EXISTS roles (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(50) NOT NULL UNIQUE,
    description text,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de permiss√µes
CREATE TABLE IF NOT EXISTS permissions (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(50) NOT NULL UNIQUE,
    description text,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de permiss√µes por role
CREATE TABLE IF NOT EXISTS role_permissions (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    role_id uuid NOT NULL REFERENCES roles(id),
    permission_id uuid NOT NULL REFERENCES permissions(id),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    UNIQUE (role_id, permission_id)
);

-- Tabela de usu√°rios
CREATE TABLE IF NOT EXISTS users (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(255) NOT NULL,
    username varchar(50) NOT NULL UNIQUE,
    password varchar(255) NOT NULL,
    email varchar(100) NOT NULL UNIQUE,
    phone varchar(30),
    document varchar(50),
    role_id uuid REFERENCES roles(id),
    active boolean NOT NULL DEFAULT true,   
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_login timestamp without time zone
);

-- Tabela de cron jobs
-- Esta tabela √© respons√°vel por armazenar as tarefas agendadas
CREATE TABLE cron_jobs (
    id               uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name             VARCHAR(255), -- Nome da tarefa
    description      TEXT, -- Descri√ß√£o da tarefa

    cron_type         cron_type DEFAULT 'cron', -- Tipo de agendamento (cron ou intervalo)
    cron_expression  TEXT DEFAULT '2 * * * *', -- Express√£o cron (se for cron)

    starts_at         TIMESTAMP DEFAULT NOW(), -- Hora de in√≠cio
    ends_at           TIMESTAMP DEFAULT NULL, -- Hora de t√©rmino

    command          TEXT, -- Comando a ser executado (caso seja via CLI)
    method           http_method, -- Tipo de requisi√ß√£o (se for API)
    api_endpoint     VARCHAR(255), -- URL do endpoint (se for API)
    payload          JSONB, -- Dados que precisam ser enviados na request
    headers          JSONB, -- Cabe√ßalhos que precisam ser enviados na request
    retries          INTEGER DEFAULT 0, -- N√∫mero de tentativas

    exec_timeout     INTEGER DEFAULT 30, -- Tempo m√°ximo de execu√ß√£o (em segundos)
    max_retries      INTEGER DEFAULT 3, -- N√∫mero m√°ximo de tentativas
    retry_interval   INTEGER DEFAULT 10, -- Intervalo entre tentativas (em segundos)
    max_execution_time INTEGER DEFAULT 300, -- Tempo m√°ximo de execu√ß√£o (em segundos)

    last_run_status   last_run_status DEFAULT 'pending', -- Status da √∫ltima execu√ß√£o
    last_run_message TEXT DEFAULT NULL, -- Mensagem da √∫ltima execu√ß√£o
    last_run_time    TIMESTAMP DEFAULT NULL, -- Hora da √∫ltima execu√ß√£o

    is_recurring     BOOLEAN DEFAULT FALSE, -- Se a tarefa √© recorrente
    is_active        BOOLEAN DEFAULT TRUE, -- Status do job (ativo ou pausado)

    created_at       TIMESTAMP DEFAULT NOW(), -- Data de cria√ß√£o
    updated_at       TIMESTAMP DEFAULT NOW(), -- √öltima modifica√ß√£o
    last_executed_at TIMESTAMP DEFAULT NULL, -- √öltima vez que foi executado com sucesso

    user_id         uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que criou o job
    created_by      uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que criou o job
    updated_by      uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que atualizou o job
    last_executed_by uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que executou o job pela √∫ltima vez

    metadata        JSONB -- Metadados adicionais
);

CREATE TABLE execution_logs (
    id            UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    cronjob_id    UUID REFERENCES cron_jobs(id),
    execution_time TIMESTAMP DEFAULT NOW(),
    status       job_status DEFAULT 'PENDING',
    output       TEXT DEFAULT NULL,
    error_message TEXT DEFAULT NULL,
    retry_count  INTEGER DEFAULT 0,
    created_at   TIMESTAMP DEFAULT NOW(), 
    updated_at   TIMESTAMP DEFAULT NOW(), 
    user_id     uuid REFERENCES users(id),
    created_by   uuid REFERENCES users(id),
    updated_by   uuid REFERENCES users(id),
    metadata     JSONB 
);

CREATE TABLE job_queue (
    id            UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    cronjob_id    UUID REFERENCES cron_jobs(id),
    status        job_status DEFAULT 'PENDING', 
    scheduled_time TIMESTAMP DEFAULT NOW(),
    execution_time TIMESTAMP DEFAULT NULL,
    error_message TEXT DEFAULT NULL,
    retry_count   INTEGER DEFAULT 0,
    next_run_time TIMESTAMP DEFAULT NULL, 
    created_at    TIMESTAMP DEFAULT NOW(),
    updated_at    TIMESTAMP DEFAULT NOW(),
    metadata      JSONB DEFAULT NULL,
    user_id      uuid REFERENCES users(id), 
    created_by    uuid REFERENCES users(id),
    updated_by    uuid REFERENCES users(id),
    last_executed_by uuid REFERENCES users(id),
    job_type       job_type DEFAULT 'cron',
    job_expression TEXT DEFAULT '2 * * * *',
    job_command   TEXT,
    job_method    http_method,
    job_api_endpoint VARCHAR(255),
    job_payload   JSONB,
    job_headers   JSONB,
    job_retries   INTEGER DEFAULT 0,
    job_timeout   INTEGER DEFAULT 0
);


-- COMMIT;

-- Tabela de endere√ßos (abstrata, reutiliz√°vel)
CREATE TABLE IF NOT EXISTS addresses (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    external_id varchar(255),
    external_code varchar(255),
    street varchar(255) NOT NULL,
    number varchar(50) NOT NULL,
    complement varchar(100),
    district varchar(100),
    city varchar(100) NOT NULL,
    state varchar(50) NOT NULL,
    country varchar(50) NOT NULL,
    zip_code varchar(20) NOT NULL,
    is_main boolean,
    is_active boolean NOT NULL DEFAULT true,
    notes text,
    latitude numeric(10,6),
    longitude numeric(10,6),
    address_type varchar(20),
    address_status varchar(20),
    address_category varchar(20),
    address_tags text[],
    is_default boolean,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone
);
-- COMMIT;

-- Tabela de logs de auditoria
CREATE TABLE IF NOT EXISTS audit_logs (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id uuid REFERENCES users(id),
    action varchar(50) NOT NULL,
    entity_type varchar(50) NOT NULL,
    entity_id uuid NOT NULL,
    changes jsonb,
    created_at timestamp without time zone NOT NULL DEFAULT now()
);
-- COMMIT;

-- Tabela de logs de erro
CREATE TABLE IF NOT EXISTS error_logs (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    error_message text NOT NULL,
    stack_trace text,
    created_at timestamp without time zone NOT NULL DEFAULT now()
);
-- COMMIT;

-- Tabela de logs de acesso
CREATE TABLE IF NOT EXISTS access_logs (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id uuid REFERENCES users(id),
    action varchar(50) NOT NULL,
    ip_address varchar(50),
    user_agent text,
    created_at timestamp without time zone NOT NULL DEFAULT now()
);
-- COMMIT;

-- Tabela de categorias de produto
CREATE TABLE IF NOT EXISTS product_category (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(255) NOT NULL,
    parent_id uuid REFERENCES product_category(id),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);

-- Tabela de produtos
CREATE TABLE IF NOT EXISTS products (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    external_id varchar(255),
    sku varchar(100) NOT NULL UNIQUE,
    barcode varchar(50),
    default_vol_type varchar(50),
    name varchar(255) NOT NULL,
    description text,
    category_id uuid NOT NULL REFERENCES product_category(id),
    manufacturer varchar(255),
    image_url varchar(255),
    image text,
    brand varchar(100),
    price numeric(18,2) NOT NULL,
    cost numeric(18,2),
    weight numeric(10,3),
    length numeric(10,3),
    width numeric(10,3),
    height numeric(10,3),
    is_active boolean NOT NULL DEFAULT true,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    min_stock_threshold integer,
    max_stock_threshold integer,
    reorder_point integer,
    lead_time_days integer,
    shelf_life_days integer,
    search_vector tsvector
);

-- COMMIT;

-- √çndices para produtos
CREATE INDEX IF NOT EXISTS idx_product_sku ON products(sku);
CREATE INDEX IF NOT EXISTS idx_product_barcode ON products(barcode);
CREATE INDEX IF NOT EXISTS idx_product_name ON products(name);
CREATE INDEX IF NOT EXISTS idx_product_category_id ON products(category_id);
CREATE INDEX IF NOT EXISTS idx_product_manufacturer ON products(manufacturer);
CREATE INDEX IF NOT EXISTS idx_product_search_vector ON products USING GIN(search_vector);
-- COMMIT;

-- Trigger para atualizar o campo search_vector
CREATE OR REPLACE FUNCTION update_product_search_vector() RETURNS TRIGGER AS $$
BEGIN
    NEW.search_vector :=
        setweight(to_tsvector('portuguese', COALESCE(NEW.name, '')), 'A') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.sku, '')), 'A') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.barcode, '')), 'A') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.description, '')), 'C') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.brand, '')), 'B') ||
        setweight(to_tsvector('portuguese', COALESCE(NEW.manufacturer, '')), 'B');
    RETURN NEW;
END
$$ LANGUAGE plpgsql;
-- COMMIT;

DROP TRIGGER IF EXISTS trigger_update_product_search_vector ON products;
CREATE TRIGGER trigger_update_product_search_vector
    BEFORE INSERT OR UPDATE ON products
    FOR EACH ROW EXECUTE FUNCTION update_product_search_vector();
-- COMMIT;

-- Tabela de parceiros
CREATE TABLE IF NOT EXISTS partners (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    external_id varchar(255),
    code varchar(100) NOT NULL UNIQUE,
    name varchar(255) NOT NULL,
    trade_name varchar(255),
    document varchar(50) NOT NULL,
    type varchar(20) NOT NULL CHECK (type IN ('individual','company')),
    category varchar(50) CHECK (category IN ('SUPERMERCADO','LOJA_DE_COSMETICOS','FARMACIA','ATACAREJO')),
    status varchar(20) NOT NULL CHECK (status IN ('ACTIVE','INACTIVE','BLOCKED','ARCHIVED')),
    region varchar(100),
    segment varchar(100),
    size varchar(10),
    address_ids uuid[] NOT NULL,
    credit_limit numeric(18,2),
    current_debt numeric(18,2),
    payment_terms text[],
    last_purchase_date timestamp without time zone,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    is_active boolean NOT NULL DEFAULT true
);

-- Tabela de contatos do parceiro
CREATE TABLE IF NOT EXISTS partner_contact (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    partner_id uuid NOT NULL REFERENCES partners(id) ON DELETE CASCADE,
    name varchar(100) NOT NULL,
    email varchar(100),
    phone varchar(30),
    position varchar(50),
    is_primary boolean NOT NULL DEFAULT false
);

-- Tabela de hist√≥rico de vendas do parceiro
CREATE TABLE IF NOT EXISTS partner_sales_history (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    partner_id uuid NOT NULL REFERENCES partners(id) ON DELETE CASCADE,
    year integer NOT NULL,
    q1 integer NOT NULL DEFAULT 0,
    q2 integer NOT NULL DEFAULT 0,
    q3 integer NOT NULL DEFAULT 0,
    q4 integer NOT NULL DEFAULT 0
);
-- COMMIT;

-- Tabela de armaz√©ns
CREATE TABLE IF NOT EXISTS warehouses (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name varchar(255) NOT NULL,
    location varchar(255),
    capacity integer,
    current_stock integer,
    manager varchar(100),
    contact varchar(100),
    address_id uuid REFERENCES addresses(id),
    external_id varchar(255),
    external_code varchar(255),
    notes text,
    tags text[],
    status varchar(50),
    created_by uuid REFERENCES users(id),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_by uuid REFERENCES users(id),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    is_active boolean NOT NULL DEFAULT true
);

-- Tabela de estoque
CREATE TABLE IF NOT EXISTS inventory (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    product_id uuid NOT NULL REFERENCES products(id),
    warehouse_id uuid NOT NULL REFERENCES warehouses(id),
    quantity numeric(18,3) NOT NULL DEFAULT 0,
    minimum_level numeric(18,3),
    maximum_level numeric(18,3),
    reorder_point numeric(18,3),
    last_count_date timestamp without time zone,
    status varchar(50),
    vol_type varchar(50),
    lot_control varchar(100),
    expiration_date timestamp without time zone,
    location_code varchar(100),
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now(),
    last_sync_at timestamp without time zone,
    is_active boolean NOT NULL DEFAULT true
);
-- COMMIT;

-- Tabela de previs√µes de estoque
CREATE TABLE IF NOT EXISTS stock_predictions (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    product_id uuid NOT NULL REFERENCES products(id) ON DELETE CASCADE,
    warehouse_id uuid NOT NULL REFERENCES warehouses(id) ON DELETE CASCADE,
    current_level NUMERIC(18,3) NOT NULL,
    predicted_level NUMERIC(18,3) NOT NULL,
    days_until_stockout INTEGER,
    confidence_level VARCHAR(10) CHECK (confidence_level IN ('high','medium','low')) NOT NULL,
    suggested_reorder_quantity NUMERIC(18,3),
    prediction_date TIMESTAMP NOT NULL DEFAULT NOW(),
    prediction_horizon_days INTEGER NOT NULL DEFAULT 30,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    CONSTRAINT unique_prediction UNIQUE (product_id, warehouse_id, prediction_date, prediction_horizon_days)
);
-- COMMIT;

-- Tabela de pedidos
-- CREATE TABLE IF NOT EXISTS orders (
--     id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
--     external_id varchar(255),
--     order_number varchar(100),
--     partner_id uuid NOT NULL REFERENCES partners(id),
--     status varchar(30) NOT NULL,
--     order_date timestamp without time zone NOT NULL,
--     estimated_delivery_date timestamp without time zone,
--     actual_delivery_date timestamp without time zone,
--     shipping_address_id uuid REFERENCES addresses(id),
--     payment_method varchar(30),
--     payment_status varchar(20),
--     notes text,
--     total_amount numeric(18,2) NOT NULL,
--     discount_amount numeric(18,2) NOT NULL DEFAULT 0,
--     tax_amount numeric(18,2),
--     shipping_amount numeric(18,2),
--     final_amount numeric(18,2) NOT NULL,
--     is_automatically_generated boolean DEFAULT false,
--     created_at timestamp without time zone NOT NULL DEFAULT now(),
--     updated_at timestamp without time zone NOT NULL DEFAULT now(),
--     last_sync_at timestamp without time zone,
--     --prediction_id uuid REFERENCES stock_predictions(id),
--     priority integer, 
--     expected_margin numeric(18,2)
-- );
-- COMMIT;

-- Tabela de configura√ß√µes de sincroniza√ß√£o
CREATE TABLE IF NOT EXISTS sync_config (
    id SERIAL PRIMARY KEY,
    entity_name VARCHAR(100) NOT NULL,
    last_sync_timestamp TIMESTAMP NOT NULL DEFAULT NOW(),
    sync_interval_minutes INTEGER NOT NULL DEFAULT 60,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    error_count INTEGER NOT NULL DEFAULT 0,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Tabela de logs de sincroniza√ß√£o
CREATE TABLE IF NOT EXISTS sync_logs (
    id SERIAL PRIMARY KEY,
    entity_name VARCHAR(100) NOT NULL,
    start_time TIMESTAMP NOT NULL,
    end_time TIMESTAMP,
    status VARCHAR(50) NOT NULL,
    records_processed INTEGER,
    records_created INTEGER,
    records_updated INTEGER,
    records_failed INTEGER,
    error_message TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);
-- COMMIT;

-- Tabela de dados de previs√£o di√°ria (para armazenar s√©ries temporais)
CREATE TABLE IF NOT EXISTS prediction_daily_data (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    --prediction_id uuid NOT NULL REFERENCES stock_predictions(id) ON DELETE CASCADE,
    day_date DATE NOT NULL,
    predicted_demand NUMERIC(18,3) NOT NULL,
    predicted_stock NUMERIC(18,3) NOT NULL,
    lower_bound NUMERIC(18,3),
    upper_bound NUMERIC(18,3),
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
    -- CONSTRAINT unique_prediction_day UNIQUE (prediction_id, day_date)
);

-- Tabela de configura√ß√µes de usu√°rios
CREATE TABLE IF NOT EXISTS user_preferences (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id uuid NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    preference_type VARCHAR(50) NOT NULL CHECK (preference_type IN ('notification', 'theme', 'language')),
    preference_value_type VARCHAR(50) NOT NULL CHECK (preference_value_type IN ('string', 'boolean', 'integer', 'float')),
    preference_key VARCHAR(100) NOT NULL,
    preference_value TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    CONSTRAINT unique_user_preference UNIQUE (user_id, preference_key)
);

-- Tabela de eventos de auditoria
CREATE TABLE IF NOT EXISTS audit_events (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    entity_type VARCHAR(100) NOT NULL,
    entity_id uuid NOT NULL,
    action VARCHAR(50) NOT NULL, -- create, update, delete
    user_id uuid NOT NULL REFERENCES users(id),
    changes JSONB,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);
-- COMMIT;

-- Tabela de tokens de sess√£o
CREATE TABLE IF NOT EXISTS refresh_tokens (
    id SERIAL PRIMARY KEY,
    user_id uuid NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    token_id varchar(255) NOT NULL UNIQUE,
    expires_at timestamp without time zone NOT NULL,
    created_at timestamp without time zone NOT NULL DEFAULT now(),
    updated_at timestamp without time zone NOT NULL DEFAULT now()
);
-- COMMIT;

-- √çndices para tabelas auxiliares
CREATE INDEX IF NOT EXISTS idx_sync_logs_entity_name ON sync_logs(entity_name);
-- CREATE INDEX IF NOT EXISTS idx_stock_predictions_product_id ON stock_predictions(product_id);
-- CREATE INDEX IF NOT EXISTS idx_stock_predictions_warehouse_id ON stock_predictions(warehouse_id);
-- CREATE INDEX IF NOT EXISTS idx_stock_predictions_days_until_stockout ON stock_predictions(days_until_stockout);
-- CREATE INDEX IF NOT EXISTS idx_stock_predictions_confidence_level ON stock_predictions(confidence_level);
-- CREATE INDEX IF NOT EXISTS idx_prediction_daily_data_prediction_id ON prediction_daily_data(prediction_id);
-- CREATE INDEX IF NOT EXISTS idx_prediction_daily_data_day_date ON prediction_daily_data(day_date);
CREATE INDEX IF NOT EXISTS idx_user_preferences_user_id ON user_preferences(user_id);
CREATE INDEX IF NOT EXISTS idx_audit_events_entity_type_id ON audit_events(entity_type, entity_id);
CREATE INDEX IF NOT EXISTS idx_audit_events_created_at ON audit_events(created_at);
CREATE INDEX IF NOT EXISTS idx_audit_events_user_id ON audit_events(user_id);
-- COMMIT;

-- Artefatos b√°sicos iniciais
INSERT INTO product_category (id, name, created_at, updated_at) VALUES (uuid_generate_v4(), 'Default', now(), now()) ON CONFLICT DO NOTHING;
INSERT INTO addresses (id, street, number, city, state, country, zip_code, is_active, created_at, updated_at) VALUES (uuid_generate_v4(), 'Rua Exemplo', '100', 'Cidade', 'UF', 'Brasil', '00000-000', true, now(), now()) ON CONFLICT DO NOTHING;
INSERT INTO partners (id, code, name, document, type, status, address_ids, is_active, created_at, updated_at) VALUES (uuid_generate_v4(), 'P0001', 'Parceiro Exemplo', '00.000.000/0001-00', 'company', 'ACTIVE', ARRAY[(SELECT id FROM addresses LIMIT 1)], true, now(), now()) ON CONFLICT DO NOTHING;
INSERT INTO warehouses (id, name, address_id, is_active, created_at, updated_at) VALUES (uuid_generate_v4(), 'Armaz√©m Central', (SELECT id FROM addresses LIMIT 1), true, now(), now()) ON CONFLICT DO NOTHING;
-- COMMIT;


-- Inserting default roles
INSERT INTO roles (id, name, description, created_at, updated_at) VALUES
(uuid_generate_v4(), 'admin', 'Administrator with full access', now(), now()),
(uuid_generate_v4(), 'editor', 'Editor with modification permissions', now(), now()),
(uuid_generate_v4(), 'viewer', 'User with read-only access', now(), now());

-- Inserting default permissions
INSERT INTO permissions (id, name, description, created_at, updated_at) VALUES
(uuid_generate_v4(), 'user_create', 'Permission to create users', now(), now()),
(uuid_generate_v4(), 'user_edit', 'Permission to edit users', now(), now()),
(uuid_generate_v4(), 'user_delete', 'Permission to delete users', now(), now()),
(uuid_generate_v4(), 'post_create', 'Permission to create posts', now(), now()),
(uuid_generate_v4(), 'post_edit', 'Permission to edit posts', now(), now()),
(uuid_generate_v4(), 'post_delete', 'Permission to delete posts', now(), now());

-- Associating permissions with roles
INSERT INTO role_permissions (id, role_id, permission_id, created_at, updated_at) VALUES
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'user_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'user_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'user_delete'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'post_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'post_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'admin'), (SELECT id FROM permissions WHERE name = 'post_delete'), now(), now());

INSERT INTO role_permissions (id, role_id, permission_id, created_at, updated_at) VALUES
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'editor'), (SELECT id FROM permissions WHERE name = 'post_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'editor'), (SELECT id FROM permissions WHERE name = 'post_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'editor'), (SELECT id FROM permissions WHERE name = 'post_delete'), now(), now());

INSERT INTO role_permissions (id, role_id, permission_id, created_at, updated_at) VALUES
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'user_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'user_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'user_delete'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'post_create'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'post_edit'), now(), now()),
(uuid_generate_v4(), (SELECT id FROM roles WHERE name = 'viewer'), (SELECT id FROM permissions WHERE name = 'post_delete'), now(), now());

-- Criando um usu√°rio de exemplo
INSERT INTO "users" ("id","name","username","password","email","phone","role_id","document","active","created_at","updated_at","last_login") 
VALUES (
    uuid_generate_v4(),
    'Test User',
    'testUser',
    '$2a$10$24gpz0aVeuDarfmgwZlZoeJufrxAVKUsw5MjpfHlFN576I.gz.oSW',
    'abcdef',
    '9898989898',
    CASE WHEN (SELECT id FROM roles WHERE name = 'admin') IS NOT NULL THEN
        (SELECT id FROM roles WHERE name = 'admin') 
    ELSE
        (SELECT id FROM roles WHERE name = 'editor')
    END,
    '22CBCA1346796431',
    true,
    now(),
    now(),
    now()
)
ON CONFLICT ("username") DO UPDATE
SET "name" = 'TestUser',
    "email" = 'abcdef@test.com',
    "phone" = '9898989898',
    "role_id" = CAST('06ccc24a-4385-4f66-b528-5f8098c8e22d' as uuid),
    "document" = '22CBCA1346796431',
    "active" = true,
    "updated_at" = now()
RETURNING id;

COMMIT;

/// internal/services/broker_info.go ///
package services

import (
	"fmt"
	"os"
	"path/filepath"
	"sync"
	"time"

	gl "github.com/rafa-mori/gdbase/logger"
)

type BrokerInfo struct {
	Name string `json:"name"`
	Port string `json:"port"`
	PID  int    `json:"pid"`
	Time string `json:"time"`
	path string
}
type BrokerInfoLock struct {
	Name  string
	Port  string
	PID   int
	Time  string
	path  string
	flock sync.Mutex
}

func NewBrokerInfo(name, port string) *BrokerInfoLock {
	path, pathErr := GetBrokersPath()
	if pathErr != nil {
		gl.Log("error", "Error getting brokers path")
		return nil
	}

	if name == "" {
		name = RndomName()
	}

	path = filepath.Clean(filepath.Join(path, fmt.Sprintf("%s.json", name)))

	return &BrokerInfoLock{
		Name: name,
		Port: port,
		PID:  os.Getpid(),
		Time: time.Now().Format(time.RFC3339),
		path: path,
	}
}

func (bi *BrokerInfoLock) GetBrokerInfo() BrokerInfo {
	return BrokerInfo{
		Name: bi.Name,
		Port: bi.Port,
		PID:  bi.PID,
		Time: bi.Time,
		path: bi.path,
	}
}
func (bi *BrokerInfoLock) GetPath() string { return bi.path }
func (bi *BrokerInfoLock) GetPort() string { return bi.Port }
func (bi *BrokerInfoLock) GetName() string { return bi.Name }
func (bi *BrokerInfoLock) GetPID() int     { return bi.PID }
func (bi *BrokerInfoLock) GetTime() string { return bi.Time }
func (bi *BrokerInfoLock) Lock()           { bi.flock.Lock() }
func (bi *BrokerInfoLock) Unlock()         { bi.flock.Unlock() }
func (bi *BrokerInfoLock) String() string {
	return fmt.Sprintf("BrokerInfo{Name: %s, Port: %s, PID: %d, Time: %s}", bi.Name, bi.Port, bi.PID, bi.Time)
}
func (bi *BrokerInfoLock) trap() {
	bi.Lock()
	defer func() {
		bi.Unlock()
		if bi.path != "" {
			if rmErr := os.Remove(bi.path); rmErr != nil {
				gl.Log("error", "Error removing broker file")
			}
		}
	}()
}

/// internal/services/broker_manager.go ///
package services

import (
	"github.com/goccy/go-json"
	"os"
	"path/filepath"
	"sync"
)

type BrokerManager struct{}

func NewBrokerManager() *BrokerManager { return &BrokerManager{} }

func (bm *BrokerManager) GetBrokers() []BrokerInfoLock {
	registryFile := "/tmp/gkbxsrv_registry.json"
	var brokers []BrokerInfoLock
	data, _ := os.ReadFile(registryFile)

	if unmarshalErr := json.Unmarshal(data, &brokers); unmarshalErr != nil {
		brokers = []BrokerInfoLock{}
	}
	return brokers
}
func (bm *BrokerManager) loadBrokerInfo(configDir string) ([]BrokerInfoLock, error) {
	var brokers []BrokerInfoLock
	err := filepath.Walk(configDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.IsDir() && filepath.Ext(path) == ".json" {
			data, readErr := os.ReadFile(path)
			if readErr != nil {
				return readErr
			}
			var broker BrokerInfo
			unmarshalErr := json.Unmarshal(data, &broker)
			if unmarshalErr != nil {
				return unmarshalErr
			}

			brokers = append(brokers, BrokerInfoLock{
				Name:  broker.Name,
				Port:  broker.Port,
				PID:   broker.PID,
				Time:  broker.Time,
				path:  path,
				flock: sync.Mutex{},
			})
		}
		return nil
	})
	return brokers, err
}

/// internal/services/broker_server.go ///
package services

import (
	"fmt"
	"os"
	"sync"
	"time"

	"github.com/goccy/go-json"
	"github.com/pebbe/zmq4"
	gl "github.com/rafa-mori/gdbase/logger"
)

const (
	HeartbeatInterval = 2500 * time.Millisecond // Interval between heartbeats
)

type BrokerImpl struct {
	context     *zmq4.Context
	frontend    *zmq4.Socket // FRONTEND (ROUTER) with clients
	backend     *zmq4.Socket // BACKEND (DEALER) with workers
	services    map[string]*Service
	workers     map[string]*Worker
	waiting     []*Worker
	mu          sync.Mutex
	heartbeatAt time.Time
	brokerInfo  *BrokerInfoLock
	verbose     bool
}
type Service struct {
	name     string
	requests [][]string
	waiting  []*Worker
}
type Worker struct {
	identity string
	service  *Service
	expiry   time.Time
	broker   *BrokerImpl
}

func NewBrokerConn(port string) (*zmq4.Socket, error) {
	ctx, err := zmq4.NewContext()
	if err != nil {
		return nil, fmt.Errorf("error creating ZMQ context: %v", err)
	}

	frontend, err := ctx.NewSocket(zmq4.ROUTER)
	if err != nil {
		return nil, fmt.Errorf("error creating FRONTEND (ROUTER): %v", err)
	}
	frontendSetRouterMandatoryErr := frontend.SetRouterMandatory(1)
	if frontendSetRouterMandatoryErr != nil {
		return nil, frontendSetRouterMandatoryErr
	}
	frontendSetRouterHandoverErr := frontend.SetRouterHandover(true)
	if frontendSetRouterHandoverErr != nil {
		return nil, frontendSetRouterHandoverErr
	}

	if hostBindErr := frontend.Bind(`tcp://0.0.0.0:` + port); hostBindErr != nil {
		return nil, fmt.Errorf("error binding FRONTEND (ROUTER): %v", hostBindErr)
	}

	return frontend, nil
}
func NewBroker(verbose bool) (*BrokerImpl, error) {
	ctx, err := zmq4.NewContext()
	if err != nil {
		return nil, fmt.Errorf("error creating ZMQ context: %v", err)
	}

	frontend, err := ctx.NewSocket(zmq4.ROUTER)
	if err != nil {
		return nil, fmt.Errorf("error creating FRONTEND (ROUTER): %v", err)
	}
	frontendSetRouterMandatoryErr := frontend.SetRouterMandatory(1)
	if frontendSetRouterMandatoryErr != nil {
		return nil, frontendSetRouterMandatoryErr
	}
	frontendSetRouterHandoverErr := frontend.SetRouterHandover(true)
	if frontendSetRouterHandoverErr != nil {
		return nil, frontendSetRouterHandoverErr
	}

	if hostBindErr := frontend.Bind(`tcp://0.0.0.0:5555`); hostBindErr != nil {
		return nil, fmt.Errorf("error binding FRONTEND (ROUTER): %v", hostBindErr)
	}

	backend, err := ctx.NewSocket(zmq4.DEALER)
	if err != nil {
		return nil, fmt.Errorf("error creating BACKEND (DEALER): %v", err)
	}
	if bindErr := backend.Bind("inproc://backend"); bindErr != nil {
		return nil, fmt.Errorf("error binding BACKEND (DEALER): %v", bindErr)
	}

	broker := &BrokerImpl{
		brokerInfo:  NewBrokerInfo(RndomName(), "5555"),
		context:     ctx,
		frontend:    frontend,
		backend:     backend,
		services:    make(map[string]*Service),
		workers:     make(map[string]*Worker),
		waiting:     []*Worker{},
		heartbeatAt: time.Now().Add(HeartbeatInterval),
		verbose:     verbose,
	}

	if broker.brokerInfo == nil {
		gl.Log("error", "Error creating broker")
		return nil, fmt.Errorf("error creating broker: Empty broker info")
	}
	data, marshalErr := json.Marshal(broker.brokerInfo.GetBrokerInfo())
	if marshalErr != nil {
		gl.Log("error", "Error marshalling broker info")
		return nil, marshalErr
	}
	if writeErr := os.WriteFile(broker.brokerInfo.GetPath(), data, 0644); writeErr != nil {
		gl.Log("error", "Error writing broker file")
		return nil, writeErr
	}

	// Launch workers
	for i := 0; i < 5; i++ {
		go broker.workerTask()
	}

	// Start the proxy
	go broker.startProxy()

	// Start heartbeat management
	//go broker.handleHeartbeats()

	return broker, nil
}

func (b *BrokerImpl) startProxy() {
	gl.Log("info", "Starting proxy between FRONTEND and BACKEND...")
	err := zmq4.Proxy(b.frontend, b.backend, nil)
	if err != nil {
		gl.Log("error", "Error in proxy between FRONTEND and BACKEND")
	}
}
func (b *BrokerImpl) workerTask() {
	worker, err := b.context.NewSocket(zmq4.DEALER)
	if err != nil {
		gl.Log("error", "Error creating socket for worker")
		return
	}

	if connErr := worker.Connect("inproc://backend"); connErr != nil {
		gl.Log("error", "Error connecting worker to BACKEND")
		return
	}

	for {
		// msg, _ := worker.RecvMessage(0)
		// if len(msg) < 2 {
		// 	gl.Log("debug", "Malformed message received in WORKER")
		// 	continue
		// }

		// //id, msg := splitMessage(msg)

		// //payload := msg[len(msg)-1]
		// //pld := []byte(payload)

		// // deserializedModel, deserializedModelErr := m.NewModelRegistryFromSerialized(pld).(Model)
		// // if deserializedModelErr != nil {
		// // 	gl.Log("error", "Error deserializing payload in WORKER")
		// // 	continue
		// // }

		// gl.Log("debug", "Payload deserialized in WORKER")

		// // tp, tpErr := deserializedModel.GetType()
		// // if tpErr != nil {
		// // 	gl.Log("error", "Error getting payload type in WORKER")
		// // 	continue
		// // }

		// gl.Log("debug", "Payload type in WORKER")

		// if tp.Name() == "PingImpl" {
		// 	response := fmt.Sprintf(`{"type":"ping","data":{"ping":"%v"}}`, "pong")
		// 	if _, workerSendMessageErr := worker.SendMessage(id, response); workerSendMessageErr != nil {
		// 		gl.Log("error", "Error sending response to BACKEND in WORKER")
		// 	} else {
		// 		gl.Log("debug", "Response sent to BACKEND in WORKER")
		// 	}
		// } else {
		// 	gl.Log("debug", "Unknown command in WORKER")
		// }
	}
}
func (b *BrokerImpl) handleHeartbeats() {
	ticker := time.NewTicker(HeartbeatInterval)
	//defer ticker.Stop()
	//defer b.mu.Unlock()

	for range ticker.C {
		b.mu.Lock()
		now := time.Now()
		for id, worker := range b.workers {
			if now.After(worker.expiry) {
				gl.Log("warn", fmt.Sprintf("Expired worker: %s", id))
				delete(b.workers, id)
			}
		}
		b.mu.Unlock()
	}

	b.mu.Unlock()
}
func (b *BrokerImpl) Stop() {
	_ = b.frontend.Close()
	_ = b.backend.Close()
	_ = b.context.Term()
	gl.Log("info", "Broker stopped")
}

/// internal/services/db_service.go ///
package services

import (
	"fmt"

	gbm "github.com/rafa-mori/gdbase"

	// gl "github.com/rafa-mori/gdbase/logger"
	"sync"

	glb "github.com/rafa-mori/gdbase/internal/globals"
	gl "github.com/rafa-mori/gdbase/logger"
	t "github.com/rafa-mori/gdbase/types"
	l "github.com/rafa-mori/logz"
	"gorm.io/driver/mysql"
	"gorm.io/driver/postgres"
	"gorm.io/driver/sqlite"
	"gorm.io/gorm"
)

type DBService struct {
	Logger    l.Logger
	reference gbm.Reference
	mutexes   gbm.Mutexes

	db   *gorm.DB
	pool *sync.Pool

	// properties are used to store database settings and configurations
	properties map[string]any
}

func NewDatabaseService(config *t.DBConfig, logger l.Logger) (*DBService, error) {
	if logger == nil {
		logger = l.GetLogger("GDBase")
	}

	if config == nil {
		return nil, fmt.Errorf("‚ùå Configura√ß√£o do banco de dados n√£o pode ser nula")
	}
	if len(config.Databases) == 0 {
		return nil, fmt.Errorf("‚ùå Configura√ß√£o de banco de dados n√£o pode ser vazia")
	}

	//driver = db.Driver // Pro futuro.. rs
	var dbHost, dbPort, dbUser, dbPass, dbName, dsn string
	for _, dbConfig := range config.Databases {
		if dsn == "" {
			dsn = dbConfig.ConnectionString
		}
		if dsn == "" {
			dbHost = dbConfig.Host
			dbPort = dbConfig.Port.(string)
			dbUser = dbConfig.Username
			if dbConfig.Type != "postgresql" {
				dbPass = dbConfig.Password
				if dbPass == "" {
					dbPassKey, dbPassErr := glb.GetOrGenPasswordKeyringPass("pgpass")
					if dbPassErr != nil {
						gl.Log("error", fmt.Sprintf("‚ùå Erro ao recuperar senha do banco de dados: %v", dbPassErr))
						continue
					}
					dbConfig.Password = string(dbPassKey)
					dbPass = dbConfig.Password
				}

				dbName = dbConfig.Name
				dsn = fmt.Sprintf(
					"host=%s port=%s user=%s password=%s dbname=%s sslmode=disable TimeZone=America/Sao_Paulo",
					dbHost, dbPort, dbUser, dbPass, dbName,
				)
			} else {
				dbPass = dbConfig.Password
				dbName = dbConfig.Name
				dsn = fmt.Sprintf(
					"host=%s port=%s user=%s dbname=%s sslmode=disable TimeZone=America/Sao_Paulo",
					dbHost, dbPort, dbUser, dbName,
				)
			}
			break
		}
	}

	dbService := &DBService{
		Logger:     logger,
		reference:  gbm.NewReference("DBService"),
		mutexes:    gbm.NewMutexesType(),
		properties: make(map[string]any),
		pool:       &sync.Pool{},
	}

	dbService.properties["config"] = gbm.NewProperty[*t.DBConfig]("config", &config, true, nil)

	if db, err := gorm.Open(postgres.Open(dsn), &gorm.Config{}); err != nil {
		return nil, fmt.Errorf("‚ùå Erro ao conectar ao banco de dados: %v", err)
	} else {
		dbService.db = db
	}

	return dbService, nil
}

func (d *DBService) Initialize() error {
	if d.db != nil {
		return nil
	}
	envT := d.properties["config"].(gbm.Property[gbm.Environment])
	if envT == nil {
		return fmt.Errorf("‚ùå Erro ao recuperar o ambiente")
	}
	env := envT.GetValue()
	if env == nil {
		return fmt.Errorf("‚ùå Erro ao recuperar o ambiente")
	}

	dbType := env.Getenv("DB_TYPE")
	dbHost := env.Getenv("DB_HOST")
	dbPort := env.Getenv("DB_PORT")
	dbUser := env.Getenv("DB_USER")
	dbPass := env.Getenv("DB_PASS")
	dbName := env.Getenv("DB_NAME")
	dsn := fmt.Sprintf(
		"host=%s port=%s user=%s password=%s dbname=%s sslmode=disable TimeZone=America/Sao_Paulo",
		dbHost, dbPort, dbUser, dbPass, dbName,
	)
	db, err := ConnectDatabase(dbType, dsn)
	if err != nil {
		return fmt.Errorf("‚ùå Erro ao conectar ao banco de dados: %v", err)
	}
	d.db = db
	return nil
}

func (d *DBService) GetDB() (*gorm.DB, error) {
	if d.db == nil {
		return nil, fmt.Errorf("‚ùå Banco de dados n√£o inicializado")
	}
	return d.db, nil
}

func (d *DBService) CloseDBConnection() error {
	sqlDB, err := d.db.DB()
	if err != nil {
		return fmt.Errorf("‚ùå Erro ao obter conex√£o SQL: %v", err)
	}
	return sqlDB.Close()
}

func (d *DBService) CheckDatabaseHealth() error {
	if err := d.db.Raw("SELECT 1").Error; err != nil {
		return fmt.Errorf("‚ùå Banco de dados offline: %v", err)
	}
	return nil
}

func (d *DBService) IsConnected() error {
	if d.db == nil {
		return fmt.Errorf("‚ùå Banco de dados n√£o inicializado")
	}
	if err := d.db.Raw("SELECT 1").Error; err != nil {
		return fmt.Errorf("‚ùå Banco de dados offline: %v", err)
	}
	return nil
}

func (d *DBService) Reconnect() error {
	if d.db != nil {
		sqlDB, err := d.db.DB()
		if err != nil {
			return fmt.Errorf("‚ùå Erro ao obter conex√£o SQL: %v", err)
		}
		if err := sqlDB.Close(); err != nil {
			return fmt.Errorf("‚ùå Erro ao fechar conex√£o SQL: %v", err)
		}
	}

	db, err := d.GetDB()
	if err != nil {
		return fmt.Errorf("‚ùå Erro ao obter banco de dados: %v", err)
	}

	d.db = db
	return nil
}

func (d *DBService) GetHost() (string, error) {
	if d.db == nil {
		return "", fmt.Errorf("‚ùå Banco de dados n√£o inicializado")
	}
	host, ok := d.properties["host"].(gbm.Property[string])
	if !ok {
		return "", fmt.Errorf("‚ùå Erro ao obter host do banco de dados")
	}
	vl := host.GetValue()
	if vl == "" {
		return "", fmt.Errorf("‚ùå Host do banco de dados n√£o encontrado")
	}
	return vl, nil
}

func (d *DBService) GetConfig() *t.DBConfig {
	if d.db == nil {
		return nil
	}
	config, ok := d.properties["config"].(gbm.Property[*t.DBConfig])
	if !ok {
		return nil
	}
	return config.GetValue()
}

func ConnectDatabase(dbType, dsn string) (*gorm.DB, error) {
	var dialector gorm.Dialector

	switch dbType {
	case "mysql":
		dialector = mysql.Open(dsn)
	case "postgres":
		dialector = postgres.Open(dsn)
	case "sqlite":
		dialector = sqlite.Open(dsn)
	default:
		return nil, fmt.Errorf("banco de dados n√£o suportado: %s", dbType)
	}

	return gorm.Open(dialector, &gorm.Config{})
}

/// internal/services/docker_client.go ///
package services

import (
	"context"
	"io"

	c "github.com/docker/docker/api/types/container"
	i "github.com/docker/docker/api/types/image"
	n "github.com/docker/docker/api/types/network"
	v "github.com/docker/docker/api/types/volume"
	o "github.com/opencontainers/image-spec/specs-go/v1"
)

type IDockerClient interface {
	ContainerStop(ctx context.Context, containerID string, options c.StopOptions) error
	ContainerRemove(ctx context.Context, containerID string, options c.RemoveOptions) error
	ContainerList(ctx context.Context, options c.ListOptions) ([]c.Summary, error)
	ContainerCreate(ctx context.Context, config *c.Config, hostConfig *c.HostConfig, networkingConfig *n.NetworkingConfig, platform *o.Platform, containerName string) (c.CreateResponse, error)
	ContainerStart(ctx context.Context, containerID string, options c.StartOptions) error
	VolumeCreate(ctx context.Context, options v.CreateOptions) (v.Volume, error)
	VolumeList(ctx context.Context, options v.ListOptions) (v.ListResponse, error)
	ImagePull(ctx context.Context, image string, options i.PullOptions) (io.ReadCloser, error)
}

/// internal/services/docker_service.go ///
package services

import (
	"bufio"
	"context"
	"fmt"
	"io"
	"strings"
	"sync"

	"github.com/docker/docker/api/types/container"
	c "github.com/docker/docker/api/types/container"
	i "github.com/docker/docker/api/types/image"
	v "github.com/docker/docker/api/types/volume"
	k "github.com/docker/docker/client"
	nl "github.com/docker/docker/libnetwork/netlabel"
	"github.com/docker/go-connections/nat"
	gbm "github.com/rafa-mori/gdbase"
	evs "github.com/rafa-mori/gdbase/internal/events"
	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	it "github.com/rafa-mori/gdbase/internal/types"
	gl "github.com/rafa-mori/gdbase/logger"
	t "github.com/rafa-mori/gdbase/types"
	l "github.com/rafa-mori/logz"

	_ "embed"
)

func NewServices(name, image string, env []string, ports []nat.PortMap, volumes map[string]struct{}) *Services {
	if containersCache == nil {
		containersCache = make(map[string]*Services)
	}
	service := &Services{
		Name:     name,
		Image:    image,
		Env:      env,
		Ports:    ports,
		Volumes:  volumes,
		StateMap: make(map[string]any),
	}
	if _, ok := containersCache[name]; !ok {
		containersCache[name] = service
	} else {
		containersCache[name].Name = name
		containersCache[name].Image = image
		containersCache[name].Env = env
		containersCache[name].Ports = ports
		containersCache[name].Volumes = volumes
	}
	return service
}

type IDockerService interface {
	IDockerUtils
	IContainerVolumeReport
	IContainerImageReport
	IContainerNameReport

	Initialize() error
	StartContainer(serviceName, image string, envVars []string, portBindings map[nat.Port]struct{}, volumes map[string]struct{}) error
	CreateVolume(volumeName, devicePath string) error
	GetContainerLogs(ctx context.Context, containerName string, follow bool) error
	GetProperty(name string) any
	GetContainersList() ([]c.Summary, error)
	GetVolumesList() ([]*v.Volume, error)
	StartContainerByName(containerName string) error
	StopContainerByName(containerName string, options c.StopOptions) error
	On(name string, event string, callback func(...any))
	Off(name string, event string)
	AddService(name string, image string, env []string, ports []nat.PortMap, volumes map[string]struct{}) *Services
}
type DockerService struct {
	*ContainerNameReport
	*ContainerImageReport
	*ContainerVolumeReport
	*DockerUtils

	Logger    l.Logger
	reference gbm.Reference
	mutexes   gbm.Mutexes

	services map[string]any

	Cli  IDockerClient
	pool *sync.Pool

	properties map[string]any
	eventBus   *evs.EventBus
}

func newDockerServiceBus(config *t.DBConfig, logger l.Logger) (IDockerService, error) {
	EnsureDockerIsRunning()

	if logger == nil {
		logger = l.GetLogger("DockerService")
	}

	var propDBConfig ci.IProperty[*t.DBConfig]
	if config != nil {
		propDBConfig = it.NewProperty[*t.DBConfig]("dbConfig", &config, false, nil)
	}

	cli, err := k.NewClientWithOpts(k.FromEnv, k.WithAPIVersionNegotiation())
	if err != nil {
		return nil, fmt.Errorf("‚ùå Error creating Docker client: %v", err)
	}
	dockerService := &DockerService{
		Logger:     logger,
		reference:  gbm.NewReference("DockerService"),
		mutexes:    gbm.NewMutexesType(),
		pool:       &sync.Pool{},
		Cli:        cli,
		properties: nil,

		DockerUtils:           NewDockerUtils(),
		ContainerNameReport:   NewContainerNameReport(),
		ContainerImageReport:  NewContainerImageReport(),
		ContainerVolumeReport: NewContainerVolumeReport(),
	}
	if config != nil {
		dockerService.properties = map[string]any{"dbConfig": propDBConfig}
	}
	if dockerService.eventBus == nil {
		dockerService.eventBus = evs.NewEventBus()
	}
	return dockerService, nil
}
func newDockerService(config *t.DBConfig, logger l.Logger) (IDockerService, error) {
	EnsureDockerIsRunning()

	if logger == nil {
		logger = l.GetLogger("DockerService")
	}

	cli, err := k.NewClientWithOpts(k.FromEnv, k.WithAPIVersionNegotiation())
	if err != nil {
		return nil, fmt.Errorf("‚ùå Error creating Docker client: %v", err)
	}

	dockerService := &DockerService{
		Logger:    logger,
		reference: gbm.NewReference("DockerService"),
		mutexes:   gbm.NewMutexesType(),
		pool:      &sync.Pool{},
		Cli:       cli,
		properties: map[string]any{
			"dbConfig": it.NewProperty[*t.DBConfig]("dbConfig", &config, false, nil),
		},
	}
	if dockerService.eventBus == nil {
		dockerService.eventBus = evs.NewEventBus()
	}

	return dockerService, nil
}
func NewDockerService(config *t.DBConfig, logger l.Logger) (IDockerService, error) {
	return newDockerService(config, logger)
}

func (d *DockerService) GetContainerLogs(ctx context.Context, containerName string, follow bool) error {
	cli, err := k.NewClientWithOpts(k.FromEnv, k.WithAPIVersionNegotiation())
	if err != nil {
		return fmt.Errorf("error creating Docker client: %w", err)
	}

	logsReader, err := cli.ContainerLogs(ctx, containerName, c.LogsOptions{
		ShowStdout: true,
		ShowStderr: true,
		Timestamps: true,
		Follow:     follow,
	})
	if err != nil {
		return fmt.Errorf("error getting logs for container %s: %w", containerName, err)
	}
	defer func(logsReader io.ReadCloser) {
		_ = logsReader.Close()
	}(logsReader)

	scanner := bufio.NewScanner(logsReader)
	for scanner.Scan() {
		fmt.Println(scanner.Text())
	}
	if scannerErr := scanner.Err(); scannerErr != nil {
		return fmt.Errorf("error processing logs for container %s: %w", containerName, scannerErr)
	}
	return nil
}
func (d *DockerService) Initialize() error {
	if d.properties != nil {
		dbServiceConfigT, exists := d.properties["dbConfig"]
		if exists {
			if dbServiceConfig, ok := dbServiceConfigT.(*it.Property[*t.DBConfig]); !ok {
				return fmt.Errorf("‚ùå Error converting database configuration")
			} else {
				dbSrvCfg := dbServiceConfig.GetValue()
				if err := SetupDatabaseServices(d, dbSrvCfg); err != nil {
					return fmt.Errorf("‚ùå Error setting up database services: %v", err)
				}
				d.properties["dbConfig"] = dbServiceConfig
			}
		} else {
			return fmt.Errorf("‚ùå Database configuration not found")
		}
	}

	d.properties["volumes"] = make(map[string]map[string]struct{})
	d.properties["services"] = make(map[string]string)

	return nil
}
func (d *DockerService) StartContainer(serviceName, image string, envVars []string, portBindings map[nat.Port]struct{}, volumes map[string]struct{}) error {
	if !isDockerRunning() {
		gl.Log("fatal", "Docker is not running. Please start Docker and try again.")
		return fmt.Errorf("docker is not running")
	}

	if IsServiceRunning(serviceName) {
		fmt.Printf("‚úÖ %s is already running!\n", serviceName)
		return nil
	}

	ctx := context.Background()

	fmt.Println("üîÑ Pulling image...")
	reader, err := d.Cli.ImagePull(ctx, image, i.PullOptions{})
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error pulling image: %v", err))
		return fmt.Errorf("error pulling image: %w", err)
	}
	defer func(reader io.ReadCloser) {
		_ = reader.Close()
	}(reader)
	_, _ = io.Copy(io.Discard, reader)

	fmt.Println("üöÄ Creating container...")
	containerConfig := &c.Config{
		Image:        image,
		Env:          envVars,
		ExposedPorts: d.ExtractPorts(portBindings),
	}

	binds := []string{}

	for volume, _ := range volumes {
		// Por enquanto coloquei os campos repetidos, mas depois PRECISAMOS melhorar isso
		structuredVolume, err := d.GetStructuredVolume(volume, volume)
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting structured volume: %v", err))
			return fmt.Errorf("error getting structured volume: %w", err)
		}

		binds = append(binds, fmt.Sprintf("%s:%s", structuredVolume.HostPath, structuredVolume.ContainerPath))
	}

	portBindingsT := make(nat.PortMap)
	for hostPort, _ := range portBindings {
		containerPort := strings.TrimSuffix(hostPort.Port(), "/tcp")
		hostPortBinding := nat.PortBinding{
			HostIP:   nl.HostIPv4,
			HostPort: hostPort.Port(),
		}
		prtPort := nat.Port(containerPort + "/tcp")
		portBindingsT[prtPort] = []nat.PortBinding{hostPortBinding}
	}

	hostConfig := &c.HostConfig{
		Binds:        binds,
		PortBindings: portBindingsT,
		RestartPolicy: c.RestartPolicy{
			Name: "unless-stopped",
		},
	}

	resp, err := d.Cli.ContainerCreate(ctx, containerConfig, hostConfig, nil, nil, serviceName)
	if err != nil {
		return fmt.Errorf("error creating container %s: %w", serviceName, err)
	}

	if err := d.Cli.ContainerStart(ctx, resp.ID, c.StartOptions{}); err != nil {
		return fmt.Errorf("error starting container %s: %w", serviceName, err)
	}

	fmt.Println("‚úÖ Container started successfully!")
	return nil
}
func (d *DockerService) CreateVolume(volumeName, pathsForBind string) error {
	structuredVolume, err := d.GetStructuredVolume(volumeName, pathsForBind)
	if err != nil {
		return fmt.Errorf("error getting structured volume: %w", err)
	}

	ctx := context.Background()

	volumes, _ := d.Cli.VolumeList(ctx, v.ListOptions{})
	for _, vol := range volumes.Volumes {
		if vol.Name == volumeName {
			gl.Log("debug", fmt.Sprintf("Volume %s already exists, skipping creation", volumeName))
			return nil
		}
	}

	vol, err := d.Cli.VolumeCreate(ctx, v.CreateOptions{
		Name:   structuredVolume.Name,
		Driver: "local",
		DriverOpts: map[string]string{
			"type":   "none",
			"device": structuredVolume.HostPath,
			"o":      "bind",
		},
	})

	if err != nil {
		return err
	}

	fmt.Printf("‚úÖ Volume created: %s\n", vol.Name)
	return nil
}
func (d *DockerService) GetContainersList() ([]c.Summary, error) {
	containers, err := d.Cli.ContainerList(context.Background(), c.ListOptions{All: true})
	if err != nil {
		panic(err)
	}

	var containerList []c.Summary
	for _, container := range containers {
		if container.State == "running" {
			containerList = append(containerList, container)
		}
	}

	return containerList, nil
}
func (d *DockerService) GetVolumesList() ([]*v.Volume, error) {
	volumes, err := d.Cli.VolumeList(context.Background(), v.ListOptions{})
	if err != nil {
		panic(err)
	}

	var volumeList []*v.Volume
	for _, volume := range volumes.Volumes {
		if volume.Name == "gdbase-pg-data" || volume.Name == "gdbase-redis-data" {
			volumeList = append(volumeList, volume)
		}
	}

	return volumeList, nil
}
func (d *DockerService) StartContainerByName(containerName string) error {
	ctx := context.Background()
	err := d.Cli.ContainerStart(ctx, containerName, c.StartOptions{})
	if err != nil {
		return fmt.Errorf("error starting container %s: %w", containerName, err)
	}
	fmt.Printf("‚úÖ Container %s started successfully!\n", containerName)
	return nil
}
func (d *DockerService) StopContainerByName(containerName string, stopOptions container.StopOptions) error {
	ctx := context.Background()
	err := d.Cli.ContainerStop(ctx, containerName, stopOptions)
	if err != nil {
		return fmt.Errorf("error stopping container %s: %w", containerName, err)
	}
	fmt.Printf("‚úÖ Container %s stopped successfully!\n", containerName)
	return nil
}
func (d *DockerService) GetProperty(name string) any {
	if prop, ok := d.properties[name]; ok {
		return prop
	}
	return nil
}
func (d *DockerService) On(name string, event string, callback func(...any)) {
	if d.mutexes == nil {
		d.mutexes = gbm.NewMutexesType()
	}
	if d.pool == nil {
		d.pool = &sync.Pool{}
	}
	// d.mutexes.MuRLock()
	// defer d.mutexes.MuRUnlock()
	if callback != nil {
		d.pool.Put(callback)
	}
}
func (d *DockerService) Off(name string, event string) {
	if d.mutexes == nil {
		d.mutexes = gbm.NewMutexesType()
	}
	if d.pool == nil {
		d.pool = &sync.Pool{}
	}
	// d.mutexes.MuRLock()
	// defer d.mutexes.MuRUnlock()
	d.pool.Put(nil)
}
func (d *DockerService) GetContainersCache() map[string]*Services {
	if containersCache == nil {
		containersCache = make(map[string]*Services)
	}
	return containersCache
}
func (d *DockerService) GetEventBus() *evs.EventBus {
	if d.eventBus == nil {
		d.eventBus = evs.NewEventBus()
	}
	return d.eventBus
}
func (d *DockerService) AddService(name string, image string, env []string, ports []nat.PortMap, volumes map[string]struct{}) *Services {
	if containersCache == nil {
		containersCache = make(map[string]*Services)
	}
	service := &Services{
		Name:     name,
		Image:    image,
		Env:      env,
		Ports:    ports,
		Volumes:  volumes,
		StateMap: make(map[string]any),
	}
	if d.services == nil {
		d.services = make(map[string]any)
	}

	d.services[name] = service

	if _, ok := containersCache[name]; !ok {
		containersCache[name] = service
	} else {
		containersCache[name].Name = name
		containersCache[name].Image = image
		containersCache[name].Env = env
		containersCache[name].Ports = ports
		containersCache[name].Volumes = volumes
	}
	return service
}

/// internal/services/docker_utils.go ///
package services

import (
	"context"
	_ "embed"
	"encoding/json"
	"fmt"
	"io"
	"reflect"
	"strings"
	"time"

	ds "github.com/docker/docker/api/types/container"

	"github.com/docker/docker/client"
	nl "github.com/docker/docker/libnetwork/netlabel"
	"github.com/docker/go-connections/nat"
	t "github.com/rafa-mori/gdbase/types"
)

// initDBSQL is an embedded SQL file that initializes the database
// with a complete schema and some initial data for testing purposes.
// The default database is implemented in PostgreSQL and can provide a simple, but complete
// database for working with almost any comercial scenario for products selling.

//go:embed assets/init-db.sql
var initDBSQL []byte

var (
	containersCache map[string]*Services
)

// Services represents a Docker service configuration.
// It preceeds the DockerService struct and is used to manage
// the state of various services running in Docker containers.
type Services struct {
	Name     string
	Image    string
	Env      []string
	Ports    []nat.PortMap
	Volumes  map[string]struct{}
	StateMap map[string]any
}

// StructuredVolume represents a structured volume configuration
type StructuredVolume struct {
	Name          string
	HostPath      string
	ContainerPath string
}

// Config represents a generic configuration type for different DATABASE services.
type Config[T t.Database | t.Redis | t.RabbitMQ | t.MongoDB] = *T
type Configs[T t.Database | t.Redis | t.RabbitMQ | t.MongoDB] = map[reflect.Type]Config[T]

type IContainerVolumeReport interface {
	GetStructuredVolume(volumeName, pathsForBind string) (StructuredVolume, error)
	GetStructuredVolumes(volumes []string) ([]StructuredVolume, error)
	GetStructuredVolumesMap(volumes []string) (map[string]StructuredVolume, error)
}
type ContainerVolumeReport struct{}

func NewContainerVolumeReport() *ContainerVolumeReport { return &ContainerVolumeReport{} }

func (cvm *ContainerVolumeReport) GetStructuredVolume(volumeName, pathsForBind string) (StructuredVolume, error) {
	var volStructuredList = StructuredVolume{Name: volumeName}
	pathsArr := strings.Split(pathsForBind, ":")
	if len(pathsArr) > 1 {
		volStructuredList.HostPath = pathsArr[0]
		volStructuredList.ContainerPath = pathsArr[1]
	} else {
		volStructuredList.HostPath = pathsForBind
		volStructuredList.ContainerPath = pathsForBind
	}
	return volStructuredList, nil
}
func (cvm *ContainerVolumeReport) GetStructuredVolumes(volumes []string) ([]StructuredVolume, error) {
	var volStructuredList []StructuredVolume
	for _, volume := range volumes {
		vol, err := cvm.GetStructuredVolume(volume, volume)
		if err != nil {
			return nil, err
		}
		volStructuredList = append(volStructuredList, vol)
	}
	return volStructuredList, nil
}
func (cvm *ContainerVolumeReport) GetStructuredVolumesMap(volumes []string) (map[string]StructuredVolume, error) {
	volStructuredList, err := cvm.GetStructuredVolumes(volumes)
	if err != nil {
		return nil, err
	}
	volMap := make(map[string]StructuredVolume)
	for _, vol := range volStructuredList {
		volMap[vol.Name] = vol
	}
	return volMap, nil
}

type IContainerImageReport interface {
	// GetImageMap returns a map of container images with their names as keys.
	GetImageMap(images []string) map[string]struct{}
}
type ContainerImageReport struct{}

func NewContainerImageReport() *ContainerImageReport { return &ContainerImageReport{} }

func (cim *ContainerImageReport) GetImageMap(images []string) map[string]struct{} {
	imageMap := make(map[string]struct{})
	for _, image := range images {
		imageMap[image] = struct{}{}
	}
	return imageMap
}

type IDockerUtils interface {
	GetStateMap(stateMap map[string]any) map[string]any
	MapPorts(hostPort, containerPort string) nat.PortMap
	MapPortsSlice(hostPorts, containerPorts []string) []nat.PortMap
	ExtractPorts(portBindings map[nat.Port]struct{}) nat.PortSet
	GetPortsMap(ports []nat.PortMap) map[string][]nat.PortBinding
	GetEnvSlice(envMap map[string]struct{}) []string
	GetEnvMap(envs []string) map[string]struct{}
}
type DockerUtils struct{}

func NewDockerUtils() *DockerUtils { return &DockerUtils{} }

func (d *DockerUtils) GetStateMap(stateMap map[string]any) map[string]any {
	if stateMap == nil {
		return make(map[string]any)
	}
	newStateMap := make(map[string]any, len(stateMap))
	for key, value := range stateMap {
		newStateMap[key] = value
	}
	return newStateMap
}
func (d *DockerUtils) MapPorts(hostPort, containerPort string) nat.PortMap {
	if strings.HasSuffix(hostPort, "/tcp") {
		hostPort = strings.TrimSuffix(hostPort, "/tcp")
	}
	hostPortBinding := nat.PortBinding{
		HostIP:   nl.HostIPv4,
		HostPort: hostPort,
	}
	if strings.HasSuffix(containerPort, "/tcp") {
		containerPort = strings.TrimSuffix(containerPort, "/tcp")
	}
	prtPort := nat.Port(containerPort + "/tcp")
	portBindings := nat.PortMap{
		prtPort: []nat.PortBinding{hostPortBinding},
	}
	return portBindings
}
func (d *DockerUtils) MapPortsSlice(hostPorts, containerPorts []string) []nat.PortMap {
	if len(hostPorts) != len(containerPorts) {
		return nil
	}
	portMaps := make([]nat.PortMap, len(hostPorts))
	for i := range hostPorts {
		portMaps[i] = d.MapPorts(hostPorts[i], containerPorts[i])
	}
	return portMaps
}
func (d *DockerUtils) ExtractPorts(portBindings map[nat.Port]struct{}) nat.PortSet {
	portSet := nat.PortSet{}
	for port := range portBindings {
		portSet[port] = struct{}{}
	}
	return portSet
}
func (d *DockerUtils) GetPortsMap(ports []nat.PortMap) map[string][]nat.PortBinding {
	portsMap := make(map[string][]nat.PortBinding)
	for _, port := range ports {
		for portKey, portValue := range port {
			portsMap[portKey.Port()] = portValue
		}
	}
	return portsMap
}
func (d *DockerUtils) GetEnvSlice(envMap map[string]struct{}) []string {
	envSlice := make([]string, 0, len(envMap))
	for env := range envMap {
		envSlice = append(envSlice, env)
	}
	return envSlice
}
func (d *DockerUtils) GetEnvMap(envs []string) map[string]struct{} {
	envMap := make(map[string]struct{})
	for _, env := range envs {
		if strings.Contains(env, "=") {
			envParts := strings.SplitN(env, "=", 2)
			if len(envParts) == 2 {
				envMap[envParts[0]] = struct{}{}
			}
		} else {
			envMap[env] = struct{}{}
		}
	}
	return envMap
}

type IContainerNameReport interface {
	// GetName returns the container name based on the service name.
	GetName(args ...any) string
	// GetNames returns a slice of container names based on the provided service names.
	GetNames(args ...any) []string
	// GetNamesMap returns a map of container names based on the provided service names.
	GetNamesMap(services []string) map[string]struct{}
}
type ContainerNameReport struct{}

func NewContainerNameReport() *ContainerNameReport { return &ContainerNameReport{} }

func (cnr *ContainerNameReport) GetName(args ...any) string {
	if len(args) < 1 {
		return ""
	}
	serviceName, ok := args[0].(string)
	if !ok {
		return ""
	}
	if strings.HasPrefix(serviceName, "gdbase-") {
		return serviceName
	}
	return "gdbase-" + serviceName
}
func (cnr *ContainerNameReport) GetNames(args ...any) []string {
	containerNames := make([]string, len(args))
	if len(args) == 0 {
		return containerNames
	}
	services, ok := args[0].([]string)
	if !ok || len(services) == 0 {
		return containerNames
	}
	if len(services) == 1 {
		containerNames[0] = cnr.GetName(services[0])
		return containerNames
	}
	containerNames = make([]string, len(services))
	if len(services) == 0 {
		return containerNames
	}
	if len(services) == 1 {
		containerNames[0] = cnr.GetName(services[0])
		return containerNames
	}
	return containerNames
}
func (cnr *ContainerNameReport) GetNamesMap(services []string) map[string]struct{} {
	containerNames := cnr.GetNames(services)
	containerNamesMap := make(map[string]struct{}, len(containerNames))
	for _, name := range containerNames {
		containerNamesMap[name] = struct{}{}
	}
	return containerNamesMap
}

// IDockerServiceReport defines the interface for reporting Docker service statistics.
type IDockerServiceReport interface {
	// GeneralStats returns general statistics of the Docker service.
	GeneralStats() (map[string]any, error)
	// ServiceStats returns statistics of a specific Docker service.
	ServiceStats(serviceName string) (map[string]any, error)
	// ServiceStatsStream returns a stream of statistics for a specific Docker service.
	ServiceStatsStream(serviceName string) (map[string]any, error)
	// ServiceStatsMap returns a map of statistics for multiple Docker services.
	ServiceStatsMap(services []string) (map[string]map[string]any, error)
	// ServiceStatsStreamMap returns a map of streamed statistics for multiple Docker services.
	ServiceStatsStreamMap(services []string) (map[string]map[string]any, error)
	// Note: The actual implementation of these methods would depend on the Docker client library being used.
}

// DockerServiceReport agora possui um cliente Docker embutido.
type DockerServiceReport struct {
	Cli *client.Client
}

// NewDockerServiceReport cria e retorna um novo DockerServiceReport, inicializando o client.
func NewDockerServiceReport() *DockerServiceReport {
	cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())
	if err != nil {
		// Em um cen√°rio real, trate o erro apropriadamente
		panic(fmt.Sprintf("Erro ao criar Docker client: %v", err))
	}
	return &DockerServiceReport{Cli: cli}
}

// GeneralStats retorna informa√ß√µes gerais do sistema Docker.
// Usa o m√©todo Info do SDK e converte o resultado para map[string]any.
func (dsr *DockerServiceReport) GeneralStats() (map[string]any, error) {
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	info, err := dsr.Cli.Info(ctx)
	if err != nil {
		return nil, err
	}
	// Convertendo o objeto types.Info para mapa por meio de JSON.
	data, err := json.Marshal(info)
	if err != nil {
		return nil, err
	}
	var result map[string]any
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, err
	}
	return result, nil
}

// ServiceStats retorna as estat√≠sticas de um container espec√≠fico (n√£o stream).
func (dsr *DockerServiceReport) ServiceStats(serviceName string) (map[string]any, error) {
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	containerID, err := dsr.findContainerIDByName(ctx, serviceName)
	if err != nil {
		return nil, err
	}

	// Solicita as estat√≠sticas em modo "n√£o streaming".
	stats, err := dsr.Cli.ContainerStats(ctx, containerID, false)
	if err != nil {
		return nil, err
	}
	defer stats.Body.Close()

	var statsJSON ds.StatsResponse
	decoder := json.NewDecoder(stats.Body)
	if err := decoder.Decode(&statsJSON); err != nil {
		return nil, err
	}

	// Converte o struct StatsJSON para map[string]any.
	data, err := json.Marshal(statsJSON)
	if err != nil {
		return nil, err
	}
	var result map[string]any
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, err
	}

	return result, nil
}

// ServiceStatsStream retorna as estat√≠sticas de um container espec√≠fico em modo stream,
// mas l√™ e retorna apenas o primeiro conjunto de dados.
func (dsr *DockerServiceReport) ServiceStatsStream(serviceName string) (map[string]any, error) {
	ctx, cancel := context.WithTimeout(context.Background(), 20*time.Second)
	defer cancel()

	containerID, err := dsr.findContainerIDByName(ctx, serviceName)
	if err != nil {
		return nil, err
	}

	// Solicita estat√≠sticas em modo streaming.
	stats, err := dsr.Cli.ContainerStats(ctx, containerID, true)
	if err != nil {
		return nil, err
	}
	defer stats.Body.Close()

	var statsJSON ds.StatsResponse
	decoder := json.NewDecoder(stats.Body)
	// L√™ o primeiro objeto de estat√≠sticas da stream.
	if err := decoder.Decode(&statsJSON); err != nil {
		if err == io.EOF {
			return nil, fmt.Errorf("stream de stats terminou prematuramente")
		}
		return nil, err
	}

	data, err := json.Marshal(statsJSON)
	if err != nil {
		return nil, err
	}
	var result map[string]any
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, err
	}

	return result, nil
}

// ServiceStatsMap obt√©m estat√≠sticas de cada container na lista de servi√ßos e retorna um mapa.
func (dsr *DockerServiceReport) ServiceStatsMap(services []string) (map[string]map[string]any, error) {
	statsMap := make(map[string]map[string]any, len(services))
	for _, service := range services {
		stats, err := dsr.ServiceStats(service)
		if err != nil {
			return nil, err
		}
		statsMap[service] = stats
	}
	return statsMap, nil
}

// ServiceStatsStreamMap obt√©m as estat√≠sticas em modo stream para cada container e retorna um mapa.
func (dsr *DockerServiceReport) ServiceStatsStreamMap(services []string) (map[string]map[string]any, error) {
	statsMap := make(map[string]map[string]any, len(services))
	for _, service := range services {
		stats, err := dsr.ServiceStatsStream(service)
		if err != nil {
			return nil, err
		}
		statsMap[service] = stats
	}
	return statsMap, nil
}

// findContainerIDByName auxilia na busca do container ID dado um nome de servi√ßo.
func (dsr *DockerServiceReport) findContainerIDByName(ctx context.Context, serviceName string) (string, error) {
	containers, err := dsr.Cli.ContainerList(ctx, ds.ListOptions{All: true})
	if err != nil {
		return "", err
	}
	for _, cnt := range containers {
		for _, name := range cnt.Names {
			// Considera que o nome pode vir com prefixo "/"
			if name == "/"+serviceName || name == serviceName {
				return cnt.ID, nil
			}
		}
	}
	return "", fmt.Errorf("container com o nome %s n√£o foi encontrado", serviceName)
}

/// internal/services/rabbitmq.go ///
package services

import (
	"fmt"
	"os"

	"github.com/docker/go-connections/nat"
	glb "github.com/rafa-mori/gdbase/internal/globals"
	gl "github.com/rafa-mori/gdbase/logger"
	t "github.com/rafa-mori/gdbase/types"
)

func SetupRabbitMQ(config *t.RabbitMQ, dockerService IDockerService) error {
	if config == nil || !config.Enabled {
		gl.Log("debug", "RabbitMQ est√° desabilitado na configura√ß√£o. Ignorando inicializa√ß√£o.")
		return nil
	}

	// Verifica se o servi√ßo j√° est√° rodando
	if IsServiceRunning(config.Reference.Name) {
		gl.Log("info", fmt.Sprintf("‚úÖ RabbitMQ (%s) j√° est√° rodando!", config.Reference.Name))
		return nil
	}

	// Configura valores padr√£o, caso estejam ausentes
	if config.Username == "" {
		config.Username = "guest"
	}
	if config.Password == "" {
		config.Password = "guest"
	}
	if config.Port == nil || config.Port == "" {
		config.Port = "5672"
	}
	if config.ManagementPort == "" {
		config.ManagementPort = "15672"
	}
	if config.ErlangCookie == "" {
		config.ErlangCookie = "defaultcookie"
	}
	if config.Volume == "" {
		config.Volume = os.ExpandEnv(glb.DefaultRabbitMQVolume)
	}

	// Cria o volume, se necess√°rio
	if err := dockerService.CreateVolume(config.Reference.Name, config.Volume); err != nil {
		gl.Log("error", fmt.Sprintf("‚ùå Erro ao criar volume do RabbitMQ: %v", err))
		return err
	}

	// Mapeia as portas
	portMap := []nat.PortMap{
		dockerService.MapPorts(fmt.Sprintf("%s", config.ManagementPort), "15672/tcp"),
		dockerService.MapPorts(fmt.Sprintf("%s", config.Port), "5672/tcp"),
	}

	// Configura as vari√°veis de ambiente
	envVars := []string{
		"RABBITMQ_DEFAULT_USER=" + config.Username,
		"RABBITMQ_DEFAULT_PASS=" + config.Password,
		"RABBITMQ_ERLANG_COOKIE=" + config.ErlangCookie,
	}

	// Inicializa o container do RabbitMQ
	service := dockerService.AddService(
		config.Reference.Name,
		"rabbitmq:3-management",
		envVars,
		portMap,
		map[string]struct{}{
			fmt.Sprintf("%s:/var/lib/rabbitmq", config.Volume): {},
		},
	)
	if service == nil {
		err := fmt.Errorf("servi√ßo n√£o encontrado: %s", config.Reference.Name)
		gl.Log("error", fmt.Sprintf("‚ùå Erro ao iniciar o RabbitMQ: %v", err))
		return err
	}

	gl.Log("success", fmt.Sprintf("‚úÖ RabbitMQ (%s) iniciado com sucesso!", config.Reference.Name))
	return nil
}

/// internal/services/utils.go ///
package services

import (
	"bufio"
	"fmt"
	"math/rand"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"strings"
	"time"

	"github.com/docker/go-connections/nat"
	glb "github.com/rafa-mori/gdbase/internal/globals"
	gl "github.com/rafa-mori/gdbase/logger"
	t "github.com/rafa-mori/gdbase/types"
	u "github.com/rafa-mori/gdbase/utils"
)

func SlitMessage(recPayload []string) (id, msg []string) {
	if recPayload[1] == "" {
		id = recPayload[:2]
		msg = recPayload[2:]
	} else {
		id = recPayload[:1]
		msg = recPayload[1:]
	}
	return
}
func GetBrokersPath() (string, error) {
	brkDir, homeErr := os.UserHomeDir()
	if homeErr != nil || brkDir == "" {
		brkDir, homeErr = os.UserConfigDir()
		if homeErr != nil || brkDir == "" {
			brkDir, homeErr = os.UserCacheDir()
			if homeErr != nil || brkDir == "" {
				brkDir = "/tmp"
			}
		}
	}

	brkDir = filepath.Join(brkDir, ".kubex", "gkbxsrv", "brokers")

	if _, statErr := os.Stat(brkDir); statErr != nil {
		if mkDirErr := os.MkdirAll(brkDir, 0755); mkDirErr != nil {
			gl.Log("error", "Error creating brokers")
			return "", mkDirErr
		}
	}

	gl.Log("info", fmt.Sprintf("PID's folder: %s", brkDir))

	return brkDir, nil
}
func RndomName() string {
	return "broker-" + randStringBytes(5)
}
func randStringBytes(n int) string {
	const letterBytes = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
	b := make([]byte, n)
	for i := range b {
		b[i] = letterBytes[rand.Intn(len(letterBytes))]
	}
	return string(b)
}

func FindAvailablePort(basePort int, maxAttempts int) (string, error) {
	for z := 0; z < maxAttempts; z++ {
		if basePort+z < 1024 || basePort+z > 49151 {
			continue
		}
		port := fmt.Sprintf("%d", basePort+z)
		isOpen, err := u.CheckPortOpen(port)
		if err != nil {
			return "", fmt.Errorf("error checking port %s: %w", port, err)
		}
		if !isOpen {
			fmt.Printf("‚ö†Ô∏è Port %s is occupied, trying the next one...\n", port)
			continue
		}
		fmt.Printf("‚úÖ Available port found: %s\n", port)
		return port, nil
	}
	return "", fmt.Errorf("no available port in range %d-%d", basePort, basePort+maxAttempts-1)
}
func IsServiceRunning(serviceName string) bool {
	cmd := exec.Command("docker", "ps", "--filter", fmt.Sprintf("name=%s", serviceName), "--format", "{{.Names}}")
	output, err := cmd.Output()
	if err != nil {
		fmt.Printf("‚ùå Error checking containers: %v\n", err)
	}
	return string(output) != ""
}
func isDockerRunning() bool {
	var cmd *exec.Cmd

	switch runtime.GOOS {
	case "linux":
		cmd = exec.Command("systemctl", "is-active", "--quiet", "docker")
	case "darwin": // macOS
		cmd = exec.Command("brew", "services", "list") // Apenas para verificar se o servi√ßo est√° ativo
	case "windows":
		cmd = exec.Command("powershell", "Get-Service", "docker", "|", "Select-Object", "Status")
	default:
		fmt.Println("Sistema operacional n√£o suportado para ativa√ß√£o autom√°tica do Docker.")
		return false
	}

	err := cmd.Run()
	return err == nil
}
func WriteInitDBSQL() (string, error) {
	configDir := filepath.Join(os.ExpandEnv(glb.DefaultPostgresVolume), "init")
	if err := u.EnsureDir(configDir, 0755, []string{}); err != nil {
		gl.Log("error", fmt.Sprintf("Error creating directory: %v", err))
		return "", err
	}
	filePath := filepath.Join(configDir, "init-db.sql")
	if _, err := os.Stat(filePath); err == nil {
		gl.Log("debug", fmt.Sprintf("File %s already exists, skipping creation", filePath))
	} else {
		if err := os.WriteFile(filePath, initDBSQL, 0644); err != nil {
			gl.Log("error", fmt.Sprintf("Error writing file: %v", err))
			return "", err
		}
		fmt.Printf("‚úÖ File %s created successfully!\n", filePath)
	}
	return filePath, nil
}
func SetupDatabaseServices(d IDockerService, config *t.DBConfig) error {
	if config == nil {
		return fmt.Errorf("‚ùå Configura√ß√£o do banco de dados n√£o encontrada")
	}
	if config.Databases == nil {
		gl.Log("debug", fmt.Sprintf("Not found databases in config, skipping DB setup"))
	}
	var services = make([]*Services, 0)

	if config.Databases != nil && len(config.Databases) > 0 {
		for _, dbConfig := range config.Databases {
			if dbConfig != nil {
				if dbConfig.Type == "postgresql" && dbConfig.Enabled {
					// Check if the database is already running
					if IsServiceRunning("gdbase-pg") {
						gl.Log("debug", fmt.Sprintf("‚úÖ %s j√° est√° rodando!", "gdbase-pg"))
						continue
					} else {
						if err := d.StartContainerByName("gdbase-pg"); err == nil {
							gl.Log("debug", fmt.Sprintf("‚úÖ %s j√° est√° rodando!", "gdbase-pg"))
							continue
						} else {
							// Check if Password is empty, if so, try to retrieve it from keyring
							// if not found, generate a new one
							if dbConfig.Password == "" {
								pgPassKey, pgPassErr := glb.GetOrGenPasswordKeyringPass("pgpass")
								if pgPassErr != nil {
									gl.Log("error", fmt.Sprintf("Error generating key: %v", pgPassErr))
									continue
								}
								dbConfig.Password = string(pgPassKey)
							} else {
								gl.Log("debug", fmt.Sprintf("Password found in config: %s", dbConfig.Password))
							}
							if dbConfig.Volume == "" {
								dbConfig.Volume = os.ExpandEnv(glb.DefaultPostgresVolume)
							}
							pgVolRootDir := os.ExpandEnv(dbConfig.Volume)
							pgVolInitDir := filepath.Join(pgVolRootDir, "init")
							if err := u.EnsureDir(pgVolInitDir, 0755, []string{}); err != nil {
								gl.Log("error", fmt.Sprintf("‚ùå Erro ao criar diret√≥rio do PostgreSQL: %v", err))
								continue
							}
							// Write the init script to the init directory
							if err := os.WriteFile(filepath.Join(pgVolInitDir, "init-db.sql"), initDBSQL, 0644); err != nil {
								gl.Log("error", fmt.Sprintf("‚ùå Erro ao criar diret√≥rio do PostgreSQL: %v", err))
								continue
							}
							if err := d.CreateVolume("gdbase-pg-init", pgVolInitDir); err != nil {
								gl.Log("error", fmt.Sprintf("‚ùå Erro ao criar volume do PostgreSQL: %v", err))
								continue
							}
							pgVolDataDir := filepath.Join(pgVolRootDir, "pgdata")
							if err := u.EnsureDir(pgVolDataDir, 0755, []string{}); err != nil {
								gl.Log("error", fmt.Sprintf("‚ùå Erro ao criar diret√≥rio do PostgreSQL: %v", err))
								continue
							}
							if err := d.CreateVolume("gdbase-pg-data", pgVolDataDir); err != nil {
								gl.Log("error", fmt.Sprintf("‚ùå Erro ao criar volume do PostgreSQL: %v", err))
								continue
							}
							// Check if the port is already in use and find an available one if necessary
							if dbConfig.Port == nil || dbConfig.Port == "" {
								dbConfig.Port = "5432"
							}
							port, err := FindAvailablePort(5432, 10)
							if err != nil {
								gl.Log("error", fmt.Sprintf("‚ùå Erro ao encontrar porta dispon√≠vel: %v", err))
								continue
							}
							dbConfig.Port = port
							// Map the port to the container
							portMap := d.MapPorts(fmt.Sprintf("%s", dbConfig.Port), "5432/tcp")

							// Check if the database name is empty, if so, generate a random one
							if dbConfig.Name == "" {
								dbConfig.Name = "godo-" + randStringBytes(5)
							}
							// Insert the PostgreSQL service into the services slice
							dbConnObj := NewServices(
								"gdbase-pg",
								"postgres:17-alpine",
								[]string{
									"POSTGRES_HOST_AUTH_METHOD=trust",
									"POSTGRES_INITDB_ARGS=--data-checksums",
									"POSTGRES_INITDB_ARGS=--encoding=UTF8",
									"POSTGRES_INITDB_ARGS=--locale=pt_BR.UTF-8",
									"POSTGRES_USER=" + dbConfig.Username,
									"POSTGRES_PASSWORD=" + dbConfig.Password,
									"POSTGRES_DB=" + dbConfig.Name,
									"POSTGRES_PORT=" + dbConfig.Port.(string),
									"POSTGRES_DB_NAME=" + dbConfig.Name,
									"POSTGRES_DB_VOLUME=" + dbConfig.Volume,
									"PGDATA=/var/lib/postgresql/data/pgdata",
									"PGSSLMODE=disable",
								}, []nat.PortMap{portMap},
								map[string]struct{}{
									pgVolInitDir + ":/docker-entrypoint-initdb.d": {},
									pgVolDataDir + ":/var/lib/postgresql/data":    {},
								},
							)
							services = append(services, dbConnObj)
						}
					}
				}
			}
		}
	} else {
		gl.Log("debug", fmt.Sprintf("Not found databases in config, skipping DB setup"))
	}
	if config.Messagery != nil {
		if config.Messagery.RabbitMQ != nil && config.Messagery.RabbitMQ.Enabled {
			// Check if the RabbitMQ service is already running
			if IsServiceRunning("gdbase-rabbitmq") {
				fmt.Printf("‚úÖ %s j√° est√° rodando!\n", "gdbase-rabbitmq")
			} else {
				rabbitCfg := config.Messagery.RabbitMQ
				rabbitUser := rabbitCfg.Username
				rabbitPass := rabbitCfg.Password
				if rabbitUser == "" {
					rabbitUser = "guest"
				}
				if rabbitPass == "" {
					rabbitPass = "guest"
				}

				// secondPortMap := mapPorts(fmt.Sprintf("%s", dbConfig.Port), "5672/tcp")
				var rabbitCfgVolume string
				if rabbitCfgVolume == "" {
					rabbitCfgVolume = os.ExpandEnv(glb.DefaultRabbitMQVolume)
				} else {
					rabbitCfgVolume = os.ExpandEnv(rabbitCfg.Volume)
				}
				// Insert the PostgreSQL service into the services slice
				if rabbitCfg.Reference.Name == "" {
					rabbitCfg.Reference.Name = "gdbase-rabbitmq"
				}
				if rabbitCfg.Volume == "" {
					rabbitCfg.Volume = os.ExpandEnv(glb.DefaultRabbitMQVolume)
				}
				if rabbitCfg.Host == "" {
					rabbitCfg.Host = "localhost"
				}
				if rabbitCfg.Port == nil || rabbitCfg.Port == "" {
					rabbitCfg.Port = "5672"
				}
				if rabbitCfg.ErlangCookie == "" {
					rabbitCfg.ErlangCookie = "defaultcookie"
				}
				// Check if the port is already in use and find an available one if necessary
				firstPortMap := d.MapPorts(fmt.Sprintf("%s", rabbitCfg.Port), "15672/tcp")

				// Vhost n√£o existe no struct original, mas se quiser adicionar:
				// if rabbitCfg.Vhost == "" {
				//     rabbitCfg.Vhost = "/"
				// }

				dbConnObj := NewServices(
					"gdbase-rabbitmq",
					"rabbitmq:3-management",
					[]string{
						"RABBITMQ_DEFAULT_USER=" + rabbitUser,
						"RABBITMQ_DEFAULT_PASS=" + rabbitPass,
						"RABBITMQ_DEFAULT_VHOST=/",
						// "RABBITMQ_DEFAULT_VHOST=" + rabbitCfg.Vhost, // Se adicionar o campo Vhost
						"RABBITMQ_PORT=" + rabbitCfg.Port.(string),
						"RABBITMQ_DB_NAME=" + rabbitCfg.Reference.Name,
						"RABBITMQ_DB_VOLUME=" + rabbitCfg.Volume,
						"RABBITMQ_ERLANG_COOKIE=" + rabbitCfg.ErlangCookie,
						"RABBITMQ_PORT_5672_TCP_ADDR=" + rabbitCfg.Host,
						"RABBITMQ_PORT_5672_TCP_PORT=" + rabbitCfg.Port.(string),
						"RABBITMQ_PORT_15672_TCP_ADDR=" + rabbitCfg.Host,
						"RABBITMQ_PORT_15672_TCP_PORT=" + rabbitCfg.Port.(string),
					}, []nat.PortMap{firstPortMap},
					map[string]struct{}{
						fmt.Sprintf("%s:/var/lib/rabbitmq", rabbitCfg.Volume): {},
					},
				)

				services = append(services, dbConnObj)
			}
		}
		if config.Messagery.Redis != nil && config.Messagery.Redis.Enabled {
			if IsServiceRunning("gdbase-redis") {
				fmt.Printf("‚úÖ %s j√° est√° rodando!\n", "gdbase-redis")
			} else {
				if err := d.StartContainerByName("gdbase-redis"); err == nil {
					fmt.Printf("‚úÖ %s j√° est√° rodando!\n", "gdbase-redis")
				} else {
					rdsCfg := config.Messagery.Redis
					redisPass := rdsCfg.Password
					if redisPass == "" {
						redisPass = "guest"
					}
					// Create the volume for Redis, if exists definitions on the config
					if rdsCfg.Volume == "" {
						rdsCfg.Volume = os.ExpandEnv(glb.DefaultRedisVolume)
						if err := d.CreateVolume("gdbase-redis-data", "/data"); err != nil {
							return fmt.Errorf("‚ùå Erro ao criar volume do Redis: %v", err)
						}
					}
					// Create the Redis service
					servicesR := []*Services{
						NewServices("gdbase-redis", "redis:latest", []string{"REDIS_PASSWORD=" + redisPass}, []nat.PortMap{d.MapPorts("6379", "6379/tcp")}, nil),
					}
					// append the Redis service to the services slice
					services = append(services, servicesR...)
				}
			}
		}
	} else {
		gl.Log("debug", fmt.Sprintf("Not found messagery in config, skipping RabbitMQ setup"))
	}
	gl.Log("debug", fmt.Sprintf("Iniciando %d servi√ßos...", len(services)))
	for _, srv := range services {
		mapPorts := map[nat.Port]struct{}{}
		for _, port := range srv.Ports {
			pt := ExtractPort(port)
			if pt == "" {
				gl.Log("error", fmt.Sprintf("‚ùå Erro ao mapear porta %s", pt))
				continue
			}
			if _, ok := pt.(map[string]string); !ok {
				gl.Log("error", fmt.Sprintf("‚ùå Erro ao mapear porta %s", pt))
				continue
			}
			// Verifica se a porta j√° est√° mapeada
			ptStr, ok := pt.(map[string]string)
			if !ok || ptStr["port"] == "" || ptStr["protocol"] == "" {
				gl.Log("error", fmt.Sprintf("‚ùå Erro ao mapear porta: tipo inv√°lido ou campos ausentes: %v", pt))
				continue
			}
			portKey := nat.Port(fmt.Sprintf("%s/%s", ptStr["port"], ptStr["protocol"]))
			if _, exists := mapPorts[portKey]; exists {
				gl.Log("error", fmt.Sprintf("‚ùå Erro ao mapear porta %s", portKey))
				continue
			}
			// Adiciona a porta ao mapa
			portMap, ok := pt.(map[string]string)
			if !ok {
				gl.Log("error", fmt.Sprintf("‚ùå Erro ao converter porta: %v", pt))
				continue
			}
			portKey = nat.Port(fmt.Sprintf("%s/%s", portMap["port"], portMap["protocol"]))
			mapPorts[portKey] = struct{}{}
		}
		// Verifica se o servi√ßo j√° est√° rodando
		// Isso j√° est√° dentro do StartContainer
		// if IsServiceRunning(srv.Name) {
		// 	gl.Log("info", fmt.Sprintf("‚úÖ %s j√° est√° rodando!", srv.Name))
		// 	continue
		// }
		if err := d.StartContainer(srv.Name, srv.Image, srv.Env, mapPorts, srv.Volumes); err != nil {
			return err
		}
	}
	return nil
}

func ExtractPort(port nat.PortMap) any {
	// Verifica se a porta √© v√°lida
	if port == nil {
		return nil
	}
	// Extrai a porta e o protocolo do primeiro elemento do map
	for k := range port {
		portStr := strings.Split(string(k), "/")
		if len(portStr) != 2 {
			return nil
		}
		portNum := portStr[0]
		protocol := portStr[1]
		return map[string]string{
			"port":     portNum,
			"protocol": protocol,
		}
	}
	return nil
}
func AskToStartDocker() bool {

	// Exibe uma mensagem de aviso ao usu√°rio
	fmt.Printf("\033[1;36m%s\033[0m", `
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                              ‚îÇ
‚îÇ  O servi√ßo do Docker n√£o est√° ativo.                         ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Para continuar, precisamos ativ√°-lo.                        ‚îÇ
‚îÇ  Podemos iniciar o Docker automaticamente para voc√™ ou       ‚îÇ
‚îÇ  voc√™ pode ativ√°-lo manualmente.                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Se voc√™ deseja iniciar o Docker automaticamente,            ‚îÇ
‚îÇ  pressione 'Y' e 'Enter'.                                    ‚îÇ
‚îÇ  Caso contr√°rio, pressione 'N' e 'Enter' para sair.          ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò`)
	fmt.Printf("\033[1;36m%s\033[0m", `
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                              ‚îÇ
‚îÇ  Se voc√™ n√£o tem certeza de como ativ√°-lo manualmente,       ‚îÇ
‚îÇ  pode siguir as instru√ß√µes abaixo em seu terminal:           ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Linux: sudo systemctl start docker                          ‚îÇ
‚îÇ  macOS: brew services start docker                           ‚îÇ
‚îÇ  Windows: powershell Start-Service docker                    ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò`)
	fmt.Printf("\033[1;33m%s\033[0m", `
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                              ‚îÇ
‚îÇ  Pressione 'Y' para iniciar o Docker automaticamente         ‚îÇ
‚îÇ  ou 'N' para sair do programa. (15 segundos para resposta)   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
`)

	fmt.Print("Resposta: ")

	// Canal para receber a resposta do usu√°rio
	// O canal √© usado para evitar o bloqueio do terminal enquanto espera a entrada do usu√°rio
	// e permite que o programa continue executando.
	responseCh := make(chan string, 1)
	defer close(responseCh)

	// L√™ a resposta do usu√°rio em uma goroutine
	// Isso permite que o programa continue executando enquanto espera a entrada do usu√°rio
	// e evita o bloqueio do terminal. O usu√°rio pode pressionar 'Y' ou 'N', caso contr√°rio
	// o programa ir√° aguardar 15 segundos antes de encerrar.
	go func() {
		reader := bufio.NewReader(os.Stdin)
		response, _ := reader.ReadString('\n')
		response = strings.TrimSpace(strings.ToUpper(response))
		responseCh <- response
	}()

	// Aguarda a resposta do usu√°rio ou timeout de 15 segundos
	select {
	case response := <-responseCh:
		return response == "Y"
	case <-time.After(15 * time.Second):
		fmt.Println("\nTempo esgotado. Docker n√£o ser√° ativado.")
		return false
	}
}

// Ativa o servi√ßo do Docker dinamicamente conforme o sistema operacional
func startDockerService() error {
	var cmd *exec.Cmd

	switch runtime.GOOS {
	case "linux":
		cmd = exec.Command("sudo", "systemctl", "start", "docker")
	case "darwin": // macOS
		cmd = exec.Command("brew", "services", "start", "docker")
	case "windows":
		cmd = exec.Command("powershell", "Start-Service", "docker")
	default:
		return fmt.Errorf("Sistema operacional n√£o suportado para ativa√ß√£o autom√°tica do Docker")
	}

	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr
	return cmd.Run()
}
func EnsureDockerIsRunning() {
	if !isDockerRunning() {
		isInteractive := os.Getenv("IS_INTERACTIVE") == "true" || os.Getenv("IS_INTERACTIVE") == "1"
		if isInteractive {
			if AskToStartDocker() {
				gl.Log("info", "Starting Docker service...")
				if err := startDockerService(); err != nil {
					gl.Log("fatal", fmt.Sprintf("Error starting Docker: %v", err))
				}
				gl.Log("success", "Docker service started successfully!")
			} else {
				gl.Log("warn", "Docker service is not running and user chose not to start it.")
				gl.Log("warn", "Please start Docker manually to continue.")
				gl.Log("warn", "Exiting...")
				os.Exit(1)
			}
		} else {
			if err := startDockerService(); err != nil {
				gl.Log("fatal", fmt.Sprintf("Error starting Docker: %v", err))
			}
		}
	}
	return
}

/// internal/types/address.go ///
package types

type Address struct {
	Street     string  `json:"street"`
	City       string  `json:"city"`
	State      string  `json:"state"`
	PostalCode string  `json:"postalCode"`
	Country    string  `json:"country"`
	Latitude   float64 `json:"latitude"`
	Longitude  float64 `json:"longitude"`
}

type AddressList struct {
	Addresses []Address `json:"addresses"`
}

type AddressListResponse struct {
	Addresses  []Address `json:"addresses"`
	Total      int       `json:"total"`
	TotalPages int       `json:"totalPages"`
	Page       int       `json:"page"`
	Limit      int       `json:"limit"`
}

type AddressFilterParams struct {
	Street          *string  `json:"street,omitempty"`
	City            *string  `json:"city,omitempty"`
	State           *string  `json:"state,omitempty"`
	PostalCode      *string  `json:"postalCode,omitempty"`
	Country         *string  `json:"country,omitempty"`
	Latitude        *float64 `json:"latitude,omitempty"`
	Longitude       *float64 `json:"longitude,omitempty"`
	SortBy          *string  `json:"sortBy,omitempty"`
	SortDirection   *string  `json:"sortDirection,omitempty"`
	IncludeArchived bool     `json:"includeArchived"`
}

type AddressSortField string
type AddressSortDirection string

const (
	StreetAddressSortField     AddressSortField     = "street"
	CityAddressSortField       AddressSortField     = "city"
	StateAddressSortField      AddressSortField     = "state"
	PostalCodeAddressSortField AddressSortField     = "postalCode"
	CountryAddressSortField    AddressSortField     = "country"
	LatitudeAddressSortField   AddressSortField     = "latitude"
	LongitudeAddressSortField  AddressSortField     = "longitude"
	AscAddressSortDirection    AddressSortDirection = "asc"
	DescAddressSortDirection   AddressSortDirection = "desc"
)

type AddressResponse struct {
	Address Address `json:"address"`
}

type CreateAddressDTO struct {
	Street     string  `json:"street"`
	City       string  `json:"city"`
	State      string  `json:"state"`
	PostalCode string  `json:"postalCode"`
	Country    string  `json:"country"`
	Latitude   float64 `json:"latitude"`
	Longitude  float64 `json:"longitude"`
}

type UpdateAddressDTO struct {
	Street     *string  `json:"street,omitempty"`
	City       *string  `json:"city,omitempty"`
	State      *string  `json:"state,omitempty"`
	PostalCode *string  `json:"postalCode,omitempty"`
	Country    *string  `json:"country,omitempty"`
	Latitude   *float64 `json:"latitude,omitempty"`
	Longitude  *float64 `json:"longitude,omitempty"`
}

type AddressStatus string
type AddressStatusEnum string

type AddressStatusEnumList struct {
	AddressStatusEnum []AddressStatusEnum `json:"addressStatusEnum"`
}

type AddressStatusEnumResponse struct {
	AddressStatusEnum AddressStatusEnum `json:"addressStatusEnum"`
}

type AddressStatusEnumListResponse struct {
	AddressStatusEnumList []AddressStatusEnum `json:"addressStatusEnumList"`
	Total                 int                 `json:"total"`
	TotalPages            int                 `json:"totalPages"`
	Page                  int                 `json:"page"`
	Limit                 int                 `json:"limit"`
}

// IAddress interface for abstraction and encapsulation
//
//go:generate mockgen -destination=../mocks/mock_address.go -package=mocks . IAddress
type IAddress interface {
	GetStreet() string
	SetStreet(street string)
	GetCity() string
	SetCity(city string)
	GetState() string
	SetState(state string)
	GetPostalCode() string
	SetPostalCode(postalCode string)
	GetCountry() string
	SetCountry(country string)
	GetLatitude() float64
	SetLatitude(lat float64)
	GetLongitude() float64
	SetLongitude(lon float64)
}

func (a *Address) GetStreet() string               { return a.Street }
func (a *Address) SetStreet(street string)         { a.Street = street }
func (a *Address) GetCity() string                 { return a.City }
func (a *Address) SetCity(city string)             { a.City = city }
func (a *Address) GetState() string                { return a.State }
func (a *Address) SetState(state string)           { a.State = state }
func (a *Address) GetPostalCode() string           { return a.PostalCode }
func (a *Address) SetPostalCode(postalCode string) { a.PostalCode = postalCode }
func (a *Address) GetCountry() string              { return a.Country }
func (a *Address) SetCountry(country string)       { a.Country = country }
func (a *Address) GetLatitude() float64            { return a.Latitude }
func (a *Address) SetLatitude(lat float64)         { a.Latitude = lat }
func (a *Address) GetLongitude() float64           { return a.Longitude }
func (a *Address) SetLongitude(lon float64)        { a.Longitude = lon }

/// internal/types/channels.go ///
package types

import (
	"fmt"

	l "github.com/rafa-mori/logz"
	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"
	tu "github.com/rafa-mori/gdbase/utils"

	"reflect"

	"github.com/google/uuid"
)

var (
	smBuf, mdBuf, lgBuf = tu.GetDefaultBufferSizes()
)

type ChannelBase[T any] struct {
	*Mutexes              // Mutexes for this Channel instance
	Name     string       // The name of the channel.
	Channel  any          // The channel for the value. Main channel for this struct.
	Type     reflect.Type // The type of the channel.
	Buffers  int          // The number of buffers for the channel.
	Shared   interface{}  // Shared data for many purposes
}

// NewChannelBase creates a new ChannelBase instance with the provided name and type.
func NewChannelBase[T any](name string, buffers int, logger l.Logger) ci.IChannelBase[any] {
	if logger == nil {
		logger = l.GetLogger("GoLife")
	}
	mu := NewMutexesType()
	if buffers <= 0 {
		buffers = lgBuf
	}
	return &ChannelBase[any]{
		Mutexes: mu,
		Name:    name,
		Channel: make(chan T, buffers),
		Type:    reflect.TypeFor[T](),
		Buffers: buffers,
	}
}

func (cb *ChannelBase[T]) GetName() string {
	cb.MuRLock()
	defer cb.MuRUnlock()
	return cb.Name
}
func (cb *ChannelBase[T]) GetChannel() (any, reflect.Type) {
	cb.MuRLock()
	defer cb.MuRUnlock()
	return cb.Channel, reflect.TypeOf(cb.Channel)
}
func (cb *ChannelBase[T]) GetType() reflect.Type {
	cb.MuRLock()
	defer cb.MuRUnlock()
	return cb.Type
}
func (cb *ChannelBase[T]) GetBuffers() int {
	cb.MuRLock()
	defer cb.MuRUnlock()
	return cb.Buffers
}
func (cb *ChannelBase[T]) SetName(name string) string {
	cb.MuLock()
	defer cb.MuUnlock()
	cb.Name = name
	return cb.Name
}
func (cb *ChannelBase[T]) SetChannel(typE reflect.Type, bufferSize int) any {
	cb.MuLock()
	defer cb.MuUnlock()
	cb.Channel = reflect.MakeChan(typE, bufferSize)
	return cb.Channel
}
func (cb *ChannelBase[T]) SetBuffers(buffers int) int {
	cb.MuLock()
	defer cb.MuUnlock()
	cb.Buffers = buffers
	cb.Channel = make(chan T, buffers)
	return cb.Buffers
}
func (cb *ChannelBase[T]) Close() error {
	cb.MuLock()
	defer cb.MuUnlock()
	if cb.Channel != nil {
		gl.LogObjLogger(cb, "info", "Closing channel for:", cb.Name)
		close(cb.Channel.(chan T))
	}
	return nil
}
func (cb *ChannelBase[T]) Clear() error {
	cb.MuLock()
	defer cb.MuUnlock()
	if cb.Channel != nil {
		gl.LogObjLogger(cb, "info", "Clearing channel for:", cb.Name)
		close(cb.Channel.(chan T))
		cb.Channel = make(chan T, cb.Buffers)
	}
	return nil
}

type ChannelCtl[T any] struct {
	// IChannelCtl is the interface for this Channel instance.
	//ci.IChannelCtl[T] // Channel interface for this Channel instance

	// Logger is the Logger instance for this Channel instance.
	Logger l.Logger // Logger for this Channel instance

	// IMutexes is the interface for the mutexes in this Channel instance.
	*Mutexes // Mutexes for this Channel instance

	// property is the property for the channel.
	property ci.IProperty[T] // Lazy load, only used when needed or created by NewChannelCtlWithProperty constructor

	// Shared is a shared data used for many purposes like sync.Cond, Telemetry, Monitor, etc.
	Shared interface{} // Shared data for many purposes

	withMetrics bool // If true, will create the telemetry and monitor channels

	// ch is a channel for the value.
	ch chan T // The channel for the value. Main channel for this struct.

	// Reference is the reference ID and name.
	*Reference `json:"reference" yaml:"reference" xml:"reference" gorm:"reference"`

	// buffers is the number of buffers for the channel.
	Buffers int `json:"buffers" yaml:"buffers" xml:"buffers" gorm:"buffers"`

	Channels map[string]any `json:"channels,omitempty" yaml:"channels,omitempty" xml:"channels,omitempty" gorm:"channels,omitempty"`
}

// NewChannelCtl creates a new ChannelCtl instance with the provided name.
func NewChannelCtl[T any](name string, logger l.Logger) ci.IChannelCtl[T] {
	if logger == nil {
		logger = l.GetLogger("GoLife")
	}
	ref := NewReference(name)
	mu := NewMutexesType()

	// Create a new ChannelCtl instance
	channelCtl := &ChannelCtl[T]{
		Logger:    logger,
		Reference: ref.GetReference(),
		Mutexes:   mu,
		ch:        make(chan T, lgBuf),
		Channels:  make(map[string]any),
	}
	channelCtl.Channels = getDefaultChannelsMap(false, logger)
	return channelCtl
}

// NewChannelCtlWithProperty creates a new ChannelCtl instance with the provided name and type.
func NewChannelCtlWithProperty[T any, P ci.IProperty[T]](name string, buffers *int, property P, withMetrics bool, logger l.Logger) ci.IChannelCtl[T] {
	if logger == nil {
		logger = l.GetLogger("GoLife")
	}
	ref := NewReference(name)
	mu := NewMutexesType()
	buf := 3
	if buffers != nil {
		buf = *buffers
	}
	channelCtl := &ChannelCtl[T]{
		Logger:    logger,
		Reference: ref.GetReference(),
		Mutexes:   mu,
		ch:        make(chan T, buf),
		Channels:  make(map[string]any),
		property:  property,
	}
	channelCtl.Channels = getDefaultChannelsMap(withMetrics, logger)

	return channelCtl
}

func (cCtl *ChannelCtl[T]) GetID() uuid.UUID {
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.ID
}
func (cCtl *ChannelCtl[T]) GetName() string {
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.Name
}
func (cCtl *ChannelCtl[T]) SetName(name string) string {
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.Name = name
	return cCtl.Name
}
func (cCtl *ChannelCtl[T]) GetProperty() ci.IProperty[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.property
}
func (cCtl *ChannelCtl[T]) GetSubChannels() map[string]interface{} {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.Channels
}
func (cCtl *ChannelCtl[T]) SetSubChannels(channels map[string]interface{}) map[string]interface{} {
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	for k, v := range channels {
		if _, ok := cCtl.Channels[k]; ok {
			cCtl.Channels[k] = v
		} else {
			cCtl.Channels[k] = v
		}
	}
	return cCtl.Channels
}
func (cCtl *ChannelCtl[T]) GetSubChannelByName(name string) (any, reflect.Type, bool) {
	if cCtl.Channels == nil {
		gl.LogObjLogger(cCtl, "info", "Creating channels map for:", cCtl.Name, "ID:", cCtl.ID.String())
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	if rawChannel, ok := cCtl.Channels[name]; ok {
		if channel, ok := rawChannel.(ci.IChannelBase[T]); ok {
			return channel, channel.GetType(), true
		} else {
			gl.LogObjLogger(cCtl, "error", fmt.Sprintf("Channel %s is not a valid channel type. Expected: %s, receive %s", name, reflect.TypeFor[ci.IChannelBase[T]]().String(), reflect.TypeOf(rawChannel)))
			return nil, nil, false
		}
	}
	gl.LogObjLogger(cCtl, "error", "Channel not found:", name, "ID:", cCtl.ID.String())
	return nil, nil, false
}
func (cCtl *ChannelCtl[T]) SetSubChannelByName(name string, channel any) (any, error) {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	if _, ok := cCtl.Channels[name]; ok {
		cCtl.Channels[name] = channel
	} else {
		cCtl.Channels[name] = channel
	}
	return channel, nil
}
func (cCtl *ChannelCtl[T]) GetSubChannelTypeByName(name string) (reflect.Type, bool) {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	if channel, ok := cCtl.Channels[name]; ok {
		return channel.(ci.IChannelBase[any]).GetType(), true
	}
	return nil, false
}
func (cCtl *ChannelCtl[T]) GetSubChannelBuffersByName(name string) (int, bool) {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	if channel, ok := cCtl.Channels[name]; ok {
		return channel.(ci.IChannelBase[any]).GetBuffers(), true
	}
	return 0, false
}
func (cCtl *ChannelCtl[T]) SetSubChannelBuffersByName(name string, buffers int) (int, error) {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	if channel, ok := cCtl.Channels[name]; ok {
		channel.(ci.IChannelBase[any]).SetBuffers(buffers)
		return buffers, nil
	}
	return 0, nil
}
func (cCtl *ChannelCtl[T]) GetMainChannel() any {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.ch
}
func (cCtl *ChannelCtl[T]) SetMainChannel(channel chan T) chan T {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.ch = channel
	return cCtl.ch
}
func (cCtl *ChannelCtl[T]) GetMainChannelType() reflect.Type {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return reflect.TypeOf(cCtl.ch)
}
func (cCtl *ChannelCtl[T]) GetHasMetrics() bool {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.withMetrics
}
func (cCtl *ChannelCtl[T]) SetHasMetrics(hasMetrics bool) bool {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.withMetrics = hasMetrics
	return cCtl.withMetrics
}
func (cCtl *ChannelCtl[T]) GetBufferSize() int {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.Buffers
}
func (cCtl *ChannelCtl[T]) SetBufferSize(size int) int {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.Buffers = size
	return cCtl.Buffers
}
func (cCtl *ChannelCtl[T]) Close() error {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	if cCtl.Channels != nil {
		for _, channel := range cCtl.Channels {
			if ch, ok := channel.(ci.IChannelBase[any]); ok {
				_ = ch.Close()
			}
		}
	}
	return nil
}
func (cCtl *ChannelCtl[T]) WithProperty(property ci.IProperty[T]) ci.IChannelCtl[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.property = property
	return cCtl
}
func (cCtl *ChannelCtl[T]) WithChannel(channel chan T) ci.IChannelCtl[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.ch = channel
	return cCtl
}
func (cCtl *ChannelCtl[T]) WithBufferSize(size int) ci.IChannelCtl[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.Buffers = size
	return cCtl
}
func (cCtl *ChannelCtl[T]) WithMetrics(metrics bool) ci.IChannelCtl[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.withMetrics = metrics
	return cCtl
}

func initChannelsMap[T any](v *ChannelCtl[T]) map[string]interface{} {
	if v.Channels == nil {
		v.MuLock()
		defer v.MuUnlock()
		gl.LogObjLogger(v, "info", "Creating channels map for:", v.Name, "ID:", v.ID.String())
		v.Channels = make(map[string]interface{})
		// done is a channel for the done signal.
		v.Channels["done"] = NewChannelBase[bool]("done", smBuf, v.Logger)
		// ctl is a channel for the internal control channel.
		v.Channels["ctl"] = NewChannelBase[string]("ctl", mdBuf, v.Logger)
		// condition is a channel for the condition signal.
		v.Channels["condition"] = NewChannelBase[string]("cond", smBuf, v.Logger)

		if v.withMetrics {
			v.Channels["telemetry"] = NewChannelBase[string]("telemetry", mdBuf, v.Logger)
			v.Channels["monitor"] = NewChannelBase[string]("monitor", mdBuf, v.Logger)
		}
	}
	return v.Channels
}
func getDefaultChannelsMap(withMetrics bool, logger l.Logger) map[string]any {
	mp := map[string]any{
		// done is a channel for the done signal.
		"done": NewChannelBase[bool]("done", smBuf, logger),
		// ctl is a channel for the internal control channel.
		"ctl": NewChannelBase[string]("ctl", mdBuf, logger),
		// condition is a channel for the condition signal.
		"condition": NewChannelBase[string]("cond", smBuf, logger),
	}

	if withMetrics {
		// metrics is a channel for the telemetry signal.
		mp["metrics"] = NewChannelBase[string]("metrics", mdBuf, logger)
		// monitor is a channel for monitoring the channel.
		mp["monitor"] = NewChannelBase[string]("monitor", mdBuf, logger)
	}

	return mp
}

/// internal/types/contact_form.go ///
package types

type ContactForm struct {
	Token   string `json:"token"`
	Name    string `json:"name"`
	Email   string `json:"email"`
	Message string `json:"message"`
	*Mapper[ContactForm]
}

/// internal/types/environment.go ///
package types

import (
	"encoding/base64"
	"reflect"

	l "github.com/rafa-mori/logz"
	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	crp "github.com/rafa-mori/gdbase/internal/security/crypto"
	sci "github.com/rafa-mori/gdbase/internal/security/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"

	"context"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"strings"
	"sync"
	"syscall"
	"time"
)

type EnvCache struct {
	m map[string]string
}

func NewEnvCache() *EnvCache {
	return &EnvCache{
		m: make(map[string]string),
	}
}

type Environment struct {
	isConfidential bool

	Logger l.Logger

	*Reference

	*EnvCache

	*Mutexes

	cpuCount int
	memTotal int
	hostname string
	os       string
	kernel   string
	envFile  string

	// For lazy loading if needed
	properties map[string]any

	mapper ci.IMapper[map[string]string]
}

func newEnvironment(envFile string, isConfidential bool, logger l.Logger) (*Environment, error) {
	if logger == nil {
		logger = l.GetLogger("Environment")
	}
	if envFile == "" {
		envFile = ".env"
		if _, err := os.Stat(envFile); os.IsNotExist(err) {
			if createErr := os.WriteFile(envFile, []byte(""), 0644); createErr != nil {
				gl.Log("error", fmt.Sprintf("Error creating env file: %s", createErr.Error()))
				return nil, fmt.Errorf("error creating env file: %s", createErr.Error())
			}
		}
	} else {
		if _, err := os.Stat(envFile); os.IsNotExist(err) {
			gl.Log("error", fmt.Sprintf("Error checking env file: %s", err.Error()))
			//return nil, fmt.Errorf("error checking env file: %s", err.Error())
			if createErr := os.WriteFile(envFile, []byte(""), 0644); createErr != nil {
				gl.Log("error", fmt.Sprintf("Error creating env file: %s", createErr.Error()))
				return nil, fmt.Errorf("error creating env file: %s", createErr.Error())
			}
		}
	}

	gl.Log("notice", "Creating new Environment instance")
	cpuCount := runtime.NumCPU()
	memTotal := syscall.Sysinfo_t{}.Totalram
	hostname, hostnameErr := os.Hostname()
	if hostnameErr != nil {
		gl.Log("error", fmt.Sprintf("Error getting hostname: %s", hostnameErr.Error()))
		return nil, fmt.Errorf("error getting hostname: %s", hostnameErr.Error())
	}
	oos := runtime.GOOS
	kernel := runtime.GOARCH
	name := filepath.Base(envFile)
	name = strings.TrimSuffix(name, filepath.Ext(name))
	if name == "" {
		name = "default"
	}
	name = strings.Join(filepath.SplitList(name), "_")

	env := &Environment{
		isConfidential: isConfidential,
		Logger:         logger,
		Reference:      NewReference(name).GetReference(),
		Mutexes:        NewMutexesType(),
		cpuCount:       cpuCount,
		memTotal:       int(memTotal),
		hostname:       hostname,
		os:             oos,
		kernel:         kernel,
		envFile:        envFile,
	}

	env.EnvCache = NewEnvCache()
	env.EnvCache.m = make(map[string]string)

	envs := os.Environ()
	for _, ev := range envs {
		parts := strings.SplitN(ev, "=", 2)
		if len(parts) != 2 {
			continue
		}
		key := strings.TrimSpace(parts[0])
		value := strings.TrimSpace(parts[1])
		env.EnvCache.m[key] = value
	}
	env.EnvCache.m["ENV_FILE"] = envFile
	env.EnvCache.m["ENV_CONFIDENTIAL"] = fmt.Sprintf("%t", isConfidential)
	env.EnvCache.m["ENV_HOSTNAME"] = env.Hostname()
	env.EnvCache.m["ENV_OS"] = env.Os()
	env.EnvCache.m["ENV_KERNEL"] = env.Kernel()
	env.EnvCache.m["ENV_CPU_COUNT"] = fmt.Sprintf("%d", env.CpuCount())
	env.EnvCache.m["ENV_MEM_TOTAL"] = fmt.Sprintf("%d", env.MemTotal())
	env.EnvCache.m["ENV_MEM_AVAILABLE"] = fmt.Sprintf("%d", env.MemAvailable())
	env.EnvCache.m["ENV_MEM_USED"] = fmt.Sprintf("%d", env.MemTotal()-env.MemAvailable())

	env.mapper = NewMapperTypeWithObject(&env.EnvCache.m, env.envFile)
	_, err := env.mapper.DeserializeFromFile("env")
	if err != nil {
		return nil, fmt.Errorf("error loading file: %s", err.Error())
	}

	return env, nil
}
func NewEnvironment(envFile string, isConfidential bool, logger l.Logger) (ci.IEnvironment, error) {
	return newEnvironment(envFile, isConfidential, logger)
}
func NewEnvironmentType(envFile string, isConfidential bool, logger l.Logger) (*Environment, error) {
	return newEnvironment(envFile, isConfidential, logger)
}

func (e *Environment) Mu() ci.IMutexes {
	if e.Mutexes == nil {
		e.Mutexes = NewMutexesType()
	}
	return e.Mutexes
}
func (e *Environment) CpuCount() int {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.cpuCount == 0 {
		e.cpuCount = runtime.NumCPU()
	}
	return e.cpuCount
}
func (e *Environment) MemTotal() int {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.memTotal == 0 {
		var mem syscall.Sysinfo_t
		err := syscall.Sysinfo(&mem)
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting memory info: %s", err.Error()))
			return 0
		}
		totalRAM := mem.Totalram * uint64(mem.Unit) / (1024 * 1024)
		e.memTotal = int(totalRAM)
	}
	return e.memTotal
}
func (e *Environment) Hostname() string {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.hostname == "" {
		hostname, err := os.Hostname()
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting hostname: %s", err.Error()))
			return ""
		}
		e.hostname = hostname
	}
	return e.hostname
}
func (e *Environment) Os() string {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.os == "" {
		e.os = runtime.GOOS
	}
	return e.os
}
func (e *Environment) Kernel() string {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.kernel == "" {
		e.kernel = runtime.GOARCH
	}
	return e.kernel
}
func (e *Environment) Getenv(key string) string {
	if val, exists := e.EnvCache.m[key]; exists {
		if val == "" {
			gl.Log("info", fmt.Sprintf("'%s' found in cache, but value is empty", key))
			return ""
		}
		isEncryptedValue := e.IsEncryptedValue(val)
		if isEncryptedValue {
			gl.Log("debug", fmt.Sprintf("'%s' found in cache, value is encrypted", key))
			decryptedVal, err := e.DecryptEnv(val)
			if err != nil {
				gl.Log("error", fmt.Sprintf("Error decrypting value for key '%s': %v", key, err))
				gl.Log("error", fmt.Sprintf("Value for key %s: %s", key, val))
				return ""
			}
			gl.Log("debug", fmt.Sprintf("Decrypted value for key '%s': %s", key, decryptedVal))
			return decryptedVal
		}
		if err := e.Setenv(key, val); err != nil {
			gl.Log("error", fmt.Sprintf("Error setting environment variable '%s': %v", key, err))
			return ""
		}
		return val
	}
	gl.Log("debug", fmt.Sprintf("'%s' not found in cache, checking system env...", key))
	return os.Getenv(key)
}
func (e *Environment) Setenv(key, value string) error {
	if e.EnvCache.m == nil {
		e.EnvCache.m = make(map[string]string)
	}
	isEncrypted := e.IsEncryptedValue(value)
	if e.isConfidential {
		if isEncrypted {
			e.EnvCache.m[key] = value
		} else {
			encryptedValue, err := e.EncryptEnv(value)
			if err != nil {
				gl.Log("error", fmt.Sprintf("Error encrypting value for key '%s': %v", key, err))
				return err
			}
			e.EnvCache.m[key] = encryptedValue
		}
	} else {
		if isEncrypted {
			decryptedValue, err := e.DecryptEnv(value)
			if err != nil {
				gl.Log("error", fmt.Sprintf("Error decrypting value for key '%s': %v", key, err))
			} else if decryptedValue != "" {
				e.EnvCache.m[key] = decryptedValue
			}
		}
		e.EnvCache.m[key] = value
	}

	gl.Log("debug", fmt.Sprintf("Key '%s' value: %s", key, value))

	return os.Setenv(key, value)
}
func (e *Environment) GetEnvCache() map[string]string {
	if e.EnvCache.m == nil {
		gl.Log("debug", "EnvCache is nil, initializing...")
		e.EnvCache.m = make(map[string]string)
	}

	return e.EnvCache.m
}
func (e *Environment) ParseEnvVar(s string) (string, string) {
	name, length := e.GetShellName(s)
	if length == 0 {
		return "", ""
	}
	value := os.Getenv(name)
	return name, value
}
func (e *Environment) LoadEnvFromShell() error {
	cmd := exec.Command("bash", "-c", "env")
	output, err := cmd.Output()
	if err != nil {
		return fmt.Errorf("erro ao carregar env via shell: %v", err)
	}

	lines := strings.Split(string(output), "\n")
	for _, line := range lines {
		parts := strings.SplitN(line, "=", 2)
		if len(parts) != 2 {
			continue
		}
		e.EnvCache.m[parts[0]] = parts[1]
		if setEnvErr := os.Setenv(parts[0], parts[1]); setEnvErr != nil {
			return setEnvErr
		}
	}

	gl.Log("debug", "Environment variables loaded from shell")
	return nil
}
func (e *Environment) MemAvailable() int {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	var mem syscall.Sysinfo_t
	if err := syscall.Sysinfo(&mem); err != nil {
		gl.Log("error", fmt.Sprintf("Erro ao obter RAM dispon√≠vel: %v", err))
		return -1
	}
	return int(mem.Freeram * uint64(mem.Unit) / (1024 * 1024))
}
func (e *Environment) GetShellName(s string) (string, int) {
	switch {
	case s[0] == '{':
		if len(s) > 2 && IsShellSpecialVar(s[1]) && s[2] == '}' {
			return s[1:2], 3
		}
		for i := 1; i < len(s); i++ {
			if s[i] == '}' {
				if i == 1 {
					return "", 2
				}
				return s[1:i], i + 1
			}
		}
		return "", 1
	case IsShellSpecialVar(s[0]):
		return s[0:1], 1
	}
	var i int
	for i = 0; i < len(s) && IsAlphaNum(s[i]); i++ {
	}
	return s[:i], i
}
func (e *Environment) GetEnvFilePath() string { return e.envFile }
func (e *Environment) BackupEnvFile() error {
	backupFile := e.envFile + ".backup"
	if _, err := os.Stat(backupFile); err == nil {
		return nil
	}

	return asyncCopyFile(e.envFile, backupFile)
}
func (e *Environment) EncryptEnvFile() error {
	if !e.isConfidential {
		gl.Log("debug", "Environment is not confidential, skipping encryption")
		return nil
	}
	isEncrypted := e.IsEncrypted(e.envFile)
	if isEncrypted {
		return nil
	}

	if err := e.BackupEnvFile(); err != nil {
		return err
	}

	data, err := os.ReadFile(e.envFile)
	if err != nil {
		return err
	}

	encryptedData, err := e.EncryptEnv(string(data))
	if err != nil {
		return err
	}

	return os.WriteFile(e.envFile, []byte(encryptedData), 0644)
}
func (e *Environment) DecryptEnvFile() (string, error) {
	isEncrypted := e.IsEncrypted(e.envFile)
	if !isEncrypted {
		gl.Log("debug", "Env file is not encrypted, skipping decryption")
		return "", nil
	}

	data, err := os.ReadFile(e.envFile)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error reading env file: %v", err))
		return "", err
	}
	if len(data) == 0 {
		gl.Log("error", "Env file is empty")
		return "", fmt.Errorf("env file is empty")
	}

	return e.DecryptEnv(string(data))
}
func (e *Environment) EncryptEnv(value string) (string, error) {
	if !e.isConfidential || e.IsEncryptedValue(value) {
		return value, nil
	}

	cryptoService, key, err := getKey(e)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error getting key: %v", err))
		return "", err
	}
	if cryptoService == nil {
		gl.Log("error", "CryptoService is nil")
		return "", fmt.Errorf("cryptoService is nil")
	}

	encrypt, _, err := cryptoService.Encrypt([]byte(value), key)
	if err != nil {
		return "", err
	}

	encoded := base64.URLEncoding.EncodeToString([]byte(encrypt))
	if len(encoded) == 0 {
		gl.Log("error", "Failed to encode the encrypted value")
		return "", fmt.Errorf("failed to encode the encrypted value")
	}

	return encoded, nil
}
func (e *Environment) DecryptEnv(encryptedValue string) (string, error) {
	if !e.isConfidential {
		if !e.IsEncryptedValue(encryptedValue) {
			return encryptedValue, nil
		}
	} else {
		if !e.IsEncryptedValue(encryptedValue) {
			gl.Log("debug", "Value is not encrypted")
			return encryptedValue, nil
		}
	}

	encryptedBytes, err := base64.URLEncoding.DecodeString(encryptedValue)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error decoding base64 string: %v", err))
		return "", err
	}

	cryptoService, key, err := getKey(e)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error getting key: %v", err))
		return "", err
	}
	if cryptoService == nil {
		gl.Log("error", "CryptoService is nil")
		return "", fmt.Errorf("cryptoService is nil")
	}

	decrypted, _, err := cryptoService.Decrypt(encryptedBytes, key)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error decrypting value: %v", err))
		return "", err
	}

	return string(decrypted), nil
}
func (e *Environment) IsEncrypted(envFile string) bool {
	if _, err := os.Stat(envFile); os.IsNotExist(err) {
		gl.Log("error", fmt.Sprintf("Arquivo n√£o encontrado: %v", err))
		return false
	}
	cryptoService, _, err := getKey(e)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error getting key: %v", err))
		return false
	}
	if cryptoService == nil {
		gl.Log("error", "CryptoService is nil")
		return false
	}
	data, err := os.ReadFile(envFile)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error reading file: %v", err))
		return false
	}
	if len(data) == 0 {
		gl.Log("error", "File is empty")
		return false
	}
	return cryptoService.IsEncrypted(data)
}
func (e *Environment) IsEncryptedValue(value string) bool {
	if arrB, arrBErr := base64.URLEncoding.DecodeString(value); arrBErr != nil || len(arrB) == 0 {
		return false
	} else {
		return len(arrB) > 0 && arrB[0] == 0x00
	}
}
func (e *Environment) EnableEnvFileEncryption() error {
	if e.isConfidential {
		gl.Log("debug", "Environment is already confidential, skipping encryption")
		return nil
	}

	e.isConfidential = true

	if err := e.EncryptEnvFile(); err != nil {
		return err
	}

	return nil
}
func (e *Environment) DisableEnvFileEncryption() error {
	if !e.isConfidential {
		gl.Log("debug", "Environment is not confidential, skipping decryption")
		return nil
	}

	e.isConfidential = false

	if err := e.EncryptEnvFile(); err != nil {
		return err
	}

	return nil
}
func (e *Environment) LoadEnvFile(watchFunc func(ctx context.Context, chanCbArg chan any) <-chan any) error {
	timeout := 10 * time.Second
	chanErr := make(chan error, 3)
	chanDone := make(chan bool, 3)
	chanCb := make(chan any, 10)

	var contextWithCancel context.Context
	var cancel context.CancelFunc
	if watchFunc != nil {
		gl.Log("debug", "Callback function provided, executing...")
		contextWithCancel, cancel = context.WithTimeout(context.Background(), timeout)
		watchFunc(contextWithCancel, chanCb)
	} else {
		gl.Log("debug", "No callback function provided")
		contextWithCancel, cancel = context.WithTimeout(context.Background(), timeout)
	}

	go func(cancel context.CancelFunc, chanErr chan error, chanDone chan bool) {
		defer func(chanErr chan error, chanDone chan bool, chanCb chan any) {
			cancel()
			close(chanErr)
			close(chanDone)
			close(chanCb)
		}(chanErr, chanDone, chanCb)

		gl.Log("debug", "Loading env file...")
		for {
			select {
			case <-contextWithCancel.Done():
				if err := contextWithCancel.Err(); err != nil {
					gl.Log("error", fmt.Sprintf("Error loading env file: %v", err))
					return
				}
				return
			case <-time.After(timeout):
				if chanErr != nil {
					chanErr <- fmt.Errorf("timeout loading env file")
				}
				return
			case <-chanDone:
				gl.Log("debug", "Env file loaded successfully")
				return
			default:
				continue
			}
		}
	}(cancel, chanErr, chanDone)

	// Will add a wait group to wait for the readEnvFile function to finish inside
	// the goroutine, inside the readEnvFile function and wait for the goroutine to finish here.
	go readEnvFile(e, contextWithCancel, e.MuCtxWg)
	e.MuCtxWg.Wait()

	return nil
}

func readEnvFile(e *Environment, ctx context.Context, wg *sync.WaitGroup) {
	if e.GetEnvFilePath() == "" || e.GetEnvFilePath() == ".env" {
		gl.Log("error", "Env file path is empty or default")
		return
	}

	wg.Add(1)
	go func(e *Environment, ctx context.Context, wg *sync.WaitGroup) {
		defer wg.Done()
		defer ctx.Done()

		// Read the env file
		fileData, err := os.ReadFile(e.GetEnvFilePath())
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error reading env file: %v", err))
			ctx.Value(fmt.Errorf("error reading env file: %v", err))
			return
		}
		if len(fileData) == 0 {
			gl.Log("error", "Env file is empty")
			ctx.Value(fmt.Errorf("env file is empty"))
			return
		}
		// Check if the env file is encrypted, if so, decrypt it
		isEncrypted := e.IsEncryptedValue(string(fileData))
		if isEncrypted {
			gl.Log("debug", "Env file is encrypted, decrypting...")
			var decryptedData string
			decryptedData, err = e.DecryptEnv(string(fileData))
			if err != nil {
				gl.Log("debug", fmt.Sprintf("Error decrypting env file: %v", err))
				return
			}
			if len(decryptedData) == 0 {
				gl.Log("error", "Decrypted env file is empty")
				return
			}
			fileData = []byte(decryptedData)
			if len(fileData) == 0 {
				gl.Log("error", "Decrypted env file is empty")
				return
			}
		}
		// Create a temp copy of the env file with Mktemp with decrypted data
		tmpFile, err := os.CreateTemp("", "env_*.tmp")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error creating temp file: %v", err))
			return
		}

		defer func(tmpFile *os.File) {
			gl.Log("debug", "Closing temp file")
			if closeErr := tmpFile.Close(); closeErr != nil {
				gl.Log("error", fmt.Sprintf("Error closing temp file: %v", closeErr.Error()))
				return
			}
			gl.Log("debug", "Removing temp file")
			if err := os.Remove(tmpFile.Name()); err != nil {
				gl.Log("error", fmt.Sprintf("Error removing temp file: %v", err))
			}
			return
		}(tmpFile)

		if _, err := tmpFile.Write(fileData); err != nil {
			gl.Log("error", fmt.Sprintf("Error writing to temp file: %v", err))
			return
		}

		var ext any
		existing := make(map[string]string)
		mapper := NewMapperTypeWithObject(&existing, tmpFile.Name())
		extT, existingErr := mapper.DeserializeFromFile("env")
		if existingErr != nil {
			gl.Log("error", fmt.Sprintf("Error deserializing env file: %v", existingErr))
			return
		}
		if extT == nil {
			gl.Log("error", "Error loading file: nil value")
		} else {
			ext = reflect.ValueOf(extT).Elem().Interface()
		}
		if oldMap, ok := ext.(map[string]string); ok {
			for key, value := range oldMap {
				gl.Log("debug", fmt.Sprintf("Key '%s' value: %s", key, value))
				if setEnvErr := e.Setenv(key, value); setEnvErr != nil {
					gl.Log("error", fmt.Sprintf("Erro ao definir vari√°vel de ambiente '%s': %v", key, setEnvErr))
					continue
				}
			}
			e.EnvCache.m = oldMap
			if err := os.Remove(tmpFile.Name()); err != nil {
				gl.Log("error", fmt.Sprintf("Error removing temp file: %v", err))
				return
			}
			gl.Log("debug", "Temp file removed successfully")
			gl.Log("debug", "Env file read successfully")
			return
		} else {
			gl.Log("error", "Error casting to map[string]string")
			return
		}
	}(e, ctx, wg)

	gl.Log("success", "Env file read successfully")
}
func getKey(e *Environment) (sci.ICryptoService, []byte, error) {
	if e.properties["cryptoService"] == nil {
		cryptoService := crp.NewCryptoService()
		if cryptoService == nil {
			gl.Log("error", "Failed to create crypto service")
			return nil, nil, fmt.Errorf("failed to create crypto service")
		}
		if e.properties == nil {
			e.properties = make(map[string]any)
		}
		e.properties["cryptoService"] = NewProperty("cryptoService", &cryptoService, false, nil)
		if e.properties["cryptoService"] == nil {
			return nil, nil, fmt.Errorf("failed to get crypto service")
		}
	}
	cryptoServiceProperty, ok := e.properties["cryptoService"].(ci.IProperty[sci.ICryptoService])
	if !ok {
		gl.Log("error", "Failed to cast crypto service")
		return nil, nil, fmt.Errorf("failed to cast crypto service")
	}
	cryptoService := cryptoServiceProperty.GetValue()
	if e.properties["key"] == nil {
		key, err := cryptoService.GenerateKey()
		if err != nil {
			return nil, nil, fmt.Errorf("failed to generate key: %v", err)
		}
		e.properties["key"] = NewProperty[[]byte]("key", &key, false, nil)
		if e.properties["key"] == nil {
			return nil, nil, fmt.Errorf("failed to get key")
		}
	}
	key := e.properties["key"].(*Property[[]byte]).GetValue()
	if key == nil {
		gl.Log("error", "Key is nil")
		return nil, nil, fmt.Errorf("key is nil")
	}
	return cryptoService, key, nil
}

/// internal/types/mapper.go ///
package types

import (
	"bufio"
	"encoding/asn1"
	"encoding/json"
	"encoding/xml"
	"fmt"
	"os"
	"reflect"
	"strings"

	"github.com/pelletier/go-toml/v2"
	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"
	"github.com/subosito/gotenv"
	"gopkg.in/yaml.v3"
)

// Mapper is a generic struct that implements the IMapper interface for serializing and deserializing objects.
type Mapper[T any] struct {
	filePath string
	object   T
}

// NewMapperTypeWithObject creates a new instance of Mapper.
func NewMapperTypeWithObject[T any](object *T, filePath string) *Mapper[T] {
	return &Mapper[T]{filePath: filePath, object: *object}
}

// NewMapperType creates a new instance of Mapper.
func NewMapperType[T any](object *T, filePath string) *Mapper[T] {
	return &Mapper[T]{filePath: filePath, object: *object}
}

// NewMapperPtr creates a new instance of Mapper.
func NewMapperPtr[T any](object *T, filePath string) *Mapper[*T] {
	return &Mapper[*T]{filePath: filePath, object: object}
}

// NewMapper creates a new instance of Mapper.
func NewMapper[T any](object *T, filePath string) ci.IMapper[T] {
	return NewMapperType[T](object, filePath)
}

// Serialize converts an object of type T to a byte array in the specified format.
func (m *Mapper[T]) Serialize(format string) ([]byte, error) {
	switch format {
	case "json":
		return json.Marshal(m.object)
	case "yaml":
		return yaml.Marshal(m.object)
	case "xml":
		return xml.Marshal(m.object)
	case "toml":
		return toml.Marshal(m.object)
	case "asn":
		return asn1.Marshal(m.object)
	case "env":
		if env, ok := reflect.ValueOf(m.object).Interface().(map[string]string); ok {
			if strM, strMErr := gotenv.Marshal(env); strMErr != nil {
				return nil, fmt.Errorf("erro ao serializar para env: %v", strMErr)
			} else {
				return []byte(strM), nil
			}
		} else {
			return nil, fmt.Errorf("tipo n√£o suportado para env: %T", m.object)
		}
	default:
		return nil, fmt.Errorf("formato n√£o suportado: %s", format)
	}
}

// Deserialize converts a byte array in the specified format to an object of type T.
func (m *Mapper[T]) Deserialize(data []byte, format string) (*T, error) {
	if len(data) == 0 {
		return nil, fmt.Errorf("os dados est√£o vazios")
	}
	if !reflect.ValueOf(m.object).IsValid() || reflect.ValueOf(m.object).IsNil() {
		m.object = reflect.New(reflect.TypeFor[T]()).Interface().(T)
	}
	var err error
	switch format {
	case "json", "js":
		err = json.Unmarshal(data, m.object)
	case "yaml", "yml":
		err = yaml.Unmarshal(data, m.object)
	case "xml", "html":
		err = xml.Unmarshal(data, m.object)
	case "toml", "tml":
		err = toml.Unmarshal(data, m.object)
	case "asn", "asn1":
		_, err = asn1.Unmarshal(data, m.object)
	case "env", "envs", ".env", "environment":
		value := reflect.ValueOf(m.object)
		envT, ok := value.Interface().(*map[string]string)
		if !ok {
			envTB, ok := value.Interface().(map[string]string)
			if !ok {
				gl.Log("error", fmt.Sprintf("Type not valid for env: %T", m.object))
				return nil, fmt.Errorf("envT n√£o √© v√°lido")
			} else {
				envT = &envTB
			}
		}
		if envT != nil {
			if !reflect.ValueOf(envT).IsValid() {
				gl.Log("error", fmt.Sprintf("Type not valid for env: %T", m.object))
				return nil, fmt.Errorf("envT n√£o √© v√°lido")
			}
			env := *envT
			if strM, strMErr := gotenv.Unmarshal(string(data)); strMErr != nil {
				return nil, fmt.Errorf("erro ao desserializar de env: %v", strMErr)
			} else {
				for k, v := range strM {
					env[k] = v
				}
			}
		} else {
			// We not set err to nil, also we not set err to another value here.
			// This is a special case where we want to return nil, to allow the caller to
			// know that the object is really nil.
			gl.Log("error", fmt.Sprintf("Nil type for env: %T", m.object))
		}
	default:
		err = fmt.Errorf("formato n√£o suportado: %s", format)
	}
	if err != nil {
		return nil, fmt.Errorf("erro ao desserializar os dados: %v", err)
	}
	return &m.object, nil
}

// SerializeToFile serializes an object of type T to a file in the specified format.
func (m *Mapper[T]) SerializeToFile(format string) {
	if dataSer, dataSerErr := m.Serialize(format); dataSerErr != nil {
		gl.Log("error", fmt.Sprintf("Error serializing object: %v", dataSerErr.Error()))
		return
	} else {
		gl.Log("debug", fmt.Sprintf("Serialized object: %s", string(dataSer)))
		orf, orfErr := os.OpenFile(m.filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
		if orfErr != nil {
			gl.Log("error", fmt.Sprintf("Error opening file: %v", orfErr.Error()))
			return
		}
		defer func() {
			if err := orf.Close(); err != nil {
				gl.Log("error", fmt.Sprintf("Error closing file: %v", err.Error()))
				return
			}
		}()
		if _, err := orf.WriteString(fmt.Sprintf("%s\n", string(dataSer))); err != nil {
			gl.Log("error", fmt.Sprintf("Error writing to file: %v", err.Error()))
			return
		}
	}
}

// DeserializeFromFile deserializes an object of type T from a file in the specified format.
func (m *Mapper[T]) DeserializeFromFile(format string) (*T, error) {
	if _, err := os.Stat(m.filePath); os.IsNotExist(err) {
		gl.Log("error", fmt.Sprintf("File does not exist: %v", err.Error()))
		return nil, err
	}

	inputFile, err := os.Open(m.filePath)
	if err != nil {
		gl.Log("error", "Error opening file: %v", err.Error())
		return nil, err
	}

	defer func(inputFile *os.File) {
		gl.Log("debug", "Closing input file")
		if closeErr := inputFile.Close(); closeErr != nil {
			gl.Log("error", fmt.Sprintf("Error closing file: %v", closeErr.Error()))
			return
		}
		return
	}(inputFile)

	reader := bufio.NewReader(inputFile)
	scanner := bufio.NewScanner(reader)

	scanner.Split(bufio.ScanLines)
	objSlice := make([]T, 0)

	for scanner.Scan() {
		line := scanner.Text()
		if len(line) == 0 {
			continue
		}

		if desObj, desObjErr := m.Deserialize([]byte(line), format); desObjErr != nil {
			gl.Log("error", fmt.Sprintf("Error deserializing line: %v", desObjErr.Error()))
			return nil, err
		} else {
			gl.Log("debug", fmt.Sprintf("Deserialized line: %s", line))
			gl.Log("debug", fmt.Sprintf("Deserialized object: %v", desObj))
			if err = scanner.Err(); err != nil {
				gl.Log("error", fmt.Sprintf("Error reading file: %v", err.Error()))
				return nil, err
			}
			objSlice = append(objSlice, *desObj)
		}
	}
	if err := scanner.Err(); err != nil {
		gl.Log("error", fmt.Sprintf("Error reading file: %v", err.Error()))
		return nil, err
	}
	gl.Log("debug", "File closed successfully")

	var isSliceOrMap int
	value := reflect.ValueOf(m.object)

	switch reflect.TypeFor[T]().Kind() {
	case reflect.Slice, reflect.SliceOf(reflect.TypeFor[map[string]string]()).Kind():
		if value.Len() == 0 {
			// If the slice is empty, assign the deserialized object to the slice
			m.object = reflect.ValueOf(objSlice).Interface().(T)
			return &m.object, nil
		}
		break
	case reflect.Map:
		if value.Len() == 0 {
			// If the map is empty, assign the deserialized object to the map
			m.object = reflect.ValueOf(objSlice).Interface().(T)
			return &m.object, nil
		}
		isSliceOrMap = 1
		break
	default:
		// If the type is neither a slice nor a map, assign the first object to m.object
		if len(objSlice) == 0 {
			gl.Log("debug", "No objects found in the file")
			return nil, fmt.Errorf("nenhum objeto encontrado no arquivo")
		}
		if len(objSlice) > 1 {
			gl.Log("debug", "Multiple objects found in the file")
			return nil, fmt.Errorf("m√∫ltiplos objetos encontrados no arquivo")
		}
		m.object = objSlice[0]
		break
	}

	for _, obj := range objSlice {
		if isSliceOrMap == 0 {
			if reflect.TypeOf(m.object).Kind() == reflect.Slice {
				m.object = reflect.AppendSlice(reflect.ValueOf(m.object), reflect.ValueOf(obj)).Interface().(T)
			} else {
				// Check if is a pointer
				if reflect.TypeOf(m.object).Kind() != reflect.Ptr {
					m.object = reflect.Append(reflect.ValueOf(m.object), reflect.ValueOf(obj)).Interface().(T)
				} else {
					// Check if is a map
					if reflect.TypeOf(m.object).Kind() == reflect.Map {
						m.object = reflect.Append(reflect.ValueOf(m.object), reflect.ValueOf(obj)).Interface().(T)
					} else {
						m.object = obj
					}
				}
			}
		} else {
			newMap := reflect.ValueOf(obj)
			iter := newMap.MapRange()
			for iter.Next() {
				value.SetMapIndex(iter.Key(), iter.Value())
			}
		}
	}

	m.object = value.Interface().(T)
	gl.Log("debug", fmt.Sprintf("File %s deserialized successfully", m.filePath))
	return &m.object, nil
}

func SanitizeQuotesAndSpaces(input string) string {
	input = strings.TrimSpace(input)
	input = strings.ReplaceAll(input, "'", "\"")
	input = strings.Trim(input, "\"")
	return input
}

func IsEqual(a, b string) bool {
	a, b = SanitizeQuotesAndSpaces(a), SanitizeQuotesAndSpaces(b)
	ptsEqual := levenshtein(a, b)
	maxLen := maxL(len(a), len(b))
	threshold := maxLen / 4
	return ptsEqual <= threshold
}

func maxL(a, b int) int {
	if a > b {
		return a
	}
	return b
}

func levenshtein(s, t string) int {
	m, n := len(s), len(t)
	if m == 0 {
		return n
	}
	if n == 0 {
		return m
	}
	prevRow := make([]int, n+1)
	for j := 0; j <= n; j++ {
		prevRow[j] = j
	}
	for i := 1; i <= m; i++ {
		currRow := make([]int, n+1)
		currRow[0] = i
		for j := 1; j <= n; j++ {
			cost := 1
			if s[i-1] == t[j-1] {
				cost = 0
			}
			currRow[j] = min(prevRow[j]+1, currRow[j-1]+1, prevRow[j-1]+cost)
		}
		prevRow = currRow
	}
	return prevRow[n]
}

/// internal/types/mapper_exporter.go ///
package types

type DataExporter interface {
	ExportFromYAML(filename string) error
	ExportFromJSON(filename string) error
	ExportFromXML(filename string) error
	ExportFromTOML(filename string) error
	ExportFromENV(filename string) error
	ExportFromINI(filename string) error
	ExportFromCSV(filename string) error
	ExportFromProperties(filename string) error
	ExportFromText(filename string) error
	ExportFromASN(filename string) error
	ExportFromBinary(filename string) error
	ExportFromHTML(filename string) error
	ExportFromExcel(filename string) error
	ExportFromPDF(filename string) error
	ExportFromMarkdown(filename string) error
}
type dataExporter struct{}

func NewDataExporter() DataExporter {
	return &dataExporter{}
}

func (e dataExporter) ExportFromYAML(filename string) error {
	// Implementation for exporting to CSV
	return nil
}
func (e dataExporter) ExportFromJSON(filename string) error {
	// Implementation for exporting to YAML
	return nil
}
func (e dataExporter) ExportFromXML(filename string) error {
	// Implementation for exporting to JSON
	return nil
}
func (e dataExporter) ExportFromTOML(filename string) error {
	// Implementation for exporting to XML
	return nil
}
func (e dataExporter) ExportFromENV(filename string) error {
	// Implementation for exporting to Excel
	return nil
}
func (e dataExporter) ExportFromINI(filename string) error {
	// Implementation for exporting to PDF
	return nil
}

func (e dataExporter) ExportFromCSV(filename string) error {
	// Implementation for exporting to Markdown
	return nil
}
func (e dataExporter) ExportFromProperties(filename string) error {
	return nil
}
func (e dataExporter) ExportFromText(filename string) error {
	return nil
}
func (e dataExporter) ExportFromASN(filename string) error {
	return nil
}
func (e dataExporter) ExportFromHTML(filename string) error {
	return nil
}
func (e dataExporter) ExportFromMarkdown(filename string) error {
	return nil
}

func (e dataExporter) ExportFromBinary(filename string) error {
	return nil
}
func (e dataExporter) ExportFromExcel(filename string) error {
	return nil
}
func (e dataExporter) ExportFromPDF(filename string) error {
	return nil
}

/// internal/types/mapper_importer.go ///
package types

type DataImporter interface {
	ImportFromYAML(filename string) error
	ImportFromJSON(filename string) error
	ImportFromXML(filename string) error
	ImportFromTOML(filename string) error
	ImportFromENV(filename string) error
	ImportFromINI(filename string) error
	ImportFromCSV(filename string) error
	ImportFromProperties(filename string) error
	ImportFromText(filename string) error
	ImportFromASN(filename string) error
	ImportFromBinary(filename string) error
	ImportFromHTML(filename string) error
	ImportFromExcel(filename string) error
	ImportFromPDF(filename string) error
	ImportFromMarkdown(filename string) error
}
type dataImporter struct{}

func NewDataImporter() DataImporter { return &dataImporter{} }

func (d dataImporter) ImportFromYAML(filename string) error {
	return nil
}
func (d dataImporter) ImportFromJSON(filename string) error {
	return nil
}
func (d dataImporter) ImportFromXML(filename string) error {
	return nil
}
func (d dataImporter) ImportFromTOML(filename string) error {
	return nil
}
func (d dataImporter) ImportFromENV(filename string) error {
	return nil
}
func (d dataImporter) ImportFromINI(filename string) error {
	return nil
}

func (d dataImporter) ImportFromCSV(filename string) error {
	return nil
}
func (d dataImporter) ImportFromProperties(filename string) error {
	return nil
}
func (d dataImporter) ImportFromText(filename string) error {
	return nil
}
func (d dataImporter) ImportFromASN(filename string) error {
	return nil
}
func (d dataImporter) ImportFromHTML(filename string) error {
	return nil
}
func (d dataImporter) ImportFromMarkdown(filename string) error {
	return nil
}

func (d dataImporter) ImportFromBinary(filename string) error {
	return nil
}
func (d dataImporter) ImportFromExcel(filename string) error {
	return nil
}
func (d dataImporter) ImportFromPDF(filename string) error {
	return nil
}

/// internal/types/money.go ///
package types

import (
	"fmt"
)

// Money represents a monetary value with precision to avoid floating-point rounding issues
type Money struct {
	Amount   int64  `json:"amount"`
	Currency string `json:"currency"`
}

// ZeroMoney represents a zero monetary value
var ZeroMoney = Money{Amount: 0, Currency: "BRL"}

// DefaultCurrency is the default currency used
const DefaultCurrency = "BRL"

// NewMoney creates a Money object from a decimal value
func NewMoney(amountDecimal float64, currency string) Money {
	if currency == "" {
		currency = DefaultCurrency
	}
	amount := int64(amountDecimal * 100)
	return Money{Amount: amount, Currency: currency}
}

// Format formats a Money object for display
func (m Money) Format() string {
	return fmt.Sprintf("%s %.2f", m.Currency, float64(m.Amount)/100)
}

// Add adds two Money values
func (m Money) Add(other Money) (Money, error) {
	if m.Currency != other.Currency {
		return Money{}, fmt.Errorf("currencies do not match: %s vs %s", m.Currency, other.Currency)
	}
	return Money{Amount: m.Amount + other.Amount, Currency: m.Currency}, nil
}

// Subtract subtracts one Money value from another
func (m Money) Subtract(other Money) (Money, error) {
	if m.Currency != other.Currency {
		return Money{}, fmt.Errorf("currencies do not match: %s vs %s", m.Currency, other.Currency)
	}
	return Money{Amount: m.Amount - other.Amount, Currency: m.Currency}, nil
}

// Multiply multiplies a Money value by a factor
func (m Money) Multiply(factor float64) Money {
	return Money{Amount: int64(float64(m.Amount) * factor), Currency: m.Currency}
}

// Divide divides a Money value by a divisor
func (m Money) Divide(divisor float64) (Money, error) {
	if divisor == 0 {
		return Money{}, fmt.Errorf("division by zero")
	}
	return Money{Amount: int64(float64(m.Amount) / divisor), Currency: m.Currency}, nil
}

// Percentage calculates a percentage of a Money value
func (m Money) Percentage(percentage float64) Money {
	return Money{Amount: int64(float64(m.Amount) * percentage / 100), Currency: m.Currency}
}

// Compare compares two Money values
// Returns -1 if m < other, 0 if m == other, 1 if m > other
func (m Money) Compare(other Money) (int, error) {
	if m.Currency != other.Currency {
		return 0, fmt.Errorf("currencies do not match: %s vs %s", m.Currency, other.Currency)
	}
	if m.Amount < other.Amount {
		return -1, nil
	} else if m.Amount > other.Amount {
		return 1, nil
	}
	return 0, nil
}

// IsNegative checks if a Money value is negative
func (m Money) IsNegative() bool {
	return m.Amount < 0
}

// IsZero checks if a Money value is zero
func (m Money) IsZero() bool {
	return m.Amount == 0
}

// Absolute returns the absolute value of a Money object
func (m Money) Absolute() Money {
	if m.Amount < 0 {
		return Money{Amount: -m.Amount, Currency: m.Currency}
	}
	return m
}

/// internal/types/mutexes.go ///
package types

import (
	gl "github.com/rafa-mori/gdbase/logger"

	"sync"
	"time"
)

type IMutexes interface {
	MuLock()
	MuUnlock()
	MuRLock()
	MuRUnlock()
	MuTryLock() bool
	MuTryRLock() bool

	MuWaitCond()
	MuSignalCond()
	MuBroadcastCond()

	GetMuSharedCtx() any
	SetMuSharedCtx(ctx any)
	GetMuSharedCtxValidate() func(any) (bool, error)
	SetMuSharedCtxValidate(validate func(any) (bool, error))
	MuWaitCondWithTimeout(timeout time.Duration) bool

	MuAdd(delta int)
	MuDone()
	MuWait()
}

// muCtx is the mutex context map
type muCtx struct {
	// MuCtxM is a mutex for the ctx map.
	MuCtxM *sync.RWMutex
	// MuCtxL is a mutex for sync.Cond in the ctx map.
	MuCtxL *sync.RWMutex
	// MuCtxCond is a condition variable for the ctx map.
	MuCtxCond *sync.Cond
	// MuCtxWg is a wait group for the ctx map.
	MuCtxWg *sync.WaitGroup
}

// newMuCtx creates a new mutex context map
func newMuCtx(mSharedCtxM *sync.RWMutex) *muCtx {
	mu := &muCtx{
		MuCtxM:    &sync.RWMutex{},
		MuCtxCond: sync.NewCond(mSharedCtxM),
		MuCtxWg:   &sync.WaitGroup{},
	}
	return mu
}

// Mutexes is a struct that holds the mutex context map
type Mutexes struct {
	// muCtx is the mutex context map
	*muCtx

	// MuCtxM is a mutex for the ctx map.
	MuCtxM *sync.RWMutex
	// MuCtxL is a mutex for sync.Cond in the ctx map.
	MuCtxL *sync.RWMutex
	// MuCtxCond is a condition variable for the ctx map.
	MuCtxCond *sync.Cond
	// MuCtxWg is a wait group for the ctx map.
	MuCtxWg *sync.WaitGroup

	// muSharedM is a mutex for the shared context.
	muSharedM *sync.RWMutex
	// muSharedCtx is the shared context for Cond. This is used to synchronize states across multiple goroutines.
	muSharedCtx any
	// muSharedCtxValidate is the shared context validation function. This is used to validate the shared context defining if it needs to wait or not.
	muSharedCtxValidate func(any) (bool, error)
}

// NewMutexesType creates a new mutex context map struct pointer.
func NewMutexesType() *Mutexes {
	mu := &Mutexes{
		MuCtxM:              &sync.RWMutex{},
		MuCtxL:              &sync.RWMutex{},
		MuCtxWg:             &sync.WaitGroup{},
		muSharedM:           &sync.RWMutex{},
		muSharedCtx:         nil,
		muSharedCtxValidate: nil,
	}
	mu.muCtx = newMuCtx(mu.muSharedM)
	mu.MuCtxCond = sync.NewCond(mu.muSharedM)
	return mu
}

// NewMutexes creates a new mutex context map interface.
func NewMutexes() IMutexes { return NewMutexesType() }

// MuLock locks the mutex
func (m *Mutexes) MuLock() { m.MuCtxM.Lock() }

// MuUnlock unlocks the mutex
func (m *Mutexes) MuUnlock() { m.MuCtxM.Unlock() }

// MuRLock locks the mutex for reading
func (m *Mutexes) MuRLock() { m.MuCtxL.RLock() }

// MuRUnlock unlocks the mutex for reading
func (m *Mutexes) MuRUnlock() { m.MuCtxL.RUnlock() }

// GetMuSharedCtx returns the shared context
func (m *Mutexes) GetMuSharedCtx() any {
	m.muSharedM.RLock()
	defer m.muSharedM.RUnlock()

	return m.muSharedCtx
}

// SetMuSharedCtx sets the shared context
func (m *Mutexes) SetMuSharedCtx(ctx any) {
	m.muSharedM.Lock()
	defer m.muSharedM.Unlock()

	m.muSharedCtx = ctx
}

// GetMuSharedCtxValidate returns the shared context validation function
func (m *Mutexes) GetMuSharedCtxValidate() func(any) (bool, error) {
	m.muSharedM.RLock()
	defer m.muSharedM.RUnlock()

	return m.muSharedCtxValidate
}

// SetMuSharedCtxValidate sets the shared context validation function
func (m *Mutexes) SetMuSharedCtxValidate(validate func(any) (bool, error)) {
	m.muSharedM.Lock()
	defer m.muSharedM.Unlock()

	m.muSharedCtxValidate = validate
}

// MuWaitCondWithTimeout waits for the condition variable to be signaled with a timeout
func (m *Mutexes) MuWaitCondWithTimeout(timeout time.Duration) bool {
	timer := time.NewTimer(timeout)
	defer timer.Stop()

	ch := make(chan struct{})
	go func() {
		m.MuCtxCond.Wait()
		close(ch)
	}()

	select {
	case <-ch:
		return true
	case <-timer.C:
		return false
	}
}

// MuWaitCond waits for the condition variable to be signaled
func (m *Mutexes) MuWaitCond() {

	m.MuCtxCond.Wait()
}

// MuSignalCond signals the condition variable
func (m *Mutexes) MuSignalCond() {
	m.muSharedM.Lock()
	defer m.muSharedM.Unlock()

	if m.muSharedCtxValidate != nil {
		isValid, err := m.muSharedCtxValidate(m.muSharedCtx)
		if err != nil || !isValid {
			gl.LogObjLogger(m, "warn", "Condition signal aborted due to validation failure")
			return
		}
	}

	gl.LogObjLogger(m, "info", "Signaling condition variable")
	m.MuCtxCond.Signal()
}

// MuBroadcastCond broadcasts the condition variable
func (m *Mutexes) MuBroadcastCond() {
	m.MuCtxCond.Broadcast()
}

// MuAdd adds a delta to the wait group counter
func (m *Mutexes) MuAdd(delta int) { m.MuCtxWg.Add(delta) }

// MuDone signals that the wait group is done
func (m *Mutexes) MuDone() { m.MuCtxWg.Done() }

// MuWait waits for the wait group counter to reach zero
func (m *Mutexes) MuWait() { m.MuCtxWg.Wait() }

func (m *Mutexes) MuTryLock() bool {
	if m.MuCtxM.TryLock() {
		return true
	}
	return false
}

func (m *Mutexes) MuTryRLock() bool {
	if m.MuCtxL.TryRLock() {
		return true
	}
	return false
}

/// internal/types/property.go ///
package types

import (
	"os"
	"reflect"

	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"
	l "github.com/rafa-mori/logz"

	"github.com/google/uuid"
)

// Property is a struct that holds the properties of the GoLife instance.
type Property[T any] struct {
	// Telemetry is the telemetry for this GoLife instance.
	metrics *Telemetry
	// Prop is the property for this GoLife instance.
	prop ci.IPropertyValBase[T]
	// Cb is the callback function for this GoLife instance.
	cb func(any) (bool, error)
}

// NewProperty creates a new IProperty[T] with the given value and Reference.
func NewProperty[T any](name string, v *T, withMetrics bool, cb func(any) (bool, error)) ci.IProperty[T] {
	p := &Property[T]{
		prop: newVal[T](name, v),
		cb:   cb,
	}
	if withMetrics {
		p.metrics = NewTelemetry()
	}
	return p
}

// GetName returns the name of the property.
func (p *Property[T]) GetName() string {
	return p.prop.GetName()
}

// GetValue returns the value of the property.
func (p *Property[T]) GetValue() T {
	value := p.prop.Get(false)
	if value == nil {
		return *new(T)
	}
	return *value.(*T)
}

// SetValue sets the value of the property.
func (p *Property[T]) SetValue(v *T) {
	p.prop.Set(v)
	if p.cb != nil {
		if _, err := p.cb(v); err != nil {
			//p.metrics.Log("error", "Error in callback function: "+err.Error())
		}
	}
}

// GetReference returns the reference of the property.
func (p *Property[T]) GetReference() (uuid.UUID, string) {
	return p.prop.GetID(), p.prop.GetName()
}

// Prop is a struct that holds the properties of the GoLife instance.
func (p *Property[T]) Prop() ci.IPropertyValBase[T] {
	return p.prop
}

// GetLogger returns the logger of the property.
func (p *Property[T]) GetLogger() l.Logger {

	return p.Prop().GetLogger()

}

// Serialize serializes the ProcessInput instance to the specified format.
func (p *Property[T]) Serialize(format, filePath string) ([]byte, error) {
	value := p.GetValue()
	mapper := NewMapper[T](&value, filePath)
	return mapper.Serialize(format)
}

// Deserialize deserializes the data into the ProcessInput instance.
func (p *Property[T]) Deserialize(data []byte, format, filePath string) error {

	if len(data) == 0 {
		return nil
	}
	value := p.GetValue()
	if !reflect.ValueOf(value).IsValid() {
		p.SetValue(new(T))
	}
	mapper := NewMapper[T](&value, filePath)
	if v, vErr := mapper.Deserialize(data, format); vErr != nil {
		gl.Log("error", "Failed to deserialize data:", vErr.Error())
		return vErr
	} else {
		p.SetValue(v)
	}
	return nil
}

func (p *Property[T]) SaveToFile(filePath string, format string) error {
	if data, err := p.Serialize(format, filePath); err != nil {
		gl.Log("error", "Failed to serialize data:", err.Error())
		return err
	} else {
		if err := os.WriteFile(filePath, data, 0644); err != nil {
			gl.Log("error", "Failed to write to file:", err.Error())
			return err
		}
	}
	return nil
}

func (p *Property[T]) LoadFromFile(filename, format string) error {
	data, err := os.ReadFile(filename)
	if err != nil {
		return err
	}
	return p.Deserialize(data, format, filename)
}

/// internal/types/property_base.go ///
package types

import (
	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"
	l "github.com/rafa-mori/logz"

	"fmt"
	"reflect"
	"sync/atomic"

	"github.com/google/uuid"
)

// PropertyValBase is a type for the value.
type PropertyValBase[T any] struct {
	// Logger is the logger for this context.
	Logger l.Logger

	// v is the value.
	*atomic.Pointer[T]

	// Reference is the identifiers for the context.
	// IReference
	*Reference

	//muCtx is the mutexes for the context.
	*Mutexes

	// validation is the validation for the value.
	*Validation[T]

	// Channel is the channel for the value.
	ci.IChannelCtl[T]
	channelCtl *ChannelCtl[T]
}

// NewVal is a function that creates a new PropertyValBase instance.
func newVal[T any](name string, v *T) *PropertyValBase[T] {
	ref := NewReference(name)

	// Create a new PropertyValBase instance
	vv := atomic.Pointer[T]{}
	if v != nil {
		vv.Store(v)
	} else {
		vv.Store(new(T))
	}

	// Create a new mutexes instance
	mu := NewMutexesType()

	// Create a new validation instance
	validation := newValidation[T]()

	gl.Log("debug", "Created new PropertyValBase instance for:", name, "ID:", ref.GetID().String())

	return &PropertyValBase[T]{
		Pointer:    &vv,
		Validation: validation,
		Reference:  ref.GetReference(),
		channelCtl: NewChannelCtl[T](name, nil).(*ChannelCtl[T]),
		Mutexes:    mu,
	}
}

func NewVal[T any](name string, v *T) ci.IPropertyValBase[T] {
	ref := NewReference(name)

	// Create a new PropertyValBase instance
	vv := atomic.Pointer[T]{}
	if v != nil {
		vv.Store(v)
	} else {
		vv.Store(new(T))
	}

	// Create a new mutexes instance
	mu := NewMutexesType()

	// Create a new validation instance
	validation := newValidation[T]()

	gl.Log("debug", "Created new PropertyValBase instance for:", name, "ID:", ref.GetID().String())

	return &PropertyValBase[T]{
		Pointer:    &vv,
		Validation: validation,
		Reference:  ref.GetReference(),
		channelCtl: NewChannelCtl[T](name, nil).(*ChannelCtl[T]),
		Mutexes:    mu,
	}
}

// GetLogger is a method that returns the logger for the value.
func (v *PropertyValBase[T]) GetLogger() l.Logger {
	if v == nil {
		gl.Log("error", "GetLogger: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	return v.Logger
}

// GetName is a method that returns the name of the value.
func (v *PropertyValBase[T]) GetName() string {
	if v == nil {
		gl.Log("error", "GetName: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return ""
	}
	return v.Name
}

// GetID is a method that returns the ID of the value.
func (v *PropertyValBase[T]) GetID() uuid.UUID {
	if v == nil {
		gl.Log("error", "GetID: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return uuid.Nil
	}
	return v.ID
}

// Value is a method that returns the value.
func (v *PropertyValBase[T]) Value() *T {
	if v == nil {
		gl.Log("error", "Value: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	return v.Load()
}

// StartCtl is a method that starts the control channel.
func (v *PropertyValBase[T]) StartCtl() <-chan string {
	if v == nil {
		gl.Log("error", "StartCtl: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	if v.channelCtl == nil {
		gl.Log("error", "StartCtl: channel control is nil (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	return v.channelCtl.Channels["ctl"].(<-chan string)
}

// Type is a method that returns the type of the value.
func (v *PropertyValBase[T]) Type() reflect.Type { return reflect.TypeFor[T]() }

// Get is a method that returns the value.
func (v *PropertyValBase[T]) Get(async bool) any {
	if v == nil {
		gl.Log("error", "Get: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	if async {
		if v.channelCtl != nil {
			gl.Log("debug", "Getting value from channel for:", v.Name, "ID:", v.ID.String())
			v.channelCtl.Channels["get"].(chan T) <- *v.Load()
		}
	} else {
		gl.Log("debug", "Getting value for:", v.Name, "ID:", v.ID.String())
		return v.Load()
	}
	return nil
}

// Set is a method that sets the value.
func (v *PropertyValBase[T]) Set(t *T) bool {
	if v == nil {
		gl.Log("error", "Set: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return false
	}
	if t == nil {
		gl.Log("error", "Set: value is nil (", reflect.TypeFor[T]().String(), ")")
		return false
	}
	if v.Validation != nil {
		if ok := v.Validation.Validate(t); !ok.GetIsValid() {
			gl.Log("error", fmt.Sprintf("Set: validation error (%s): %v", reflect.TypeFor[T]().String(), v.Validation.GetResults()))
			return false
		}
	}
	v.Store(t)
	if v.channelCtl != nil {
		gl.Log("debug", "Setting value for:", v.Name, "ID:", v.ID.String())
		v.channelCtl.Channels["set"].(chan T) <- *t
	}
	return true
}

// Clear is a method that clears the value.
func (v *PropertyValBase[T]) Clear() bool {
	if v == nil {
		gl.Log("error", "Clear: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return false
	}
	if v.channelCtl != nil {
		gl.Log("debug", "Clearing value for:", v.Name, "ID:", v.ID.String())
		v.channelCtl.Channels["clear"].(chan string) <- "clear"
	}
	return true
}

// IsNil is a method that checks if the value is nil.
func (v *PropertyValBase[T]) IsNil() bool {
	if v == nil {
		gl.Log("error", "Get: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return true
	}
	return v.Load() == nil
}

// Serialize is a method that serializes the value.
func (v *PropertyValBase[T]) Serialize(filePath, format string) ([]byte, error) {
	if value := v.Value(); value == nil {
		return nil, fmt.Errorf("value is nil")
	} else {
		mapper := NewMapper[T](value, filePath)
		if data, err := mapper.Serialize(format); err != nil {
			gl.Log("error", "Failed to serialize data:", err.Error())
			return nil, err
		} else {
			return data, nil
		}
	}
}

// Deserialize is a method that deserializes the data into the value.
func (v *PropertyValBase[T]) Deserialize(data []byte, format, filePath string) error {
	if value := v.Value(); value == nil {
		return fmt.Errorf("value is nil")
	} else {
		mapper := NewMapper[T](value, filePath)
		if vl, vErr := mapper.Deserialize(data, format); vErr != nil {
			gl.Log("error", "Failed to deserialize data:", vErr.Error())
			return vErr
		} else {
			v.Store(vl)
			return nil
		}
	}
}

/// internal/types/reference.go ///
package types

import (
	"fmt"
	"reflect"
	"runtime"

	"github.com/google/uuid"
	gl "github.com/rafa-mori/gdbase/logger"
)

type IReference interface {
	GetID() uuid.UUID
	GetName() string
	SetName(name string)
	String() string
	GetReference() *Reference
}

// Reference is a struct that holds the Reference ID and name.
type Reference struct {
	// refID is the unique identifier for this context.
	ID uuid.UUID
	// refName is the name of the context.
	Name string
}

// newReference is a function that creates a new Reference instance.
func newReference(name string) *Reference {
	if name == "" {
		pc, _, line, ok := runtime.Caller(1)
		if ok {
			fn := runtime.FuncForPC(pc)
			name = fmt.Sprintf("%s:%d", fn.Name(), line)
		} else {
			name = "unknown"
		}
	}
	return &Reference{
		ID:   uuid.New(),
		Name: name,
	}
}

// NewReference is a function that creates a new IReference instance.
func NewReference(name string) IReference {
	return newReference(name)
}

// String is a method that returns the string representation of the reference.
func (r *Reference) String() string {
	return fmt.Sprintf("ID: %s, Name: %s", r.ID.String(), r.Name)
}

// GetID is a method that returns the ID of the reference.
func (r *Reference) GetID() uuid.UUID {
	if r == nil {
		gl.Log("error", "GetID: reference does not exist (", reflect.TypeFor[Reference]().String(), ")")
		return uuid.Nil
	}
	return r.ID
}

// GetName is a method that returns the name of the reference.
func (r *Reference) GetName() string {
	if r == nil {
		gl.Log("error", "GetName: reference does not exist (", reflect.TypeFor[Reference]().String(), ")")
		return ""
	}
	return r.Name
}

// SetName is a method that sets the name of the reference.
func (r *Reference) SetName(name string) {
	if r == nil {
		gl.Log("error", "SetName: reference does not exist (", reflect.TypeFor[Reference]().String(), ")")
		return
	}
	r.Name = name
}

// GetReference is a method that returns the reference struct (non-interface).
func (r *Reference) GetReference() *Reference {
	if r == nil {
		gl.Log("error", "GetReference: reference does not exist (", reflect.TypeFor[Reference]().String(), ")")
		return nil
	}
	return r
}

/// internal/types/reflect.go ///
package types

import (
	"fmt"
	"reflect"

	gl "github.com/rafa-mori/gdbase/logger"
)

func AutoEncode[T any](v T, format, filePath string) ([]byte, error) {
	mapper := NewMapper[T](&v, filePath)
	if data, err := mapper.Serialize(format); err != nil {
		gl.Log("error", "AutoEncode: unknown type for serialization (", reflect.TypeOf(v).Name(), "):", err.Error())
		return nil, fmt.Errorf("error: %s", err.Error())
	} else {
		return data, nil
	}
}

func AutoDecode[T any](data []byte, target *T, format string) error {
	mapper := NewMapperTypeWithObject[T](target, "")
	if obj, err := mapper.Deserialize(data, format); err != nil {
		gl.Log("error", "AutoDecode: unknown type for deserialization (", reflect.TypeOf(target).Name(), "):", err.Error())
		return fmt.Errorf("error: %s", err.Error())
	} else {
		if reflect.ValueOf(obj).IsValid() {
			target = obj
			gl.Log("success", "AutoDecode: deserialized object of type ", reflect.TypeOf(obj).Name())
		} else {
			gl.Log("error", "AutoDecode: deserialized object is nil")
			return fmt.Errorf("deserialized object is nil")
		}
		return nil
	}
}

/// internal/types/request_tracer.go ///
package types

import (
	"bufio"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"
	l "github.com/rafa-mori/logz"
)

var (
	RequestTracers = make(map[string]ci.IRequestsTracer)
)

const RequestLimit = 5
const RequestWindow = 60 * time.Second

type RequestsTracer struct {
	Mutexes       ci.IMutexes
	IP            string      `json:"ip" yaml:"ip" xml:"ip" toml:"ip" gorm:"ip"`
	Port          string      `json:"port" yaml:"port" xml:"port" toml:"port" gorm:"port"`
	LastUserAgent string      `json:"last_user_agent" yaml:"last_user_agent" xml:"last_user_agent" toml:"last_user_agent" gorm:"last_user_agent"`
	UserAgents    []string    `json:"user_agents" yaml:"user_agents" xml:"user_agents" toml:"user_agents" gorm:"user_agents"`
	Endpoint      string      `json:"endpoint" yaml:"endpoint" xml:"endpoint" toml:"endpoint" gorm:"endpoint"`
	Method        string      `json:"method" yaml:"method" xml:"method" toml:"method" gorm:"method"`
	TimeList      []time.Time `json:"time_list" yaml:"time_list" xml:"time_list" toml:"time_list" gorm:"time_list"`
	Count         int         `json:"count" yaml:"count" xml:"count" toml:"count" gorm:"count"`
	Valid         bool
	Error         error
	RequestWindow time.Duration
	RequestLimit  int
	FilePath      string
	OldFilePath   string
	Mapper        ci.IMapper[ci.IRequestsTracer]
}

func newRequestsTracer(ip, port, endpoint, method, userAgent, filePath string) *RequestsTracer {
	var tracer *RequestsTracer
	var exists bool

	if RequestTracers == nil {
		RequestTracers = make(map[string]ci.IRequestsTracer)
	}
	var tracerT ci.IRequestsTracer
	var ok bool
	if tracerT, exists = RequestTracers[ip]; exists {
		tracer, ok = tracerT.(*RequestsTracer)
		if !ok {
			gl.Log("error", fmt.Sprintf("Error casting tracer to RequestsTracer for IP: %s", ip))
			return nil
		}

		tracer.GetMutexes().MuLock()
		defer tracer.GetMutexes().MuUnlock()

		tracer.Count++
		tracer.TimeList = append(tracer.TimeList, time.Now())
		tracer.LastUserAgent = userAgent
		tracer.UserAgents = append(tracer.UserAgents, userAgent)

		if len(tracer.TimeList) > 1 {
			if tracer.TimeList[len(tracer.TimeList)-1].Sub(tracer.TimeList[len(tracer.TimeList)-2]) <= RequestWindow {
				gl.Log("info", fmt.Sprintf("Request limit exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count))
				tracer.Valid = false
				tracer.Error = fmt.Errorf("request limit exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count)
			} else if tracer.TimeList[len(tracer.TimeList)-1].Sub(tracer.TimeList[0]) > RequestWindow {
				gl.Log("info", fmt.Sprintf("Request window exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count))
				tracer.Count = 1
				tracer.TimeList = []time.Time{tracer.TimeList[len(tracer.TimeList)-1]}
				tracer.UserAgents = []string{userAgent}
				tracer.Valid = true
				tracer.Error = nil
			} else if tracer.Count > RequestLimit {
				gl.Log("info", fmt.Sprintf("Request limit exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count))
				tracer.Valid = false
				tracer.Error = fmt.Errorf("request limit exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count)
			} else {
				gl.Log("info", fmt.Sprintf("Request limit not exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count))
				tracer.Valid = true
				tracer.Error = nil
			}
		}
		if tracer.FilePath != filePath {
			gl.Log("info", fmt.Sprintf("File path changed for IP: %s, Count: %d", tracer.IP, tracer.Count))
			tracer.OldFilePath = tracer.FilePath
			tracer.FilePath = filePath
		}
	} else {
		tracer = &RequestsTracer{
			IP:            ip,
			Port:          port,
			LastUserAgent: userAgent,
			UserAgents:    []string{userAgent},
			Endpoint:      endpoint,
			Method:        method,
			TimeList:      []time.Time{time.Now()},
			Count:         1,
			Valid:         true,
			Error:         nil,
			Mutexes:       NewMutexesType(),
			FilePath:      filePath,
			OldFilePath:   "",

			RequestWindow: RequestWindow,
			RequestLimit:  RequestLimit,
		}
	}

	RequestTracers[ip] = tracer
	rTracer := ci.IRequestsTracer(tracer)

	tracer.Mapper = NewMapperType[ci.IRequestsTracer](&rTracer, tracer.FilePath)

	tracer.Mutexes.MuAdd(1)
	go func(tracer *RequestsTracer) {
		defer tracer.Mutexes.MuDone()
		tracer.Mapper.SerializeToFile("json")
	}(tracer)
	tracer.Mutexes.MuWait()

	return tracer
}
func NewRequestsTracerType(ip, port, endpoint, method, userAgent, filePath string) ci.IRequestsTracer {
	return newRequestsTracer(ip, port, endpoint, method, userAgent, filePath)
}
func NewRequestsTracer(ip, port, endpoint, method, userAgent, filePath string) ci.IRequestsTracer {
	return newRequestsTracer(ip, port, endpoint, method, userAgent, filePath)
}

func (r *RequestsTracer) GetIP() string            { return r.IP }
func (r *RequestsTracer) GetPort() string          { return r.Port }
func (r *RequestsTracer) GetLastUserAgent() string { return r.LastUserAgent }
func (r *RequestsTracer) GetUserAgents() []string  { return r.UserAgents }
func (r *RequestsTracer) GetEndpoint() string      { return r.Endpoint }
func (r *RequestsTracer) GetMethod() string        { return r.Method }
func (r *RequestsTracer) GetTimeList() []time.Time { return r.TimeList }
func (r *RequestsTracer) GetCount() int            { return r.Count }
func (r *RequestsTracer) GetError() error          { return r.Error }
func (r *RequestsTracer) GetMutexes() ci.IMutexes  { return r.Mutexes }
func (r *RequestsTracer) IsValid() bool            { return r.Valid }
func (r *RequestsTracer) GetOldFilePath() string {
	if r.OldFilePath == "" {
		abs, err := filepath.Abs(filepath.Join("./", "requests_tracer.json"))
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting absolute path: %v", err))
			return ""
		}
		r.OldFilePath = abs
	}
	return r.OldFilePath
}

func (r *RequestsTracer) GetFilePath() string {
	if r.FilePath == "" {
		abs, err := filepath.Abs(filepath.Join("./", "requests_tracer.json"))
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting absolute path: %v", err))
			return ""
		}
		r.FilePath = abs
	}
	return r.FilePath
}
func (r *RequestsTracer) SetFilePath(filePath string) {
	if filePath == "" {
		abs, err := filepath.Abs(filepath.Join("./", "requests_tracer.json"))
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting absolute path: %v", err))
			return
		}
		r.FilePath = abs
	} else {
		r.FilePath = filePath
	}
}
func (r *RequestsTracer) GetMapper() ci.IMapper[ci.IRequestsTracer] { return r.Mapper }
func (r *RequestsTracer) SetMapper(mapper ci.IMapper[ci.IRequestsTracer]) {
	if mapper == nil {
		gl.Log("error", "Mapper cannot be nil")
		return
	}
	r.Mapper = mapper
}
func (r *RequestsTracer) GetRequestWindow() time.Duration { return r.RequestWindow }
func (r *RequestsTracer) SetRequestWindow(window time.Duration) {
	if window <= 0 {
		gl.Log("error", "Request window cannot be negative or zero")
		return
	}
	r.RequestWindow = window
}
func (r *RequestsTracer) GetRequestLimit() int { return r.RequestLimit }
func (r *RequestsTracer) SetRequestLimit(limit int) {
	if limit <= 0 {
		gl.Log("error", "Request limit cannot be negative or zero")
		return
	}
	r.RequestLimit = limit
}
func (r *RequestsTracer) Mu() ci.IMutexes {
	return r.Mutexes
}

func LoadRequestsTracerFromFile(g ci.IGoBE) (map[string]ci.IRequestsTracer, error) {
	if RequestTracers == nil {
		RequestTracers = make(map[string]ci.IRequestsTracer)
	}

	gl.Log("info", "Loading request tracers from file")
	if _, err := os.Stat(g.GetLogFilePath()); os.IsNotExist(err) {
		gl.Log("warn", fmt.Sprintf("File does not exist: %v, creating new file", err.Error()))
		if _, createErr := os.Create(g.GetLogFilePath()); createErr != nil {
			gl.Log("error", fmt.Sprintf("Error creating file: %v", createErr.Error()))
			return nil, createErr
		} else {
			gl.Log("info", "File created successfully")
		}
		return nil, nil
	}

	gl.Log("info", "File exists, proceeding to load")
	inputFile, err := os.Open(g.GetLogFilePath())
	if err != nil {
		gl.Log("error", "Erro ao abrir arquivo: %v", err.Error())
		return nil, err
	}

	defer func(inputFile *os.File) {
		gl.Log("info", "Closing input file")
		if closeErr := inputFile.Close(); closeErr != nil {
			gl.Log("error", fmt.Sprintf("Erro ao fechar arquivo: %v", err))
		}
	}(inputFile)

	reader := bufio.NewReader(inputFile)
	decoder := json.NewDecoder(reader)
	decoder.DisallowUnknownFields()

	g.Mu().MuAdd(1)
	go func(g ci.IGoBE) {
		defer g.Mu().MuDone()
		gl.Log("info", "Decoding request tracers from file")
		for decoder.More() {
			var existing *RequestsTracer
			if err := decoder.Decode(&existing); err != nil || existing == nil {
				if err == nil {
					err = fmt.Errorf("existing n√£o inicializado: %v, err: %s", existing, err)
				}
				gl.Log("error", fmt.Sprintf("Erro ao decodificar:%s", err.Error()))
				continue
			}
			gl.Log("info", fmt.Sprintf("Decoded request tracer: %s", existing.IP))
			RequestTracers[existing.IP] = existing
		}
	}(g)

	gl.Log("info", "Waiting for decoding to finish")
	g.Mu().MuWait()

	if len(RequestTracers) > 0 {
		gl.Log("info", fmt.Sprintf("Loaded %d request tracers", len(RequestTracers)))
	} else {
		gl.Log("warn", "No request tracers loaded from file")
	}

	return RequestTracers, nil
}
func updateRequestTracer(g ci.IGoBE, updatedTracer ci.IRequestsTracer) error {
	var decoder *json.Decoder
	var outputFile *os.File
	var err error
	tmpFilePath := filepath.Join(g.GetConfigFilePath(), "temp"+updatedTracer.GetFilePath())

	if inputFile, inputFileErr := os.Open(updatedTracer.GetFilePath()); inputFileErr != nil || inputFile == nil {
		if inputFileErr == nil {
			inputFileErr = fmt.Errorf("inputFile n√£o inicializado")
		}
		return fmt.Errorf("erro ao abrir arquivo: %v", inputFileErr)
	} else {
		defer func(inputFile *os.File) {
			_ = inputFile.Close()
		}(inputFile)

		if outputFile, err = os.Create(tmpFilePath); err != nil || outputFile == nil {
			if err == nil {
				err = fmt.Errorf("outputFile n√£o inicializado")
			}
			return fmt.Errorf("erro ao criar arquivo tempor√°rio: %v", err)
		} else {
			defer func(outputFile *os.File, tmpFilePath string) {
				_ = outputFile.Close()
				if removeErr := os.Remove(tmpFilePath); removeErr != nil {
					gl.Log("error", fmt.Sprintf("Erro ao remover arquivo tempor√°rio: %v", removeErr))
					return
				}
			}(outputFile, tmpFilePath)

			decoder = json.NewDecoder(inputFile)
			decoder.DisallowUnknownFields()

			var existing *RequestsTracer
			for decoder.More() {
				existing = &RequestsTracer{}
				if err = decoder.Decode(&existing); err != nil || existing == nil {
					if err == nil {
						err = fmt.Errorf("existing n√£o inicializado")
					}

					gl.Log("error", fmt.Sprintf("Erro ao decodificar linha: %v", err))

					continue
				} else {
					var line []byte

					// If the existing tracer matches the updated tracer, update it
					if existing.IP == updatedTracer.GetIP() && existing.Port == updatedTracer.GetPort() {
						lineBytes, _ := json.Marshal(updatedTracer)
						line = []byte(string(lineBytes) + "\n")
					}

					// Escreve a linha no novo arquivo, em array de bytes (que seria "bufferizado" e mais r√°pido)
					if _, writeErr := outputFile.Write(line); writeErr != nil {
						return writeErr
					}
				}
			}
		}
	}
	if _, tmpFilePathStatErr := os.Stat(tmpFilePath); tmpFilePathStatErr != nil {
		if replaceErr := os.Rename(tmpFilePath, updatedTracer.GetFilePath()); replaceErr != nil {
			return replaceErr
		}
	}
	return nil
}
func isDuplicateRequest(g ci.IGoBE, rt ci.IRequestsTracer, logger l.Logger) bool {
	env := g.Environment()
	strategy := screeningByRAMSize(env, rt.GetFilePath())

	if strategy == "strings" {
		data, err := os.ReadFile(rt.GetFilePath())
		if err != nil {
			gl.Log("error", fmt.Sprintf("Erro ao ler arquivo: %v", err))
			return false
		}

		lines := strings.Split(string(data), "\n")
		for _, line := range lines {
			if strings.Contains(line, rt.GetIP()) && strings.Contains(line, rt.GetPort()) {
				return true
			}
		}
	} else {
		f, err := os.Open(rt.GetFilePath())
		if err != nil {
			gl.Log("error", fmt.Sprintf("Erro ao abrir arquivo: %v", err))
			return false
		}
		defer func(f *os.File) {
			_ = f.Close()
		}(f)

		scanner := bufio.NewScanner(f)
		for scanner.Scan() {
			var existing RequestsTracer
			if err := json.Unmarshal([]byte(scanner.Text()), &existing); err != nil {
				continue
			}
			if existing.IP == rt.GetIP() && existing.Port == rt.GetPort() {
				return true
			}
		}
	}

	return false
}
func updateRequestTracerInMemory(updatedTracer ci.IRequestsTracer) error {
	if data, err := os.ReadFile(updatedTracer.GetFilePath()); err != nil {
		return fmt.Errorf("erro ao ler arquivo: %v", err)
	} else {
		lines := strings.Split(string(data), "\n")
		for i, line := range lines {
			if line == "" {
				continue
			}
			var existing RequestsTracer
			if err := json.Unmarshal([]byte(line), &existing); err != nil {
				continue
			}
			if existing.IP == updatedTracer.GetIP() && existing.Port == updatedTracer.GetPort() {
				lines[i] = func(data ci.IRequestsTracer) string {
					if lineBytes, lineBytesErr := json.Marshal(data); lineBytesErr != nil {
						gl.Log("error", fmt.Sprintf("Error marshalling updated tracer: %v", lineBytesErr))
						return ""
					} else {
						return string(lineBytes)
					}
				}(updatedTracer)
			}
		}
		return os.WriteFile(updatedTracer.GetFilePath(), []byte(strings.Join(lines, "\n")), 0644)
	}
}

/// internal/types/retryable.go ///
package types

import "time"

type IRetryable interface {
	Retry() error
}
type Retryable[T any] struct{}

func (r *Retryable[T]) Retry(fn func() (T, error), retries int) (T, error) {
	var result T
	var err error
	for i := 0; i < retries; i++ {
		result, err = fn()
		if err == nil {
			return result, nil
		}
	}
	return result, err
}

type IRetryableVoid interface {
	RetryVoid() error
}
type RetryableVoid struct{}

func (rv *RetryableVoid) Retry(fn func() error, retries int) error {
	for i := 0; i < retries; i++ {
		if err := fn(); err == nil {
			return nil
		}
	}
	return nil
}

type IRetryableWithDelay interface {
	RetryWithDelay(delayMs int) error
}
type RetryableWithDelay[T any] struct{}

func (r *RetryableWithDelay[T]) Retry(fn func() (T, error), retries int, delayMs int) (T, error) {
	var result T
	var err error
	for i := 0; i < retries; i++ {
		result, err = fn()
		if err == nil {
			return result, nil
		}
		if delayMs > 0 {
			time.Sleep(time.Duration(delayMs) * time.Millisecond)
		}
	}
	return result, err
}

type IRetryableWithTimeout interface {
	RetryWithTimeout(timeout time.Duration) error
}
type RetryableWithTimeout[T any] struct{}

func (r *RetryableWithTimeout[T]) Retry(fn func() (T, error), retries int, timeout time.Duration) (T, error) {
	startTime := time.Now()
	for i := 0; i < retries; i++ {
		if time.Since(startTime) > timeout {
			return *new(T), nil // Timeout reached, return zero value without error
		}
		if result, err := fn(); err == nil {
			return result, nil
		}
	}
	return *new(T), nil
}

type IRetryableWithDelayAndTimeout interface {
	RetryWithDelayAndTimeout(delayMs int, timeout time.Duration) error
}
type RetryableWithDelayAndTimeout[T any] struct{}

func (r *RetryableWithDelayAndTimeout[T]) Retry(fn func() (T, error), retries int, delayMs int, timeout time.Duration) (T, error) {
	startTime := time.Now()
	var result T
	var err error
	for i := 0; i < retries; i++ {
		if time.Since(startTime) > timeout {
			return result, nil // Timeout reached, return zero value without error
		}
		result, err = fn()
		if err == nil {
			return result, nil
		}
		if delayMs > 0 {
			time.Sleep(time.Duration(delayMs) * time.Millisecond)
		}
	}
	return result, err
}

type IRetryableWithDelayAndTimeoutAndRetries interface {
	RetryWithDelayAndTimeoutAndRetries(delayMs int, timeout time.Duration, retries int) error
}
type RetryableWithDelayAndTimeoutAndRetries[T any] struct{}

func (r *RetryableWithDelayAndTimeoutAndRetries[T]) Retry(fn func() (T, error), retries int, delayMs int, timeout time.Duration) (T, error) {
	startTime := time.Now()
	var result T
	var err error
	for i := 0; i < retries; i++ {
		if time.Since(startTime) > timeout {
			return result, nil // Timeout reached, return zero value without error
		}
		result, err = fn()
		if err == nil {
			return result, nil
		}
		if delayMs > 0 {
			time.Sleep(time.Duration(delayMs) * time.Millisecond)
		}
	}
	return result, err
}

type IRetryableWithRetries interface {
	RetryWithRetries(retries int) error
}
type RetryableWithRetries[T any] struct{}

func (r *RetryableWithRetries[T]) Retry(fn func() (T, error), retries int) (T, error) {
	var result T
	var err error
	for i := 0; i < retries; i++ {
		result, err = fn()
		if err == nil {
			return result, nil
		}
	}
	return result, err
}

type IRetryableVoidWithDelay interface {
	RetryVoidWithDelay(delayMs int) error
}
type RetryableVoidWithDelay struct{}

func (rv *RetryableVoidWithDelay) Retry(fn func() error, retries int, delayMs int) error {
	for i := 0; i < retries; i++ {
		if err := fn(); err == nil {
			return nil
		}
		if delayMs > 0 {
			time.Sleep(time.Duration(delayMs) * time.Millisecond)
		}
	}
	return nil
}

type IRetryableVoidWithTimeout interface {
	RetryVoidWithTimeout(timeout time.Duration) error
}
type RetryableVoidWithTimeout struct{}

func (rv *RetryableVoidWithTimeout) Retry(fn func() error, retries int, timeout time.Duration) error {
	startTime := time.Now()
	for i := 0; i < retries; i++ {
		if time.Since(startTime) > timeout {
			return nil // Timeout reached, return without error
		}
		if err := fn(); err == nil {
			return nil
		}
	}
	return nil
}

type IRetryableVoidWithDelayAndTimeout interface {
	RetryVoidWithDelayAndTimeout(delayMs int, timeout time.Duration) error
}
type RetryableVoidWithDelayAndTimeout struct{}

func (rv *RetryableVoidWithDelayAndTimeout) Retry(fn func() error, retries int, delayMs int, timeout time.Duration) error {
	startTime := time.Now()
	for i := 0; i < retries; i++ {
		if time.Since(startTime) > timeout {
			return nil // Timeout reached, return without error
		}
		if err := fn(); err == nil {
			return nil
		}
		if delayMs > 0 {
			time.Sleep(time.Duration(delayMs) * time.Millisecond)
		}
	}
	return nil
}

/// internal/types/secure_crypt.go ///
package types

import (
	"bufio"
	"crypto/aes"
	"crypto/cipher"
	"crypto/rand"
	"encoding/base64"
	"fmt"
	"io"
	"os"
	"strings"

	gl "github.com/rafa-mori/gdbase/logger"
)

func EncryptEnv(value string, isConfidential bool) (string, error) {
	if !isConfidential {
		return value, nil
	}
	block, err := aes.NewCipher([]byte(""))
	if err != nil {
		return "", err
	}

	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return "", err
	}

	nonce := make([]byte, gcm.NonceSize())
	if _, err = io.ReadFull(rand.Reader, nonce); err != nil {
		return "", err
	}

	ciphertext := gcm.Seal(nonce, nonce, []byte(value), nil)

	err = nil
	encoded := base64.URLEncoding.EncodeToString(ciphertext)
	if len(encoded) == 0 {
		err = fmt.Errorf("failed to encode the encrypted value")
	}

	return encoded, err
}
func DecryptEnv(encryptedValue string, isConfidential bool) (string, error) {
	if !isConfidential {
		if !IsEncryptedValue(encryptedValue) {
			return encryptedValue, nil
		}
	}
	block, err := aes.NewCipher([]byte(""))
	if err != nil {
		return "", err
	}
	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return "", err
	}
	nonceSize := gcm.NonceSize()
	if len(encryptedValue) < nonceSize {
		return "", fmt.Errorf("ciphertext too short")
	}
	nonce, ciphertext := []byte(encryptedValue)[:nonceSize], []byte(encryptedValue)[nonceSize:]
	plaintext, err := gcm.Open(nil, nonce, ciphertext, nil)
	if err != nil {
		return "", err
	}

	decoded, err := base64.URLEncoding.DecodeString(string(plaintext))
	if err != nil {
		return "", err
	}

	if len(decoded) == 0 {
		return "", fmt.Errorf("failed to decode the encrypted value")
	}
	return string(decoded), nil
}
func IsEncrypted(envFile string) bool {
	if _, err := os.Stat(envFile); os.IsNotExist(err) {
		gl.Log("error", fmt.Sprintf("Arquivo n√£o encontrado: %v", err))
		return false
	}
	file, err := os.Open(envFile)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Erro ao abrir o arquivo: %v", err))
		return false
	}
	defer func(file *os.File) {
		_ = file.Close()
	}(file)

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.Contains(line, "ENCRYPTED") {
			return true
		}
	}

	if err := scanner.Err(); err != nil {
		gl.Log("error", fmt.Sprintf("Erro ao ler o arquivo: %v", err))
		return false
	}

	return false
}
func IsEncryptedValue(value string) bool {
	if arrB, arrBErr := base64.URLEncoding.DecodeString(value); arrBErr != nil || len(arrB) == 0 {
		return false
	} else {
		return len(arrB) > 0 && arrB[0] == 0x00
	}
}

/// internal/types/signal_manager.go ///
package types

import (
	"fmt"
	"os"
	"os/signal"
	"syscall"

	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"
	l "github.com/rafa-mori/logz"
)

type SignalManager[T chan string] struct {
	// Logger is the Logger instance for this GoLife instance.
	Logger l.Logger
	// Reference is the reference ID and name.
	*Reference
	// SigChan is the channel for the signal.
	SigChan    chan os.Signal
	channelCtl T
}

// NewSignalManager creates a new SignalManager instance.
func newSignalManager[T chan string](channelCtl T, logger l.Logger) *SignalManager[T] {
	if logger == nil {
		logger = l.GetLogger("GoLife")
	}
	return &SignalManager[T]{
		Logger:     logger,
		Reference:  newReference("SignalManager"),
		SigChan:    make(chan os.Signal, 1),
		channelCtl: channelCtl,
	}
}

// NewSignalManager creates a new SignalManager instance.
func NewSignalManager[T chan string](channelCtl chan string, logger l.Logger) ci.ISignalManager[T] {
	return newSignalManager[T](channelCtl, logger)
}

// ListenForSignals sets up the signal channel to listen for specific signals.
func (sm *SignalManager[T]) ListenForSignals() error {
	signal.Notify(sm.SigChan, os.Interrupt, syscall.SIGTERM, syscall.SIGHUP)

	go func() {
		for sig := range sm.SigChan {
			fmt.Printf("Sinal recebido: %s\n", sig.String())
			if sm.channelCtl != nil {
				sm.channelCtl <- fmt.Sprintf("{\"context\":\"%s\", \"message\":\"%s\"}", sm.GetName(), ""+sig.String())
			} else {
				fmt.Println("Canal de controle n√£o definido.")
			}
		}
	}()
	return nil
}

// StopListening stops listening for signals and closes the channel.
func (sm *SignalManager[T]) StopListening() {
	signal.Stop(sm.SigChan) // üî• Para de escutar sinais
	close(sm.SigChan)       // üî• Fecha o canal para evitar vazamento de goroutines
	gl.LogObjLogger(sm, "info", "Parando escuta de sinais")
}

/// internal/types/telemetry.go ///
package types

import (
	l "github.com/rafa-mori/logz"
	"sync"
	"time"
)

// TelemetryIdentifier is a struct that holds the identifier for telemetry data
type TelemetryIdentifier struct {
	// ID is the unique identifier for this telemetry instance
	ID string
	// Name is the name of the telemetry instance
	Name string
	// Logger is the Logger instance for this telemetry
	Logger l.Logger
	// Type is the type of telemetry (e.g., CPU, Memory, etc.)
	Type string
}

// TelemetryMutex is a struct that holds mutexes for synchronizing access to telemetry data
type TelemetryMutex struct {
	// mutex is a mutex for synchronizing access to the telemetry data
	mutex *sync.RWMutex
	// mutexL is a mutex for synchronizing access to the Logger
	mutexL *sync.RWMutex
	// mutexC is a mutex for synchronizing access to the channels
	mutexC *sync.RWMutex
	// mutexW is a mutex for synchronizing access to the wait group
	mutexW *sync.RWMutex
}

// TelemetryChannel is a struct that holds channels for telemetry data
type TelemetryChannel struct {
	// channelOut is a channel for sending telemetry data
	channelOut chan map[string]float64
	// channelIn is a channel for receiving telemetry data
	channelIn chan map[string]float64
	// channelErr is a channel for sending error messages
	channelErr chan error
	// channelDone is a channel for signaling when the telemetry is done
	channelDone chan struct{}
	// channelExit is a channel for signaling when the telemetry should exit
	channelExit chan struct{}
}

// TelemetryData is a struct that holds telemetry data
type TelemetryData struct {
	// LastUpdated is the last time the telemetry data was updated
	LastUpdated time.Time
	// Metrics is a map of metric names to their values
	Metrics map[string]float64
}

// TelemetryLogger is a struct that holds a Logger for telemetry data
type TelemetryLogger struct {
	// logger is the logger instance
	logger l.Logger
}

// TelemetryProperty is a struct that holds a property for telemetry data
type TelemetryProperty struct {
	// property is the property instance
	property any
}

// TelemetryConfig is a struct that holds the configuration for telemetry data
type TelemetryConfig struct {
	// config is the configuration instance
	config any
}

// Telemetry is a struct that holds telemetry data for a process
type Telemetry struct {
	// TelemetryIdentifier is the identifier for telemetry data
	TelemetryIdentifier
	// TelemetryLogger is the Logger for telemetry data
	TelemetryLogger
	// TelemetryData is the telemetry data
	TelemetryData
	// TelemetryMutex is a mutex for synchronizing access to the telemetry data
	TelemetryMutex
	// TelemetryChannel is a struct that holds channels for telemetry data
	TelemetryChannel
	// TelemetryProperty is a struct that holds a property for telemetry data
	TelemetryProperty
	// TelemetryConfig is a struct that holds the configuration for telemetry data
	TelemetryConfig
}

// NewTelemetry creates a new Telemetry instance
func NewTelemetry() *Telemetry {
	return &Telemetry{
		TelemetryIdentifier: TelemetryIdentifier{
			ID:     "default",
			Name:   "default",
			Logger: l.GetLogger("Telemetry"),
			Type:   "default",
		},
		TelemetryLogger: TelemetryLogger{
			logger: l.GetLogger("Telemetry"),
		},
		TelemetryData: TelemetryData{
			LastUpdated: time.Now(),
			Metrics:     make(map[string]float64),
		},
		TelemetryMutex: TelemetryMutex{
			mutex:  &sync.RWMutex{},
			mutexL: &sync.RWMutex{},
			mutexC: &sync.RWMutex{},
			mutexW: &sync.RWMutex{},
		},
		TelemetryChannel: TelemetryChannel{
			channelOut:  make(chan map[string]float64, 1),
			channelIn:   make(chan map[string]float64, 1),
			channelErr:  make(chan error, 1),
			channelDone: make(chan struct{}, 1),
			channelExit: make(chan struct{}, 1),
		},
	}
}

// UpdateMetrics updates the telemetry metrics with the given data
func (t *Telemetry) UpdateMetrics(data map[string]float64) {
	t.mutex.Lock()
	defer t.mutex.Unlock()
	t.LastUpdated = time.Now()
	for key, value := range data {
		t.Metrics[key] = value
	}
}

// GetMetrics returns the telemetry metrics
func (t *Telemetry) GetMetrics() map[string]float64 {
	t.mutex.RLock()
	defer t.mutex.RUnlock()
	return t.Metrics
}

// GetLastUpdated returns the last updated time of the telemetry
func (t *Telemetry) GetLastUpdated() time.Time {
	t.mutex.RLock()
	defer t.mutex.RUnlock()
	return t.LastUpdated
}

// ResetMetrics resets the telemetry metrics
func (t *Telemetry) ResetMetrics() {
	t.mutex.Lock()
	defer t.mutex.Unlock()
	t.Metrics = make(map[string]float64)
	t.LastUpdated = time.Now()
}

/// internal/types/utils.go ///
package types

import (
	"fmt"
	"io"
	"os"

	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"
)

func IsShellSpecialVar(c uint8) bool {
	switch c {
	case '*', '#', '$', '@', '!', '?', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':
		return true
	}
	return false
}
func IsAlphaNum(c uint8) bool {
	return c == '_' || '0' <= c && c <= '9' || 'a' <= c && c <= 'z' || 'A' <= c && c <= 'Z'
}
func screeningByRAMSize(env ci.IEnvironment, filePath string) string {
	memAvailable := env.MemTotal()

	fileInfo, err := os.Stat(filePath)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Erro ao obter tamanho do arquivo: %v", err))
		return "fallback"
	}

	// Se a mem√≥ria dispon√≠vel for menor que 100MB E arquivo for grande (>5MB), usa strings
	if memAvailable < 100 && fileInfo.Size() > 5*1024*1024 {
		return "strings"
	}
	return "json"
}
func asyncCopyFile(src, dst string) error {
	go func() {
		_, err := copyFile(src, dst)
		if err != nil {
			fmt.Printf("Erro ao fazer backup do arquivo: %v\n", err)
		}
	}()
	return nil
}
func copyFile(src, dst string) (int64, error) {
	source, err := os.Open(src)
	if err != nil {
		return 0, err
	}
	defer func(source *os.File) {
		_ = source.Close()
	}(source)

	destination, err := os.Create(dst)
	if err != nil {
		return 0, err
	}
	defer func(destination *os.File) {
		_ = destination.Close()
	}(destination)

	return io.Copy(destination, source)
}

/// internal/types/validation.go ///
package types

import (
	"reflect"

	"github.com/google/uuid"
	ci "github.com/rafa-mori/gdbase/internal/interfaces"

	"fmt"
	"sort"
	"sync"
)

type ValidationResult struct {
	*Mutexes
	*Reference
	IsValid  bool
	Message  string
	Error    error
	Metadata map[string]any
	Callback func(result *ValidationResult)
}

func newValidationResult(isValid bool, message string, metadata map[string]any, err error) *ValidationResult {
	if metadata == nil {
		metadata = make(map[string]any)
	}
	return &ValidationResult{
		Mutexes:   NewMutexesType(),
		Reference: newReference("ValidationResult"),
		IsValid:   isValid,
		Message:   message,
		Error:     err,
		Metadata:  metadata,
	}
}
func NewValidationResult(isValid bool, message string, metadata map[string]any, err error) ci.IValidationResult {
	return newValidationResult(isValid, message, metadata, err)
}

func (vr *ValidationResult) String() string {
	if vr == nil {
		return ""
	}
	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()
	if vr.IsValid {
		return "Validation is valid"
	}
	if vr.Error != nil {
		return fmt.Sprintf("Validation is invalid: %s", vr.Error.Error())
	}
	return fmt.Sprintf("Validation is invalid: %s", vr.Message)
}
func (vr *ValidationResult) GetID() uuid.UUID {
	if vr == nil {
		return uuid.Nil
	}
	return vr.Reference.GetID()
}
func (vr *ValidationResult) GetName() string {
	if !reflect.ValueOf(vr).IsValid() {
		return ""
	}
	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()
	return vr.Reference.GetName()
}
func (vr *ValidationResult) GetIsValid() bool {
	if vr == nil {
		return false
	}
	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()
	return vr.IsValid
}
func (vr *ValidationResult) GetMessage() string {
	if vr == nil {
		return ""
	}
	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()
	return vr.Message
}
func (vr *ValidationResult) GetMetadata(key string) (any, bool) {
	if !reflect.ValueOf(vr.Metadata).IsValid() {
		vr.Mutexes.MuLock()
		defer vr.Mutexes.MuUnlock()

		vr.Metadata = make(map[string]any)
		return nil, false
	}

	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()

	if key == "" {
		return vr.Metadata, true
	}
	value, exists := vr.Metadata[key]

	return value, exists
}
func (vr *ValidationResult) SetMetadata(key string, value any) {
	if vr == nil {
		return
	}
	vr.Mutexes.MuLock()
	defer vr.Mutexes.MuUnlock()

	if vr.Metadata == nil {
		vr.Metadata = make(map[string]any)
	}
	if !reflect.ValueOf(value).IsValid() {
		return
	}
	if key == "" {
		return
	} else if key == "all" {
		if vl, ok := value.(map[string]any); ok {
			vr.Metadata = vl
			return
		} else if vl, ok := value.(ValidationResult); ok {
			vr.Metadata = vl.Metadata
			return
		}
	}

	vr.Metadata[key] = value
}
func (vr *ValidationResult) GetAllMetadataKeys() []string {
	if vr == nil || vr.Metadata == nil {
		return nil
	}

	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()

	keys := make([]string, 0, len(vr.Metadata))
	for key := range vr.Metadata {
		keys = append(keys, key)
	}
	return keys
}
func (vr *ValidationResult) GetError() error {
	if vr == nil {
		return nil
	}
	return vr.Error
}

type ValidationFunc[T any] struct {
	Priority int
	Func     func(value *T, args ...any) ci.IValidationResult
	Result   ci.IValidationResult
}

func newValidationFunc[T any](priority int, f func(value *T, args ...any) ci.IValidationResult) *ValidationFunc[T] {
	return &ValidationFunc[T]{
		Priority: priority,
		Func:     f,
		Result:   nil,
	}
}
func NewValidationFunc[T any](priority int, f func(value *T, args ...any) ci.IValidationResult) ci.IValidationFunc[T] {
	validFunc := newValidationFunc[T](priority, nil)
	validFunc.Func = f
	return validFunc
}

func (vf *ValidationFunc[T]) GetPriority() int {
	if vf == nil {
		return -1
	}
	return vf.Priority
}
func (vf *ValidationFunc[T]) SetPriority(priority int) {
	if vf == nil {
		return
	}
	vf.Priority = priority
}
func (vf *ValidationFunc[T]) GetFunction() func(value *T, args ...any) ci.IValidationResult {
	if vf == nil {
		return nil
	}
	return vf.Func
}
func (vf *ValidationFunc[T]) SetFunction(f func(value *T, args ...any) ci.IValidationResult) {
	if vf == nil {
		return
	}
	vf.Func = f
}
func (vf *ValidationFunc[T]) GetResult() ci.IValidationResult {
	if vf == nil {
		return nil
	}
	return vf.Result
}
func (vf *ValidationFunc[T]) SetResult(result ci.IValidationResult) {
	if vf == nil {
		return
	}
	vf.Result = result
}

// Validation is a struct that holds the validation function and the errors.
type Validation[T any] struct {
	mu sync.RWMutex
	// isValid is a boolean that indicates if the value is valid.
	isValid bool
	// hasValidate is a boolean that indicates if the value will be validated.
	hasValidation bool
	// validatorMap is the map of validators.
	validatorMap sync.Map
	// validateFunc is the function that validates the value.
	validateFunc func(value *T, args ...any) ci.IValidationResult
}

// vldtFunc is a function that validates the value.
func vldtFunc[T any](v *Validation[T]) func(value *T, args ...any) ci.IValidationResult {
	return func(value *T, args ...any) ci.IValidationResult {
		if v == nil {
			return newValidationResult(false, "validation is nil", nil, fmt.Errorf("validation is nil"))
		}
		if !v.IsValid() {
			return newValidationResult(false, "validation is invalid", nil, fmt.Errorf("validation is invalid"))
		}

		for _, arg := range args {
			if validator, ok := arg.(*ValidationFunc[T]); ok {
				if validator.Func != nil {
					result := validator.Func(value, args...)
					if result != nil && !result.GetIsValid() {
						return result
					}
				}
			}
		}

		return newValidationResult(true, "validation is valid", nil, nil)
	}
}

func VldtFunc[T any](v ci.IValidation[T]) func(value *T, args ...any) ci.IValidationResult {
	return func(value *T, args ...any) ci.IValidationResult {
		if v == nil {
			return NewValidationResult(false, "validation is nil", nil, fmt.Errorf("validation is nil"))
		}
		if !v.IsValid() {
			return NewValidationResult(false, "validation is invalid", nil, fmt.Errorf("validation is invalid"))
		}

		//v.mu.Lock()
		//defer v.mu.Unlock()

		for _, arg := range args {
			if validator, ok := arg.(ci.IValidationFunc[T]); ok {
				if validator.GetFunction() != nil {
					result := validator.GetFunction()(value, args...)
					if result != nil && !result.GetIsValid() {
						return result
					}
				}
			}
		}

		return NewValidationResult(true, "validation is valid", nil, nil)
	}
}

func newValidation[T any]() *Validation[T] {
	validation := &Validation[T]{
		isValid:      false,
		validatorMap: sync.Map{},
	}
	validation.validateFunc = vldtFunc(validation)
	return validation
}
func NewValidation[T any]() ci.IValidation[T] {
	validation := &Validation[T]{
		isValid:      false,
		validatorMap: sync.Map{},
	}
	validation.validateFunc = vldtFunc(validation)
	return validation
}

func (v *Validation[T]) CheckIfWillValidate() bool {
	if v == nil {
		return false
	}

	v.mu.RLock()
	defer v.mu.RUnlock()

	hasValidator := false
	v.validatorMap.Range(func(key, value any) bool {
		if _, vld := key.(int); vld {
			if _, ok := value.(ValidationFunc[T]); ok {
				hasValidator = true
				return false
			}
		}
		return true
	})
	v.hasValidation = hasValidator
	return hasValidator
}

// Validate is the function that validates the value.
func (v *Validation[T]) Validate(value *T, args ...any) ci.IValidationResult {
	if v == nil {
		return NewValidationResult(false, "validation is nil", nil, fmt.Errorf("validation is nil"))
	}
	if value == nil {
		return NewValidationResult(false, "value is nil", nil, fmt.Errorf("value is nil"))
	}
	if !v.hasValidation {
		return NewValidationResult(false, "validation has no validators", nil, fmt.Errorf("validation has no validators"))
	}

	v.mu.Lock()
	defer v.mu.Unlock()

	results := make([]ci.IValidationResult, 0)
	v.validatorMap.Range(func(key, val any) bool {
		if validator, ok := val.(ValidationFunc[T]); ok {
			result := validator.Func(value, args...)
			results = append(results, result)
			if result != nil && !result.GetIsValid() {
				v.isValid = false
				return false
			}
		}
		return true
	})

	if len(results) > 0 {
		sort.Slice(results, func(i, j int) bool {
			return results[i].GetMessage() < results[j].GetMessage()
		})
	}

	v.isValid = true
	for _, result := range results {
		if result != nil && !result.GetIsValid() {
			v.isValid = false
			break
		}
	}

	return NewValidationResult(v.isValid, "validation is valid", nil, nil)
}

// AddValidator is a function that adds a validator to the map of validators.
func (v *Validation[T]) AddValidator(validator ci.IValidationFunc[T]) error {
	if v == nil {
		return fmt.Errorf("validation is nil")
	}

	// Will update v.hasValidation always, if this method is called.
	v.CheckIfWillValidate()

	if validator.GetFunction() == nil {
		return fmt.Errorf("validator function is nil")
	}
	if validator.GetPriority() < 0 {
		return fmt.Errorf("priority must be greater than or equal to 0")
	}
	if _, ok := v.validatorMap.LoadOrStore(validator.GetPriority(), validator); ok {
		return fmt.Errorf("validator with priority %d already exists", validator.GetPriority())
	}

	// If the validator was added, we need to update v.hasValidation again, just for safety.
	v.CheckIfWillValidate()

	return nil
}

// RemoveValidator is a function that removes a validator from the map of validators.
func (v *Validation[T]) RemoveValidator(priority int) error {
	if v == nil {
		return fmt.Errorf("validation is nil")
	}
	if _, ok := v.validatorMap.LoadAndDelete(priority); !ok {
		return fmt.Errorf("validator with priority %d does not exist", priority)
	}

	// If the validator was removed, we need to update v.hasValidation.
	v.CheckIfWillValidate()

	return nil
}

// GetValidator is a function that gets a validator from the map of validators.
func (v *Validation[T]) GetValidator(priority int) (any, error) {
	if v == nil {
		return nil, fmt.Errorf("validation is nil")
	}
	if !v.hasValidation {
		return nil, fmt.Errorf("validation has no validators")
	}
	if validator, ok := v.validatorMap.Load(priority); ok {
		return validator, nil
	}
	return nil, fmt.Errorf("validator with priority %d does not exist", priority)
}

// GetValidators is a function that gets the map of validators.
func (v *Validation[T]) GetValidators() map[int]ci.IValidationFunc[T] {
	if v == nil {
		return nil
	}
	if !v.hasValidation {
		return nil
	}
	validatorMapSnapshot := make(map[int]ci.IValidationFunc[T])
	v.validatorMap.Range(func(key, value any) bool {
		if validator, ok := value.(ci.IValidationFunc[T]); ok {
			validatorMapSnapshot[validator.GetPriority()] = validator
		}
		return true
	})
	return validatorMapSnapshot
}

// GetResults is a function that gets the map of errors.
func (v *Validation[T]) GetResults() map[int]ci.IValidationResult {
	if v == nil {
		return nil
	}
	if !v.hasValidation {
		return nil
	}
	results := make(map[int]ci.IValidationResult)
	v.validatorMap.Range(func(key, value any) bool {
		if validator, ok := value.(ci.IValidationFunc[T]); ok {
			results[validator.GetPriority()] = validator.GetResult()
		}
		return true
	})
	return results
}

// ClearResults is a function that clears the map of errors.
func (v *Validation[T]) ClearResults() {
	if v == nil {
		return
	}
	if !v.hasValidation {
		return
	}
	v.validatorMap.Range(func(key, value any) bool {
		if validator, ok := value.(ValidationFunc[T]); ok {
			validator.Result = nil
			v.validatorMap.Store(key, validator)
		}
		return true
	})
}

// IsValid is a function that gets the boolean that indicates if the value is valid.
func (v *Validation[T]) IsValid() bool {
	if v == nil {
		// If the validation is nil, we need to return false.
		// But we will Log that the validation is nil.
		return false
	}
	if !v.hasValidation {
		// If the validation has no validators, we need to return false.
		// But we will Log that the validation has no validators.
		return false
	}
	return v.isValid
}

/// internal/types/validation_listener.go ///
package types

import (
	"reflect"

	gl "github.com/rafa-mori/gdbase/logger"
)

type ValidationListenerType string

const (
	ValidationListenerTypeBefore  ValidationListenerType = "before"  // Before validation
	ValidationListenerTypeAfter   ValidationListenerType = "after"   // After validation
	ValidationListenerTypeError   ValidationListenerType = "error"   // Error validation
	ValidationListenerTypeSuccess ValidationListenerType = "success" // Success validation
	ValidationListenerTypeDefault ValidationListenerType = "default" // Default validation
)

type ValidationFilterType string

const (
	ValidationFilterTypeEvent    ValidationFilterType = "event"    // Event filter
	ValidationFilterTypeListener ValidationFilterType = "listener" // Listener filter
	ValidationFilterTypeResult   ValidationFilterType = "result"   // Result filter
)

type ValidationListener struct {
	*Mutexes
	Filters   map[ValidationFilterType]func(*ValidationResult) bool
	Handlers  []func(*ValidationResult)
	Listeners map[Reference]map[ValidationListenerType]func(*ValidationResult)
}

func NewValidationListener() *ValidationListener {
	return &ValidationListener{
		Mutexes:   NewMutexesType(),
		Listeners: make(map[Reference]map[ValidationListenerType]func(*ValidationResult)),
		Filters:   make(map[ValidationFilterType]func(*ValidationResult) bool),
		Handlers:  []func(*ValidationResult){},
	}
}

func (vl *ValidationListener) AddFilter(filterType ValidationFilterType, filter func(*ValidationResult) bool) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	if vl.Filters == nil {
		vl.Filters = make(map[ValidationFilterType]func(*ValidationResult) bool)
	}
	if filter == nil {
		gl.Log("error", "RegisterListener: filter is nil")
		return
	}

	vl.Filters[filterType] = filter
}

func (vl *ValidationListener) RemoveFilter(filterType ValidationFilterType) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	delete(vl.Filters, filterType)
}

func (vl *ValidationListener) AddHandler(handler func(*ValidationResult)) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	vl.Handlers = append(vl.Handlers, handler)
}

func (vl *ValidationListener) RemoveHandler(handler func(*ValidationResult)) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	for i, h := range vl.Handlers {
		if reflect.ValueOf(h).Pointer() == reflect.ValueOf(handler).Pointer() {
			vl.Handlers = append(vl.Handlers[:i], vl.Handlers[i+1:]...)
			break
		}
	}
}

func (vl *ValidationListener) AddListener(reference Reference, listenerType ValidationListenerType, handler func(*ValidationResult)) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	if _, exists := vl.Listeners[reference]; !exists {
		vl.Listeners[reference] = make(map[ValidationListenerType]func(*ValidationResult))
	}
	vl.Listeners[reference][listenerType] = handler
}

func (vl *ValidationListener) RemoveListener(reference Reference, listenerType ValidationListenerType) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	if _, exists := vl.Listeners[reference]; exists {
		delete(vl.Listeners[reference], listenerType)
		if len(vl.Listeners[reference]) == 0 {
			delete(vl.Listeners, reference)
		}
	}
}

func (vl *ValidationListener) GetFilters() map[string]func(*ValidationResult) bool {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	filters := make(map[string]func(*ValidationResult) bool)
	for k, v := range vl.Filters {
		if v == nil {
			gl.Log("error", "RegisterListener: filter is nil")
			continue
		}
		filters[string(k)] = v
	}
	return filters
}

func (vl *ValidationListener) GetHandlersByName(name string) []func(*ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	for _, handler := range vl.Handlers {
		if handler == nil {
			gl.Log("error", "RegisterListener: handler is nil")
			continue
		}
		if name == "" {
			gl.Log("error", "RegisterListener: name is empty")
			continue
		}
		return []func(*ValidationResult){handler}
	}
	return nil
}

func (vl *ValidationListener) GetHandlers() []func(*ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	handlers := make([]func(*ValidationResult), len(vl.Handlers))
	copy(handlers, vl.Handlers)
	return handlers
}

func (vl *ValidationListener) GetListeners() map[Reference]map[ValidationListenerType]func(*ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	listeners := make(map[Reference]map[ValidationListenerType]func(*ValidationResult))
	for k, v := range vl.Listeners {
		listeners[k] = v
	}
	return listeners
}

func (vl *ValidationListener) GetListenersByName(name string) map[ValidationListenerType]func(*ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	for k, v := range vl.Listeners {
		if k.GetName() == name {
			return v
		}
	}
	return nil
}

func (vl *ValidationListener) GetListenersKeys() map[string]Reference {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	keys := make(map[string]Reference)
	for k := range vl.Listeners {
		keys[k.GetName()] = k
	}
	return keys
}

func (vl *ValidationListener) RegisterListener(reference Reference, handler func(*ValidationResult)) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	if handler == nil {
		gl.Log("error", "RegisterListener: handler is nil")
		return
	}

	if _, exists := vl.Listeners[reference]; !exists {
		vl.Listeners[reference] = make(map[ValidationListenerType]func(*ValidationResult))
	}
	vl.Listeners[reference][ValidationListenerTypeDefault] = handler
}

func (vl *ValidationListener) Trigger(event string, result *ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}

	vl.Mutexes.MuRLock()
	defer vl.Mutexes.MuRUnlock()

	if result == nil {
		gl.Log("error", "RegisterListener: result is nil")
		return
	}
	if event == "" {
		gl.Log("error", "RegisterListener: event is empty")
		return
	}

	if listenerZ := vl.GetListenersByName(event); listenerZ != nil {
		// Check event filters
		for _, filter := range vl.Filters {
			if filter == nil {
				gl.Log("error", "RegisterListener: filter is nil")
				continue
			}
			if !filter(result) {
				gl.Log("info", "RegisterListener: filter failed")
				return
			}
		}
		for _, listener := range listenerZ {
			if listener == nil {
				gl.Log("error", "RegisterListener: listener is nil")
				continue
			}
			// Check listener filters
			for _, filter := range vl.Filters {
				if filter == nil {
					gl.Log("error", "RegisterListener: filter is nil")
					continue
				}
				if !filter(result) {
					gl.Log("info", "RegisterListener: filter failed")
					return
				}
			}
			// Async dispatch
			go listener(result)
		}
	}
}

/// logger/logger.go ///
package logger

import (
	"fmt"
	"reflect"
	"runtime"
	"strings"

	l "github.com/rafa-mori/logz"
)

type gLog struct {
	l.Logger
	gLogLevel LogType
}

var (
	// debug is a boolean that indicates whether to log debug messages.
	debug bool
	// g is the global logger instance.
	g *gLog = &gLog{
		Logger:    l.GetLogger("GoBE - Test"),
		gLogLevel: LogTypeInfo,
	}
)

func init() {
	// Set the debug flag to true for testing purposes.
	debug = false
	// Initialize the global logger instance with a default logger.
	if g.Logger == nil {
		g = &gLog{
			Logger:    l.GetLogger("GoBE - Test"),
			gLogLevel: LogTypeInfo,
		}
	}
}

type LogType string

const (
	LogTypeNotice  LogType = "notice"
	LogTypeInfo    LogType = "info"
	LogTypeDebug   LogType = "debug"
	LogTypeError   LogType = "error"
	LogTypeWarn    LogType = "warn"
	LogTypeFatal   LogType = "fatal"
	LogTypePanic   LogType = "panic"
	LogTypeSuccess LogType = "success"
)

// SetDebug is a function that sets the debug flag for logging.
func SetDebug(d bool) { debug = d }

// LogObjLogger is a function that logs messages with the specified log type.
func LogObjLogger[T any](obj *T, logType string, messages ...string) {
	if obj == nil {
		g.ErrorCtx(fmt.Sprintf("log object (%s) is nil", reflect.TypeFor[T]()), map[string]any{
			"context":  "Log",
			"logType":  logType,
			"object":   obj,
			"msg":      messages,
			"showData": true,
		})
		return
	}
	var lgr l.Logger
	vlr := reflect.ValueOf(obj)
	if objValueLogger := vlr.Elem().MethodByName("GetLogger"); !objValueLogger.IsValid() {
		if objValueLogger = vlr.Elem().FieldByName("Logger"); !objValueLogger.IsValid() {
			g.ErrorCtx(fmt.Sprintf("log object (%s) does not have a logger field", reflect.TypeFor[T]()), map[string]any{
				"context":  "Log",
				"logType":  logType,
				"object":   obj,
				"msg":      messages,
				"showData": true,
			})
			return
		} else {
			lgrC := objValueLogger.Convert(reflect.TypeFor[l.Logger]())
			if lgrC.IsNil() {
				lgrC = reflect.ValueOf(g.Logger)
			}
			if lgr = lgrC.Interface().(l.Logger); lgr == nil {
				lgr = g.Logger
			}
		}
	} else {
		//lgrC := objValueLogger.Call(nil)[0].Convert(reflect.TypeFor[l.Logger]())
		//if lgrC.IsNil() {
		//	lgrC = reflect.ValueOf(g.Logger)
		//}
		//if lgr = lgrC.Interface().(l.Logger); lgr == nil {
		lgr = g.Logger
		//}
	}
	pc, file, line, ok := runtime.Caller(1)
	if !ok {
		lgr.ErrorCtx("Log: unable to get caller information", nil)
		return
	}
	funcName := runtime.FuncForPC(pc).Name()
	ctxMessageMap := map[string]any{
		"context":  funcName,
		"file":     file,
		"line":     line,
		"showData": debug,
	}
	fullMessage := strings.Join(messages, " ")
	logType = strings.ToLower(logType)
	if logType != "" {
		if reflect.TypeOf(logType).ConvertibleTo(reflect.TypeFor[LogType]()) {
			lType := LogType(logType)
			ctxMessageMap["logType"] = logType
			logging(lgr, lType, fullMessage, ctxMessageMap)
		} else {
			lgr.ErrorCtx(fmt.Sprintf("logType (%s) is not valid", logType), ctxMessageMap)
		}
	} else {
		lgr.InfoCtx(fullMessage, ctxMessageMap)
	}
}

// Log is a function that logs messages with the specified log type and caller information.
func Log(logType string, messages ...any) {
	pc, file, line, ok := runtime.Caller(1)
	if !ok {
		g.ErrorCtx("Log: unable to get caller information", nil)
		return
	}
	funcName := runtime.FuncForPC(pc).Name()
	ctxMessageMap := map[string]any{
		"context":  funcName,
		"file":     file,
		"line":     line,
		"showData": debug,
	}
	fullMessage := ""
	if len(messages) > 0 {
		fullMessage = fmt.Sprintf("%v", messages[0:])
	}
	logType = strings.ToLower(logType)
	if logType != "" {
		if reflect.TypeOf(logType).ConvertibleTo(reflect.TypeFor[LogType]()) {
			lType := LogType(logType)
			ctxMessageMap["logType"] = logType
			logging(g.Logger, lType, fullMessage, ctxMessageMap)
		} else {
			g.ErrorCtx(fmt.Sprintf("logType (%s) is not valid", logType), ctxMessageMap)
		}
	} else {
		g.InfoCtx(fullMessage, ctxMessageMap)
	}
}

// logging is a helper function that logs messages with the specified log type.
func logging(lgr l.Logger, lType LogType, fullMessage string, ctxMessageMap map[string]interface{}) {
	debugCtx := debug
	if !debugCtx {
		if lType == "error" || lType == "fatal" || lType == "panic" || lType == "debug" {
			// If debug is false, set the debug value based on the logType
			debugCtx = true
		} else {
			debugCtx = false
		}
	}
	ctxMessageMap["showData"] = debugCtx
	switch lType {
	case LogTypeInfo:
		lgr.InfoCtx(fullMessage, ctxMessageMap)
	case LogTypeDebug:
		lgr.DebugCtx(fullMessage, ctxMessageMap)
	case LogTypeError:
		lgr.ErrorCtx(fullMessage, ctxMessageMap)
	case LogTypeWarn:
		lgr.WarnCtx(fullMessage, ctxMessageMap)
	case LogTypeNotice:
		lgr.NoticeCtx(fullMessage, ctxMessageMap)
	case LogTypeSuccess:
		lgr.SuccessCtx(fullMessage, ctxMessageMap)
	case LogTypeFatal:
		lgr.FatalCtx(fullMessage, ctxMessageMap)
	case LogTypePanic:
		lgr.FatalCtx(fullMessage, ctxMessageMap)
	default:
		lgr.InfoCtx(fullMessage, ctxMessageMap)
	}
	debugCtx = debug
}

/// services/db_service.go ///
package services

import (
	t "github.com/rafa-mori/gdbase/types"
	"gorm.io/gorm"
)

type IDBService interface {
	Initialize() error
	GetDB() (*gorm.DB, error)
	CloseDBConnection() error
	CheckDatabaseHealth() error
	IsConnected() error
	Reconnect() error
	GetHost() (string, error)
	GetConfig() *t.DBConfig
}

/// support/composer.sh ///
#!/bin/bash

# Define o diret√≥rio base
BASE_DIR="lib"

# Lista de arquivos a serem criados
FILES=(
  "config.sh"
  "utils.sh"
  "platform.sh"
  "build.sh"
  "validate.sh"
  "install_funcs.sh"
  "info.sh"
)

# Cria o diret√≥rio base, se ainda n√£o existir
mkdir -p "$BASE_DIR"

# Cria os arquivos dentro do diret√≥rio
for file in "${FILES[@]}"; do
  FILE_PATH="$BASE_DIR/$file"
  if [[ ! -f "$FILE_PATH" ]]; then
    touch "$FILE_PATH"
    printf '%s' "#!/bin/bash" | tee "$FILE_PATH" >/dev/null
    printf '%s' "# $file - script placeholder" | tee -a "$FILE_PATH" >/dev/null
    chmod +x "$FILE_PATH"
    echo "Criado: $FILE_PATH"
  else
    echo "J√° existe: $FILE_PATH"
  fi
done


/// support/config.sh ///
#!/usr/bin/env bash

set -euo pipefail
set -o errtrace
set -o functrace
set -o posix
IFS=$'\n\t'

# Define o diret√≥rio raiz (assumindo que este script est√° em lib/ no root)
_ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
_APP_NAME="${APP_NAME:-$(basename "${_ROOT_DIR}")}"
_PROJECT_NAME="$_APP_NAME"
_OWNER="${OWNER:-rafa-mori}"
# Tenta ler a vers√£o, ou define um fallback
_VERSION=$(cat "$_ROOT_DIR/version/CLI_VERSION" 2>/dev/null || echo "v0.0.0")
# Extrai a vers√£o do Go do go.mod (certifique-se de que este arquivo exista na raiz)
_VERSION_GO=$(grep '^go ' "$_ROOT_DIR/go.mod" | awk '{print $2}')

_LICENSE="MIT"

_ABOUT="################################################################################
  Este script instala o projeto ${_PROJECT_NAME}, vers√£o ${_VERSION}.
  OS suportados: Linux, MacOS, Windows
  Arquiteturas suportadas: amd64, arm64, 386
  Fonte: https://github.com/${_OWNER}/${_PROJECT_NAME}
  Binary Release: https://github.com/${_OWNER}/${_PROJECT_NAME}/releases/latest
  License: ${_LICENSE}
  Notas:
    - [version] √© opcional; se omitido, a √∫ltima vers√£o ser√° utilizada.
    - Se executado localmente, o script tentar√° resolver a vers√£o pelos tags do reposit√≥rio.
    - Instala em ~/.local/bin para usu√°rio n√£o-root ou em /usr/local/bin para root.
    - Adiciona o diret√≥rio de instala√ß√£o √† vari√°vel PATH.
    - Instala o UPX se necess√°rio, ou compila o bin√°rio (build) conforme o comando.
    - Faz download do bin√°rio via URL de release ou efetua limpeza de artefatos.
    - Verifica depend√™ncias e vers√£o do Go.
################################################################################"

_BANNER="################################################################################

               ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà     ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà     ‚ñà‚ñà
              ‚ñë‚ñà‚ñà  ‚ñà‚ñà ‚ñë‚ñà‚ñà    ‚ñë‚ñà‚ñà‚ñë‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë ‚ñë‚ñë‚ñà‚ñà   ‚ñà‚ñà
              ‚ñë‚ñà‚ñà ‚ñà‚ñà  ‚ñë‚ñà‚ñà    ‚ñë‚ñà‚ñà‚ñë‚ñà   ‚ñë‚ñà‚ñà ‚ñë‚ñà‚ñà       ‚ñë‚ñë‚ñà‚ñà ‚ñà‚ñà
              ‚ñë‚ñà‚ñà‚ñà‚ñà   ‚ñë‚ñà‚ñà    ‚ñë‚ñà‚ñà‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñë‚ñë‚ñà‚ñà‚ñà
              ‚ñë‚ñà‚ñà‚ñë‚ñà‚ñà  ‚ñë‚ñà‚ñà    ‚ñë‚ñà‚ñà‚ñë‚ñà‚ñë‚ñë‚ñë‚ñë ‚ñà‚ñà‚ñë‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë     ‚ñà‚ñà‚ñë‚ñà‚ñà
              ‚ñë‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà ‚ñë‚ñà‚ñà    ‚ñë‚ñà‚ñà‚ñë‚ñà    ‚ñë‚ñà‚ñà‚ñë‚ñà‚ñà        ‚ñà‚ñà ‚ñë‚ñë‚ñà‚ñà
              ‚ñë‚ñà‚ñà ‚ñë‚ñë‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà   ‚ñë‚ñë‚ñà‚ñà
              ‚ñë‚ñë   ‚ñë‚ñë  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚ñë‚ñë     ‚ñë‚ñë"

# Caminhos para a compila√ß√£o
_CMD_PATH="$_ROOT_DIR/cmd"
_BUILD_PATH="$(dirname "$_CMD_PATH")"
_BINARY="$_BUILD_PATH/$_APP_NAME"

# Diret√≥rios de instala√ß√£o
_LOCAL_BIN="${HOME:-"~"}/.local/bin"
_GLOBAL_BIN="/usr/local/bin"

# Caso queira, defina o OWNER (use no get_release_url)
_OWNER="rafa-mori"

/// support/info.sh ///
#!/usr/bin/env bash
# lib/info.sh ‚Äì Fun√ß√µes para exibir banners e resumo de instala√ß√£o

show_about() {
    printf '%s\n\n' "${_ABOUT:-}"
}

show_banner() {
    printf '\n%s\n\n' "${_BANNER:-}"
}

show_headers() {
    show_banner || return 1
    show_about || return 1
}

summary() {
    local install_dir="$_BINARY"
    log success "Build e instala√ß√£o conclu√≠dos!"
    log success "Bin√°rio: $_BINARY"
    log success "Instalado em: ${install_dir}"
    check_path "$install_dir"
}

export -f show_about
export -f show_banner
export -f show_headers
export -f summary


/// support/install.sh ///
#!/usr/bin/env bash

set -euo pipefail
set -o errtrace
set -o functrace
set -o posix

IFS=$'\n\t'

_DEBUG=${DEBUG:-false}
_HIDE_ABOUT=${HIDE_ABOUT:-false}

# Carrega os arquivos de biblioteca
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
#shellcheck source=/dev/null
source "${SCRIPT_DIR}/config.sh"
#shellcheck source=/dev/null
source "${SCRIPT_DIR}/utils.sh"
#shellcheck source=/dev/null
source "${SCRIPT_DIR}/platform.sh"
#shellcheck source=/dev/null
source "${SCRIPT_DIR}/validate.sh"
#shellcheck source=/dev/null
source "${SCRIPT_DIR}/install_funcs.sh"
#shellcheck source=/dev/null
source "${SCRIPT_DIR}/build.sh"
#shellcheck source=/dev/null
source "${SCRIPT_DIR}/info.sh"

# Inicializa os traps
set_trap "$@"

clear_screen

main() {
  if ! what_platform; then
    log error "Plataforma n√£o suportada: ${_PLATFORM}"
    exit 1
  fi

  if [[ "${_DEBUG}" != true ]]; then
    show_headers
    if [[ -z "${_HIDE_ABOUT}" ]]; then
      show_about
    fi
  else
    log info "Modo debug ativado; banner ser√° ignorado..."
    if [[ -z "${_HIDE_ABOUT}" ]]; then
      show_about
    fi
  fi

  _ARGS=( "$@" )
  local default_label='Auto detect'
  local arrArgs=( "${_ARGS[@]:0:$#}" )
  local PLATFORM_ARG
  PLATFORM_ARG=$(_get_os_from_args "${arrArgs[1]:-${_PLATFORM}}")
  local ARCH_ARG
  ARCH_ARG=$(_get_arch_arr_from_args "${arrArgs[2]:-${_ARCH}}")

  log info "Comando: ${arrArgs[0]:-}" true
  log info "Plataforma: ${PLATFORM_ARG:-$default_label}" true
  log info "Arquitetura: ${ARCH_ARG:-$default_label}" true
  log info "Args: ${_ARGS[*]:-}" true

  case "${arrArgs[0]:-}" in
    build|BUILD|-b|-B)
      # validate_versions
      log info "Executando comando de build..."
      build_binary "${PLATFORM_ARG}" "${ARCH_ARG}" || exit 1
      ;;
    install|INSTALL|-i|-I)
      log info "Executando comando de instala√ß√£o..."
      read -r -p "Deseja baixar o bin√°rio pr√©-compilado? [y/N] (Caso contr√°rio, far√° build local): " choice </dev/tty
      log info "Escolha do usu√°rio: ${choice}"
      if [[ "$choice" == "y" || "$choice" == "Y" ]]; then
          log info "Baixando bin√°rio pr√©-compilado..."
          install_from_release
      else
          log info "Realizando build local..."
          validate_versions
          build_binary "${PLATFORM_ARG}" "${ARCH_ARG}" || exit 1
          install_binary
      fi
      summary
      ;;
    clear|clean|CLEAN|-c|-C)
      log info "Executando comando de limpeza..."
      clean_artifacts
      log success "Clean executado com sucesso."
      ;;
    *)
      log error "Comando inv√°lido: ${arrArgs[0]:-}"
      echo "Uso: $0 {build|install|clean}"
      ;;
  esac
}

# Fun√ß√£o para limpar artefatos de build
clean_artifacts() {
    log info "Limpando artefatos de build..."
    local platforms=("windows" "darwin" "linux")
    local archs=("amd64" "386" "arm64")
    for platform in "${platforms[@]}"; do
        for arch in "${archs[@]}"; do
            local output_name
            output_name=$(printf '%s_%s_%s' "${_BINARY}" "${platform}" "${arch}")
            if [[ "${platform}" != "windows" ]]; then
                local compress_name="${output_name}.tar.gz"
            else
                output_name="${output_name}.exe"
                local compress_name="${_BINARY}_${platform}_${arch}.zip"
            fi
            rm -f "${output_name}" || true
            rm -f "${compress_name}" || true
        done
    done
    log success "Artefatos de build removidos."
}

# echo "MAKE ARGS: ${ARGS[*]:-}"
log info "Starting installation script..."
main "$@"


/// support/install_funcs.sh ///
#!/usr/bin/env bash
# lib/install_funcs.sh ‚Äì Fun√ß√µes para instala√ß√£o e manipula√ß√£o de PATH

install_upx() {
    if ! command -v upx &> /dev/null; then
        if ! sudo -v &> /dev/null; then
            log error "Voc√™ n√£o tem permiss√µes de superusu√°rio para instalar o empacotador de bin√°rios."
            log warn "Se deseja o empacotamento de bin√°rios, instale o UPX manualmente."
            log warn "Veja: https://upx.github.io/"
            return 1
        fi
        if [[ "$(uname)" == "Darwin" ]]; then
            brew install upx >/dev/null
        elif command -v apt-get &> /dev/null; then
            sudo apt-get install -y upx >/dev/null
        elif command -v yum &> /dev/null; then
            sudo yum install -y upx >/dev/null
        elif command -v dnf &> /dev/null; then
            sudo dnf install -y upx >/dev/null
        elif command -v pacman &> /dev/null; then
            sudo pacman -S --noconfirm upx >/dev/null
        elif command -v zypper &> /dev/null; then
            sudo zypper install -y upx >/dev/null
        elif command -v apk &> /dev/null; then
            sudo apk add upx >/dev/null
        elif command -v port &> /dev/null; then
            sudo port install upx >/dev/null
        elif command -v snap &> /dev/null; then
            sudo snap install upx >/dev/null
        elif command -v flatpak &> /dev/null; then
            sudo flatpak install flathub org.uptane.upx -y >/dev/null
        else
            log warn "Se deseja o empacotamento de bin√°rios, instale o UPX manualmente."
            log warn "Veja: https://upx.github.io/"
            return 1
        fi
    fi

    return 0
}

detect_shell_rc() {
    local shell_rc_file
    local user_shell
    user_shell=$(basename "$SHELL")

    case "$user_shell" in
        bash) shell_rc_file="${HOME:-~}/.bashrc" ;;
        zsh) shell_rc_file="${HOME:-~}/.zshrc" ;;
        sh) shell_rc_file="${HOME:-~}/.profile" ;;
        fish) shell_rc_file="${HOME:-~}/.config/fish/config.fish" ;;
        *)
            log warn "Shell n√£o suportado; ajuste o PATH manualmente."
            return 1
            ;;
    esac
    
    if [ ! -f "$shell_rc_file" ]; then
        log error "Arquivo de configura√ß√£o n√£o encontrado: ${shell_rc_file}"
        return 1
    fi

    echo "$shell_rc_file"

    return 0
}

add_to_path() {
    local target_path="${1:-}"

    local shell_rc_file=""

    local path_expression=""

    path_expression="export PATH=\"${target_path}:\$PATH\""

    shell_rc_file="$(detect_shell_rc)"


    if [ -z "$shell_rc_file" ]; then
        log error "N√£o foi poss√≠vel identificar o arquivo de configura√ß√£o do shell."
        return 1
    fi
    if grep -q "${path_expression}" "$shell_rc_file" 2>/dev/null; then
        log success "$target_path j√° est√° no PATH do $shell_rc_file."
        return 0
    fi

    if [[ -z "${target_path}" ]]; then
        log error "Caminho de destino n√£o fornecido."
        return 1
    fi

    if [[ ! -d "${target_path}" ]]; then
        log error "Caminho de destino n√£o √© um diret√≥rio v√°lido: $target_path"
        return 1
    fi

    if [[ ! -f "${shell_rc_file}" ]]; then
        log error "Arquivo de configura√ß√£o n√£o encontrado: ${shell_rc_file}"
        return 1
    fi

    # echo "export PATH=${target_path}:\$PATH" >> "$shell_rc_file"
    printf '%s\n' "${path_expression}" | tee -a "$shell_rc_file" >/dev/null || {
        log error "Falha ao adicionar $target_path ao PATH em $shell_rc_file."
        return 1
    }

    log success "Adicionado $target_path ao PATH em $shell_rc_file."
    
    "$SHELL" -c "source ${shell_rc_file}" || {
        log warn "Falha ao recarregar o shell. Por favor, execute 'source ${shell_rc_file}' manualmente."
    }

    return 0
}

install_binary() {
    local SUFFIX="${_PLATFORM_WITH_ARCH}"
    local BINARY_TO_INSTALL="${_BINARY}${SUFFIX:+_${SUFFIX}}"
    log info "Instalando o bin√°rio: '${BINARY_TO_INSTALL}' como '$_APP_NAME'"

    if [ "$(id -u)" -ne 0 ]; then
        log info "Usu√°rio n√£o-root detectado. Instalando em ${_LOCAL_BIN}..."
        mkdir -p "$_LOCAL_BIN"
        cp "$BINARY_TO_INSTALL" "$_LOCAL_BIN/$_APP_NAME" || exit 1
        add_to_path "$_LOCAL_BIN"
    else
        log info "Usu√°rio root detectado. Instalando em ${_GLOBAL_BIN}..."
        cp "$BINARY_TO_INSTALL" "$_GLOBAL_BIN/$_APP_NAME" || exit 1
        add_to_path "$_GLOBAL_BIN"
    fi
}

download_binary() {
    if ! what_platform; then
        log error "Falha ao detectar a plataforma."
        return 1
    fi
    if [[ -z "${_PLATFORM}" ]]; then
        log error "Plataforma n√£o suportada: ${_PLATFORM}"
        return 1
    fi
    local version
    version=$(curl -s "https://api.github.com/repos/${_OWNER}/${_PROJECT_NAME}/releases/latest" | grep "tag_name" | cut -d '"' -f 4 || echo "latest")
    if [ -z "$version" ]; then
        log error "Falha ao determinar a √∫ltima vers√£o."
        return 1
    fi

    local release_url
    release_url=$(get_release_url)
    log info "Baixando o bin√°rio ${_APP_NAME} para OS=${_PLATFORM}, ARCH=${_ARCH}, Vers√£o=${version}..."
    log info "URL de Release: ${release_url}"

    local archive_path="${_TEMP_DIR}/${_APP_NAME}.tar.gz"
    if ! curl -L -o "${archive_path}" "${release_url}"; then
        log error "Falha ao baixar o bin√°rio de: ${release_url}"
        return 1
    fi
    log success "Bin√°rio baixado com sucesso."

    log info "Extraindo o bin√°rio para: $(dirname "${_BINARY}")"
    if ! tar -xzf "${archive_path}" -C "$(dirname "${_BINARY}")"; then
        log error "Falha ao extrair o bin√°rio de: ${archive_path}"
        rm -rf "${_TEMP_DIR}"
        exit 1
    fi

    rm -rf "${_TEMP_DIR}"
    log success "Bin√°rio extra√≠do com sucesso."

    if [ ! -f "$_BINARY" ]; then
        log error "Bin√°rio n√£o encontrado ap√≥s extra√ß√£o: ${_BINARY}"
        exit 1
    fi
    log success "Download e extra√ß√£o de ${_APP_NAME} conclu√≠dos!"
}

install_from_release() {
    download_binary
    install_binary
}

check_path() {
    log info "Verificando se o diret√≥rio de instala√ß√£o est√° no PATH..."
    if ! echo "$PATH" | grep -q "$1"; then
        log warn "$1 n√£o est√° no PATH."
        log warn "Adicione: export PATH=$1:\$PATH"
    else
        log success "$1 j√° est√° no PATH."
    fi
}

export -f install_upx
export -f detect_shell_rc
export -f add_to_path
export -f install_binary
export -f download_binary
export -f install_from_release
export -f check_path

/// support/platform.sh ///
#!/usr/bin/env bash

set -euo pipefail
set -o errtrace
set -o functrace
set -o posix
IFS=$'\n\t'

get_release_url() {
    local os="${_PLATFORM%%-*}"
    local format
    if [[ "$os" == "windows" ]]; then
      format="zip"
    else
      format="tar.gz"
    fi
    echo "'https://github.com/${_OWNER}/${_PROJECT_NAME}/releases/download/${_VERSION}/${_PROJECT_NAME}_.${format}'"
}

what_platform() {
  local _os
  _os="$(uname -s)"
  local _arch
  _arch="$(uname -m)"
  local platform=""

  case "${_os}" in
  *Linux*|*Nix*)
    _os="linux"
    case "${_arch}" in
      "x86_64") _arch="amd64" ;;
      "armv6") _arch="armv6l" ;;
      "armv8"|"aarch64") _arch="arm64" ;;
      *386*) _arch="386" ;;
    esac
    platform="linux-${_arch}"
    ;;
  *Darwin*)
    _os="darwin"
    case "${_arch}" in
      "x86_64") _arch="amd64" ;;
      "arm64") _arch="arm64" ;;
    esac
    platform="darwin-${_arch}"
    ;;
  MINGW*|MSYS*|CYGWIN*|Win*)
    _os="windows"
    case "${_arch}" in
      "x86_64") _arch="amd64" ;;
      "arm64") _arch="arm64" ;;
    esac
    platform="windows-${_arch}"
    ;;
  *)
    log error "Plataforma n√£o suportada: ${_os} ${_arch}"
    log error "Informe este problema aos mantenedores do projeto."
    return 1
    ;;
  esac

  export _PLATFORM_WITH_ARCH="${platform//-/_}"
  export _PLATFORM="${_os}"
  export _ARCH="${_arch}"

  return 0
}

_get_os_arr_from_args() {
  local _PLATFORM_ARG=$1
  if [[ "${_PLATFORM_ARG}" == "all" ]]; then
    echo "windows darwin linux"
  else
    echo "${_PLATFORM_ARG}"
  fi
}

_get_arch_arr_from_args() {
  local _ARCH_ARG=$1
  if [[ "${_ARCH_ARG}" == "all" ]]; then
    echo "amd64 386 arm64"
  else
    echo "${_ARCH_ARG}"
  fi
}

_get_os_from_args() {
  local arg=$1
  case "$arg" in
    all|ALL|a|A|-a|-A) echo "all" ;;
    win|WIN|windows|WINDOWS|w|W|-w|-W) echo "windows" ;;
    linux|LINUX|l|L|-l|-L) echo "linux" ;;
    darwin|DARWIN|macOS|MACOS|m|M|-m|-M) echo "darwin" ;;
    *)
      log error "Plataforma inv√°lida: '${arg}'. Op√ß√µes v√°lidas: windows, linux, darwin, all."
      exit 1
      ;;
  esac
}

_get_arch_from_args() {
  local arg=$1
  case "$arg" in
    all|ALL|a|A|-a|-A) echo "all" ;;
    amd64|AMD64|x86_64|X86_64|x64|X64) echo "amd64" ;;
    arm64|ARM64|aarch64|AARCH64) echo "arm64" ;;
    386|i386|I386) echo "386" ;;
    *)
      log error "Arquitetura inv√°lida: '${arg}'. Op√ß√µes v√°lidas: amd64, arm64, 386."
      exit 1
      ;;
  esac
}

export -f _get_os_arr_from_args
export -f _get_arch_arr_from_args
export -f _get_os_from_args
export -f _get_arch_from_args
export -f get_release_url
export -f what_platform

what_platform "${@}"

/// support/utils.sh ///
#!/usr/bin/env bash
# lib/utils.sh ‚Äì Fun√ß√µes utilit√°rias

set -euo pipefail
set -o errtrace
set -o functrace
set -o posix
IFS=$'\n\t'

# C√≥digos de cor para logs
_SUCCESS="\033[0;32m"
_WARN="\033[0;33m"
_ERROR="\033[0;31m"
_INFO="\033[0;36m"
_NC="\033[0m"

log() {
  local type=${1:-info}
  local message=${2:-}
  local debug=${3:-${DEBUG:-false}}

  case $type in
    info|_INFO|-i|-I)
      if [[ "$debug" == true ]]; then
        printf '%b[_INFO]%b ‚ÑπÔ∏è  %s\n' "$_INFO" "$_NC" "$message"
      fi
      ;;
    warn|_WARN|-w|-W)
      if [[ "$debug" == true ]]; then
        printf '%b[_WARN]%b ‚ö†Ô∏è  %s\n' "$_WARN" "$_NC" "$message"
      fi
      ;;
    error|_ERROR|-e|-E)
      printf '%b[_ERROR]%b ‚ùå  %s\n' "$_ERROR" "$_NC" "$message"
      ;;
    success|_SUCCESS|-s|-S)
      printf '%b[_SUCCESS]%b ‚úÖ  %s\n' "$_SUCCESS" "$_NC" "$message"
      ;;
    *)
      if [[ "$debug" == true ]]; then
        log "info" "$message" "$debug"
      fi
      ;;
  esac
}

clear_screen() {
  printf "\033[H\033[2J"
}

get_current_shell() {
  local shell_proc
  shell_proc=$(cat /proc/$$/comm)
  case "${0##*/}" in
    ${shell_proc}*)
      local shebang
      shebang=$(head -1 "$0")
      printf '%s\n' "${shebang##*/}"
      ;;
    *)
      printf '%s\n' "$shell_proc"
      ;;
  esac
}

# Cria um diret√≥rio tempor√°rio para cache
_TEMP_DIR="${_TEMP_DIR:-$(mktemp -d)}"
if [[ -d "${_TEMP_DIR}" ]]; then
    log info "Diret√≥rio tempor√°rio criado: ${_TEMP_DIR}"
else
    log error "Falha ao criar o diret√≥rio tempor√°rio."
fi

clear_script_cache() {
  trap - EXIT HUP INT QUIT ABRT ALRM TERM
  if [[ ! -d "${_TEMP_DIR}" ]]; then
    exit 0
  fi
  rm -rf "${_TEMP_DIR}" || true
  if [[ -d "${_TEMP_DIR}" ]] && sudo -v 2>/dev/null; then
    sudo rm -rf "${_TEMP_DIR}"
    if [[ -d "${_TEMP_DIR}" ]]; then
      printf '%b[_ERROR]%b ‚ùå  %s\n' "$_ERROR" "$_NC" "Falha ao remover o diret√≥rio tempor√°rio: ${_TEMP_DIR}"
    else
      printf '%b[_SUCCESS]%b ‚úÖ  %s\n' "$_SUCCESS" "$_NC" "Diret√≥rio tempor√°rio removido: ${_TEMP_DIR}"
    fi
  fi
  exit 0
}

set_trap() {
  local current_shell=""
  current_shell=$(get_current_shell)
  case "${current_shell}" in
    *ksh|*zsh|*bash)
      declare -a FULL_SCRIPT_ARGS=("$@")
      if [[ "${FULL_SCRIPT_ARGS[*]}" =~ -d ]]; then
          set -x
      fi
      if [[ "${current_shell}" == "bash" ]]; then
        set -o errexit
        set -o pipefail
        set -o errtrace
        set -o functrace
        shopt -s inherit_errexit
      fi
      trap 'clear_script_cache' EXIT HUP INT QUIT ABRT ALRM TERM
      ;;
  esac
}

/// support/validate.sh ///
#!/usr/bin/env bash
# lib/validate.sh ‚Äì Valida√ß√£o da vers√£o do Go e depend√™ncias

validate_versions() {
    local REQUIRED_GO_VERSION="${_VERSION_GO:-1.20.0}"
    local GO_VERSION
    GO_VERSION=$(go version | awk '{print $3}' | sed 's/go//')
    if [[ "$(printf '%s\n' "$REQUIRED_GO_VERSION" "$GO_VERSION" | sort -V | head -n1)" != "$REQUIRED_GO_VERSION" ]]; then
        log error "A vers√£o do Go deve ser >= $REQUIRED_GO_VERSION. Detectado: $GO_VERSION"
        exit 1
    fi
    log success "Vers√£o do Go v√°lida: $GO_VERSION"
    go mod tidy || return 1
}

check_dependencies() {
    for dep in "$@"; do
        if ! command -v "$dep" > /dev/null; then
            log error "$dep n√£o est√° instalado."
            exit 1
        else
            log success "$dep est√° instalado."
        fi
    done
}

export -f validate_versions
export -f check_dependencies

/// tests/bkp/KUBEX_LOCAL_TEST_A.session.sql ///
INSERT INTO products (
    id,
    external_id,
    sku,
    barcode,
    name,
    description,
    category,
    manufacturer,
    price,
    cost,
    weight,
    length,
    width,
    height,
    is_active,
    created_at,
    updated_at,
    last_sync_at,
    search_vector,
    min_stock_threshold,
    max_stock_threshold,
    reorder_point,
    lead_time_days,
    shelf_life_days
  )
VALUES (
    'id:uuid',
    'external_id:character varying',
    'sku:character varying',
    'barcode:character varying',
    'name:character varying',
    'description:text',
    'category:character varying',
    'manufacturer:character varying',
    price:numeric,
    cost:numeric,
    weight:numeric,
    length:numeric,
    width:numeric,
    height:numeric,
    is_active:boolean,
    'created_at:timestamp without time zone',
    'updated_at:timestamp without time zone',
    'last_sync_at:timestamp without time zone',
    'search_vector:tsvector',
    min_stock_threshold:integer,
    max_stock_threshold:integer,
    reorder_point:integer,
    lead_time_days:integer,
    shelf_life_days:integer
  );

/// tests/bkp/Makefile.txt ///
# Description: Makefile for building and installing a Go application
# Author: Rafael Mori
# Copyright (c) 2025 Rafael Mori
# License: MIT License

# This Makefile is used to build and install a Go application.
# It provides commands for building the binary, installing it, cleaning up build artifacts,
# and running tests. It also includes a help command to display usage information.
# The Makefile uses color codes for logging messages and provides a consistent interface
# for interacting with the application.

# Define the application name and root directory
private APP_NAME := $(shell echo $(basename $(CURDIR)) | tr '[:upper:]' '[:lower:]')
private ROOT_DIR := $(dir $(abspath $(lastword $(MAKEFILE_LIST))))
private BINARY_NAME := $(ROOT_DIR)$(APP_NAME)
private CMD_DIR := $(ROOT_DIR)cmd

# Define the color codes
private COLOR_GREEN := \033[32m
private COLOR_YELLOW := \033[33m
private COLOR_RED := \033[31m
private COLOR_BLUE := \033[34m
private COLOR_RESET := \033[0m

# Logging Functions
log = @printf "%b%s%b %s\n" "$(COLOR_BLUE)" "[LOG]" "$(COLOR_RESET)" "$(1)"
log_info = @printf "%b%s%b %s\n" "$(COLOR_BLUE)" "[INFO]" "$(COLOR_RESET)" "$(1)"
log_success = @printf "%b%s%b %s\n" "$(COLOR_GREEN)" "[SUCCESS]" "$(COLOR_RESET)" "$(1)"
log_warning = @printf "%b%s%b %s\n" "$(COLOR_YELLOW)" "[WARNING]" "$(COLOR_RESET)" "$(1)"
log_break =	 @printf "%b%s%b\n" "$(COLOR_BLUE)" "[INFO]" "$(COLOR_RESET)"
log_error = @printf "%b%s%b %s\n" "$(COLOR_RED)" "[ERROR]" "$(COLOR_RESET)" "$(1)"

ARGUMENTS := $(MAKECMDGOALS)
INSTALL_SCRIPT=$(ROOT_DIR)support/scripts/install.sh
CMD_STR := $(strip $(firstword $(ARGUMENTS)))
ARGS := $(filter-out $(strip $(CMD_STR)), $(ARGUMENTS))

# Build the binary using the install script.
build:
	$(call log_info, Building $(APP_NAME) binary)
	$(call log_info, Args: $(ARGS))
	@#$(INSTALL_SCRIPT) clean $(ARGS) 2>&1 >/dev/null || exit 1
	@$(INSTALL_SCRIPT) build $(ARGS)
    $(shell exit 0)

# Install the binary and configure the environment.
install:
	$(call log_info, Installing $(APP_NAME) binary)
	$(call log_info, Args: $(ARGS))
	@#bash $(INSTALL_SCRIPT) clean $(ARGS) 2>&1 >/dev/null || exit 1
	bash $(INSTALL_SCRIPT) install $(ARGS)
	$(shell exit 0)

# Clean up build artifacts.
clean:
	$(call log_info, Cleaning up build artifacts)
	$(call log_info, Args: $(ARGS))
	@bash $(INSTALL_SCRIPT) clean $(ARGS)
	$(shell exit 0)

# Run tests.
test:
	$(call log_info, Running tests)
	$(call log_info, Args: $(ARGS))
	@bash $(INSTALL_SCRIPT) test $(ARGS)
	$(shell exit 0)

## Run dynamic commands with arguments calling the install script.
%:
	@:
	$(call log_info, Running command: $(CMD_STR))
	$(call log_info, Args: $(ARGS))
	@bash $(INSTALL_SCRIPT) $(CMD_STR) $(ARGS)
	$(shell exit 0)

# Display help message.
help:
	$(call log, $(APP_NAME) Makefile )
	$(call break, b )
	$(call log, Usage: )
	$(call log,   make [target] [ARGS='--custom-arg value'] )
	$(call break, b )
	$(call log, Available targets: )
	$(call log,   make build      - Build the binary using install script)
	$(call log,   make build-dev  - Build the binary without compressing it)
	$(call log,   make install    - Install the binary and configure environment)
	$(call log,   make clean      - Clean up build artifacts)
	$(call log,   make test       - Run tests)
	$(call log,   make help       - Display this help message)
	$(call break, b )
	$(call log, Usage with arguments: )
	$(call log,   make install ARGS='--custom-arg value' - Pass custom arguments to the install script)
	$(call break, b )
	$(call log, Example: )
	$(call log,   make install ARGS='--prefix /usr/local')
	$(call break, b )
	$(call log, $(APP_NAME) is a tool for managing Kubernetes resources)
	$(call break, b )
	$(call log, For more information, visit: )
	$(call log, 'https://github.com/rafa-mori/'$(APP_NAME))
	$(call break, b )
	$(call success, End of help message)
	$(shell exit 0)


# End of Makefile

/// tests/bkp/cron_job.go ///
package bkp

// package cron

/* -- Tabela de cron jobs
-- Esta tabela √© respons√°vel por armazenar as tarefas agendadas
CREATE TABLE CronJob (
    id               uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    name             VARCHAR(255), -- Nome da tarefa
    description      TEXT, -- Descri√ß√£o da tarefa

    cron_type        ENUM('cron', 'interval') DEFAULT 'cron', -- Tipo de agendamento (cron ou intervalo)
    cron_expression  TEXT DEFAULT '2 * * * *', -- Express√£o cron (se for cron)

    starts_at         TIMESTAMP DEFAULT NOW(), -- Hora de in√≠cio
    ends_at           TIMESTAMP DEFAULT NULL, -- Hora de t√©rmino

    command          TEXT, -- Comando a ser executado (caso seja via CLI)
    method           ENUM('GET', 'POST', 'PUT', 'DELETE'), -- Tipo de requisi√ß√£o (se for API)
    api_endpoint     VARCHAR(255), -- URL do endpoint (se for API)
    payload          JSONB, -- Dados que precisam ser enviados na request
    headers          JSONB, -- Cabe√ßalhos que precisam ser enviados na request
    retries          INTEGER DEFAULT 0, -- N√∫mero de tentativas

    exec_timeout     INTEGER DEFAULT 30, -- Tempo m√°ximo de execu√ß√£o (em segundos)
    max_retries      INTEGER DEFAULT 3, -- N√∫mero m√°ximo de tentativas
    retry_interval   INTEGER DEFAULT 10, -- Intervalo entre tentativas (em segundos)
    max_execution_time INTEGER DEFAULT 300, -- Tempo m√°ximo de execu√ß√£o (em segundos)

    last_run_status  ENUM('success', 'failure') DEFAULT 'pending', -- Status da √∫ltima execu√ß√£o
    last_run_message TEXT DEFAULT NULL, -- Mensagem da √∫ltima execu√ß√£o
    last_run_time    TIMESTAMP DEFAULT NULL, -- Hora da √∫ltima execu√ß√£o

    is_recurring     BOOLEAN DEFAULT FALSE, -- Se a tarefa √© recorrente
    is_active        BOOLEAN DEFAULT TRUE, -- Status do job (ativo ou pausado)

    created_at       TIMESTAMP DEFAULT NOW(), -- Data de cria√ß√£o
    updated_at       TIMESTAMP DEFAULT NOW(), -- √öltima modifica√ß√£o
    last_executed_at TIMESTAMP DEFAULT NULL -- √öltima vez que foi executado com sucesso

    user_id         uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que criou o job
    created_by      uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que criou o job
    updated_by      uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que atualizou o job
    last_executed_by uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que executou o job pela √∫ltima vez

    metadata        JSONB -- Metadados adicionais
);

CREATE TABLE ExecutionLog (
    id            UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    cronjob_id    UUID REFERENCES CronJob(id), -- Refer√™ncia ao job executado
    execution_time TIMESTAMP DEFAULT NOW(), -- Quando o job foi disparado
    status       ENUM('SUCCESS', 'FAILED', 'PENDING') DEFAULT 'PENDING', -- Resultado da execu√ß√£o
    output       TEXT DEFAULT NULL, -- Retorno da execu√ß√£o (logs, mensagens, respostas da API)
    error_message TEXT DEFAULT NULL, -- Caso tenha falhado, log de erro
    retry_count  INTEGER DEFAULT 0, -- N√∫mero de tentativas
    created_at   TIMESTAMP DEFAULT NOW(), -- Data de cria√ß√£o
    updated_at   TIMESTAMP DEFAULT NOW(), -- √öltima modifica√ß√£o
    user_id     uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que executou o job
    created_by   uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que criou o log
    updated_by   uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que atualizou o log
    metadata     JSONB -- Metadados adicionais
);

CREATE TABLE JobQueue (
    id            UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    cronjob_id    UUID REFERENCES CronJob(id), -- Refer√™ncia ao job na fila
    status        ENUM('PENDING', 'RUNNING', 'COMPLETED', 'FAILED') DEFAULT 'PENDING', -- Status do job na fila
    scheduled_time TIMESTAMP DEFAULT NOW(), -- Quando o job foi agendado
    execution_time TIMESTAMP DEFAULT NULL, -- Quando o job foi executado
    error_message TEXT DEFAULT NULL, -- Caso tenha falhado, log de erro
    retry_count   INTEGER DEFAULT 0, -- N√∫mero de tentativas
    next_run_time TIMESTAMP DEFAULT NULL, -- Pr√≥xima vez que o job deve ser executado
    created_at    TIMESTAMP DEFAULT NOW(), -- Data de cria√ß√£o
    updated_at    TIMESTAMP DEFAULT NOW(), -- √öltima modifica√ß√£o
    metadata      JSONB DEFAULT NULL, -- Metadados adicionais
    user_id      uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que criou o job
    created_by    uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que criou o job
    updated_by    uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que atualizou o job
    last_executed_by uuid REFERENCES users(id), -- Refer√™ncia ao usu√°rio que executou o job pela √∫ltima vez

    job_type      ENUM('cron', 'interval') DEFAULT 'cron', -- Tipo de job (cron ou intervalo)
    job_expression TEXT DEFAULT '2 * * * *', -- Express√£o do job (se for cron)
    job_command   TEXT, -- Comando a ser executado (caso seja via CLI)
    job_method    ENUM('GET', 'POST', 'PUT', 'DELETE'), -- Tipo de requisi√ß√£o (se for API)
    job_api_endpoint VARCHAR(255), -- URL do endpoint (se for API)
    job_payload   JSONB, -- Dados que precisam ser enviados na request
    job_headers   JSONB, -- Cabe√ßalhos que precisam ser enviados na request
    job_retries   INTEGER DEFAULT 0, -- N√∫mero de tentativas
    job_timeout   INTEGER DEFAULT 0 -- Tempo limite para execu√ß√£o (em segundos)
); */

// CronJob √© uma estrutura que representa um trabalho agendado.
type CronJob struct {
	Name          string `json:"name" validate:"required" gorm:"column:name"`
	Description   string `json:"description" validate:"required" gorm:"column:description"`
	JobType       string `json:"job_type" validate:"required" gorm:"column:job_type"`
	JobStatus     string `json:"job_status" validate:"required" gorm:"column:job_status"`
	JobStatusMsg  string `json:"job_status_msg" gorm:"column:job_status_msg"`
	LastRunStatus string `json:"last_run_status" gorm:"column:last_run_status"`
	LastRunMsg    string `json:"last_run_msg" gorm:"column:last_run_msg"`
	LastRunTime   string `json:"last_run_time" gorm:"column:last_run_time"`
	LastRunBy     string `json:"last_run_by" gorm:"column:last_run_by"`
	LastRunAt     string `json:"last_run_at" gorm:"column:last_run_at"`
	CreatedAt     string `json:"created_at" gorm:"column:created_at"`
	UpdatedAt     string `json:"updated_at" gorm:"column:updated_at"`
	CreatedBy     string `json:"created_by" gorm:"column:created_by"`
	UpdatedBy     string `json:"updated_by" gorm:"column:updated_by"`
	LastExecAt    string `json:"last_exec_at" gorm:"column:last_exec_at"`
	LastExecBy    string `json:"last_exec_by" gorm:"column:last_exec_by"`
	Metadata      string `json:"metadata" gorm:"column:metadata"`
}

/// tests/bkp/models.go ///
package bkp

// package main

// type Access_logs struct {

// 		User_id any `json:"User_id" yaml:"User_id" xml:"User_id"`
// 		User_agent string `json:"User_agent" yaml:"User_agent" xml:"User_agent"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Ip_address string `json:"Ip_address" yaml:"Ip_address" xml:"Ip_address"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Action string `json:"Action" yaml:"Action" xml:"Action"`
// }

// type Addresses struct {

// 		Latitude float64 `json:"Latitude" yaml:"Latitude" xml:"Latitude"`
// 		Is_active bool `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
// 		Number string `json:"Number" yaml:"Number" xml:"Number"`
// 		Is_default bool `json:"Is_default" yaml:"Is_default" xml:"Is_default"`
// 		Address_category string `json:"Address_category" yaml:"Address_category" xml:"Address_category"`
// 		Last_sync_at time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
// 		Address_tags any `json:"Address_tags" yaml:"Address_tags" xml:"Address_tags"`
// 		Zip_code string `json:"Zip_code" yaml:"Zip_code" xml:"Zip_code"`
// 		Address_type string `json:"Address_type" yaml:"Address_type" xml:"Address_type"`
// 		Address_status string `json:"Address_status" yaml:"Address_status" xml:"Address_status"`
// 		Is_main bool `json:"Is_main" yaml:"Is_main" xml:"Is_main"`
// 		Country string `json:"Country" yaml:"Country" xml:"Country"`
// 		External_id string `json:"External_id" yaml:"External_id" xml:"External_id"`
// 		Longitude float64 `json:"Longitude" yaml:"Longitude" xml:"Longitude"`
// 		Street string `json:"Street" yaml:"Street" xml:"Street"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		External_code string `json:"External_code" yaml:"External_code" xml:"External_code"`
// 		Notes string `json:"Notes" yaml:"Notes" xml:"Notes"`
// 		State string `json:"State" yaml:"State" xml:"State"`
// 		District string `json:"District" yaml:"District" xml:"District"`
// 		City string `json:"City" yaml:"City" xml:"City"`
// 		Complement string `json:"Complement" yaml:"Complement" xml:"Complement"`
// }

// type Audit_events struct {

// 		Entity_type string `json:"Entity_type" yaml:"Entity_type" xml:"Entity_type"`
// 		User_id any `json:"User_id" yaml:"User_id" xml:"User_id"`
// 		Changes any `json:"Changes" yaml:"Changes" xml:"Changes"`
// 		Entity_id any `json:"Entity_id" yaml:"Entity_id" xml:"Entity_id"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Action string `json:"Action" yaml:"Action" xml:"Action"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// }

// type Audit_logs struct {

// 		Entity_id any `json:"Entity_id" yaml:"Entity_id" xml:"Entity_id"`
// 		User_id any `json:"User_id" yaml:"User_id" xml:"User_id"`
// 		Action string `json:"Action" yaml:"Action" xml:"Action"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Entity_type string `json:"Entity_type" yaml:"Entity_type" xml:"Entity_type"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Changes any `json:"Changes" yaml:"Changes" xml:"Changes"`
// }

// type Cron_jobs struct {

// 		Last_executed_at time.Time `json:"Last_executed_at" yaml:"Last_executed_at" xml:"Last_executed_at"`
// 		User_id any `json:"User_id" yaml:"User_id" xml:"User_id"`
// 		Created_by any `json:"Created_by" yaml:"Created_by" xml:"Created_by"`
// 		Last_run_time time.Time `json:"Last_run_time" yaml:"Last_run_time" xml:"Last_run_time"`
// 		Headers any `json:"Headers" yaml:"Headers" xml:"Headers"`
// 		Api_endpoint string `json:"Api_endpoint" yaml:"Api_endpoint" xml:"Api_endpoint"`
// 		Last_run_status any `json:"Last_run_status" yaml:"Last_run_status" xml:"Last_run_status"`
// 		Name string `json:"Name" yaml:"Name" xml:"Name"`
// 		Payload any `json:"Payload" yaml:"Payload" xml:"Payload"`
// 		Max_execution_time int `json:"Max_execution_time" yaml:"Max_execution_time" xml:"Max_execution_time"`
// 		Retries int `json:"Retries" yaml:"Retries" xml:"Retries"`
// 		Is_recurring bool `json:"Is_recurring" yaml:"Is_recurring" xml:"Is_recurring"`
// 		Cron_expression string `json:"Cron_expression" yaml:"Cron_expression" xml:"Cron_expression"`
// 		Max_retries int `json:"Max_retries" yaml:"Max_retries" xml:"Max_retries"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Last_run_message string `json:"Last_run_message" yaml:"Last_run_message" xml:"Last_run_message"`
// 		Command string `json:"Command" yaml:"Command" xml:"Command"`
// 		Updated_by any `json:"Updated_by" yaml:"Updated_by" xml:"Updated_by"`
// 		Metadata any `json:"Metadata" yaml:"Metadata" xml:"Metadata"`
// 		Starts_at time.Time `json:"Starts_at" yaml:"Starts_at" xml:"Starts_at"`
// 		Last_executed_by any `json:"Last_executed_by" yaml:"Last_executed_by" xml:"Last_executed_by"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Is_active bool `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
// 		Retry_interval int `json:"Retry_interval" yaml:"Retry_interval" xml:"Retry_interval"`
// 		Cron_type any `json:"Cron_type" yaml:"Cron_type" xml:"Cron_type"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Method any `json:"Method" yaml:"Method" xml:"Method"`
// 		Ends_at time.Time `json:"Ends_at" yaml:"Ends_at" xml:"Ends_at"`
// 		Description string `json:"Description" yaml:"Description" xml:"Description"`
// 		Exec_timeout int `json:"Exec_timeout" yaml:"Exec_timeout" xml:"Exec_timeout"`
// }

// type Error_logs struct {

// 		Stack_trace string `json:"Stack_trace" yaml:"Stack_trace" xml:"Stack_trace"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Error_message string `json:"Error_message" yaml:"Error_message" xml:"Error_message"`
// }

// type Execution_logs struct {

// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Error_message string `json:"Error_message" yaml:"Error_message" xml:"Error_message"`
// 		Status any `json:"Status" yaml:"Status" xml:"Status"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Execution_time time.Time `json:"Execution_time" yaml:"Execution_time" xml:"Execution_time"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Retry_count int `json:"Retry_count" yaml:"Retry_count" xml:"Retry_count"`
// 		Created_by any `json:"Created_by" yaml:"Created_by" xml:"Created_by"`
// 		User_id any `json:"User_id" yaml:"User_id" xml:"User_id"`
// 		Updated_by any `json:"Updated_by" yaml:"Updated_by" xml:"Updated_by"`
// 		Cronjob_id any `json:"Cronjob_id" yaml:"Cronjob_id" xml:"Cronjob_id"`
// 		Metadata any `json:"Metadata" yaml:"Metadata" xml:"Metadata"`
// 		Output string `json:"Output" yaml:"Output" xml:"Output"`
// }

// type Inventory struct {

// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Minimum_level float64 `json:"Minimum_level" yaml:"Minimum_level" xml:"Minimum_level"`
// 		Location_code string `json:"Location_code" yaml:"Location_code" xml:"Location_code"`
// 		Is_active bool `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
// 		Lot_control string `json:"Lot_control" yaml:"Lot_control" xml:"Lot_control"`
// 		Product_id any `json:"Product_id" yaml:"Product_id" xml:"Product_id"`
// 		Expiration_date time.Time `json:"Expiration_date" yaml:"Expiration_date" xml:"Expiration_date"`
// 		Vol_type string `json:"Vol_type" yaml:"Vol_type" xml:"Vol_type"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Warehouse_id any `json:"Warehouse_id" yaml:"Warehouse_id" xml:"Warehouse_id"`
// 		Reorder_point float64 `json:"Reorder_point" yaml:"Reorder_point" xml:"Reorder_point"`
// 		Status string `json:"Status" yaml:"Status" xml:"Status"`
// 		Quantity float64 `json:"Quantity" yaml:"Quantity" xml:"Quantity"`
// 		Last_sync_at time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Maximum_level float64 `json:"Maximum_level" yaml:"Maximum_level" xml:"Maximum_level"`
// 		Last_count_date time.Time `json:"Last_count_date" yaml:"Last_count_date" xml:"Last_count_date"`
// }

// type Job_queue struct {

// 		Error_message string `json:"Error_message" yaml:"Error_message" xml:"Error_message"`
// 		Next_run_time time.Time `json:"Next_run_time" yaml:"Next_run_time" xml:"Next_run_time"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Retry_count int `json:"Retry_count" yaml:"Retry_count" xml:"Retry_count"`
// 		Status any `json:"Status" yaml:"Status" xml:"Status"`
// 		Updated_by any `json:"Updated_by" yaml:"Updated_by" xml:"Updated_by"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Job_headers any `json:"Job_headers" yaml:"Job_headers" xml:"Job_headers"`
// 		Job_type any `json:"Job_type" yaml:"Job_type" xml:"Job_type"`
// 		Scheduled_time time.Time `json:"Scheduled_time" yaml:"Scheduled_time" xml:"Scheduled_time"`
// 		Job_retries int `json:"Job_retries" yaml:"Job_retries" xml:"Job_retries"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		User_id any `json:"User_id" yaml:"User_id" xml:"User_id"`
// 		Job_command string `json:"Job_command" yaml:"Job_command" xml:"Job_command"`
// 		Cronjob_id any `json:"Cronjob_id" yaml:"Cronjob_id" xml:"Cronjob_id"`
// 		Metadata any `json:"Metadata" yaml:"Metadata" xml:"Metadata"`
// 		Job_expression string `json:"Job_expression" yaml:"Job_expression" xml:"Job_expression"`
// 		Job_api_endpoint string `json:"Job_api_endpoint" yaml:"Job_api_endpoint" xml:"Job_api_endpoint"`
// 		Job_timeout int `json:"Job_timeout" yaml:"Job_timeout" xml:"Job_timeout"`
// 		Job_method any `json:"Job_method" yaml:"Job_method" xml:"Job_method"`
// 		Created_by any `json:"Created_by" yaml:"Created_by" xml:"Created_by"`
// 		Job_payload any `json:"Job_payload" yaml:"Job_payload" xml:"Job_payload"`
// 		Execution_time time.Time `json:"Execution_time" yaml:"Execution_time" xml:"Execution_time"`
// 		Last_executed_by any `json:"Last_executed_by" yaml:"Last_executed_by" xml:"Last_executed_by"`
// }

// type Partner_contact struct {

// 		Email string `json:"Email" yaml:"Email" xml:"Email"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Name string `json:"Name" yaml:"Name" xml:"Name"`
// 		Is_primary bool `json:"Is_primary" yaml:"Is_primary" xml:"Is_primary"`
// 		Position string `json:"Position" yaml:"Position" xml:"Position"`
// 		Phone string `json:"Phone" yaml:"Phone" xml:"Phone"`
// 		Partner_id any `json:"Partner_id" yaml:"Partner_id" xml:"Partner_id"`
// }

// type Partner_sales_history struct {

// 		Q2 int `json:"Q2" yaml:"Q2" xml:"Q2"`
// 		Partner_id any `json:"Partner_id" yaml:"Partner_id" xml:"Partner_id"`
// 		Year int `json:"Year" yaml:"Year" xml:"Year"`
// 		Q4 int `json:"Q4" yaml:"Q4" xml:"Q4"`
// 		Q1 int `json:"Q1" yaml:"Q1" xml:"Q1"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Q3 int `json:"Q3" yaml:"Q3" xml:"Q3"`
// }

// type Partners struct {

// 		Current_debt float64 `json:"Current_debt" yaml:"Current_debt" xml:"Current_debt"`
// 		Trade_name string `json:"Trade_name" yaml:"Trade_name" xml:"Trade_name"`
// 		Address_ids any `json:"Address_ids" yaml:"Address_ids" xml:"Address_ids"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Is_active bool `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
// 		Last_purchase_date time.Time `json:"Last_purchase_date" yaml:"Last_purchase_date" xml:"Last_purchase_date"`
// 		Segment string `json:"Segment" yaml:"Segment" xml:"Segment"`
// 		External_id string `json:"External_id" yaml:"External_id" xml:"External_id"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Size string `json:"Size" yaml:"Size" xml:"Size"`
// 		Region string `json:"Region" yaml:"Region" xml:"Region"`
// 		Name string `json:"Name" yaml:"Name" xml:"Name"`
// 		Payment_terms any `json:"Payment_terms" yaml:"Payment_terms" xml:"Payment_terms"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Credit_limit float64 `json:"Credit_limit" yaml:"Credit_limit" xml:"Credit_limit"`
// 		Code string `json:"Code" yaml:"Code" xml:"Code"`
// 		Type string `json:"Type" yaml:"Type" xml:"Type"`
// 		Status string `json:"Status" yaml:"Status" xml:"Status"`
// 		Category string `json:"Category" yaml:"Category" xml:"Category"`
// 		Document string `json:"Document" yaml:"Document" xml:"Document"`
// }

// type Permissions struct {

// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Description string `json:"Description" yaml:"Description" xml:"Description"`
// 		Name string `json:"Name" yaml:"Name" xml:"Name"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// }

// type Prediction_daily_data struct {

// 		Lower_bound float64 `json:"Lower_bound" yaml:"Lower_bound" xml:"Lower_bound"`
// 		Day_date any `json:"Day_date" yaml:"Day_date" xml:"Day_date"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Predicted_demand float64 `json:"Predicted_demand" yaml:"Predicted_demand" xml:"Predicted_demand"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Predicted_stock float64 `json:"Predicted_stock" yaml:"Predicted_stock" xml:"Predicted_stock"`
// 		Upper_bound float64 `json:"Upper_bound" yaml:"Upper_bound" xml:"Upper_bound"`
// }

// type Product_category struct {

// 		Name string `json:"Name" yaml:"Name" xml:"Name"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Parent_id any `json:"Parent_id" yaml:"Parent_id" xml:"Parent_id"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// }

// type Products struct {

// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Reorder_point int `json:"Reorder_point" yaml:"Reorder_point" xml:"Reorder_point"`
// 		Lead_time_days int `json:"Lead_time_days" yaml:"Lead_time_days" xml:"Lead_time_days"`
// 		Shelf_life_days int `json:"Shelf_life_days" yaml:"Shelf_life_days" xml:"Shelf_life_days"`
// 		Image string `json:"Image" yaml:"Image" xml:"Image"`
// 		Width float64 `json:"Width" yaml:"Width" xml:"Width"`
// 		Image_url string `json:"Image_url" yaml:"Image_url" xml:"Image_url"`
// 		Brand string `json:"Brand" yaml:"Brand" xml:"Brand"`
// 		Height float64 `json:"Height" yaml:"Height" xml:"Height"`
// 		External_id string `json:"External_id" yaml:"External_id" xml:"External_id"`
// 		Weight float64 `json:"Weight" yaml:"Weight" xml:"Weight"`
// 		Price float64 `json:"Price" yaml:"Price" xml:"Price"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Default_vol_type string `json:"Default_vol_type" yaml:"Default_vol_type" xml:"Default_vol_type"`
// 		Is_active bool `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
// 		Max_stock_threshold int `json:"Max_stock_threshold" yaml:"Max_stock_threshold" xml:"Max_stock_threshold"`
// 		Category_id any `json:"Category_id" yaml:"Category_id" xml:"Category_id"`
// 		Search_vector any `json:"Search_vector" yaml:"Search_vector" xml:"Search_vector"`
// 		Name string `json:"Name" yaml:"Name" xml:"Name"`
// 		Length float64 `json:"Length" yaml:"Length" xml:"Length"`
// 		Barcode string `json:"Barcode" yaml:"Barcode" xml:"Barcode"`
// 		Min_stock_threshold int `json:"Min_stock_threshold" yaml:"Min_stock_threshold" xml:"Min_stock_threshold"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Last_sync_at time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
// 		Sku string `json:"Sku" yaml:"Sku" xml:"Sku"`
// 		Cost float64 `json:"Cost" yaml:"Cost" xml:"Cost"`
// 		Manufacturer string `json:"Manufacturer" yaml:"Manufacturer" xml:"Manufacturer"`
// 		Description string `json:"Description" yaml:"Description" xml:"Description"`
// }

// type Refresh_tokens struct {

// 		User_id any `json:"User_id" yaml:"User_id" xml:"User_id"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Token_id string `json:"Token_id" yaml:"Token_id" xml:"Token_id"`
// 		Id int `json:"Id" yaml:"Id" xml:"Id"`
// 		Expires_at time.Time `json:"Expires_at" yaml:"Expires_at" xml:"Expires_at"`
// }

// type Role_permissions struct {

// 		Permission_id any `json:"Permission_id" yaml:"Permission_id" xml:"Permission_id"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Role_id any `json:"Role_id" yaml:"Role_id" xml:"Role_id"`
// }

// type Roles struct {

// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Description string `json:"Description" yaml:"Description" xml:"Description"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Name string `json:"Name" yaml:"Name" xml:"Name"`
// }

// type Stock_predictions struct {

// 		Predicted_level float64 `json:"Predicted_level" yaml:"Predicted_level" xml:"Predicted_level"`
// 		Product_id any `json:"Product_id" yaml:"Product_id" xml:"Product_id"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Prediction_horizon_days int `json:"Prediction_horizon_days" yaml:"Prediction_horizon_days" xml:"Prediction_horizon_days"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Current_level float64 `json:"Current_level" yaml:"Current_level" xml:"Current_level"`
// 		Confidence_level string `json:"Confidence_level" yaml:"Confidence_level" xml:"Confidence_level"`
// 		Prediction_date time.Time `json:"Prediction_date" yaml:"Prediction_date" xml:"Prediction_date"`
// 		Warehouse_id any `json:"Warehouse_id" yaml:"Warehouse_id" xml:"Warehouse_id"`
// 		Suggested_reorder_quantity float64 `json:"Suggested_reorder_quantity" yaml:"Suggested_reorder_quantity" xml:"Suggested_reorder_quantity"`
// 		Days_until_stockout int `json:"Days_until_stockout" yaml:"Days_until_stockout" xml:"Days_until_stockout"`
// }

// type Sync_config struct {

// 		Is_active bool `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
// 		Entity_name string `json:"Entity_name" yaml:"Entity_name" xml:"Entity_name"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Last_sync_timestamp time.Time `json:"Last_sync_timestamp" yaml:"Last_sync_timestamp" xml:"Last_sync_timestamp"`
// 		Id int `json:"Id" yaml:"Id" xml:"Id"`
// 		Sync_interval_minutes int `json:"Sync_interval_minutes" yaml:"Sync_interval_minutes" xml:"Sync_interval_minutes"`
// 		Error_count int `json:"Error_count" yaml:"Error_count" xml:"Error_count"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// }

// type Sync_logs struct {

// 		Status string `json:"Status" yaml:"Status" xml:"Status"`
// 		Entity_name string `json:"Entity_name" yaml:"Entity_name" xml:"Entity_name"`
// 		Error_message string `json:"Error_message" yaml:"Error_message" xml:"Error_message"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Records_created int `json:"Records_created" yaml:"Records_created" xml:"Records_created"`
// 		Records_failed int `json:"Records_failed" yaml:"Records_failed" xml:"Records_failed"`
// 		Start_time time.Time `json:"Start_time" yaml:"Start_time" xml:"Start_time"`
// 		Id int `json:"Id" yaml:"Id" xml:"Id"`
// 		End_time time.Time `json:"End_time" yaml:"End_time" xml:"End_time"`
// 		Records_processed int `json:"Records_processed" yaml:"Records_processed" xml:"Records_processed"`
// 		Records_updated int `json:"Records_updated" yaml:"Records_updated" xml:"Records_updated"`
// }

// type User_preferences struct {

// 		Preference_value string `json:"Preference_value" yaml:"Preference_value" xml:"Preference_value"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Preference_type string `json:"Preference_type" yaml:"Preference_type" xml:"Preference_type"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Preference_value_type string `json:"Preference_value_type" yaml:"Preference_value_type" xml:"Preference_value_type"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		User_id any `json:"User_id" yaml:"User_id" xml:"User_id"`
// 		Preference_key string `json:"Preference_key" yaml:"Preference_key" xml:"Preference_key"`
// }

// type Users struct {

// 		Name string `json:"Name" yaml:"Name" xml:"Name"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Last_login time.Time `json:"Last_login" yaml:"Last_login" xml:"Last_login"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		Email string `json:"Email" yaml:"Email" xml:"Email"`
// 		Role_id any `json:"Role_id" yaml:"Role_id" xml:"Role_id"`
// 		Phone string `json:"Phone" yaml:"Phone" xml:"Phone"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Password string `json:"Password" yaml:"Password" xml:"Password"`
// 		Document string `json:"Document" yaml:"Document" xml:"Document"`
// 		Active bool `json:"Active" yaml:"Active" xml:"Active"`
// 		Username string `json:"Username" yaml:"Username" xml:"Username"`
// }

// type Warehouses struct {

// 		Address_id any `json:"Address_id" yaml:"Address_id" xml:"Address_id"`
// 		Manager string `json:"Manager" yaml:"Manager" xml:"Manager"`
// 		Updated_by any `json:"Updated_by" yaml:"Updated_by" xml:"Updated_by"`
// 		Capacity int `json:"Capacity" yaml:"Capacity" xml:"Capacity"`
// 		Id any `json:"Id" yaml:"Id" xml:"Id"`
// 		Location string `json:"Location" yaml:"Location" xml:"Location"`
// 		Created_by any `json:"Created_by" yaml:"Created_by" xml:"Created_by"`
// 		External_id string `json:"External_id" yaml:"External_id" xml:"External_id"`
// 		Contact string `json:"Contact" yaml:"Contact" xml:"Contact"`
// 		Notes string `json:"Notes" yaml:"Notes" xml:"Notes"`
// 		Updated_at time.Time `json:"Updated_at" yaml:"Updated_at" xml:"Updated_at"`
// 		External_code string `json:"External_code" yaml:"External_code" xml:"External_code"`
// 		Tags any `json:"Tags" yaml:"Tags" xml:"Tags"`
// 		Last_sync_at time.Time `json:"Last_sync_at" yaml:"Last_sync_at" xml:"Last_sync_at"`
// 		Name string `json:"Name" yaml:"Name" xml:"Name"`
// 		Created_at time.Time `json:"Created_at" yaml:"Created_at" xml:"Created_at"`
// 		Status string `json:"Status" yaml:"Status" xml:"Status"`
// 		Current_stock int `json:"Current_stock" yaml:"Current_stock" xml:"Current_stock"`
// 		Is_active bool `json:"Is_active" yaml:"Is_active" xml:"Is_active"`
// }

/// tests/client_model_test.go ///
package tests

import (
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"gorm.io/driver/sqlite"
	"gorm.io/gorm"

	clients "github.com/rafa-mori/gdbase/internal/models/clients"
)

func setupClientTestDB(t *testing.T) *gorm.DB {
	db, err := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	if err != nil {
		t.Fatalf("failed to connect to test db: %v", err)
	}
	db.AutoMigrate(&clients.ClientDetailed{})
	return db
}

func TestClientModel_CRUD(t *testing.T) {
	db := setupClientTestDB(t)
	client := &clients.ClientDetailed{
		ID:           "client1",
		Code:         ptrStr("C001"),
		TradingName:  ptrStr("Empresa Teste"),
		DocumentType: clients.Company,
		Status:       clients.Active,
		CreatedAt:    time.Now(),
		UpdatedAt:    time.Now(),
	}
	err := db.Create(client).Error
	assert.NoError(t, err)

	var found clients.ClientDetailed
	err = db.First(&found, "id = ?", client.ID).Error
	assert.NoError(t, err)
	assert.Equal(t, client.ID, found.ID)

	client.Status = clients.Blocked
	err = db.Save(client).Error
	assert.NoError(t, err)

	err = db.Delete(&clients.ClientDetailed{}, client.ID).Error
	assert.NoError(t, err)
}

/// tests/client_repo_test.go ///
package tests

import (
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"gorm.io/driver/sqlite"
	"gorm.io/gorm"

	clients "github.com/rafa-mori/gdbase/internal/models/clients"
)

func setupClientRepoTestDB(t *testing.T) *gorm.DB {
	db, err := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	if err != nil {
		t.Fatalf("failed to connect to test db: %v", err)
	}
	db.AutoMigrate(&clients.ClientDetailed{})
	return db
}

func TestClientRepo_CRUD(t *testing.T) {
	db := setupClientRepoTestDB(t)
	repo := clients.NewClientRepo(db)
	client := &clients.ClientDetailed{
		ID:           "client2",
		Code:         ptrStr("C002"),
		TradingName:  ptrStr("Empresa Teste 2"),
		DocumentType: clients.Company,
		Status:       clients.Active,
		CreatedAt:    time.Now(),
		UpdatedAt:    time.Now(),
	}
	// Create
	created, err := repo.Create(client)
	assert.NoError(t, err)
	assert.Equal(t, client.ID, created.ID)

	// FindOne
	found, err := repo.FindOne("id = ?", client.ID)
	assert.NoError(t, err)
	assert.Equal(t, client.ID, found.ID)

	// Update
	client.Status = clients.Blocked
	updated, err := repo.Update(client)
	assert.NoError(t, err)
	assert.Equal(t, clients.Blocked, updated.Status)

	// FindAll
	list, err := repo.FindAll("status = ?", clients.Blocked)
	assert.NoError(t, err)
	assert.Len(t, list, 1)

	// Delete
	err = repo.Delete(client.ID)
	assert.NoError(t, err)
}

func ptrStr(s string) *string { return &s }

/// tests/database_test.go ///
package tests

//func TestDBConfigSerialization(t *testing.T) {
//	logger := logz.NewLogger("TestDBConfig")
//
//	// üî• Criando uma configura√ß√£o inicial simulada
//	dbConfig := NewDBConfigWithArgs(
//		"GodoTestDB",
//		"/srv/apps/projects/gdbase/tests/bkp/godo-test-config.yaml",
//		true,
//		logger,
//		false,
//	)
//
//	// üîÑ Tentando serializar pra YAML
//	serializedData, err := yaml.Marshal(dbConfig)
//	require.NoError(t, err, "Erro ao serializar DBConfig para YAML")
//
//	// üöÄ Escrevendo para arquivo tempor√°rio
//	filePath := "/srv/apps/projects/gdbase/tests/bkp/godo-test-config.yaml"
//	err = os.WriteFile(filePath, serializedData, 0644)
//	require.NoError(t, err, "Erro ao salvar arquivo YAML")
//
//	// üí° Lendo de volta pra garantir consist√™ncia
//	readData, err := os.ReadFile(filePath)
//	require.NoError(t, err, "Erro ao ler arquivo YAML gerado")
//
//	fmt.Println("‚úÖ Teste de serializa√ß√£o: Arquivo YAML gerado com sucesso!")
//	fmt.Println(string(readData))
//}

/// tests/dkr_abs_test.go ///
package tests

// type MockReadCloser struct{}

// func (m *MockReadCloser) Read(p []byte) (n int, err error) {
// 	return 0, io.EOF
// }

// func (m *MockReadCloser) Close() error {
// 	return nil
// }

// type MockDockerClient struct {
// 	m.Mock
// }

// func (m *MockDockerClient) ImagePull(ctx context.Context, image string, options i.PullOptions) (io.ReadCloser, error) {
// 	args := m.Called(ctx, image, options)
// 	return args.Get(0).(io.ReadCloser), args.Error(1)
// }

// func (m *MockDockerClient) ContainerList(ctx context.Context, options c.ListOptions) ([]c.Summary, error) {
// 	args := m.Called(ctx, options)
// 	return args.Get(0).([]c.Summary), args.Error(1)
// }

// func (m *MockDockerClient) ContainerCreate(ctx context.Context, config *c.Config, hostConfig *c.HostConfig, networkingConfig *n.NetworkingConfig, platform *o.Platform, containerName string) (c.CreateResponse, error) {
// 	args := m.Called(ctx, config, hostConfig, networkingConfig, platform, containerName)
// 	return args.Get(0).(c.CreateResponse), args.Error(1)
// }

// func (m *MockDockerClient) ContainerStart(ctx context.Context, containerID string, options c.StartOptions) error {
// 	args := m.Called(ctx, containerID, options)
// 	return args.Error(0)
// }

// func (m *MockDockerClient) VolumeCreate(ctx context.Context, options v.CreateOptions) (v.Volume, error) {
// 	args := m.Called(ctx, options)
// 	return args.Get(0).(v.Volume), args.Error(1)
// }

// func (m *MockDockerClient) VolumeList(ctx context.Context, options v.ListOptions) (v.ListResponse, error) {
// 	args := m.Called(ctx, options)
// 	return args.Get(0).(v.ListResponse), args.Error(1)
// }

// func TestStartContainerWithValidInputsStartsContainer(t *testing.T) {
// 	mockClient := new(MockDockerClient)
// 	dockerService := &s.DockerService{Cli: mockClient}

// 	mockClient.On("ContainerCreate", m.Anything, m.Anything, m.Anything, m.Anything, m.Anything, "test-service").Return(c.CreateResponse{ID: "12345"}, nil)
// 	mockClient.On("ContainerStart", m.Anything, "12345", m.Anything).Return(nil)
// 	mockClient.On("ImagePull", m.Anything, m.Anything, m.Anything).Return(&MockReadCloser{}, nil)

// 	err := dockerService.StartContainer("test-service", "test-image", []string{"ENV_VAR=value"}, nil, nil)
// 	r.NoError(t, err)
// 	mockClient.AssertExpectations(t)
// }

// func TestStartContainerWithErrorDuringCreationReturnsError(t *testing.T) {
// 	mockClient := new(MockDockerClient)
// 	dockerService := &s.DockerService{Cli: mockClient}

// 	mockClient.On("ContainerCreate", m.Anything, m.Anything, m.Anything, m.Anything, m.Anything, "test-service").Return(c.CreateResponse{}, errors.New("creation error"))
// 	mockClient.On("ImagePull", m.Anything, m.Anything, m.Anything).Return(&MockReadCloser{}, nil)

// 	err := dockerService.StartContainer("test-service", "test-image", []string{"ENV_VAR=value"}, nil, nil)
// 	r.Error(t, err)
// 	r.Contains(t, err.Error(), "creation error")
// 	mockClient.AssertExpectations(t)
// }

// func TestCreateVolumeWithValidInputsCreatesVolume(t *testing.T) {
// 	mockClient := new(MockDockerClient)
// 	dockerService := &s.DockerService{Cli: mockClient}

// 	mockClient.On("VolumeList", m.Anything, m.Anything).Return(v.ListResponse{Volumes: []*v.Volume{}}, nil)
// 	mockClient.On("VolumeCreate", m.Anything, m.Anything).Return(v.Volume{Name: "test-volume"}, nil)

// 	err := dockerService.CreateVolume("test-volume", "/path/to/device")
// 	r.NoError(t, err)
// 	mockClient.AssertExpectations(t)
// }

// func TestCreateVolumeWithExistingVolumeSkipsCreation(t *testing.T) {
// 	mockClient := new(MockDockerClient)
// 	dockerService := &s.DockerService{Cli: mockClient}

// 	mockClient.On("VolumeList", m.Anything, m.Anything).Return(v.ListResponse{Volumes: []*v.Volume{{Name: "test-volume"}}}, nil)

// 	err := dockerService.CreateVolume("test-volume", "/path/to/device")
// 	r.NoError(t, err)
// 	mockClient.AssertExpectations(t)
// }

// func TestCreateVolumeWithErrorDuringCreationReturnsError(t *testing.T) {
// 	mockClient := new(MockDockerClient)
// 	dockerService := &s.DockerService{Cli: mockClient}

// 	mockClient.On("VolumeList", m.Anything, m.Anything).Return(v.ListResponse{Volumes: []*v.Volume{}}, nil)
// 	mockClient.On("VolumeCreate", m.Anything, m.Anything).Return(v.Volume{}, errors.New("creation error"))

// 	err := dockerService.CreateVolume("test-volume", "/path/to/device")
// 	r.Error(t, err)
// 	r.Contains(t, err.Error(), "creation error")
// 	mockClient.AssertExpectations(t)
// }

/// tests/order_repo_service_test.go ///
package tests

import (
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"gorm.io/driver/sqlite"
	"gorm.io/gorm"

	orders "github.com/rafa-mori/gdbase/internal/models/orders"
)

func setupTestDB(t *testing.T) *gorm.DB {
	db, err := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	if err != nil {
		t.Fatalf("failed to connect to test db: %v", err)
	}
	db.AutoMigrate(&orders.Order{})
	return db
}

func TestOrderRepo_CRUD(t *testing.T) {
	db := setupTestDB(t)
	repo := orders.NewOrderRepo(db)

	order := &orders.Order{
		ID:        "order1",
		ClientID:  "client1",
		UserID:    "user1",
		Status:    orders.OrderStatusCreated,
		CreatedAt: time.Now(),
		UpdatedAt: time.Now(),
	}
	// Create
	created, err := repo.Create(order)
	assert.NoError(t, err)
	assert.Equal(t, order.ID, created.ID)

	// FindOne
	found, err := repo.FindOne("id = ?", order.ID)
	assert.NoError(t, err)
	assert.Equal(t, order.ID, found.ID)

	// Update
	order.Status = orders.OrderStatusApproved
	updated, err := repo.Update(order)
	assert.NoError(t, err)
	assert.Equal(t, orders.OrderStatusApproved, updated.Status)

	// FindAll
	ordersList, err := repo.FindAll("user_id = ?", order.UserID)
	assert.NoError(t, err)
	assert.Len(t, ordersList, 1)

	// Delete
	err = repo.Delete(order.ID)
	assert.NoError(t, err)
}

func TestOrderService_CRUD(t *testing.T) {
	db := setupTestDB(t)
	repo := orders.NewOrderRepo(db)
	service := orders.NewOrderService(repo)

	order := &orders.Order{
		ID:        "order2",
		ClientID:  "client2",
		UserID:    "user2",
		Status:    orders.OrderStatusCreated,
		CreatedAt: time.Now(),
		UpdatedAt: time.Now(),
	}
	// Create
	created, err := service.CreateOrder(order)
	assert.NoError(t, err)
	assert.Equal(t, order.ID, created.ID)

	// GetOrderByID
	got, err := service.GetOrderByID(order.ID)
	assert.NoError(t, err)
	assert.Equal(t, order.ID, got.ID)

	// UpdateOrder
	order.Status = orders.OrderStatusDelivered
	updated, err := service.UpdateOrder(order)
	assert.NoError(t, err)
	assert.Equal(t, orders.OrderStatusDelivered, updated.Status)

	// ListOrders
	list, err := service.ListOrders()
	assert.NoError(t, err)
	assert.Len(t, list, 1)

	// DeleteOrder
	err = service.DeleteOrder(order.ID)
	assert.NoError(t, err)
}

/// tests/product_model_test.go ///
package tests

import (
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"gorm.io/driver/sqlite"
	"gorm.io/gorm"

	products "github.com/rafa-mori/gdbase/internal/models/products"
)

func setupProductTestDB(t *testing.T) *gorm.DB {
	db, err := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	if err != nil {
		t.Fatalf("failed to connect to test db: %v", err)
	}
	db.AutoMigrate(&products.Product{}, &products.ProductCategory{})
	return db
}

func TestProductModel_CRUD(t *testing.T) {
	db := setupProductTestDB(t)
	cat := &products.ProductCategory{ID: "cat1", Name: "Categoria Teste"}
	db.Create(cat)
	prod := &products.Product{
		ID:         "prod1",
		Code:       "P001",
		SKU:        "SKU001",
		Name:       "Produto Teste",
		CategoryID: cat.ID,
		Unit:       "un",
		IsActive:   true,
		CreatedAt:  time.Now(),
		UpdatedAt:  time.Now(),
		Stock:      products.Stock{Available: 10, Reserved: 0, Virtual: 0},
	}
	err := db.Create(prod).Error
	assert.NoError(t, err)

	var found products.Product
	err = db.First(&found, "id = ?", prod.ID).Error
	assert.NoError(t, err)
	assert.Equal(t, prod.ID, found.ID)

	prod.Name = "Produto Alterado"
	err = db.Save(prod).Error
	assert.NoError(t, err)

	err = db.Delete(&products.Product{}, prod.ID).Error
	assert.NoError(t, err)
}

/// tests/product_repo_test.go ///
package tests

import (
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"gorm.io/driver/sqlite"
	"gorm.io/gorm"

	products "github.com/rafa-mori/gdbase/internal/models/products"
)

func setupProductRepoTestDB(t *testing.T) *gorm.DB {
	db, err := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	if err != nil {
		t.Fatalf("failed to connect to test db: %v", err)
	}
	db.AutoMigrate(&products.Product{}, &products.ProductCategory{})
	return db
}

func TestProductRepo_CRUD(t *testing.T) {
	db := setupProductRepoTestDB(t)
	repo := products.NewProductRepo(db)
	cat := &products.ProductCategory{ID: "cat1", Name: "Categoria Teste"}
	db.Create(cat)
	prod := &products.Product{
		ID:         "prod2",
		Code:       "P002",
		SKU:        "SKU002",
		Name:       "Produto Teste 2",
		CategoryID: cat.ID,
		Unit:       "un",
		IsActive:   true,
		CreatedAt:  time.Now(),
		UpdatedAt:  time.Now(),
		Stock:      products.Stock{Available: 5, Reserved: 0, Virtual: 0},
	}
	// Create
	created, err := repo.Create(prod)
	assert.NoError(t, err)
	assert.Equal(t, prod.ID, created.ID)

	// FindOne
	found, err := repo.FindOne("id = ?", prod.ID)
	assert.NoError(t, err)
	assert.Equal(t, prod.ID, found.ID)

	// Update
	prod.Name = "Produto Alterado 2"
	updated, err := repo.Update(prod)
	assert.NoError(t, err)
	assert.Equal(t, "Produto Alterado 2", updated.Name)

	// FindAll
	list, err := repo.FindAll("category_id = ?", cat.ID)
	assert.NoError(t, err)
	assert.Len(t, list, 1)

	// Delete
	err = repo.Delete(prod.ID)
	assert.NoError(t, err)
}

/// tests/user_model_crud_test.go ///
package tests

import (
	"testing"

	"github.com/stretchr/testify/assert"
	"gorm.io/driver/sqlite"
	"gorm.io/gorm"

	um "github.com/rafa-mori/gdbase/internal/models/users"
)

func setupUserTestDB(t *testing.T) *gorm.DB {
	db, err := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	if err != nil {
		t.Fatalf("failed to connect to test db: %v", err)
	}
	db.AutoMigrate(&um.UserModel{})
	return db
}

func TestUserModel_CRUD(t *testing.T) {
	db := setupUserTestDB(t)
	user := &um.UserModel{
		ID:       "user1",
		Name:     "Usu√°rio Teste",
		Username: "usertest",
		Email:    "user@test.com",
		Phone:    "123456789",
		Active:   true,
	}
	err := db.Create(user).Error
	assert.NoError(t, err)

	var found um.UserModel
	err = db.First(&found, "id = ?", user.ID).Error
	assert.NoError(t, err)
	assert.Equal(t, user.ID, found.ID)

	user.Name = "Usu√°rio Alterado"
	err = db.Save(user).Error
	assert.NoError(t, err)

	err = db.Delete(&um.UserModel{}, user.ID).Error
	assert.NoError(t, err)
}

/// tests/user_model_test.go ///
package tests

// import (
// 	"testing"

// 	um "github.com/rafa-mori/gdbase/internal/models/users"
// 	"github.com/stretchr/testify/assert"
// 	"golang.org/x/crypto/bcrypt"
// )

// func TestUserModel_SetName(t *testing.T) {
// 	user := &um.UserModel{}
// 	user.SetName("John Doe")
// 	assert.Equal(t, "John Doe", user.Name)
// }

// func TestUserModel_SetUsername(t *testing.T) {
// 	user := &um.UserModel{}
// 	user.SetUsername("johndoe")
// 	assert.Equal(t, "johndoe", user.Username)
// }

// func TestUserModel_SetPassword(t *testing.T) {
// 	user := &um.UserModel{}
// 	err := user.SetPassword("securepassword")
// 	assert.NoError(t, err)

// 	err = bcrypt.CompareHashAndPassword([]byte(user.Password), []byte("securepassword"))
// 	assert.NoError(t, err)
// }

// func TestUserModel_SetEmail(t *testing.T) {
// 	user := &um.UserModel{}
// 	user.SetEmail("johndoe@example.com")
// 	assert.Equal(t, "johndoe@example.com", user.Email)
// }

// func TestUserModel_SetRoleID(t *testing.T) {
// 	user := &um.UserModel{}
// 	user.SetRoleID(1)
// 	assert.Equal(t, uint(1), user.RoleID)
// }

// func TestUserModel_SetPhone(t *testing.T) {
// 	user := &um.UserModel{}
// 	user.SetPhone("1234567890")
// 	assert.Equal(t, "1234567890", user.Phone)
// }

// func TestUserModel_SetActive(t *testing.T) {
// 	user := &um.UserModel{}
// 	user.SetActive(true)
// 	assert.True(t, user.Active)
// }

// func TestUserModel_Getters(t *testing.T) {
// 	user := &um.UserModel{
// 		ID:       "123",
// 		Name:     "John Doe",
// 		Username: "johndoe",
// 		Password: "hashedpassword",
// 		Email:    "johndoe@example.com",
// 		Phone:    "1234567890",
// 		RoleID:   1,
// 		Active:   true,
// 	}

// 	assert.Equal(t, "123", user.GetID())
// 	assert.Equal(t, "John Doe", user.GetName())
// 	assert.Equal(t, "johndoe", user.GetUsername())
// 	assert.Equal(t, "hashedpassword", user.GetPassword())
// 	assert.Equal(t, "johndoe@example.com", user.GetEmail())
// 	assert.Equal(t, uint(1), user.GetRoleID())
// 	assert.Equal(t, "1234567890", user.GetPhone())
// 	assert.True(t, user.GetActive())
// }

/// tests/user_repo_test.go ///
package tests

/* import (
	"testing"

	um "github.com/rafa-mori/gdbase/internal/models/users"
	"github.com/stretchr/testify/assert"
	"gorm.io/driver/sqlite"
	"gorm.io/gorm"
)

type MockUserModel struct {
	ID       string
	Name     string
	Username string
	Email    string
	Phone    string
	Active   bool
}

func (m *MockUserModel) GetID() string       { return m.ID }
func (m *MockUserModel) GetName() string     { return m.Name }
func (m *MockUserModel) GetUsername() string { return m.Username }
func (m *MockUserModel) GetEmail() string    { return m.Email }
func (m *MockUserModel) GetPhone() string    { return m.Phone }
func (m *MockUserModel) GetActive() bool     { return m.Active }

func TestUserRepo_Create(t *testing.T) {
	db, _ := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	db.AutoMigrate(&um.UserModel{})
	repo := um.NewUserRepo(db)

	mockUser := &um.UserModel{ID: "1", Name: "John Doe", Username: "johndoe", Email: "john@example.com", Phone: "1234567890", Active: true}
	createdUser, err := repo.Create(mockUser)

	assert.NoError(t, err)
	assert.Equal(t, mockUser.ID, createdUser.GetID())
}

func TestUserRepo_FindOne(t *testing.T) {
	db, _ := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	db.AutoMigrate(&um.UserModel{})
	repo := um.NewUserRepo(db)

	mockUser := &um.UserModel{ID: "1", Name: "John Doe"}
	db.Create(mockUser)

	foundUser, err := repo.FindOne("id = ?", "1")

	assert.NoError(t, err)
	assert.Equal(t, mockUser.ID, foundUser.GetID())
}

func TestUserRepo_FindAll(t *testing.T) {
	db, _ := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	db.AutoMigrate(&um.UserModel{})
	repo := um.NewUserRepo(db)

	mockUser1 := &um.UserModel{ID: "1", Name: "John Doe", Email: "j@d.com", Username: "johndoe"}
	mockUser2 := &um.UserModel{ID: "2", Name: "Jane Doe", Email: "a@j.com", Username: "janedoe"}
	db.Create(mockUser1)
	db.Create(mockUser2)

	users, err := repo.FindAll("id IN(?)", []string{"1", "2"})

	assert.NoError(t, err)
	assert.Len(t, users, 2)
}

func TestUserRepo_Update(t *testing.T) {
	db, _ := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	db.AutoMigrate(&um.UserModel{})
	repo := um.NewUserRepo(db)

	mockUser := &um.UserModel{ID: "1", Name: "John Doe"}
	db.Create(mockUser)

	mockUser.Name = "John Updated"
	updatedUser, err := repo.Update(mockUser)

	assert.NoError(t, err)
	assert.Equal(t, "John Updated", updatedUser.GetName())
}

func TestUserRepo_Delete(t *testing.T) {
	db, _ := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	db.AutoMigrate(&um.UserModel{})
	repo := um.NewUserRepo(db)

	mockUser := &um.UserModel{ID: "1", Name: "John Doe"}
	db.Create(mockUser)

	err := repo.Delete("1")

	assert.NoError(t, err)
	var count int64
	db.Model(&um.UserModel{}).Where("id = ?", "1").Count(&count)
	assert.Equal(t, int64(0), count)
}

func TestUserRepo_List(t *testing.T) {
	db, _ := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{})
	db.AutoMigrate(&um.UserModel{})
	repo := um.NewUserRepo(db)

	mockUser1 := &um.UserModel{ID: "1", Name: "John Doe", Username: "johndoe", Email: "john@example.com", Phone: "1234567890", Active: true}
	mockUser2 := &um.UserModel{ID: "2", Name: "Jane Doe", Username: "janedoe", Email: "jane@example.com", Phone: "0987654321", Active: false}
	db.Create(mockUser1)
	db.Create(mockUser2)

	tableHandler, err := repo.List("id IN ?", []string{"1", "2"})

	assert.NoError(t, err)
	assert.Len(t, tableHandler.Rows, 2)
	assert.Equal(t, "John Doe", tableHandler.Rows[0][2])
}
*/

/// tests/user_service_test.go ///
package tests

// import (
// 	"errors"
// 	"testing"

// 	um "github.com/rafa-mori/gdbase/internal/models/users"
// 	"github.com/rafa-mori/gdbase/types"
// 	"github.com/rafa-mori/xtui/types"
// 	"github.com/stretchr/testify/assert"
// 	"github.com/stretchr/testify/mock"
// )

// // MockIUserRepo is a mock implementation of IUserRepo for testing purposes.
// type MockIUserRepo struct {
// 	mock.Mock
// }

// // GetContextDbService implements user.IUserRepo.
// func (m *MockIUserRepo) GetContextDbService() types.DBService {
// 	panic("unimplemented")
// }

// // TableName implements user.IUserRepo.
// func (m *MockIUserRepo) TableName() string {
// 	panic("unimplemented")
// }

// // List implements IUserRepo.
// func (m *MockIUserRepo) List(where ...interface{}) (types.TableHandler, error) {
// 	panic("unimplemented")
// }

// func (m *MockIUserRepo) Close() error {
// 	return nil
// }

// func (m *MockIUserRepo) Create(user um.IUser) (um.IUser, error) {
// 	args := m.Called(user)
// 	return args.Get(0).(um.IUser), args.Error(1)
// }

// func (m *MockIUserRepo) FindOne(args ...interface{}) (um.IUser, error) {
// 	return nil, nil
// }

// func (m *MockIUserRepo) Update(user um.IUser) (um.IUser, error) {
// 	return nil, nil
// }

// func (m *MockIUserRepo) Delete(id string) error {
// 	return nil
// }

// func (m *MockIUserRepo) FindAll(args ...interface{}) ([]um.IUser, error) {
// 	return nil, nil
// }

// // MockIUser is a mock implementation of IUser for testing purposes.
// type MockIUser struct {
// 	mock.Mock
// }

// // TableName implements user.IUser.
// func (m *MockIUser) TableName() string {
// 	panic("unimplemented")
// }

// // SetID implements user.IUser.
// func (m *MockIUser) SetID(id string) {
// 	panic("unimplemented")
// }

// // GetActive implements IUser.
// func (m *MockIUser) GetActive() bool {
// 	panic("unimplemented")
// }

// // GetID implements IUser.
// func (m *MockIUser) GetID() string {
// 	panic("unimplemented")
// }

// // GetName implements IUser.
// func (m *MockIUser) GetName() string {
// 	panic("unimplemented")
// }

// // GetPhone implements IUser.
// func (m *MockIUser) GetPhone() string {
// 	panic("unimplemented")
// }

// // GetRoleID implements IUser.
// func (m *MockIUser) GetRoleID() uint {
// 	panic("unimplemented")
// }

// // SetActive implements IUser.
// func (m *MockIUser) SetActive(active bool) {
// 	panic("unimplemented")
// }

// // SetEmail implements IUser.
// func (m *MockIUser) SetEmail(email string) {
// 	panic("unimplemented")
// }

// // SetName implements IUser.
// func (m *MockIUser) SetName(name string) {
// 	panic("unimplemented")
// }

// // SetPassword implements IUser.
// func (m *MockIUser) SetPassword(password string) error {
// 	panic("unimplemented")
// }

// // SetPhone implements IUser.
// func (m *MockIUser) SetPhone(phone string) {
// 	panic("unimplemented")
// }

// // SetRoleID implements IUser.
// func (m *MockIUser) SetRoleID(roleID uint) {
// 	panic("unimplemented")
// }

// // SetUsername implements IUser.
// func (m *MockIUser) SetUsername(username string) {
// 	panic("unimplemented")
// }

// func (m *MockIUser) GetUsername() string {
// 	args := m.Called()
// 	return args.String(0)
// }

// func (m *MockIUser) GetEmail() string {
// 	args := m.Called()
// 	return args.String(0)
// }

// func (m *MockIUser) GetPassword() string {
// 	args := m.Called()
// 	return args.String(0)
// }

// func TestCreateUser(t *testing.T) {
// 	mockRepo := new(MockIUserRepo)
// 	mockUser := new(MockIUser)

// 	userService := um.NewUserService(mockRepo)

// 	t.Run("should return error when required fields are missing", func(t *testing.T) {
// 		// Set up the mock user model
// 		mockUser.On("GetUsername").Return("")
// 		mockUser.On("GetEmail").Return("")
// 		mockUser.On("GetPassword").Return("")
// 		mockUser.On("GetName").Return("")
// 		mockUser.On("GetPhone").Return("")
// 		mockUser.On("GetRoleID").Return(uint(0))
// 		mockUser.On("GetActive").Return(false)
// 		assert.NotNil(t, mockUser)

// 		// Simulate the error
// 		mockRepo.On("Create", mockUser).Return(nil, errors.New("missing required fields"))

// 		// Call the CreateUser method
// 		// with the mock user model
// 		// and expect it to return an error
// 		_, err := userService.CreateUser(mockUser)

// 		// Assert that the error is not nil
// 		// and the created user is nil
// 		// and the error message is as expected
// 		assert.NotNil(t, err)
// 		// Assert that the error message is as expected
// 		assert.EqualError(t, err, "missing required fields")

// 	})

// 	t.Run("should return error when repo.Create fails", func(t *testing.T) {
// 		mockUser.On("GetUsername").Return("testuser")
// 		mockUser.On("GetEmail").Return("test@example.com")
// 		mockUser.On("GetPassword").Return("password123")
// 		mockRepo.On("Create", mockUser).Return(nil, errors.New("database error"))

// 		createdUser, err := userService.CreateUser(mockUser)

// 		assert.Nil(t, createdUser)
// 		assert.EqualError(t, err, "error creating user: database error")
// 		mockUser.AssertExpectations(t)
// 		mockRepo.AssertExpectations(t)
// 	})

// 	t.Run("should create user successfully", func(t *testing.T) {
// 		mockUser.On("GetUsername").Return("testuser")
// 		mockUser.On("GetEmail").Return("test@example.com")
// 		mockUser.On("GetPassword").Return("password123")
// 		mockRepo.On("Create", mockUser).Return(mockUser, nil)

// 		createdUser, err := userService.CreateUser(mockUser)

// 		assert.NotNil(t, createdUser)
// 		assert.NoError(t, err)
// 		mockUser.AssertExpectations(t)
// 		mockRepo.AssertExpectations(t)
// 	})
// }

/// types/database.go ///
package types

import (
	"database/sql/driver"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"

	l "github.com/rafa-mori/logz"
	glb "github.com/rafa-mori/gdbase/internal/globals"
	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	crp "github.com/rafa-mori/gdbase/internal/security/crypto"
	krs "github.com/rafa-mori/gdbase/internal/security/external"
	t "github.com/rafa-mori/gdbase/internal/types"
	gl "github.com/rafa-mori/gdbase/logger"
	"gorm.io/gorm"
)

type JsonB map[string]any

// Serializer manual para o GORM
func (m JsonB) Value() (driver.Value, error) {
	return json.Marshal(m)
}

func (m *JsonB) Scan(vl any) error {
	if vl == nil {
		*m = JsonB{}
		return nil
	}
	return json.Unmarshal(vl.([]byte), m)
}

type DBService = IDBService

type JWT struct {
	Reference             *t.Reference `json:"reference" yaml:"reference" xml:"reference" toml:"reference" mapstructure:"reference,squash"`
	FilePath              string       `json:"file_path" yaml:"file_path" xml:"file_path" toml:"file_path" mapstructure:"file_path"`
	RefreshSecret         string       `gorm:"omitempty" json:"refresh_secret" yaml:"refresh_secret" xml:"refresh_secret" toml:"refresh_secret" mapstructure:"refresh_secret"`
	PrivateKey            string       `gorm:"omitempty" json:"private_key" yaml:"private_key" xml:"private_key" toml:"private_key" mapstructure:"private_key"`
	PublicKey             string       `gorm:"omitempty" json:"public_key" yaml:"public_key" xml:"public_key" toml:"public_key" mapstructure:"public_key"`
	ExpiresIn             int          `gorm:"omitempty" json:"expires_in" yaml:"expires_in" xml:"expires_in" toml:"expires_in" mapstructure:"expires_in"`
	IDExpirationSecs      int          `gorm:"omitempty" json:"id_expiration_secs" yaml:"id_expiration_secs" xml:"id_expiration_secs" toml:"id_expiration_secs" mapstructure:"id_expiration_secs"`
	RefreshExpirationSecs int          `gorm:"omitempty" json:"refresh_expiration_secs" yaml:"refresh_expiration_secs" xml:"refresh_expiration_secs" toml:"refresh_expiration_secs" mapstructure:"refresh_expiration_secs"`
	Mapper                ci.IMapper[JWT]
}
type Database struct {
	Reference        *t.Reference `json:"reference" yaml:"reference" xml:"reference" toml:"reference" mapstructure:"reference,squash"`
	Enabled          bool         `gorm:"default:true" json:"enabled" yaml:"enabled" xml:"enabled" toml:"enabled" mapstructure:"enabled"`
	FilePath         string       `json:"file_path" yaml:"file_path" xml:"file_path" toml:"file_path" mapstructure:"file_path"`
	Type             string       `gorm:"not null" json:"type" yaml:"type" xml:"type" toml:"type" mapstructure:"type"`
	Driver           string       `gorm:"not null" json:"driver" yaml:"driver" xml:"driver" toml:"driver" mapstructure:"driver"`
	ConnectionString string       `gorm:"omitempty" json:"connection_string" yaml:"connection_string" xml:"connection_string" toml:"connection_string" mapstructure:"connection_string"`
	Dsn              string       `gorm:"omitempty" json:"dsn" yaml:"dsn" xml:"dsn" toml:"dsn" mapstructure:"dsn"`
	Path             string       `gorm:"omitempty" json:"path" yaml:"path" xml:"path" toml:"path" mapstructure:"path"`
	Host             string       `gorm:"omitempty" json:"host" yaml:"host" xml:"host" toml:"host" mapstructure:"host"`
	Port             interface{}  `gorm:"omitempty" json:"port" yaml:"port" xml:"port" toml:"port" mapstructure:"port"`
	Username         string       `gorm:"omitempty" json:"username" yaml:"username" xml:"username" toml:"username" mapstructure:"username"`
	Password         string       `gorm:"omitempty" json:"password" yaml:"password" xml:"password" toml:"password" mapstructure:"password"`
	Name             string       `gorm:"omitempty" json:"name" yaml:"name" xml:"name" toml:"name" mapstructure:"name"`
	Volume           string       `gorm:"omitempty" json:"volume" yaml:"volume" xml:"volume" toml:"volume" mapstructure:"volume"`
	Mapper           ci.IMapper[Database]
}
type Redis struct {
	Reference *t.Reference `json:"reference" yaml:"reference" xml:"reference" toml:"reference" mapstructure:"reference,squash"`
	FilePath  string       `json:"file_path" yaml:"file_path" xml:"file_path" toml:"file_path" mapstructure:"file_path"`
	Enabled   bool         `gorm:"default:true" json:"enabled" yaml:"enabled" xml:"enabled" toml:"enabled" mapstructure:"enabled"`
	Addr      string       `gorm:"omitempty" json:"addr" yaml:"addr" xml:"addr" toml:"addr" mapstructure:"addr"`
	Port      interface{}  `gorm:"omitempty" json:"port" yaml:"port" xml:"port" toml:"port" mapstructure:"port"`
	Username  string       `gorm:"omitempty" json:"username" yaml:"username" xml:"username" toml:"username" mapstructure:"username"`
	Password  string       `gorm:"omitempty" json:"password" yaml:"password" xml:"password" toml:"password" mapstructure:"password"`
	DB        interface{}  `gorm:"omitempty" json:"db" yaml:"db" xml:"db" toml:"db" mapstructure:"db"`
	Volume    string       `gorm:"omitempty" json:"volume" yaml:"volume" xml:"volume" toml:"volume" mapstructure:"volume"`
	Mapper    ci.IMapper[Redis]
}
type RabbitMQ struct {
	Reference      *t.Reference `json:"reference" yaml:"reference" xml:"reference" toml:"reference" mapstructure:"reference,squash"`
	FilePath       string       `json:"file_path" yaml:"file_path" xml:"file_path" toml:"file_path" mapstructure:"file_path"`
	Enabled        bool         `gorm:"default:true" json:"enabled" yaml:"enabled" xml:"enabled" toml:"enabled" mapstructure:"enabled"`
	Username       string       `gorm:"omitempty" json:"username" yaml:"username" xml:"username" toml:"username" mapstructure:"username"`
	Password       string       `gorm:"omitempty" json:"password" yaml:"password" xml:"password" toml:"password" mapstructure:"password"`
	Port           interface{}  `gorm:"omitempty" json:"port" yaml:"port" xml:"port" toml:"port" mapstructure:"port"`
	Host           string       `gorm:"omitempty" json:"host" yaml:"host" xml:"host" toml:"host" mapstructure:"host"`
	Volume         string       `gorm:"omitempty" json:"volume" yaml:"volume" xml:"volume" toml:"volume" mapstructure:"volume"`
	ErlangCookie   string       `gorm:"omitempty" json:"erlang_cookie" yaml:"erlang_cookie" xml:"erlang_cookie" toml:"erlang_cookie" mapstructure:"erlang_cookie"`
	ManagementUser string       `gorm:"omitempty" json:"management_user" yaml:"management_user" xml:"management_user" toml:"management_user" mapstructure:"management_user"`
	ManagementPass string       `gorm:"omitempty" json:"management_pass" yaml:"management_pass" xml:"management_pass" toml:"management_pass" mapstructure:"management_pass"`
	ManagementHost string       `gorm:"omitempty" json:"management_host" yaml:"management_host" xml:"management_host" toml:"management_host" mapstructure:"management_host"`
	ManagementPort string       `gorm:"omitempty" json:"management_port" yaml:"management_port" xml:"management_port" toml:"management_port" mapstructure:"management_port"`
	Mapper         ci.IMapper[RabbitMQ]
}
type Messagery struct {
	RabbitMQ *RabbitMQ `json:"rabbitmq" yaml:"rabbitmq" xml:"rabbitmq" toml:"rabbitmq" mapstructure:"rabbitmq"`
	Redis    *Redis    `json:"redis" yaml:"redis" xml:"redis" toml:"redis" mapstructure:"redis"`
	//*Kafka    `json:"kafka" yaml:"kafka" xml:"kafka" toml:"kafka" mapstructure:"kafka"`
	//*Nats     `json:"nats" yaml:"nats" xml:"nats" toml:"nats" mapstructure:"nats"`
	//*ActiveMQ `json:"activemq" yaml:"activemq" xml:"activemq" toml:"activemq" mapstructure:"activemq"`
	//*AMQP     `json:"amqp" yaml:"amqp" xml:"amqp" toml:"amqp" mapstructure:"amqp"`
	Mapper ci.IMapper[Messagery]
}
type MongoDB struct {
	Reference *t.Reference `json:"reference" yaml:"reference" xml:"reference" toml:"reference" mapstructure:"reference,squash"`
	FilePath  string       `json:"file_path" yaml:"file_path" xml:"file_path" toml:"file_path" mapstructure:"file_path"`
	Enabled   bool         `json:"enabled" yaml:"enabled" xml:"enabled" toml:"enabled" mapstructure:"enabled"`
	Host      string       `json:"host" yaml:"host" xml:"host" toml:"host" mapstructure:"host"`
	Port      interface{}  `json:"port" yaml:"port" xml:"port" toml:"port" mapstructure:"port"`
	Username  string       `json:"username" yaml:"username" xml:"username" toml:"username" mapstructure:"username"`
	Password  string       `json:"password" yaml:"password" xml:"password" toml:"password" mapstructure:"password"`
	Mapper    ci.IMapper[MongoDB]
}
type DBConfig struct {
	// FilePath is used to configure the file path of the database
	FilePath string `json:"file_path" yaml:"file_path" xml:"file_path" toml:"file_path" mapstructure:"file_path"`

	// Logger is used to configure the logger
	Logger l.Logger `json:"logger" yaml:"logger" xml:"logger" toml:"logger" mapstructure:"logger"`

	// Mutexes is used to configure the mutexes, not serialized
	*t.Mutexes

	// JWT is used to configure the JWT token settings
	JWT JWT `json:"jwt" yaml:"jwt" xml:"jwt" toml:"jwt" mapstructure:"jwt"`

	// Reference is used to configure the reference of the database
	*t.Reference `json:"reference" yaml:"reference" xml:"reference" toml:"reference" mapstructure:"reference,squash"`

	// Enabled is used to enable or disable the database
	Enabled bool `json:"enabled" yaml:"enabled" xml:"enabled" toml:"enabled" mapstructure:"enabled"`

	// MongoDB is used to configure the MongoDB database
	MongoDB MongoDB `json:"mongodb" yaml:"mongodb" xml:"mongodb" toml:"mongodb" mapstructure:"mongodb"`

	// Databases is used to configure the databases (Postgres, MySQL, SQLite, SQLServer, Oracle)
	Databases map[string]*Database `json:"databases" yaml:"databases" xml:"databases" toml:"databases" mapstructure:"databases"`

	// Messagery is used to configure the messagery database
	Messagery *Messagery

	Mapper ci.IMapper[*DBConfig]
}

func newDBConfig(name, filePath string, enabled bool, logger l.Logger, debug bool) *DBConfig {
	if logger == nil {
		logger = l.NewLogger("GodoBase")
	}

	if debug {
		gl.SetDebug(debug)
	}

	if name == "" {
		name = "default"
	}
	if filePath == "" {
		filePath = os.ExpandEnv(glb.DefaultGodoBaseConfigPath)
	}

	dbConfig := &DBConfig{FilePath: filePath}
	mapper := t.NewMapper[*DBConfig](&dbConfig, filePath)
	obj, err := mapper.DeserializeFromFile("json")
	if err != nil {
		gl.Log("warn", fmt.Sprintf("Error deserializing file: %v", err))
		if obj == nil {
			pgPass, pgPassErr := getPasswordFromKeyring(name)
			if pgPassErr != nil {
				gl.Log("error", fmt.Sprintf("Error getting password from keyring: %v", pgPassErr))
				return nil
			}
			redisPass, redisPassErr := getPasswordFromKeyring(name + "_Redis")
			if redisPassErr != nil {
				gl.Log("error", fmt.Sprintf("Error getting password from keyring: %v", redisPassErr))
				return nil
			}
			rabbitPass, rabbitPassErr := getPasswordFromKeyring(name + "_RabbitMQ")
			if rabbitPassErr != nil {
				gl.Log("error", fmt.Sprintf("Error getting password from keyring: %v", rabbitPassErr))
				return nil
			}

			dbConfigDefault := &DBConfig{
				Databases: map[string]*Database{
					"postgresql": {
						Enabled:          true,
						Reference:        t.NewReference(name).GetReference(),
						Type:             "postgresql",
						Driver:           "postgres",
						ConnectionString: fmt.Sprintf("postgres://kubex_adm:%s@localhost:5432/kubex_db", pgPass),
						Dsn:              fmt.Sprintf("postgres://kubex_adm:%s@localhost:5432/kubex_db", pgPass),
						Path:             os.ExpandEnv(glb.DefaultPostgresVolume),
						Host:             "localhost",
						Port:             "5432",
						Username:         "kubex_adm",
						Password:         pgPass,
						Volume:           os.ExpandEnv(glb.DefaultPostgresVolume),
						Name:             "kubex_db",
					},
				},
				Messagery: &Messagery{
					Redis: &Redis{
						Reference: t.NewReference(name + "_Redis").GetReference(),
						FilePath:  filePath,
						Enabled:   true,
						Addr:      "localhost",
						Port:      "6379",
						Username:  "default",
						Password:  redisPass,
						DB:        0,
					},
					RabbitMQ: &RabbitMQ{
						Reference:      t.NewReference(name + "_RabbitMQ").GetReference(),
						FilePath:       filePath,
						Enabled:        true,
						Username:       "guest",
						Password:       rabbitPass,
						Port:           "5672",
						ManagementPort: "15672",
					},
				},
			}
			dbConfig = dbConfigDefault
			mapper = t.NewMapper[*DBConfig](&dbConfig, filePath)
			mapper.SerializeToFile("json")
			if _, statErr := os.Stat(filepath.Dir(filePath)); os.IsNotExist(statErr) {
				gl.Log("fatal", fmt.Sprintf("Error creating directory: %v", statErr))
			}
			gl.Log("info", fmt.Sprintf("File %s created with default values", filePath))

			if data, dataErr := mapper.Serialize("json"); dataErr != nil {
				gl.Log("fatal", fmt.Sprintf("Error serializing file: %v", dataErr))
			} else {
				if err := os.WriteFile(filePath, data, 0644); err != nil {
					gl.Log("fatal", fmt.Sprintf("Error writing file: %v", err))
				}
			}
		}
	}
	if dbConfig.Logger == nil {
		dbConfig.Logger = logger
	}
	if dbConfig.Databases == nil {
		dbConfig.Databases = map[string]*Database{}
	}
	if dbConfig.Messagery == nil {
		dbConfig.Messagery = &Messagery{}
	}

	return dbConfig
}
func NewDBConfigWithArgs(name, filePath string, enabled bool, logger l.Logger, debug bool) *DBConfig {
	return newDBConfig(name, filePath, enabled, logger, debug)
}
func NewDBConfig(dbConfig *DBConfig) *DBConfig {
	if dbConfig.Logger == nil {
		dbConfig.Logger = l.NewLogger("GodoBase")
	}
	if dbConfig.Name == "" {
		dbConfig.Name = "default"
	}
	if dbConfig.Mutexes == nil {
		dbConfig.Mutexes = t.NewMutexesType()
	}
	if dbConfig.FilePath == "" {
		dbConfig.FilePath = os.ExpandEnv(glb.DefaultGodoBaseConfigPath)
	}
	willWrite := false
	if dbConfig.Mapper == nil {
		dbConfig.Mapper = t.NewMapper[*DBConfig](&dbConfig, dbConfig.FilePath)
		if _, statErr := os.Stat(dbConfig.FilePath); os.IsNotExist(statErr) {
			if err := os.MkdirAll(dbConfig.FilePath, os.ModePerm); err != nil {
				gl.Log("error", fmt.Sprintf("Error creating directory: %v", err))
			} else {
				willWrite = true
			}
		} else {
			_, err := dbConfig.Mapper.DeserializeFromFile("yaml")
			if err != nil {
				gl.Log("error", fmt.Sprintf("Error deserializing file: %v", err))
			}
		}
	}
	if willWrite {
		dbConfig.Mapper.SerializeToFile("json")
	}
	return dbConfig
}
func NewDBConfigWithDBConnection(db *gorm.DB) *DBConfig {
	return newDBConfig("default", "", true, nil, false)
}
func NewDBConfigWithFilePath(name, filePath string) *DBConfig {
	return newDBConfig(name, filePath, true, nil, false)
}
func getPasswordFromKeyring(name string) (string, error) {
	krPass, pgPassErr := krs.NewKeyringService(glb.KeyringService, fmt.Sprintf("gdbase-%s", name)).RetrievePassword()
	if pgPassErr != nil && pgPassErr.Error() != "keyring: item not found" {
		krPassKey, krPassKeyErr := crp.NewCryptoServiceType().GenerateKey()
		if krPassKeyErr != nil {
			gl.Log("error", fmt.Sprintf("Error generating key: %v", krPassKeyErr))
			return "", krPassKeyErr
		}
		storeErr := krs.NewKeyringService(glb.KeyringService, fmt.Sprintf("gdbase-%s", name)).StorePassword(string(krPassKey))
		if storeErr != nil {
			gl.Log("error", fmt.Sprintf("Error storing key: %v", storeErr))
			return "", storeErr
		}
		krPass = string(krPassKey)
	}
	return base64.URLEncoding.EncodeToString([]byte(krPass)), nil
}

/// types/interfaces.go ///
package types

import (
	"gorm.io/gorm"
)

type IDBService interface {
	Initialize() error
	GetDB() (*gorm.DB, error)
	CloseDBConnection() error
	CheckDatabaseHealth() error
	IsConnected() error
	Reconnect() error
	GetHost() (string, error)
	GetConfig() *DBConfig
}

/// types/models/users.go ///
package models

import (
	m "github.com/rafa-mori/gdbase/internal/interfaces"
)

type User = m.User
type UserRepo = m.IUserRepo

/// types/token.go ///
package types

import (
	"context"
	"crypto/rsa"
	"time"

	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	sci "github.com/rafa-mori/gdbase/internal/security/interfaces"
)

type TSConfig struct {
	TokenRepository       TokenRepo
	PrivKey               *rsa.PrivateKey
	PubKey                *rsa.PublicKey
	RefreshSecret         string
	IDExpirationSecs      int64
	RefreshExpirationSecs int64
	KeyringPass           string
	TokenClient           TokenClient
	DBService             *IDBService
	KeyringService        sci.IKeyringService
}
type TokenPair struct {
	IDToken
	RefreshToken
}
type RefreshToken struct {
	ID  string `json:"-"`
	UID string `json:"-"`
	SS  string
}
type IDToken struct {
	SS string
}

type TokenClient interface {
	LoadPrivateKey() (*rsa.PrivateKey, error)
	LoadPublicKey() *rsa.PublicKey
	LoadTokenCfg() (TokenService, int64, int64, error)
}
type TokenRepo interface {
	SetRefreshToken(ctx context.Context, userID string, tokenID string, expiresIn time.Duration) error
	DeleteRefreshToken(ctx context.Context, userID string, prevTokenID string) error
	DeleteUserRefreshTokens(ctx context.Context, userID string) error
}

type TokenService interface {
	NewPairFromUser(ctx context.Context, u ci.User, prevTokenID string) (*TokenPair, error)
	SignOut(ctx context.Context, uid string) error
	ValidateIDToken(tokenString string) (ci.User, error)
	ValidateRefreshToken(refreshTokenString string) (*RefreshToken, error)
	RenewToken(ctx context.Context, refreshToken string) (*TokenPair, error)
}

/// utils/channels.go ///
package utils

import (
	ci "github.com/rafa-mori/gdbase/internal/interfaces"
	gl "github.com/rafa-mori/gdbase/logger"

	"fmt"
	"reflect"
)

func chanRoutineCtl[T any](v ci.IChannelCtl[T], chCtl chan string, ch chan T) {
	select {
	case msg := <-chCtl:
		switch msg {
		case "stop":
			if ch != nil {
				gl.Log("debug", "Stopping channel for:", v.GetName(), "ID:", v.GetID().String())
				ch <- v.GetProperty().GetValue()
				return
			}
		case "get":
			if ch != nil {
				gl.Log("debug", "Getting value from channel for:", v.GetName(), "ID:", v.GetID().String())
				ch <- v.GetProperty().GetValue()
			}
		case "set":
			if ch != nil {
				gl.Log("debug", "Waiting for value from channel for:", v.GetName(), "ID:", v.GetID().String())
				nVal := <-ch
				if reflect.ValueOf(nVal).IsValid() {
					if reflect.ValueOf(nVal).CanConvert(reflect.TypeFor[T]()) {
						gl.Log("debug", "Setting value from channel for:", v.GetName(), "ID:", v.GetID().String())
						v.GetProperty().SetValue(&nVal)
					} else {
						gl.Log("error", "Set: invalid type for channel value (", reflect.TypeFor[T]().String(), ")")
					}
				}
			}
		case "save":
			if ch != nil {
				gl.Log("debug", "Saving value from channel for:", v.GetName(), "ID:", v.GetID().String())
				nVal := <-ch
				if reflect.ValueOf(nVal).IsValid() {
					if reflect.ValueOf(nVal).CanConvert(reflect.TypeFor[T]()) {
						gl.Log("debug", "Saving value from channel for:", v.GetName(), "ID:", v.GetID().String())
						v.GetProperty().SetValue(&nVal)
					} else {
						gl.Log("error", "Save: invalid type for channel value (", reflect.TypeFor[T]().String(), ")")
					}
				}
			}
		case "clear":
			if ch != nil {
				gl.Log("debug", "Clearing channel for:", v.GetName(), "ID:", v.GetID().String())
				v.GetProperty().SetValue(nil)
			}
		}
	}
}
func chanRoutineDefer[T any](v ci.IChannelCtl[T], chCtl chan string, ch chan T) {
	if r := recover(); r != nil {
		gl.Log("error", "Recovering from panic in monitor routine for:", v.GetName(), "ID:", v.GetID().String(), "Error:", fmt.Sprintf("%v", r))
		// In recovering from panic, we need to check if the channel is nil.
		// If it is nil, we need to create a new channel.
		if ch == nil {
			gl.Log("debug", "Creating new channel for:", v.GetName(), "ID:", v.GetID().String())
			// If the channel is nil, create a new channel.
			ch = make(chan T, 3)
		}
		if chCtl == nil {
			gl.Log("debug", "Creating new control channel for:", v.GetName(), "ID:", v.GetID().String())
			// If the control channel is nil, create a new control channel.
			chCtl = make(chan string, 2)
		}
	} else {
		gl.Log("debug", "Exiting monitor routine for:", v.GetName(), "ID:", v.GetID().String())
		// When the monitor routine is done, we need to close the channels.
		// If the channel is not nil, close it.
		if ch != nil {
			close(ch)
		}
		if chCtl != nil {
			close(chCtl)
		}
		ch = nil
		chCtl = nil
	}
	// Always check the v mutexes to see if someone is locking the mutex or not on exit (defer).
	if v.MuTryLock() {
		// If the mutex was locked, unlock it.
		v.MuUnlock()
	} else if v.MuTryRLock() {
		// If the mutex was locked, unlock it.
		v.MuRUnlock()
	}
}
func chanRoutineWrapper[T any](v ci.IChannelCtl[T]) {
	gl.Log("debug", "Setting monitor routine for:", v.GetName(), "ID:", v.GetID().String())
	if rawChCtl, chCtlType, chCtlOk := v.GetSubChannelByName("ctl"); !chCtlOk {
		gl.LogObjLogger(&v, "error", "ChannelCtl: no control channel found")
		return
	} else {
		if chCtlType != reflect.TypeOf("string") {
			gl.LogObjLogger(&v, "error", "ChannelCtl: control channel is not a string channel")
			return
		}
		chCtl := reflect.ValueOf(rawChCtl).Interface().(chan string)
		rawCh := v.GetMainChannel()
		ch := reflect.ValueOf(rawCh).Interface().(chan T)

		defer chanRoutineDefer[T](v, chCtl, ch)
		for {
			chanRoutineCtl[T](v, chCtl, ch)
			if ch == nil {
				gl.Log("debug", "Channel is nil for:", v.GetName(), "ID:", v.GetID().String(), "Exiting monitor routine")
				break
			}
			if chCtl == nil {
				gl.Log("debug", "Control channel is nil for:", v.GetName(), "ID:", v.GetID().String(), "Exiting monitor routine")
				break
			}
		}
	}
}

func GetDefaultBufferSizes() (sm, md, lg int) { return 2, 5, 10 }

/// utils/data.go ///
package utils

import (
	"bytes"
	"compress/gzip"
	"crypto"
	"crypto/aes"
	"crypto/cipher"
	"crypto/rand"
	"crypto/rsa"
	"crypto/sha256"
	"crypto/x509"
	"encoding/base64"
	"encoding/hex"
	"encoding/pem"
	"fmt"
	"hash"
	"io"
	"os"
	"os/exec"
	"reflect"
	"regexp"
	"strconv"
	"strings"

	"gopkg.in/ini.v1"
)

// Contains verifica se um elemento est√° presente em um slice, mapa ou string
// slice: cole√ß√£o onde o elemento ser√° procurado
// element: elemento a ser procurado
// Retorna true se o elemento estiver presente, caso contr√°rio, false
func Contains(slice interface{}, element interface{}) bool {
	if element == nil || element == "" {
		return false
	}

	interfaceType := reflect.TypeOf(slice).Kind()
	elemToCompare := element.(string)

	switch interfaceType {
	case reflect.String:
		s := slice.(string)
		return strings.Contains(s, elemToCompare)
	case reflect.Int:
		s := slice.(int)
		return s == element
	case reflect.Slice:
		s := reflect.ValueOf(slice)
		for i := 0; i < s.Len(); i++ {
			if s.Index(i).String() == element {
				return true
			}
		}
		return false
	case reflect.Map:
		s := reflect.ValueOf(slice)
		for _, val := range s.MapKeys() {
			if val.String() == element {
				return true
			}
		}
		return false
	case reflect.Array:
		s := reflect.ValueOf(slice)
		for i := 0; i < s.Len(); i++ {
			if s.Index(i).String() == element {
				return true
			}
		}
		return false
	case reflect.Struct:
		s := reflect.ValueOf(slice)
		for i := 0; i < s.NumField(); i++ {
			if s.Field(i).String() == element {
				return true
			}
		}
		return false
	case reflect.Ptr:
		s := reflect.ValueOf(slice).Elem()
		for i := 0; i < s.Len(); i++ {
			if s.Index(i).String() == element {
				return true
			}
		}
		return false
	default:
		return false
	}
}

// ContainsPattern verifica se o nome do arquivo cont√©m um dos padr√µes fornecidos
// filename: nome do arquivo a ser verificado
// patterns: lista de padr√µes a serem procurados
// Retorna true se o nome do arquivo contiver um dos padr√µes, caso contr√°rio, false
func ContainsPattern(filename string, patterns []string) bool {
	for _, pattern := range patterns {
		if strings.Contains(filename, pattern) {
			return true
		}
	}
	return false
}

// EncryptData encripta os dados usando uma chave fornecida
// data: dados a serem encriptados
// key: chave usada para encriptar os dados
// Retorna os dados encriptados como string e um erro, se houver
func EncryptData(data, key string) (string, error) {
	block, err := aes.NewCipher([]byte(createHash(key)))
	if err != nil {
		return "", err
	}

	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return "", err
	}

	nonce := make([]byte, gcm.NonceSize())
	if _, err = io.ReadFull(rand.Reader, nonce); err != nil {
		return "", err
	}

	ciphertext := gcm.Seal(nonce, nonce, []byte(data), nil)
	return fmt.Sprintf("%x", ciphertext), nil
}

// DecryptData descriptografa os dados usando uma chave fornecida
// data: dados a serem descriptografados
// key: chave usada para descriptografar os dados
// Retorna os dados descriptografados como string e um erro, se houver
func DecryptData(data, key string) (string, error) {
	block, err := aes.NewCipher([]byte(createHash(key)))
	if err != nil {
		return "", err
	}

	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return "", err
	}

	nonceSize := gcm.NonceSize()
	dataBytes, err := hex.DecodeString(data)
	if err != nil {
		return "", err
	}

	nonce, ciphertext := dataBytes[:nonceSize], dataBytes[nonceSize:]
	plaintext, err := gcm.Open(nil, nonce, ciphertext, nil)
	if err != nil {
		return "", err
	}

	return string(plaintext), nil
}

// HashData gera um hash SHA-256 dos dados fornecidos
// data: dados a serem hasheados
// Retorna o hash dos dados como string
func HashData(data string) string {
	hash := sha256.New()
	hash.Write([]byte(data))
	return hex.EncodeToString(hash.Sum(nil))
}

func NewHash() hash.Hash {
	return sha256.New()
}

// ValidateHash valida se os dados correspondem ao hash fornecido
// data: dados a serem validados
// hash: hash a ser comparado
// Retorna true se os dados corresponderem ao hash, caso contr√°rio, false
func ValidateHash(data, hash string) bool {
	return HashData(data) == hash
}

// createHash cria um hash SHA-256 de uma chave fornecida
// key: chave a ser hasheada
// Retorna o hash da chave como string
func createHash(key string) string {
	hash := sha256.New()
	hash.Write([]byte(key))
	return hex.EncodeToString(hash.Sum(nil))
}

// CompressData comprime dados usando gzip
// data: dados a serem comprimidos
// Retorna os dados comprimidos como string e um erro, se houver
func CompressData(data string) (string, error) {
	var buf bytes.Buffer
	writer := gzip.NewWriter(&buf)
	_, err := writer.Write([]byte(data))
	if err != nil {
		return "", err
	}
	writer.Close()
	return base64.URLEncoding.EncodeToString(buf.Bytes()), nil
}

// DecompressData descomprime dados previamente comprimidos
// data: dados a serem descomprimidos
// Retorna os dados descomprimidos como string e um erro, se houver
func DecompressData(data string) (string, error) {
	decoded, err := base64.URLEncoding.DecodeString(data)
	if err != nil {
		return "", err
	}
	reader, err := gzip.NewReader(bytes.NewReader(decoded))
	if err != nil {
		return "", err
	}
	defer reader.Close()
	result, err := io.ReadAll(reader)
	if err != nil {
		return "", err
	}
	return string(result), nil
}

func CompressFolder(folderPath string, outputPath string, compressType string) error {
	if compressType == "zip" {
		return compressFolderToZip(folderPath, outputPath)
	} else if compressType == "tar" {
		return compressFolderToTar(folderPath, outputPath)
	} else {
		return fmt.Errorf("tipo de compress√£o n√£o suportado")
	}
}
func compressFolderToZip(folderPath string, outputPath string) error {
	compressCmd := fmt.Sprintf("zip -r %s %s -9", outputPath, folderPath)
	cmd := exec.Command("sh", "-c", compressCmd)
	err := cmd.Run()
	if err != nil {
		return err
	}
	return nil
}
func compressFolderToTar(folderPath string, outputPath string) error {
	compressCmd := fmt.Sprintf("tar -czf %s %s", outputPath, folderPath)
	cmd := exec.Command("sh", "-c", compressCmd)
	err := cmd.Run()
	if err != nil {
		return err
	}
	return nil
}

func DecompressFolder(folderPath string, outputPath string) error {
	detectedType, detectedTypeErr := detectCompressType(folderPath)
	if detectedTypeErr != nil {
		return detectedTypeErr
	}
	if detectedType == "zip" {
		return decompressFolderFromZip(folderPath, outputPath)
	} else if detectedType == "tar" {
		return decompressFolderFromTar(folderPath, outputPath)
	} else {
		return fmt.Errorf("tipo de compress√£o n√£o suportado")
	}
}
func detectCompressType(folderPath string) (string, error) {
	cmdFile := fmt.Sprintf("file %s", folderPath)
	cmd := exec.Command("sh", "-c", cmdFile)
	output, err := cmd.Output()
	if err != nil {
		return "", err
	}
	if strings.Contains(string(output), "Zip archive data") {
		return "zip", nil
	} else if strings.Contains(string(output), "gzip compressed data") {
		return "tar", nil
	} else {
		return "", fmt.Errorf("tipo de compress√£o n√£o suportado")
	}
}
func decompressFolderFromZip(folderPath string, outputPath string) error {
	decompressCmd := fmt.Sprintf("unzip %s -d %s", folderPath, outputPath)
	cmd := exec.Command("sh", "-c", decompressCmd)
	err := cmd.Run()
	if err != nil {
		return err
	}
	return nil
}
func decompressFolderFromTar(folderPath string, outputPath string) error {
	decompressCmd := fmt.Sprintf("tar -xzf %s -C %s", folderPath, outputPath)
	cmd := exec.Command("sh", "-c", decompressCmd)
	err := cmd.Run()
	if err != nil {
		return err
	}
	return nil
}

// EncodeData codifica dados em Base64
// data: dados a serem codificados
// Retorna os dados codificados como string
func EncodeData(data string) string {
	return base64.URLEncoding.EncodeToString([]byte(data))
}

// DecodeData decodifica dados de Base64
// data: dados a serem decodificados
// Retorna os dados decodificados como string e um erro, se houver
func DecodeData(data string) (string, error) {
	decoded, err := base64.URLEncoding.DecodeString(data)
	if err != nil {
		return "", err
	}
	return string(decoded), nil
}

// SignData assina dados digitalmente usando uma chave privada
// data: dados a serem assinados
// privateKey: chave privada usada para assinar os dados
// Retorna a assinatura dos dados como string e um erro, se houver
func SignData(data string, privateKey *rsa.PrivateKey) (string, error) {
	hashed := sha256.Sum256([]byte(data))
	signature, err := rsa.SignPKCS1v15(rand.Reader, privateKey, crypto.SHA256, hashed[:])
	if err != nil {
		return "", err
	}
	return base64.URLEncoding.EncodeToString(signature), nil
}

// VerifyData verifica a assinatura digital dos dados usando uma chave p√∫blica
// data: dados a serem verificados
// signature: assinatura a ser verificada
// publicKey: chave p√∫blica usada para verificar a assinatura
// Retorna um erro se a verifica√ß√£o falhar, caso contr√°rio, nil
func VerifyData(data, signature string, publicKey *rsa.PublicKey) error {
	hashed := sha256.Sum256([]byte(data))
	decodedSig, err := base64.URLEncoding.DecodeString(signature)
	if err != nil {
		return err
	}
	return rsa.VerifyPKCS1v15(publicKey, crypto.SHA256, hashed[:], decodedSig)
}

// LoadPrivateKey carrega uma chave privada de um arquivo
// path: caminho do arquivo contendo a chave privada
// Retorna a chave privada e um erro, se houver
func LoadPrivateKey(path string) (*rsa.PrivateKey, error) {
	keyData, err := os.ReadFile(path)
	if err != nil {
		return nil, err
	}
	block, _ := pem.Decode(keyData)
	if block == nil || block.Type != "RSA PRIVATE KEY" {
		return nil, fmt.Errorf("chave privada inv√°lida")
	}
	return x509.ParsePKCS1PrivateKey(block.Bytes)
}

// LoadPublicKey carrega uma chave p√∫blica de um arquivo
// path: caminho do arquivo contendo a chave p√∫blica
// Retorna a chave p√∫blica e um erro, se houver
func LoadPublicKey(path string) (any, error) {
	keyData, err := os.ReadFile(path)
	if err != nil {
		return nil, err
	}
	block, _ := pem.Decode(keyData)
	if block == nil || block.Type != "PUBLIC KEY" {
		return nil, fmt.Errorf("chave p√∫blica inv√°lida")
	}
	return x509.ParsePKIXPublicKey(block.Bytes)
}

// ConvertAnyDataToType converte qualquer tipo de dados para o tipo fornecido
// data: dados a serem convertidos
// targetType: tipo alvo para a convers√£o
// Retorna os dados convertidos e um erro, se houver
func ConvertAnyDataToType(data interface{}, targetType string) (interface{}, error) {
	if reflect.TypeOf(data).String() == targetType {
		return data, nil
	}

	switch targetType {
	case "string":
		if data == nil {
			return "", nil
		}
		return fmt.Sprintf("%v", data), nil
	case "int":
		if data == nil {
			return 0, nil
		}
		return strconv.Atoi(fmt.Sprintf("%v", data))
	case "float":
		if data == nil {
			return 0.0, nil
		}
		return strconv.ParseFloat(fmt.Sprintf("%v", data), 64)
	case "bool":
		if data == nil {
			return false, nil
		}
		return strconv.ParseBool(fmt.Sprintf("%v", data))
	case "[]byte":
		if data == nil {
			return []byte{}, nil
		}
		return []byte(fmt.Sprintf("%v", data)), nil
	default:
		return nil, fmt.Errorf("tipo de dados n√£o suportado")
	}
}

// GetGoType retorna o tipo de dados de uma vari√°vel em Go
// data: vari√°vel a ser verificada
// Retorna o tipo de dados como string
func GetGoType(data interface{}) string {
	return reflect.TypeOf(data).String()
}

// DBTypeToGoType converte um tipo de dados de banco de dados para um tipo de dados em Go
// dbType: tipo de dados do banco de dados
// Retorna o tipo de dados correspondente em Go como string
func DBTypeToGoType(dbType string) string {
	switch dbType {
	case "NUMBER", "REAL", "DECIMAL", "NUMERIC", "FLOAT":
		return "float64"
	case "VARCHAR", "TEXT", "VARCHAR2":
		return "string"
	case "INT", "INTEGER":
		return "int"
	case "DATE", "DATETIME", "TIMESTAMP":
		return "time.Time"
	case "BOOLEAN", "BIT":
		return "bool"
	case "BLOB", "VARBINARY", "BYTEA":
		return "[]byte"
	case "CLOB":
		return "string"
	case "TINYINT":
		return "int8"
	default:
		return "interface{}"
	}
}

func LoadConfigFile(fileType, configPath string) (any, error) {
	switch fileType {
	case "ini":
		return LoadINIConfigFile(configPath)
	case "json":
		return LoadJSONConfigFile(configPath)
	case "yaml":
		return LoadYAMLConfigFile(configPath)
	case "xml":
		return LoadXMLConfigFile(configPath)
	case "toml":
		return LoadTOMLConfigFile(configPath)
	default:
		return nil, fmt.Errorf("tipo de arquivo de configura√ß√£o n√£o suportado")
	}
}

func LoadINIConfigFile(configPath string) (interface{}, error) {
	if configPath == "" {
		return nil, fmt.Errorf("caminho do arquivo de configura√ß√£o n√£o fornecido")
	}
	if _, err := os.Stat(configPath); os.IsNotExist(err) {
		return nil, fmt.Errorf("arquivo de configura√ß√£o n√£o encontrado")
	}

	cfg, err := ini.Load(configPath)
	if err != nil {
		return nil, fmt.Errorf("erro ao carregar arquivo de configura√ß√£o: %v", err)
	}

	return cfg, nil
}

func LoadJSONConfigFile(configPath string) (interface{}, error) {
	if configPath == "" {
		return nil, fmt.Errorf("caminho do arquivo de configura√ß√£o n√£o fornecido")
	}
	if _, err := os.Stat(configPath); os.IsNotExist(err) {
		return nil, fmt.Errorf("arquivo de configura√ß√£o n√£o encontrado")
	}
	config, err := os.ReadFile(configPath)
	if err != nil {
		return nil, err
	}
	return config, nil
}

func LoadYAMLConfigFile(configPath string) (interface{}, error) {
	if configPath == "" {
		return nil, fmt.Errorf("caminho do arquivo de configura√ß√£o n√£o fornecido")
	}
	if _, err := os.Stat(configPath); os.IsNotExist(err) {
		return nil, fmt.Errorf("arquivo de configura√ß√£o n√£o encontrado")
	}
	config, err := os.ReadFile(configPath)
	if err != nil {
		return nil, err
	}
	return config, nil
}

func LoadXMLConfigFile(configPath string) (interface{}, error) {
	if configPath == "" {
		return nil, fmt.Errorf("caminho do arquivo de configura√ß√£o n√£o fornecido")
	}
	if _, err := os.Stat(configPath); os.IsNotExist(err) {
		return nil, fmt.Errorf("arquivo de configura√ß√£o n√£o encontrado")
	}
	config, err := os.ReadFile(configPath)
	if err != nil {
		return nil, err
	}
	return config, nil
}

func LoadTOMLConfigFile(configPath string) (interface{}, error) {
	if configPath == "" {
		return nil, fmt.Errorf("caminho do arquivo de configura√ß√£o n√£o fornecido")
	}
	if _, err := os.Stat(configPath); os.IsNotExist(err) {
		return nil, fmt.Errorf("arquivo de configura√ß√£o n√£o encontrado")
	}
	config, err := os.ReadFile(configPath)
	if err != nil {
		return nil, err
	}
	return config, nil
}

func IsBase64String(s string) bool {
	matched, _ := regexp.MatchString("^([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{3}=|[A-Za-z0-9+/]{2}==)?$", s)
	return matched
}

func IsBase64ByteSlice(s []byte) bool {
	matched, _ := regexp.Match("^([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{3}=|[A-Za-z0-9+/]{2}==)?$", s)
	return matched
}

func IsBase64ByteSliceString(s string) bool {
	matched, _ := regexp.Match("^([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{3}=|[A-Za-z0-9+/]{2}==)?$", []byte(s))
	return matched
}
func IsBase64ByteSliceStringWithPadding(s string) bool {
	matched, _ := regexp.Match("^([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{3}=|[A-Za-z0-9+/]{2}==)?$", []byte(s))
	return matched
}

func IsUrlEncodeString(s string) bool {
	matched, _ := regexp.MatchString("^[a-zA-Z0-9%_.-]+$", s)
	return matched
}
func IsUrlEncodeByteSlice(s []byte) bool {
	matched, _ := regexp.Match("^[a-zA-Z0-9%_.-]+$", s)
	return matched
}

func IsBase62String(s string) bool {
	matched, _ := regexp.MatchString("^[a-zA-Z0-9+_]+$", s)
	return matched
}
func IsBase62ByteSlice(s []byte) bool {
	matched, _ := regexp.Match("^[a-zA-Z0-9+_]+$", s)
	return matched
}

/// utils/helpers/bash_yes_no_question.go ///
package helpers

const cdxYesNoQyestionTemplate = `#!/bin/bash

function _mri_yes_no_question() {
  source $HOME/.mori_logging_env

  local _question="${1:-$2}"
  local _default_answer="${2:-}"
  local _timeout="${3:-5}"
  local _answer=""
  local _counter=0
  
  while [[ ! "$_answer" =~ ^[yYnN]$ ]]; do
    if [ "$_counter" -gt 3 ]; then
      mri_log error "Maximum number of attempts reached."
      printf '%s\n' "Please try again later."
      return 1 
    else
      _counter=$((_counter + 1))
    fi
    read -rt "${_timeout}" -rp "${_question} " -n 1 _answer || _answer="${_default_answer:-}"
    if [ -z "${_answer}" ]; then
      if [ -n "${_default_answer}" ]; then
        _answer="${_default_answer}"
      fi
    fi
  done
  if [[ "${_answer}" =~ ^[yY]$ ]]; then
    # printf '%s\n' "y"
    return 0
  else
    # printf '%s\n' "n"
    return 1
  fi
}

_mri_yes_no_question "$@"

exit $?

`

/// utils/helpers/helpers.go ///
package helpers

import (
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"
)

// writeFileIfNotExists creates a file and writes default content if it does not exist.
func writeFileIfNotExists(filePath, content string) error {
	// Check if the file already exists
	if _, err := os.Stat(filePath); err == nil {
		return nil // File already exists, do nothing
	}

	// Create the file and write the content
	file, err := os.Create(filePath)
	if err != nil {
		return err
	}
	defer file.Close()

	_, err = file.WriteString(content)
	return err
}

// appendToShellConfig adds a snippet to the shell configuration file if it's not already present.
func appendToShellConfig(shellConfig, snippet string) error {
	// Read the file content if it exists
	content, err := os.ReadFile(shellConfig)
	if err != nil && !os.IsNotExist(err) {
		return err
	}

	// Check if the snippet is already present
	if strings.Contains(string(content), snippet) {
		return nil // Snippet is already in the file, no need to modify
	}

	// Open the file for appending
	file, err := os.OpenFile(shellConfig, os.O_APPEND|os.O_WRONLY|os.O_CREATE, 0644)
	if err != nil {
		return err
	}
	defer file.Close()

	// Append the snippet at the end of the file
	_, err = file.WriteString("\n" + snippet + "\n")
	return err
}

// removeSnippetFromShellConfig removes a specific snippet from the shell configuration file.
func removeSnippetFromShellConfig(shellConfig, snippet string) error {
	// Read the file content
	content, err := os.ReadFile(shellConfig)
	if err != nil {
		if os.IsNotExist(err) {
			return nil // File does not exist, nothing to remove
		}
		return err
	}

	// Convert content to a string and remove the snippet
	newContent := strings.ReplaceAll(string(content), "\n"+snippet+"\n", "")

	// If no changes, return early
	if newContent == string(content) {
		return nil
	}

	// Write the modified content back to the file
	return os.WriteFile(shellConfig, []byte(newContent), 0644)
}

// InstallBashHelpers creates the necessary scripts and adds them to the shell startup files.
func InstallBashHelpers() {
	homeDir, err := os.UserHomeDir()
	if err != nil {
		fmt.Println("Error getting home directory:", err)
		return
	}

	// Environment files to be created
	filesToCreate := map[string]string{
		filepath.Join(homeDir, ".mori_utils_env"):       cdxBashEnvTemplate,
		filepath.Join(homeDir, ".mori_logging_env"):     cdxBashLogTemplate,
		filepath.Join(homeDir, ".mori_yes_no_question"): cdxYesNoQyestionTemplate,
	}

	// Create files if they do not exist
	for filePath, content := range filesToCreate {
		if err := writeFileIfNotExists(filePath, content); err != nil {
			fmt.Println("Error creating file:", filePath, err)
		}
	}

	// Snippet to be added to .bashrc or .zshrc
	snippet := `if test -f "$HOME/.mori_utils_env"; then
	. "$HOME/.mori_utils_env"
fi

if test -f "$HOME/.mori_logging_env"; then
	. "$HOME/.mori_logging_env"
fi
`
	// Detect which shell is being used
	shell := os.Getenv("SHELL")
	shellConfig := filepath.Join(homeDir, ".bashrc") // Default for Bash

	if strings.HasSuffix(shell, "zsh") {
		shellConfig = filepath.Join(homeDir, ".zshrc")
	}

	// Add the snippet to the shell configuration file
	if err := appendToShellConfig(shellConfig, snippet); err != nil {
		fmt.Println("Error modifying shell configuration file:", err)
	} else {
		fmt.Println("Configuration successfully added to", shellConfig)
	}

	// Determina o arquivo de configura√ß√£o correto do shell
	shellRC := fmt.Sprintf("$HOME/.$(basename $SHELL)rc")

	// Comando a ser injetado
	command := fmt.Sprintf(". %s\n", shellRC)

	// Obt√©m o terminal do usu√°rio (stdin ativo)
	tty, err := os.OpenFile("/dev/tty", os.O_WRONLY, 0)
	if err != nil {
		fmt.Println("‚ö†Ô∏è N√£o foi poss√≠vel acessar o terminal:", err)
		fmt.Printf("Por favor, execute manualmente: . %s\n", shellRC)
		return
	}
	defer tty.Close()

	// Aguarda um breve momento para garantir que a sa√≠da foi impressa antes da inje√ß√£o
	time.Sleep(500 * time.Millisecond)

	// Escreve o comando diretamente no terminal do usu√°rio
	_, wrtErr := tty.WriteString(command)
	if wrtErr != nil {
		return
	}
}

// UninstallBashHelpers removes the scripts and their references from the shell startup files.
func UninstallBashHelpers() {
	homeDir, err := os.UserHomeDir()
	if err != nil {
		fmt.Println("Error getting home directory:", err)
		return
	}

	// Files to be removed
	filesToRemove := []string{
		filepath.Join(homeDir, ".mori_utils_env"),
		filepath.Join(homeDir, ".mori_logging_env"),
		filepath.Join(homeDir, ".mori_yes_no_question"),
		filepath.Join(filepath.Join(homeDir, ".cache"), ".mori_install_log"),
		filepath.Join(filepath.Join(homeDir, ".cache"), ".mri_usage_warning"),
	}

	// Remove files
	for _, filePath := range filesToRemove {
		if err := os.Remove(filePath); err != nil && !os.IsNotExist(err) {
			fmt.Println("Error removing file:", filePath, err)
		}
	}

	// Snippet to be removed from .bashrc or .zshrc
	snippet := `if test -f "$HOME/.mori_utils_env"; then
	. "$HOME/.mori_utils_env"
fi

if test -f "$HOME/.mori_logging_env"; then
	. "$HOME/.mori_logging_env"
fi
`
	// Detect which shell is being used
	shell := os.Getenv("SHELL")
	shellConfig := filepath.Join(homeDir, ".bashrc") // Default for Bash

	if strings.HasSuffix(shell, "zsh") {
		shellConfig = filepath.Join(homeDir, ".zshrc")
	}

	// Remove the snippet from the shell configuration file
	if err := removeSnippetFromShellConfig(shellConfig, snippet); err != nil {
		fmt.Println("Error modifying shell configuration file:", err)
	} else {
		fmt.Println("Configuration successfully removed from", shellConfig)
	}

	fmt.Println("Bash helpers successfully uninstalled.")
}

/// utils/path.go ///
package utils

import (
	"archive/tar"
	"archive/zip"
	"compress/gzip"
	"crypto/md5"
	"errors"
	"fmt"
	"io"
	"os"
	"os/exec"
	"path/filepath"
	"strconv"
	"strings"
	"time"
)

// getAbsRelativesPaths obt√©m os caminhos absolutos dos caminhos relativos fornecidos.
// basePath: caminho base a partir do qual os caminhos relativos ser√£o resolvidos.
// paths: lista de caminhos relativos.
// Retorna uma lista de caminhos absolutos e um erro, se houver.
func getAbsRelativesPaths(basePath string, paths []string) ([]string, error) {
	var absPaths []string
	for _, path := range paths {
		absPath, err := filepath.Abs(filepath.Join(basePath, path))
		if err != nil {
			return nil, fmt.Errorf("erro ao obter o caminho absoluto do arquivo: %v", err)
		}
		absPaths = append(absPaths, absPath)
	}
	return absPaths, nil
}

// SanitizePath sanitiza um caminho de arquivo, garantindo que ele esteja dentro do caminho base.
// basePath: caminho base.
// inputPath: caminho de entrada a ser sanitizado.
// Retorna o caminho sanitizado e um erro, se houver.
func SanitizePath(basePath, inputPath string) (string, error) {
	// Limpa o caminho de entrada
	cleanPath := filepath.Clean(inputPath)

	// Junta o caminho base e o caminho de entrada limpo
	fullPath := filepath.Join(basePath, cleanPath)

	// Garante que o caminho completo esteja dentro do caminho base
	if !strings.HasPrefix(fullPath, filepath.Clean(basePath)+string(filepath.Separator)) {
		return "", errors.New("invalid file path")
	}

	return fullPath, nil
}

// EnsureDir garante que um diret√≥rio exista, criando-o se necess√°rio.
// path: caminho do diret√≥rio.
// perm: permiss√µes do diret√≥rio.
// userGroup: lista contendo o usu√°rio e grupo do diret√≥rio.
// Retorna um erro, se houver.
func EnsureDir(path string, perm os.FileMode, userGroup []string) error {
	basePath := filepath.Dir(path)
	targetPath := filepath.Base(path)
	pathSSanitized, pathSSanitizedErr := SanitizePath(basePath, targetPath)
	if pathSSanitizedErr != nil {
		return pathSSanitizedErr
	}

	// Verifica se o diret√≥rio j√° existe
	cmdCheckDir := exec.Command("test", "-d", pathSSanitized)
	cmdCheckDirErr := cmdCheckDir.Run()
	if cmdCheckDirErr == nil {
		return nil
	}

	// Cria o diret√≥rio
	cmdPathUser := exec.Command("mkdir", "-p", pathSSanitized)
	cmdPathUserErr := cmdPathUser.Run()
	if cmdPathUserErr != nil {
		cmdPathRoot := exec.Command("sudo", "mkdir", "-p", pathSSanitized)
		cmdPathRootErr := cmdPathRoot.Run()
		if cmdPathRootErr != nil {
			return fmt.Errorf("erro ao criar o diret√≥rio: %w", cmdPathRootErr)
		}

		// Define o propriet√°rio e as permiss√µes do diret√≥rio
		if len(userGroup) > 0 {
			cmdChown := exec.Command("sudo", "chown", strings.Join(userGroup, ":"), pathSSanitized)
			cmdChownErr := cmdChown.Run()
			if cmdChownErr != nil {
				return fmt.Errorf("erro ao definir o propriet√°rio do diret√≥rio: %v", cmdChownErr)
			}
		}

		permOp := perm
		if permOp == 0 {
			permOp = os.ModePerm
		}

		// Define as permiss√µes do diret√≥rio
		cmdChmod := exec.Command("sudo", "chmod", strconv.Itoa(int(permOp)), pathSSanitized)
		cmdChmodErr := cmdChmod.Run()
		if cmdChmodErr != nil {
			return fmt.Errorf("erro ao definir permiss√µes do diret√≥rio: %w", cmdChmodErr)
		}
	}
	return nil
}

// EnsureFile garante que um arquivo exista, criando-o se necess√°rio.
// path: caminho do arquivo.
// perm: permiss√µes do arquivo.
// userGroup: lista contendo o usu√°rio e grupo do arquivo.
// Retorna um erro, se houver.
func EnsureFile(path string, perm os.FileMode, userGroup []string) error {
	basePath := filepath.Dir(path)
	targetPath := filepath.Base(path)
	pathSSanitized, pathSSanitizedErr := SanitizePath(basePath, targetPath)
	if pathSSanitizedErr != nil {
		return pathSSanitizedErr
	}

	// Verifica se o diret√≥rio base existe
	cmdCheckDir := exec.Command("ls", "-d", basePath)
	cmdCheckDirErr := cmdCheckDir.Run()
	if cmdCheckDirErr != nil {
		ensureDirErr := EnsureDir(basePath, perm, userGroup)
		if ensureDirErr != nil {
			return ensureDirErr
		}
	}

	// Verifica se o arquivo j√° existe
	cmdCheckFile := exec.Command("ls", pathSSanitized)
	cmdCheckFileErr := cmdCheckFile.Run()
	if cmdCheckFileErr == nil {
		return nil
	}

	// Cria o arquivo
	cmdPathUser := exec.Command("touch", pathSSanitized)
	cmdPathUserErr := cmdPathUser.Run()
	if cmdPathUserErr != nil {
		cmdPathRoot := exec.Command("sudo", "touch", pathSSanitized)
		cmdPathRootErr := cmdPathRoot.Run()
		if cmdPathRootErr != nil {
			return fmt.Errorf("erro ao criar o arquivo: %v", cmdPathRootErr)
		}

		// Define o propriet√°rio e as permiss√µes do arquivo
		if len(userGroup) > 0 {
			cmdChown := exec.Command("sudo", "chown", strings.Join(userGroup, ":"), pathSSanitized)
			cmdChownErr := cmdChown.Run()
			if cmdChownErr != nil {
				return fmt.Errorf("erro ao definir o propriet√°rio do arquivo: %v", cmdChownErr)
			}
		}
		permOp := perm
		if permOp == 0 {
			permOp = os.ModePerm
		}

		// Define as permiss√µes do arquivo
		cmdChmod := exec.Command("sudo", "chmod", strconv.Itoa(int(permOp)), pathSSanitized)
		cmdChmodErr := cmdChmod.Run()
		if cmdChmodErr != nil {
			return fmt.Errorf("erro ao definir permiss√µes do arquivo: %v", cmdChmodErr)
		}
	}
	return nil
}

// createTempDirTree cria a estrutura de diret√≥rios tempor√°rios.
// Retorna um erro, se houver.
func createTempDirTree() error {
	tempDir := os.Getenv("XDG_CACHE_HOME")
	if tempDir == "" {
		tempDir = os.Getenv("HOME")
		if tempDir == "" {
			tempDir = "/tmp"
		}
		tempDir = filepath.Join(tempDir, ".cache")
	}

	primaryUser, primaryUserErr := GetPrimaryUser()
	if primaryUserErr != nil {
		return primaryUserErr
	}
	primaryGroup, primaryGroupErr := GetPrimaryGroup()
	if primaryGroupErr != nil {
		return primaryGroupErr
	}
	owners := []string{primaryUser, primaryGroup}

	// Garantir que o diret√≥rio .cache exista
	tempDirBaseErr := EnsureDir(tempDir, 0777, owners)
	if tempDirBaseErr != nil {
		return tempDirBaseErr
	}

	// Garantir que o diret√≥rio kubex exista dentro de .cache
	tempDir = filepath.Join(tempDir, "kubex")
	tempDirKubexErr := EnsureDir(tempDir, 0777, owners)
	if tempDirKubexErr != nil {
		return tempDirKubexErr
	}

	// Garantir que o diret√≥rio kbx exista dentro de kubex
	tempDir = filepath.Join(tempDir, "kbx")
	tempDirKbxErr := EnsureDir(tempDir, 0777, owners)
	if tempDirKbxErr != nil {
		return tempDirKbxErr
	}

	_ = os.Setenv("KBX_TEMP_DIR", tempDir)

	return nil
}

// EnsureTempDir garante que o diret√≥rio tempor√°rio exista.
// Retorna um erro, se houver.
func EnsureTempDir() error {
	tempDir := os.Getenv("KBX_TEMP_DIR")
	if tempDir == "" {
		createTempDirTreeErr := createTempDirTree()
		if createTempDirTreeErr != nil {
			return createTempDirTreeErr
		}
		tempDir = os.Getenv("KBX_TEMP_DIR")
		if tempDir == "" {
			return errors.New("erro ao garantir o diret√≥rio tempor√°rio")
		}
	}

	SocketPath := filepath.Join(tempDir, "kbx.sock")
	_ = os.Setenv("KBX_UNIX_SOCK_FILE", SocketPath)

	SocketPidPath := filepath.Join(tempDir, "unixz.pid")
	_ = os.Setenv("KBX_UNIX_PID_FILE", SocketPidPath)

	SrvLogFilePath := filepath.Join(tempDir, "unix.log")
	_ = os.Setenv("KBX_UNIX_LOG_FILE", SrvLogFilePath)

	TcpLogFilePath := filepath.Join(tempDir, "tcp.log")
	_ = os.Setenv("KBX_TCP_LOG_FILE", TcpLogFilePath)

	CliLogFilePath := filepath.Join(tempDir, "cli.log")
	_ = os.Setenv("KBX_CLI_LOG_FILE", CliLogFilePath)

	return nil
}

// GetTempDir obt√©m o diret√≥rio tempor√°rio.
// Retorna o caminho do diret√≥rio tempor√°rio e um erro, se houver.
func GetTempDir() (string, error) {
	tempDir := os.Getenv("KBX_TEMP_DIR")
	if tempDir == "" {
		tempDirErr := EnsureTempDir()
		if tempDirErr != nil {
			return "", tempDirErr
		}
		tempDir = os.Getenv("KBX_TEMP_DIR")
		if tempDir == "" {
			return "", errors.New("erro ao obter o diret√≥rio tempor√°rio")
		}
	}
	return tempDir, nil
}

// GetWorkDir obt√©m o diret√≥rio de trabalho.
// Retorna o caminho do diret√≥rio de trabalho e um erro, se houver.
func GetWorkDir() (string, error) {
	cwd := os.Getenv("KBX_CWD")
	if cwd == "" {
		homeDir, _ := os.UserHomeDir()
		if homeDir == "" {
			homedirCmd := exec.Command("echo", "$HOME")
			homedirOut, _ := homedirCmd.Output()
			homeDir = strings.TrimSpace(string(homedirOut))
			if homeDir == "" {
				homeDir, _ = os.Getwd()
			}
		}
		homeDir = filepath.Join(homeDir, ".kubex", "kbx")
		ensureHomeDirErr := EnsureDir(homeDir, 0777, []string{})
		if ensureHomeDirErr != nil {
			return "", ensureHomeDirErr
		}
		cwd = homeDir
	}
	return cwd, nil
}

func GetKubexDir() (string, error) {
	cwd := os.Getenv("KBX_CWD")
	if cwd == "" {
		homeDir, _ := os.UserHomeDir()
		if homeDir == "" {
			homedirCmd := exec.Command("echo", "$HOME")
			homedirOut, _ := homedirCmd.Output()
			homeDir = strings.TrimSpace(string(homedirOut))
			if homeDir == "" {
				homeDir, _ = os.Getwd()
			}
		}
		homeDir = filepath.Join(homeDir, ".kubex")
		ensureHomeDirErr := EnsureDir(homeDir, 0777, []string{})
		if ensureHomeDirErr != nil {
			return "", ensureHomeDirErr
		}
		cwd = homeDir
	}
	return cwd, nil
}

// GetHomeDir obt√©m o diret√≥rio home do usu√°rio.
// Retorna o caminho do diret√≥rio home e um erro, se houver.
func GetHomeDir() (string, error) {
	homeDir := os.Getenv("HOME")
	if homeDir == "" {
		homeDirCmd := exec.Command("echo", "$HOME")
		homeDirOut, _ := homeDirCmd.Output()
		homeDir = strings.TrimSpace(string(homeDirOut))
		if homeDir == "" {
			homeDir, _ = os.UserHomeDir()
			if homeDir == "" {
				primaryUserName, primaryUserNameErr := GetPrimaryUser()
				if primaryUserNameErr != nil {
					return "", primaryUserNameErr
				}
				homeDir = filepath.Join("/home", primaryUserName)
				if _, err := os.Stat(homeDir); os.IsNotExist(err) {
					homeDir = filepath.Join("/Users", primaryUserName)
					if _, err := os.Stat(homeDir); os.IsNotExist(err) {
						homeDir = filepath.Join("/root")
						if _, err := os.Stat(homeDir); os.IsNotExist(err) {
							return "", errors.New("erro ao obter o diret√≥rio home")
						}
					}
				}
			}
		}
	}
	return homeDir, nil
}

// ListFiles lista os arquivos em um diret√≥rio que correspondem a um padr√£o.
// path: caminho do diret√≥rio.
// pattern: padr√£o a ser procurado nos nomes dos arquivos.
// Retorna uma lista de arquivos que correspondem ao padr√£o e um erro, se houver.
func ListFiles(path string, pattern string) ([]string, error) {
	var files []string
	err := filepath.Walk(path, func(filePath string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.IsDir() && strings.Contains(info.Name(), pattern) {
			files = append(files, filePath)
		}
		return nil
	})
	if err != nil {
		return nil, err
	}
	return files, nil
}

// CheckFilePathExists verifica se um caminho de arquivo existe.
// path: caminho do arquivo.
// Retorna true se o arquivo existir, caso contr√°rio, false e um erro, se houver.
func CheckFilePathExists(path string) (bool, error) {
	info, err := os.Stat(path)
	if os.IsNotExist(err) {
		return false, err
	}
	if err != nil {
		return false, err
	}
	if info.IsDir() {
		return false, errors.New("path is a directory, not a file")
	}
	return true, nil
}

// CheckPathLastAccessTime verifica o tempo de √∫ltimo acesso de um caminho.
// path: caminho do arquivo ou diret√≥rio.
// Retorna o tempo de √∫ltimo acesso e um erro, se houver.
func CheckPathLastAccessTime(path string) (time.Time, error) {
	info, err := os.Stat(path)
	if err != nil {
		return time.Time{}, err
	}
	return info.ModTime(), nil
}

// unmountTmpfsOrSecuredTempDir desmonta um diret√≥rio tmpfs ou seguro.
// tempDir: caminho do diret√≥rio tempor√°rio.
// Retorna um erro, se houver.
func unmountTmpfsOrSecuredTempDir(tempDir string) error {
	defer func() {
		// Ensure umount at the end, or remove all contents forcibly if umount fails
		// Check if tmpfs is mounted
		mountCmd := exec.Command("mount")
		mountCmdOut, mountCmdOutErr := mountCmd.Output()
		if mountCmdOutErr != nil {
			return
		}
		if strings.Contains(string(mountCmdOut), tempDir) {
			// Remove all contents forcibly
			rmCmd := exec.Command("rm", "-rf", tempDir)
			rmCmdErr := rmCmd.Run()
			if rmCmdErr != nil {
				return
			}
		}
	}()

	// Unmount tmpfs
	umountCmd := exec.Command("umount", tempDir)
	if umountCmdErr := umountCmd.Run(); umountCmdErr != nil {
		return fmt.Errorf("erro ao desmontar tmpfs: %v", umountCmdErr)
	}
	return nil
}

// checkTmpfsOrSecuredTempDirUsage verifica o uso de um diret√≥rio tmpfs ou seguro.
// tempDir: caminho do diret√≥rio tempor√°rio.
// Retorna um erro, se houver.
func checkTmpfsOrSecuredTempDirUsage(tempDir string) error {
	// Check tmpfs usage and unmount if unused for 10 minutes
	time.Sleep(10 * time.Minute)
	lastAccessTime, lastAccessTimeErr := CheckPathLastAccessTime(tempDir)
	if lastAccessTimeErr != nil {
		unmountTmpfsOrSecuredTempDirErr := unmountTmpfsOrSecuredTempDir(tempDir)
		if unmountTmpfsOrSecuredTempDirErr != nil {
			return unmountTmpfsOrSecuredTempDirErr
		}
	}
	if time.Since(lastAccessTime) > 10*time.Minute {
		unmountTmpfsOrSecuredTempDirErr := unmountTmpfsOrSecuredTempDir(tempDir)
		if unmountTmpfsOrSecuredTempDirErr != nil {
			return unmountTmpfsOrSecuredTempDirErr
		} else {
			return nil
		}
	}
	return checkTmpfsOrSecuredTempDirUsage(tempDir)
}

// mountTmpfsOrSecuredTempDir monta um diret√≥rio tmpfs ou seguro.
// tempDir: caminho do diret√≥rio tempor√°rio.
// path: caminho do arquivo tempor√°rio.
// Retorna o caminho do diret√≥rio tempor√°rio e um erro, se houver.
func mountTmpfsOrSecuredTempDir(tempDir string, path string) (string, error) {
	// Mount tmpfs
	mountCmd := exec.Command("mount", "-t", "tmpfs", "-o", "size=64M", "tmpfs", tempDir)
	if mountCmdErr := mountCmd.Run(); mountCmdErr != nil {
		logzExtCmdA := exec.Command("kbx", "logz", "warn", "erro ao montar tmpfs: "+mountCmdErr.Error(), "utils")
		logzExtCmdB := exec.Command("kbx", "logz", "warn", "tentando montar diret√≥rio seguro: "+tempDir, "utils")
		_ = logzExtCmdA.Run()
		_ = logzExtCmdB.Run()
	} else {
		// Monitor tmpfs, if it has been unused for 10 minutes, unmount it
		go func() {
			_ = checkTmpfsOrSecuredTempDirUsage(tempDir)
		}()
		return tempDir, nil
	}
	// Getting user and group for ensure ownership of tempDir all contents
	primaryUser, primaryUserErr := GetPrimaryUser()
	if primaryUserErr != nil {
		return "", primaryUserErr
	}
	primaryGroup, primaryGroupErr := GetPrimaryGroup()
	if primaryGroupErr != nil {
		return "", primaryGroupErr
	}
	owners := []string{primaryUser, primaryGroup}
	// Ensure dir
	ensureDirErr := EnsureDir(tempDir, 0700, owners)
	if ensureDirErr != nil {
		return "", ensureDirErr
	}
	// Ensure file
	ensureFileErr := EnsureFile(path, 0600, owners)
	if ensureFileErr != nil {
		return "", ensureFileErr
	}
	return tempDir, nil
}

// AcctTempSsCtx cria um arquivo tempor√°rio seguro para um token.
// token: o token a ser armazenado.
// Retorna o caminho do arquivo tempor√°rio e um erro, se houver.
func AcctTempSsCtx(token string) (string, error) {
	tempDir, tempDirErr := GetTempDir()
	if tempDirErr != nil {
		return "", tempDirErr
	}
	tempDir = filepath.Join(tempDir, ".kbx_tmpfs")
	ensureDirErr := EnsureDir(tempDir, 0700, []string{})
	if ensureDirErr != nil {
		return "", ensureDirErr
	}

	// Remove todos os conte√∫dos antigos do tempDir que cont√™m "acxtkb" em qualquer parte do nome
	oldFiles, oldFilesErr := ListFiles(tempDir, "acxtkb")
	if oldFilesErr != nil {
		return "", oldFilesErr
	}
	for _, oldFile := range oldFiles {
		commonRmErr := os.Remove(oldFile)
		if commonRmErr != nil {
			rootRmCmd := exec.Command("sudo", "rm", "-rf", oldFile)
			rootRmCmdErr := rootRmCmd.Run()
			if rootRmCmdErr != nil {
				return "", fmt.Errorf("erro ao remover arquivo antigo: %v", rootRmCmdErr)
			}
		}
	}

	// Cria um arquivo tempor√°rio seguro para o token
	mkSsCtxFilePth, mkSsCtxFilePthErr := mountTmpfsOrSecuredTempDir(tempDir, filepath.Join(tempDir, "acxtkb"))
	if mkSsCtxFilePthErr != nil {
		return "", mkSsCtxFilePthErr
	}

	// Criptografa o token e escreve no arquivo tmpfs, assina o arquivo com hash e mant√©m o hash na mem√≥ria
	tokenFilePath, tokenFilePathErr := SetSecureSignedTempData(mkSsCtxFilePth, token, "")
	if tokenFilePathErr != nil {
		return "", tokenFilePathErr
	}

	return tokenFilePath, nil
}

// AcctTempSsCtxCheck verifica se o token √© v√°lido.
// Retorna o conte√∫do do token e um erro, se houver.
func AcctTempSsCtxCheck() (string, error) {
	tempDir, tempDirErr := GetTempDir()
	if tempDirErr != nil {
		return "", tempDirErr
	}
	tempDir = filepath.Join(tempDir, ".kbx_tmpfs")
	ensureDirErr := EnsureDir(tempDir, 0700, []string{})
	if ensureDirErr != nil {
		return "", ensureDirErr
	}
	tokenCnt, tokenCntErr := CheckSecureSignedTempData(tempDir, "")
	if tokenCntErr != nil {
		return "", tokenCntErr
	}

	return tokenCnt, nil
}

// AcctTempSsCtxClear remove todos os conte√∫dos antigos do tempDir que cont√™m "acxtkb" em qualquer parte do nome.
// Retorna um erro, se houver.
func AcctTempSsCtxClear() error {
	tempDir, tempDirErr := GetTempDir()
	if tempDirErr != nil {
		return tempDirErr
	}
	tempDir = filepath.Join(tempDir, ".kbx_tmpfs")
	ensureDirErr := EnsureDir(tempDir, 0700, []string{})
	if ensureDirErr != nil {
		return ensureDirErr
	}
	// Remove todos os conte√∫dos antigos do tempDir que cont√™m "acxtkb" em qualquer parte do nome, recursivamente
	oldFiles, oldFilesErr := ListFiles(tempDir, "acxtkb")
	if oldFilesErr != nil {
		return oldFilesErr
	}
	for _, oldFile := range oldFiles {
		commonRmErr := os.Remove(oldFile)
		if commonRmErr != nil {
			rootRmCmd := exec.Command("sudo", "rm", "-rf", oldFile)
			rootRmCmdErr := rootRmCmd.Run()
			if rootRmCmdErr != nil {
				return fmt.Errorf("erro ao remover arquivo antigo: %v", rootRmCmdErr)
			}
		}
	}
	return nil
}

// SetSecureSignedTempData criptografa o token e escreve no arquivo tmpfs, assina o arquivo com hash e mant√©m o hash na mem√≥ria.
// tempDir: diret√≥rio tempor√°rio.
// data: dados a serem armazenados.
// tag: tag opcional para o arquivo.
// Retorna o nome do arquivo tempor√°rio e um erro, se houver.
func SetSecureSignedTempData(tempDir string, data string, tag string) (string, error) {
	tokenFilePrefix := "acxtkb"
	if tag != "" {
		tokenFilePrefix = tag
	}
	tokenFileTimeSufix := fmt.Sprintf("%x", md5.Sum([]byte(time.Now().String())))
	tokenFileNameHash := tokenFilePrefix + tokenFileTimeSufix
	tokenFilePath := filepath.Join(tempDir, tokenFileNameHash)
	signTokenHash := createHash("acctkn" + data + tokenFileTimeSufix)
	encryptedToken, encryptedTokenErr := EncryptData(data, signTokenHash)
	if encryptedTokenErr != nil {
		return "", fmt.Errorf("erro ao criptografar token: %w", encryptedTokenErr)
	}
	if writeFileErr := os.WriteFile(tokenFilePath, []byte(encryptedToken), 0600); writeFileErr != nil {
		return "", fmt.Errorf("erro ao escrever token: %w", writeFileErr)
	}
	if writeSignHashErr := os.WriteFile(filepath.Join("/dev/shm", tokenFileNameHash), []byte(signTokenHash), 0600); writeSignHashErr != nil {
		return "", fmt.Errorf("erro ao escrever hash do token: %w", writeSignHashErr)
	}
	return tokenFileNameHash, nil
}

// CheckSecureSignedTempData verifica se o token armazenado √© v√°lido.
// tempDir: diret√≥rio tempor√°rio.
// tag: tag opcional para o arquivo.
// Retorna o conte√∫do do token e um erro, se houver.
func CheckSecureSignedTempData(tempDir string, tag string) (string, error) {
	tokenFilePrefix := "acxtkb"
	if tag != "" {
		tokenFilePrefix = tag
	}
	tokenFiles, tokenFilesErr := ListFiles(tempDir, tokenFilePrefix)
	if tokenFilesErr != nil {
		return "", fmt.Errorf("erro ao listar arquivos de token: %w", tokenFilesErr)
	}
	if len(tokenFiles) == 0 {
		return "", errors.New("nenhum arquivo de token encontrado")
	}
	tokenFileName := tokenFiles[0]
	tokenFileHash, tokenFileHashErr := os.ReadFile(filepath.Join("/dev/shm", tokenFileName))
	if tokenFileHashErr != nil {
		return "", fmt.Errorf("erro ao ler hash do arquivo de token: %w", tokenFileHashErr)
	}
	tokenFileData, tokenFileDataErr := os.ReadFile(tokenFileName)
	if tokenFileDataErr != nil {
		return "", fmt.Errorf("erro ao ler arquivo de token: %w", tokenFileDataErr)
	}
	tokenFileDataStr := string(tokenFileData)
	tokenFileDataHash := createHash("acctkn" + tokenFileDataStr + tokenFileName)
	if string(tokenFileHash) != tokenFileDataHash {
		return "", errors.New("hash do arquivo de token inv√°lido")
	}
	decryptedToken, decryptedTokenErr := DecryptData(tokenFileDataStr, string(tokenFileHash))
	if decryptedTokenErr != nil {
		return "", fmt.Errorf("erro ao descriptografar token: %w", decryptedTokenErr)
	}
	return decryptedToken, nil
}

func WatchKubexFiles() error {
	// watch --no-title --color -n 1 'bash -c "tput -x clear && tree $HOME/.cache/kubex -s --du -C -h && tree $HOME/.kubex -s --du -C -h"'
	watchCmd := exec.Command("watch", "--no-title", "--color", "-n", "1", "bash", "-c", "'tput -x clear && tree $HOME/.cache/kubex -s --du -C -h && tree $HOME/.kubex -s --du -C -h'")
	watchCmd.Stdout = os.Stdout
	watchCmd.Stderr = os.Stderr
	if watchCmdErr := watchCmd.Run(); watchCmdErr != nil {
		return fmt.Errorf("erro ao assistir arquivos Kubex: %v", watchCmdErr)
	}
	return nil
}

func CreateTarGz(archivePath string, files []string) error {
	archiveFile, err := os.Create(archivePath)
	if err != nil {
		return fmt.Errorf("erro ao criar o arquivo tar.gz: %v", err)
	}
	defer func(archiveFile *os.File) {
		_ = archiveFile.Close()
	}(archiveFile)

	gw := gzip.NewWriter(archiveFile)
	defer func(gw *gzip.Writer) {
		_ = gw.Close()
	}(gw)

	tw := tar.NewWriter(gw)
	defer func(tw *tar.Writer) {
		_ = tw.Close()
	}(tw)

	for _, file := range files {
		addErr := AddFileToTar(tw, file)
		if addErr != nil {
			return addErr
		}
	}

	return nil
}

func AddFileToTar(tw *tar.Writer, filePath string) error {
	tempDir, tempDirErr := GetTempDir()
	if tempDirErr != nil {
		return tempDirErr
	}

	// Validar e sanitizar o caminho do arquivo
	cleanPath := filepath.Clean(filePath)
	if !strings.HasPrefix(cleanPath, tempDir) {
		return fmt.Errorf("caminho do arquivo inv√°lido: %s", filePath)
	}

	file, err := os.Open(cleanPath)
	if err != nil {
		return fmt.Errorf("erro ao abrir o arquivo para o tar: %v", err)
	}
	defer func(file *os.File) {
		_ = file.Close()
	}(file)

	info, err := file.Stat()
	if err != nil {
		return fmt.Errorf("erro ao obter informa√ß√µes do arquivo: %v", err)
	}

	header, err := tar.FileInfoHeader(info, info.Name())
	if err != nil {
		return fmt.Errorf("erro ao criar o cabe√ßalho do tar: %v", err)
	}
	header.Name = filepath.Base(cleanPath)

	err = tw.WriteHeader(header)
	if err != nil {
		return fmt.Errorf("erro ao escrever o cabe√ßalho do tar: %v", err)
	}

	_, err = io.Copy(tw, file)
	if err != nil {
		return fmt.Errorf("erro ao copiar o arquivo para o tar: %v", err)
	}

	return nil
}

func ArchiveOldFiles() error {
	tempDir, tempDirErr := GetTempDir()
	if tempDirErr != nil {
		return tempDirErr
	}

	archiveName := fmt.Sprintf("logs_archive_%s.zip", time.Now().Format("20060102_150405"))
	archivePath := filepath.Join(tempDir, archiveName)

	zipFile, err := os.Create(archivePath)
	if err != nil {
		return fmt.Errorf("erro ao criar o arquivo zip: %v", err)
	}
	defer func(zipFile *os.File) {
		_ = zipFile.Close()
	}(zipFile)

	zipWriter := zip.NewWriter(zipFile)
	defer func(zipWriter *zip.Writer) {
		_ = zipWriter.Close()
	}(zipWriter)

	files, err := os.ReadDir(tempDir)
	if err != nil {
		return fmt.Errorf("erro ao ler o diret√≥rio de logs: %v", err)
	}

	for _, file := range files {
		if strings.HasSuffix(file.Name(), ".log") {
			filePath := filepath.Join(tempDir, file.Name())
			err := AddFileToZip(zipWriter, filePath)
			if err != nil {
				return err
			}
		}
	}

	fmt.Println("Logs arquivados com sucesso em:", archivePath)
	return nil
}

func AddFileToZip(zipWriter *zip.Writer, filePath string) error {
	file, err := os.Open(filePath)
	if err != nil {
		return fmt.Errorf("erro ao abrir o arquivo: %v", err)
	}
	defer func(file *os.File) {
		_ = file.Close()
	}(file)

	info, err := file.Stat()
	if err != nil {
		return fmt.Errorf("erro ao obter informa√ß√µes do arquivo: %v", err)
	}

	header, err := zip.FileInfoHeader(info)
	if err != nil {
		return fmt.Errorf("erro ao criar o cabe√ßalho do arquivo zip: %v", err)
	}
	header.Name = filepath.Base(filePath)
	header.Method = zip.Deflate

	writer, err := zipWriter.CreateHeader(header)
	if err != nil {
		return fmt.Errorf("erro ao criar o cabe√ßalho do arquivo zip: %v", err)
	}

	_, err = io.Copy(writer, file)
	if err != nil {
		return fmt.Errorf("erro ao copiar o arquivo para o zip: %v", err)
	}

	return nil
}

func CopyFile(src, dst string) error {
	sourceFile, err := os.Open(src)
	if err != nil {
		return fmt.Errorf("erro ao abrir o arquivo de origem: %v", err)
	}
	defer func(sourceFile *os.File) {
		_ = sourceFile.Close()
	}(sourceFile)

	destFile, err := os.Create(dst)
	if err != nil {
		return fmt.Errorf("erro ao criar o arquivo de destino: %v", err)
	}
	defer func(destFile *os.File) {
		_ = destFile.Close()
	}(destFile)

	_, err = io.Copy(destFile, sourceFile)
	if err != nil {
		return fmt.Errorf("erro ao copiar o arquivo: %v", err)
	}

	return nil
}

func RemoveFile(path string) error {
	err := os.Remove(path)
	if err != nil {
		return fmt.Errorf("erro ao remover o arquivo: %v", err)
	}
	return nil
}

func RemoveFiles(paths []string) error {
	for _, path := range paths {
		err := RemoveFile(path)
		if err != nil {
			return err
		}
	}
	return nil
}

/// utils/ports.go ///
package utils

import (
	"fmt"
	"net"
	"os/exec"
	"strings"
)

// CheckPortOpen verifica se uma porta est√° aberta.
// port: a porta a ser verificada.
// Retorna true se a porta estiver aberta, caso contr√°rio, false. Retorna um erro, se houver.
func CheckPortOpen(port string) (bool, error) {
	ln, err := net.Listen("tcp", ":"+port)
	if err != nil {
		return false, err // Porta j√° est√° em uso ou bloqueada
	}
	_ = ln.Close()
	return true, nil // Porta dispon√≠vel
}

// ListOpenPorts lista todas as portas abertas no sistema.
// Executa o comando `netstat` para obter as portas abertas.
// Retorna uma lista de strings com as portas abertas e um erro, se houver.
func ListOpenPorts() ([]string, error) {
	cmd := exec.Command("sh", "-c", "netstat -tuln | grep LISTEN | awk '{print $4}' | sed 's/.*://' | sort -n | uniq")
	output, err := cmd.Output()
	if err != nil {
		return nil, err
	}
	ports := strings.Split(strings.TrimSpace(string(output)), "\n")
	return ports, nil
}

// ClosePort fecha uma porta espec√≠fica.
// port: a porta a ser fechada.
// Retorna um erro, se houver.
func ClosePort(port string) error {
	cmd := exec.Command("fuser", "-k", port+"/tcp")
	err := cmd.Run()
	if err != nil {
		return fmt.Errorf("falha ao fechar a porta %s: %v", port, err)
	}
	return nil
}

// OpenPort abre uma porta espec√≠fica.
// port: a porta a ser aberta.
// Retorna um erro, se houver.
func OpenPort(port string) error {
	cmd := exec.Command("iptables", "-A", "INPUT", "-p", "tcp", "--dport", port, "-j", "ACCEPT")
	err := cmd.Run()
	if err != nil {
		return fmt.Errorf("falha ao abrir a porta %s: %v", port, err)
	}
	return nil
}

// IsIPv6 verifica se um endere√ßo IP √© um endere√ßo IPv6.
// ip: o endere√ßo IP a ser verificado.
// Retorna true se o endere√ßo IP for um endere√ßo IPv6, caso contr√°rio, false.
func IsIPv6(ip string) bool {
	var sanitizedIP string
	if strings.Contains(ip, ":") {
		sanitizedIP = strings.Replace(ip, ":", "", -1)

		// If the sanitized IP is still the same as the original, then it's an IPv6
		if sanitizedIP == ip {
			return true
		}
	}
	return false
}

/// utils/ssh.go ///
package utils

import (
	"fmt"
	"golang.org/x/crypto/ssh"
	"io"
	"log"
	"net"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
)

// acquireHostKey adquire a chave do host.
// host: o endere√ßo do host.
// Retorna a chave p√∫blica do host e um erro, se houver.
func acquireHostKey(host string) (ssh.PublicKey, error) {
	var pubKey ssh.PublicKey

	pubKey = getKnownHostKey(host, "")
	if pubKey != nil {
		return pubKey, nil
	}

	pubKey = getKnownHostKey(host, filepath.Join(os.Getenv("HOME"), ".ssh", "id_rsa.pub"))
	if pubKey != nil {
		return pubKey, nil
	}

	return nil, fmt.Errorf("chave do host n√£o encontrada")
}

// saveHostKey salva a chave do host no arquivo known_hosts.
// host: o endere√ßo do host.
// pubKey: a chave p√∫blica do host.
// Retorna um erro, se houver.
func saveHostKey(host string, pubKey ssh.PublicKey) error {
	knownHostsPath := filepath.Join(os.Getenv("HOME"), ".ssh", "known_hosts")
	file, err := os.OpenFile(knownHostsPath, os.O_APPEND|os.O_WRONLY|os.O_CREATE, 0644)
	if err != nil {
		return fmt.Errorf("falha ao abrir o arquivo known_hosts: %v", err)
	}
	defer file.Close()

	_, err = file.WriteString(fmt.Sprintf("%s %s\n", host, strings.TrimSpace(string(ssh.MarshalAuthorizedKey(pubKey)))))
	if err != nil {
		return fmt.Errorf("falha ao escrever no arquivo known_hosts: %v", err)
	}

	return nil
}

// SshTunnel configura um t√∫nel SSH com base nos par√¢metros fornecidos.
// sshUser: o nome de usu√°rio SSH.
// sshCert: o certificado SSH.
// sshPassword: a senha SSH.
// sshAddress: o endere√ßo do servidor SSH.
// sshPort: a porta do servidor SSH.
// tunnels: os t√∫neis a serem configurados.
// Retorna um erro, se houver.
func SshTunnel(sshUser string, sshCert string, sshPassword string, sshAddress string, sshPort string, tunnels ...string) error {
	if sshUser == "" || sshAddress == "" || sshPort == "" || len(tunnels) == 0 {
		return fmt.Errorf("argumentos inv√°lidos")
	}

	var sshHost string
	var sshConfig *ssh.ClientConfig

	sshHost = fmt.Sprintf("%s:%s", sshAddress, sshPort)

	if sshCert != "" {
		sshSigner, sshSignerErr := ssh.ParsePrivateKey([]byte(sshCert))
		if sshSignerErr != nil {
			return fmt.Errorf("falha ao analisar a chave privada: %v", sshSignerErr)
		}
		sshConfig = &ssh.ClientConfig{
			User: sshUser,
			Auth: []ssh.AuthMethod{
				ssh.PublicKeys(sshSigner),
			},
			HostKeyCallback: ssh.InsecureIgnoreHostKey(), // Adiciona um HostKeyCallback
		}
	} else {
		sshConfig = &ssh.ClientConfig{
			User: sshUser,
			Auth: []ssh.AuthMethod{
				ssh.Password(sshPassword),
			},
			HostKeyCallback: ssh.InsecureIgnoreHostKey(), // Adiciona um HostKeyCallback
		}
	}

	sshConn, sshConnErr := ssh.Dial("tcp", sshHost, sshConfig)
	if sshConnErr != nil {
		return fmt.Errorf("falha ao conectar ao servidor SSH: %v", sshConnErr)
	}
	defer sshConn.Close()

	var localListeners []*net.Listener
	var localListener net.Listener
	var localListenerErr error
	for _, tunnel := range tunnels {
		localListener, localListenerErr = net.Listen("tcp", tunnel)
		if localListenerErr != nil {
			return fmt.Errorf("falha ao iniciar o listener local: %v", localListenerErr)
		}
		localListeners = append(localListeners, &localListener)
		defer localListener.Close()
		log.Printf("T√∫nel local iniciado em %s", tunnel)
	}

	for {
		localConn, localConnErr := localListener.Accept()
		if localConnErr != nil {
			log.Printf("Erro ao aceitar a conex√£o local: %v", localConnErr)
			continue
		}

		remoteConn, remoteConnErr := sshConn.Dial("tcp", localConn.RemoteAddr().String())
		if remoteConnErr != nil {
			log.Printf("Erro ao conectar ao servidor remoto: %v", remoteConnErr)
			continue
		}

		go forwardData(localConn, remoteConn)
		go forwardData(remoteConn, localConn)
	}
}

// forwardData encaminha dados entre as conex√µes.
// src: a conex√£o de origem.
// dest: a conex√£o de destino.
func forwardData(src, dest net.Conn) {
	defer src.Close()
	defer dest.Close()

	_, err := io.Copy(src, dest)
	if err != nil {
		log.Printf("Erro ao transferir dados: %v", err)
	}
}

// getKnownHostKey obt√©m a chave de host conhecida para valida√ß√£o.
// host: o endere√ßo do host.
// publicKeyPath: o caminho para a chave p√∫blica.
// Retorna a chave p√∫blica do host.
func getKnownHostKey(host string, publicKeyPath string) ssh.PublicKey {
	if publicKeyPath != "" {
		key, err := os.ReadFile(publicKeyPath)
		if err != nil {
			log.Fatalf("falha ao ler a chave p√∫blica: %v", err)
			return nil
		}
		pubKey, _, _, _, parseAuthorizedKeyErr := ssh.ParseAuthorizedKey(key)
		if parseAuthorizedKeyErr != nil {
			log.Fatalf("falha ao analisar a chave p√∫blica: %v", parseAuthorizedKeyErr)
			return nil
		}
		return pubKey
	}

	// Tenta usar o ssh-copy-id para obter a chave p√∫blica, se n√£o der certo, retorna nil
	copyIDCmd, copyIDCmdErr := exec.Command("bash", "-c", fmt.Sprintf("ssh-copy-id %s", host)).Output()
	if copyIDCmdErr != nil {
		log.Printf("falha ao executar o comando ssh-copy-id: %v", copyIDCmdErr)
		return nil
	}
	pubKey, _, _, _, parseAuthorizedKeyErr := ssh.ParseAuthorizedKey(copyIDCmd)
	if parseAuthorizedKeyErr != nil {
		log.Fatalf("falha ao analisar a chave p√∫blica: %v", parseAuthorizedKeyErr)
		return nil
	}
	return pubKey // Substitua pela chave p√∫blica apropriada para o seu caso.
}

/// utils/term.go ///
package utils

import (
	"fmt"
	"os/exec"
)

// ClearScreen limpa a tela do terminal.
func ClearScreen() {
	fmt.Println("\033[H\033[2J")
}

// Figlet exibe um t√≠tulo estilizado usando o comando `figlet`.
// title: o t√≠tulo a ser exibido.
// Retorna um erro, se houver.
func Figlet(title string) error {
	if !CommandExists("figlet") {
		cmdFigletErr := exec.Command("kbx", "pkg", "install", "figlet").Run()
		if cmdFigletErr != nil {
			return cmdFigletErr
		}
		return nil
	}
	return exec.Command("figlet", "-W", "-c", "-t", "-X", title).Run()
}

// CommandExists verifica se um comando existe no sistema.
// cmd: o comando a ser verificado.
// Retorna true se o comando existir, caso contr√°rio, false.
func CommandExists(cmd string) bool {
	if _, err := exec.LookPath(cmd); err != nil {
		if dpkgErr := exec.Command("dpkg", "-l", cmd).Run(); dpkgErr != nil {
			return false
		}
	}
	return true
}

// PrintTitle exibe um t√≠tulo formatado no terminal.
// title: o t√≠tulo a ser exibido.
func PrintTitle(title string) {
	fmt.Println("========================================")
	fmt.Println(title)
	fmt.Println("========================================")
}

// PrintSection exibe uma se√ß√£o formatada no terminal.
// section: a se√ß√£o a ser exibida.
func PrintSection(section string) {
	fmt.Println("----------------------------------------")
	fmt.Println(section)
	fmt.Println("----------------------------------------")
}

// WaitEnter aguarda o usu√°rio pressionar ENTER para continuar.
func WaitEnter() {
	fmt.Print("Pressione ENTER para continuar...")
	_, scanlnErr := fmt.Scanln()
	if scanlnErr != nil {
		return // Ignora erro
	}
}

// WaitEnterClear aguarda o usu√°rio pressionar ENTER e limpa a tela do terminal.
func WaitEnterClear() {
	WaitEnter()
	ClearScreen()
}

/// utils/time.go ///
package utils

const (
	// GoFormat √© o formato de data e hora padr√£o do Go.
	GoFormat = "2006-01-02 15:04:05.999999999"
	// Format √© o formato de data e hora padr√£o.
	Format = "2006-01-02 15:04:05"
	// TimeFormat √© o formato de hora padr√£o.
	TimeFormat = "15:04:05"
	// DateFormat √© o formato de data padr√£o.
	DateFormat = "2006-01-02"
	// ShortDateFormat √© o formato de data curta.
	ShortDateFormat = "06-01-02"
	// ShortestDateFormat √© o formato de data mais curta.
	ShortestDateFormat = "06-1-2"
	// ShortTimeFormat √© o formato de hora curta.
	ShortTimeFormat = "15:04"
	// LongTimeFormat √© o formato de hora longa.
	LongTimeFormat = "15:04:05"
	// ShortDateTimeFormat √© o formato de data e hora curtas.
	ShortDateTimeFormat = "06-01-02 15:04"
	// DateTimeFormat √© o formato de data e hora padr√£o.
	DateTimeFormat = "2006-01-02 15:04"
	// ISO8601Date √© o formato de data ISO 8601.
	ISO8601Date = "2006-01-02"
	// ISO8601Time √© o formato de hora ISO 8601.
	ISO8601Time = "15:04:05"
	// ISO8601TimeMs √© o formato de hora com milissegundos ISO 8601.
	ISO8601TimeMs = "15:04:05.999"
	// ISO8601DateTime √© o formato de data e hora ISO 8601.
	ISO8601DateTime = "2006-01-02T15:04:05"
	// ISO8601TZ √© o formato de data e hora com fuso hor√°rio ISO 8601.
	ISO8601TZ = "2006-01-02T15:04:05-0700"
	// ISO8601TZs √© o formato de data e hora com fuso hor√°rio (Z) ISO 8601.
	ISO8601TZs = "2006-01-02T15:04:05Z0700"
	// ISO8601TZms √© o formato de data e hora com milissegundos e fuso hor√°rio ISO 8601.
	ISO8601TZms = "2006-01-02T15:04:05.999-0700"
	// HourMinuteFormat √© o formato de hora e minuto.
	HourMinuteFormat = "15:04"
	// HourFormat √© o formato de hora.
	HourFormat = "15"
	// FormattedDateFormat √© o formato de data formatada.
	FormattedDateFormat = "Jan 2, 2006"
	// DayDateTimeFormat √© o formato de data e hora com dia da semana.
	DayDateTimeFormat = "Mon, Aug 2, 2006 3:04 PM"
	// ISO8601Format √© o formato de data e hora ISO 8601.
	ISO8601Format = "2006-01-02T15:04:05-0700"
	// CookieFormat √© o formato de data e hora para cookies.
	CookieFormat = "Monday, 02-Jan-2006 15:04:05 MST"
	// RFC822Format √© o formato de data e hora RFC 822.
	RFC822Format = "Mon, 02 Jan 06 15:04:05 -0700"
	// RFC1036Format √© o formato de data e hora RFC 1036.
	RFC1036Format = "Mon, 02 Jan 06 15:04:05 -0700"
	// RFC2822Format √© o formato de data e hora RFC 2822.
	RFC2822Format = "Mon, 02 Jan 2006 15:04:05 -0700"
	// RFC3339Format √© o formato de data e hora RFC 3339.
	RFC3339Format = "2006-01-02T15:04:05-07:00"
	// RSSFormat √© o formato de data e hora RSS.
	RSSFormat = "Mon, 02 Jan 2006 15:04:05 -0700"
	// W3CFormat √© o formato de data e hora W3C.
	W3CFormat = "2006-01-02T15:04:05-07:00"
	// UnixFormat √© o formato de data e hora Unix.
	UnixFormat = "Mon Jan _2 15:04:05 MST 2006"
	// UnixDate √© o formato de data e hora Unix.
	UnixDate = "Mon Jan _2 15:04:05 MST 2006"
	// UnixDate2 √© o formato de data e hora Unix.
	UnixDate2 = "Mon Jan 02 15:04:05 MST 2006"
	// UnixDate3 √© o formato de data e hora Unix.
	UnixDate3 = "Mon Jan 02 15:04:05 -0700 2006"
	// UnixDate4 √© o formato de data e hora Unix.
	UnixDate4 = "Mon Jan 02 15:04:05 -0700 MST 2006"
	// UnixDate5 √© o formato de data e hora Unix.
	UnixDate5 = "Mon Jan 02 15:04:05 -0700 (MST) 2006"

	// TimezoneUTC √© o fuso hor√°rio UTC.
	TimezoneUTC = "UTC"
	// TimezoneGMT √© o fuso hor√°rio GMT.
	TimezoneGMT = "GMT"
	// TimezoneEST √© o fuso hor√°rio EST.
	TimezoneEST = "EST"
	// TimezoneEDT √© o fuso hor√°rio EDT.
	TimezoneEDT = "EDT"
	// TimezoneCST √© o fuso hor√°rio CST.
	TimezoneCST = "CST"
	// TimezoneCDT √© o fuso hor√°rio CDT.
	TimezoneCDT = "CDT"
	// TimezoneMST √© o fuso hor√°rio MST.
	TimezoneMST = "MST"
	// TimezoneMDT √© o fuso hor√°rio MDT.
	TimezoneMDT = "MDT"
	// TimezonePST √© o fuso hor√°rio PST.
	TimezonePST = "PST"
	// TimezonePDT √© o fuso hor√°rio PDT.
	TimezonePDT = "PDT"
	// TimezoneCET √© o fuso hor√°rio CET.
	TimezoneCET = "CET"
	// TimezoneCEST √© o fuso hor√°rio CEST.
	TimezoneCEST = "CEST"
	// TimezoneJST √© o fuso hor√°rio JST.
	TimezoneJST = "JST"
	// TimezoneKST √© o fuso hor√°rio KST.
	TimezoneKST = "KST"
	// TimezoneSGT √© o fuso hor√°rio SGT.
	TimezoneSGT = "SGT"
	// TimezoneHKT √© o fuso hor√°rio HKT.
	TimezoneHKT = "HKT"
	// TimezoneAEST √© o fuso hor√°rio AEST.
	TimezoneAEST = "AEST"
	// TimezoneACST √© o fuso hor√°rio ACST.
	TimezoneACST = "ACST"
	// TimezoneAWST √© o fuso hor√°rio AWST.
	TimezoneAWST = "AWST"
	// TimezoneNZST √© o fuso hor√°rio NZST.
	TimezoneNZST = "NZST"

	// TimezoneOffsetUTC √© o offset do fuso hor√°rio UTC.
	TimezoneOffsetUTC = "+0000"
	// TimezoneOffsetGMT √© o offset do fuso hor√°rio GMT.
	TimezoneOffsetGMT = "+0000"
	// TimezoneOffsetEST √© o offset do fuso hor√°rio EST.
	TimezoneOffsetEST = "-0500"
	// TimezoneOffsetEDT √© o offset do fuso hor√°rio EDT.
	TimezoneOffsetEDT = "-0400"
	// TimezoneOffsetCST √© o offset do fuso hor√°rio CST.
	TimezoneOffsetCST = "-0600"
	// TimezoneOffsetCDT √© o offset do fuso hor√°rio CDT.
	TimezoneOffsetCDT = "-0500"
	// TimezoneOffsetMST √© o offset do fuso hor√°rio MST.
	TimezoneOffsetMST = "-0700"
	// TimezoneOffsetMDT √© o offset do fuso hor√°rio MDT.
	TimezoneOffsetMDT = "-0600"
	// TimezoneOffsetPST √© o offset do fuso hor√°rio PST.
	TimezoneOffsetPST = "-0800"
	// TimezoneOffsetPDT √© o offset do fuso hor√°rio PDT.
	TimezoneOffsetPDT = "-0700"
	// TimezoneOffsetCET √© o offset do fuso hor√°rio CET.
	TimezoneOffsetCET = "+0100"
	// TimezoneOffsetCEST √© o offset do fuso hor√°rio CEST.
	TimezoneOffsetCEST = "+0200"
	// TimezoneOffsetJST √© o offset do fuso hor√°rio JST.
	TimezoneOffsetJST = "+0900"
	// TimezoneOffsetKST √© o offset do fuso hor√°rio KST.
	TimezoneOffsetKST = "+0900"
	// TimezoneOffsetSGT √© o offset do fuso hor√°rio SGT.
	TimezoneOffsetSGT = "+0800"
	// TimezoneOffsetHKT √© o offset do fuso hor√°rio HKT.
	TimezoneOffsetHKT = "+0800"
	// TimezoneOffsetAEST √© o offset do fuso hor√°rio AEST.
	TimezoneOffsetAEST = "+1000"
	// TimezoneOffsetACST √© o offset do fuso hor√°rio ACST.
	TimezoneOffsetACST = "+0930"
	// TimezoneOffsetAWST √© o offset do fuso hor√°rio AWST.
	TimezoneOffsetAWST = "+0800"
	// TimezoneOffsetNZST √© o offset do fuso hor√°rio NZST.
	TimezoneOffsetNZST = "+1200"
)

// GetTimezoneOffset retorna o offset do fuso hor√°rio.
// timezone: o fuso hor√°rio.
// Retorna uma string contendo o offset do fuso hor√°rio.
func GetTimezoneOffset(timezone string) string {
	switch timezone {
	case TimezoneUTC:
		return TimezoneOffsetUTC
	case TimezoneGMT:
		return TimezoneOffsetGMT
	case TimezoneEST:
		return TimezoneOffsetEST
	case TimezoneEDT:
		return TimezoneOffsetEDT
	case TimezoneCST:
		return TimezoneOffsetCST
	case TimezoneCDT:
		return TimezoneOffsetCDT
	case TimezoneMST:
		return TimezoneOffsetMST
	case TimezoneMDT:
		return TimezoneOffsetMDT
	case TimezonePST:
		return TimezoneOffsetPST
	case TimezonePDT:
		return TimezoneOffsetPDT
	case TimezoneCET:
		return TimezoneOffsetCET
	case TimezoneCEST:
		return TimezoneOffsetCEST
	case TimezoneJST:
		return TimezoneOffsetJST
	case TimezoneKST:
		return TimezoneOffsetKST
	case TimezoneSGT:
		return TimezoneOffsetSGT
	case TimezoneHKT:
		return TimezoneOffsetHKT
	case TimezoneAEST:
		return TimezoneOffsetAEST
	case TimezoneACST:
		return TimezoneOffsetACST
	case TimezoneAWST:
		return TimezoneOffsetAWST
	case TimezoneNZST:
		return TimezoneOffsetNZST
	default:
		return ""
	}
}

// ConvertTimezone retorna o nome completo do fuso hor√°rio.
// timezone: o fuso hor√°rio.
// Retorna uma string contendo o nome completo do fuso hor√°rio.
func ConvertTimezone(timezone string) string {
	switch timezone {
	case TimezoneUTC:
		return "Coordinated Universal Time"
	case TimezoneGMT:
		return "Greenwich Mean Time"
	case TimezoneEST:
		return "Eastern Standard Time"
	case TimezoneEDT:
		return "Eastern Daylight Time"
	case TimezoneCST:
		return "Central Standard Time"
	case TimezoneCDT:
		return "Central Daylight Time"
	case TimezoneMST:
		return "Mountain Standard Time"
	case TimezoneMDT:
		return "Mountain Daylight Time"
	case TimezonePST:
		return "Pacific Standard Time"
	case TimezonePDT:
		return "Pacific Daylight Time"
	case TimezoneCET:
		return "Central European Time"
	case TimezoneCEST:
		return "Central European Summer Time"
	case TimezoneJST:
		return "Japan Standard Time"
	case TimezoneKST:
		return "Korea Standard Time"
	case TimezoneSGT:
		return "Singapore Time"
	case TimezoneHKT:
		return "Hong Kong Time"
	case TimezoneAEST:
		return "Australian Eastern Standard Time"
	case TimezoneACST:
		return "Australian Central Standard Time"
	case TimezoneAWST:
		return "Australian Western Standard Time"
	case TimezoneNZST:
		return "New Zealand Standard Time"
	default:
		return ""
	}
}

// ConvertTimezoneOffset retorna o offset do fuso hor√°rio no formato UTC.
// timezone: o fuso hor√°rio.
// Retorna uma string contendo o offset do fuso hor√°rio no formato UTC.
func ConvertTimezoneOffset(timezone string) string {
	switch timezone {
	case TimezoneUTC:
		return "UTC+00:00"
	case TimezoneGMT:
		return "GMT+00:00"
	case TimezoneEST:
		return "UTC-05:00"
	case TimezoneEDT:
		return "UTC-04:00"
	case TimezoneCST:
		return "UTC-06:00"
	case TimezoneCDT:
		return "UTC-05:00"
	case TimezoneMST:
		return "UTC-07:00"
	case TimezoneMDT:
		return "UTC-06:00"
	case TimezonePST:
		return "UTC-08:00"
	case TimezonePDT:
		return "UTC-07:00"
	case TimezoneCET:
		return "UTC+01:00"
	case TimezoneCEST:
		return "UTC+02:00"
	case TimezoneJST:
		return "UTC+09:00"
	case TimezoneKST:
		return "UTC+09:00"
	case TimezoneSGT:
		return "UTC+08:00"
	case TimezoneHKT:
		return "UTC+08:00"
	case TimezoneAEST:
		return "UTC+10:00"
	case TimezoneACST:
		return "UTC+09:30"
	case TimezoneAWST:
		return "UTC+08:00"
	case TimezoneNZST:
		return "UTC+12:00"
	default:
		return ""
	}
}

// GetWeekdayByAnyType retorna o dia da semana a partir de qualquer tipo.
// v: o valor que representa o dia da semana.
// Retorna uma string contendo o dia da semana.
func GetWeekdayByAnyType(v interface{}) string {
	switch v.(type) {
	case string:
		return GetWeekday(v.(string))
	case int:
		return GetWeekdayByInt(v.(int))
	default:
		return ""
	}
}

// GetWeekday retorna o dia da semana a partir de uma string.
// weekday: a string que representa o dia da semana.
// Retorna uma string contendo o dia da semana em portugu√™s.
func GetWeekday(weekday string) string {
	switch weekday {
	case "Sunday":
		return "Domingo"
	case "Monday":
		return "Segunda-feira"
	case "Tuesday":
		return "Ter√ßa-feira"
	case "Wednesday":
		return "Quarta-feira"
	case "Thursday":
		return "Quinta-feira"
	case "Friday":
		return "Sexta-feira"
	case "Saturday":
		return "S√°bado"
	default:
		return ""
	}
}

// GetWeekdayByInt retorna o dia da semana a partir de um inteiro.
// weekday: o inteiro que representa o dia da semana (0 para Domingo, 1 para Segunda-feira, etc.).
// Retorna uma string contendo o dia da semana em portugu√™s.
func GetWeekdayByInt(weekday int) string {
	switch weekday {
	case 0:
		return "Domingo"
	case 1:
		return "Segunda-feira"
	case 2:
		return "Ter√ßa-feira"
	case 3:
		return "Quarta-feira"
	case 4:
		return "Quinta-feira"
	case 5:
		return "Sexta-feira"
	case 6:
		return "S√°bado"
	default:
		return ""
	}
}

// ExtractTime extrai a hora de uma string.
// s: a string que cont√©m a hora.
// Retorna uma string contendo a hora extra√≠da.
func ExtractTime(s string) string {
	return ExtractDateTime(s, TimeFormat)
}

// ExtractDate extrai a data de uma string.
// s: a string que cont√©m a data.
// Retorna uma string contendo a data extra√≠da.
func ExtractDate(s string) string {
	return ExtractDateTime(s, DateFormat)
}

// ExtractDateTime extrai a data e a hora de uma string.
// s: a string que cont√©m a data e a hora.
// format: o formato da data e hora a ser extra√≠do.
// Retorna uma string contendo a data e hora extra√≠da.
func ExtractDateTime(s string, format string) string {
	if len(s) < len(format) {
		return s
	}
	return s[:len(format)]
}

// FormatTime formata a hora.
// t: a string que cont√©m a hora.
// Retorna uma string contendo a hora formatada.
func FormatTime(t string) string {
	return FormatDateTime(t, TimeFormat)
}

// FormatDate formata a data.
// t: a string que cont√©m a data.
// Retorna uma string contendo a data formatada.
func FormatDate(t string) string {
	return FormatDateTime(t, DateFormat)
}

// FormatDateTime formata a data e a hora.
// t: a string que cont√©m a data e a hora.
// format: o formato da data e hora a ser formatado.
// Retorna uma string contendo a data e hora formatada.
func FormatDateTime(t string, format string) string {
	if len(t) < len(format) {
		return t
	}
	return t[:len(format)]
}

/// utils/users.go ///
package utils

import (
	"fmt"
	"os/exec"
	"strings"
)

// GetPrimaryUser retorna o nome do usu√°rio principal do sistema.
// Executa o comando `id -un` para obter o nome do usu√°rio.
// Retorna o nome do usu√°rio como string e um erro, se houver.
func GetPrimaryUser() (string, error) {
	cmd := exec.Command("id", "-un")
	output, err := cmd.Output()
	if err != nil {
		return "", fmt.Errorf("erro ao obter o usu√°rio principal: %v", err)
	}
	user := strings.TrimSpace(string(output))
	return user, nil
}

// GetPrimaryGroup retorna o nome do grupo principal do sistema.
// Executa o comando `id -gn` para obter o nome do grupo.
// Retorna o nome do grupo como string e um erro, se houver.
func GetPrimaryGroup() (string, error) {
	cmd := exec.Command("id", "-gn")
	output, err := cmd.Output()
	if err != nil {
		return "", fmt.Errorf("erro ao obter o grupo principal: %v", err)
	}
	group := strings.TrimSpace(string(output))
	return group, nil
}

// GetGroups retorna uma lista de IDs dos grupos aos quais o usu√°rio pertence.
// Executa o comando `id -G` para obter os IDs dos grupos.
// Retorna uma lista de strings com os IDs dos grupos e um erro, se houver.
func GetGroups() ([]string, error) {
	cmd := exec.Command("id", "-G")
	output, err := cmd.Output()
	if err != nil {
		return nil, fmt.Errorf("erro ao obter os grupos: %v", err)
	}
	groups := strings.Split(strings.TrimSpace(string(output)), " ")
	return groups, nil
}

/// utils/utils.go ///
package utils

import (
	"fmt"
	"os"
	"os/exec"
	"strings"
	"time"

	gl "github.com/rafa-mori/gdbase/logger"
)

// ValidateWorkerLimit valida o limite de workers
func ValidateWorkerLimit(value any) error {
	if limit, ok := value.(int); ok {
		if limit < 0 {
			return fmt.Errorf("worker limit cannot be negative")
		}
	} else {
		return fmt.Errorf("invalid type for worker limit")
	}
	return nil
}

func generateProcessFileName(processName string, pid int) string {
	bootID, err := GetBootID()
	if err != nil {
		gl.Log("error", fmt.Sprintf("Failed to get boot ID: %v", err))
		return ""
	}
	return fmt.Sprintf("%s_%d_%s.pid", processName, pid, bootID)
}

func createProcessFile(processName string, pid int) (*os.File, error) {
	fileName := generateProcessFileName(processName, pid)
	file, err := os.Create(fileName)
	if err != nil {
		return nil, err
	}

	// Escrever os detalhes do processo no arquivo
	_, err = file.WriteString(fmt.Sprintf("Process Name: %s\nPID: %d\nTimestamp: %d\n", processName, pid, time.Now().Unix()))
	if err != nil {
		file.Close()
		return nil, err
	}

	return file, nil
}

func removeProcessFile(file *os.File) {
	if file == nil {
		return
	}

	fileName := file.Name()
	file.Close()

	// Apagar o arquivo tempor√°rio
	if err := os.Remove(fileName); err != nil {
		gl.Log("error", fmt.Sprintf("Failed to remove process file %s: %v", fileName, err))
	} else {
		gl.Log("info", fmt.Sprintf("Successfully removed process file: %s", fileName))
	}
}

func GetBootID() (string, error) {
	data, err := os.ReadFile("/proc/sys/kernel/random/boot_id")
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(string(data)), nil
}

func GetBootTimeMac() (string, error) {
	cmd := exec.Command("sysctl", "-n", "kern.boottime")
	out, err := cmd.Output()
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(string(out)), nil
}

func GetBootTimeWindows() (string, error) {
	cmd := exec.Command("powershell", "-Command", "(Get-WmiObject Win32_OperatingSystem).LastBootUpTime")
	out, err := cmd.Output()
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(string(out)), nil
}

/// version/semantic.go ///
package version

import (
	gl "github.com/rafa-mori/gdbase/logger"
	l "github.com/rafa-mori/logz"

	"github.com/spf13/cobra"

	_ "embed"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strconv"
	"strings"
	"time"
)

const moduleAlias = "GDBase"
const moduleName = "gdbase"
const gitModelUrl = "https://github.com/rafa-mori/" + moduleName + ".git"
const currentVersionFallback = "v1.0.1" // First version with the version file

type Service interface {
	GetLatestVersion() (string, error)
	GetCurrentVersion() string
	IsLatestVersion() (bool, error)
}
type ServiceImpl struct {
	gitModelUrl    string
	latestVersion  string
	currentVersion string
}
type Tag struct {
	Name string `json:"name"`
}

func init() {
	l.GetLogger(moduleAlias)
}

func getLatestTag(repoURL string) (string, error) {
	apiURL := fmt.Sprintf("%s/tags", repoURL)
	resp, err := http.Get(apiURL)
	if err != nil {
		return "", err
	}
	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("failed to fetch tags: %s", resp.Status)
	}

	var tags []Tag
	if err := json.NewDecoder(resp.Body).Decode(&tags); err != nil {
		return "", err
	}

	if len(tags) == 0 {
		return "", fmt.Errorf("no tags found")
	}

	return tags[0].Name, nil
}

func (v *ServiceImpl) updateLatestVersion() error {
	repoURL := strings.TrimSuffix(v.gitModelUrl, ".git")
	tag, err := getLatestTag(repoURL)
	if err != nil {
		return err
	}
	v.latestVersion = tag
	return nil
}
func (v *ServiceImpl) vrsCompare(v1, v2 []int) (int, error) {
	if len(v1) != len(v2) {
		return 0, fmt.Errorf("version length mismatch")
	}

	for idx, v2S := range v2 {
		v1S := v1[idx]
		if v1S > v2S {
			return 1, nil
		}

		if v1S < v2S {
			return -1, nil
		}
	}
	return 0, nil
}
func (v *ServiceImpl) versionAtMost(versionAtMostArg, max []int) (bool, error) {
	if comp, err := v.vrsCompare(versionAtMostArg, max); err != nil {
		return false, err
	} else if comp == 1 {
		return false, nil
	}
	return true, nil
}
func (v *ServiceImpl) parseVersion(versionToParse string) []int {
	version := make([]int, 3)
	for idx, vStr := range strings.Split(versionToParse, ".") {
		vS, err := strconv.Atoi(vStr)
		if err != nil {
			return nil
		}
		version[idx] = vS
	}
	return version
}

func (v *ServiceImpl) IsLatestVersion() (bool, error) {
	if v.latestVersion == "" {
		if err := v.updateLatestVersion(); err != nil {
			return false, err
		}
	}

	curr := v.parseVersion(v.currentVersion)
	latest := v.parseVersion(v.latestVersion)

	if curr == nil || latest == nil {
		return false, fmt.Errorf("error parsing versions")
	}

	if isLatest, err := v.versionAtMost(curr, latest); err != nil {
		return false, err
	} else if isLatest {
		return true, nil
	}
	return false, nil
}
func (v *ServiceImpl) GetLatestVersion() (string, error) {
	if v.latestVersion == "" {
		if err := v.updateLatestVersion(); err != nil {
			return "", err
		}
	}

	return v.latestVersion, nil
}
func (v *ServiceImpl) GetCurrentVersion() string { return v.currentVersion }

func NewVersionService() Service {
	return &ServiceImpl{
		gitModelUrl:    gitModelUrl,
		currentVersion: currentVersion,
		latestVersion:  "",
	}
}

var (
	versionCmd = &cobra.Command{
		Use:   "version",
		Short: "Print the version number of " + moduleAlias,
		Long:  "Print the version number of " + moduleAlias,
		Run: func(cmd *cobra.Command, args []string) {
			GetVersionInfo()
		},
	}
	subLatestCmd = &cobra.Command{
		Use:   "latest",
		Short: "Print the latest version number of " + moduleAlias,
		Long:  "Print the latest version number of " + moduleAlias,
		Run: func(cmd *cobra.Command, args []string) {
			GetLatestVersionInfo()
		},
	}
	subCmdCheck = &cobra.Command{
		Use:   "check",
		Short: "Check if the current version is the latest version of " + moduleAlias,
		Long:  "Check if the current version is the latest version of " + moduleAlias,
		Run: func(cmd *cobra.Command, args []string) {
			GetVersionInfoWithLatestAndCheck()
		},
	}
)

//go:embed CLI_VERSION
var currentVersion string

func GetVersion() string {
	if currentVersion == "" {
		return currentVersionFallback
	}
	return currentVersion
}

func GetGitModelUrl() string {
	return gitModelUrl
}

func GetVersionInfo() string {
	gl.Log("info", "Version: "+GetVersion())
	gl.Log("info", "Git repository: "+GetGitModelUrl())
	return fmt.Sprintf("Version: %s\nGit repository: %s", GetVersion(), GetGitModelUrl())
}

func GetLatestVersionFromGit() string {
	netClient := &http.Client{
		Timeout: time.Second * 10,
	}

	gitUrlWithoutGit := strings.TrimSuffix(gitModelUrl, ".git")

	response, err := netClient.Get(gitUrlWithoutGit + "/releases/latest")
	if err != nil {
		gl.Log("error", "ErrorCtx fetching latest version: "+err.Error())
		gl.Log("error", gitUrlWithoutGit+"/releases/latest")
		return err.Error()
	}

	if response.StatusCode != 200 {
		gl.Log("error", "ErrorCtx fetching latest version: "+response.Status)
		gl.Log("error", "Url: "+gitUrlWithoutGit+"/releases/latest")
		body, _ := io.ReadAll(response.Body)
		return fmt.Sprintf("ErrorCtx: %s\nResponse: %s", response.Status, string(body))
	}

	tag := strings.Split(response.Request.URL.Path, "/")

	return tag[len(tag)-1]
}

func GetLatestVersionInfo() string {
	gl.Log("info", "Latest version: "+GetLatestVersionFromGit())
	return "Latest version: " + GetLatestVersionFromGit()
}

func GetVersionInfoWithLatestAndCheck() string {
	if GetVersion() == GetLatestVersionFromGit() {
		gl.Log("info", "You are using the latest version.")
		return fmt.Sprintf("You are using the latest version.\n%s\n%s", GetVersionInfo(), GetLatestVersionInfo())
	} else {
		gl.Log("warn", "You are using an outdated version.")
		return fmt.Sprintf("You are using an outdated version.\n%s\n%s", GetVersionInfo(), GetLatestVersionInfo())
	}
}

func CliCommand() *cobra.Command {
	versionCmd.AddCommand(subLatestCmd)
	versionCmd.AddCommand(subCmdCheck)
	return versionCmd
}
