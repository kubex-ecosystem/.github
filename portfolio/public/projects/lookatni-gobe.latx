# LookAtni Code - Gerado automaticamente
# Data: 2025-07-13T23:15:21.349Z
# Fonte: /srv/apps/KUBEX/gobe/
# Total de arquivos: 156

/// CODE_OF_CONDUCT.md ///
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
discord.gg/CCBJsFHT.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
<https://www.contributor-covenant.org/version/2/0/code_of_conduct.html>.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
<https://www.contributor-covenant.org/faq>. Translations are available at
<https://www.contributor-covenant.org/translations>.

/// NOTICE.md ///
# NOTICE

This software is licensed under the MIT License. Below are additional notes on usage and attribution:

## Attribution Requirement (Optional)

- When distributing or using this software, please provide credit to the original author(s) in one or more of the following ways:
- Retain the copyright notice: `Copyright (c) 2025 Rafael Mori`.
- Include a link to the original project repository or website.

## Acknowledgment

This project was developed with the goal of enhancing usability and providing open access to its features.

For further information about the license and terms of use, please refer to the `LICENSE` file included with this project.

/// ORG_FILES.txt ///
.
â”‚   # Camada de abstraÃ§Ã£o para exposiÃ§Ã£o de lÃ³gicas para uso externo como programa executÃ¡vel autÃ´nomo.
â”‚   # Essa estrutura praticamente todos possuem e Ã© onde a lÃ³gica usada na execuÃ§Ã£o da CLI, por exemplo,
â”‚   # irÃ¡ interagir com a lÃ³gica encapsulada, sem que ocorra o contrÃ¡rio. Como se fosse um mÃ³dulo separado
â”‚   # dentro do prÃ³prio mÃ³dulo, dedicado Ã  execuÃ§Ã£o destacada, direta, integrada e independente do restante, direto no OS.
â”œâ”€â”€ cmd
â”‚Â Â  â”œâ”€â”€ cli
â”‚Â Â  â”œâ”€â”€ main.go
â”‚Â Â  â”œâ”€â”€ usage.go
â”‚Â Â  â””â”€â”€ wrpr.go

â”‚  # Camada de abstraÃ§Ã£o para exposiÃ§Ã£o de lÃ³gicas para uso externo das estruturas e coisas
â”‚  # encapsuladas no internal, mas que demandam exposiÃ§Ã£o de constructors, middlewares ou coisas do tipo
â”‚  # para que a interface exportada lÃ¡ de dentro seja funcional e totalmente utilizÃ¡vel de fora
â”œâ”€â”€ factory
â”‚Â Â  â”œâ”€â”€ gateway
â”‚Â Â  â”œâ”€â”€ gobemin.go
â”‚Â Â  â”œâ”€â”€ gobjects
â”‚Â Â  â””â”€â”€ security

â”‚   # Camada estrutural que Go usa pra gerir dependÃªncias e para permitir que seja
â”‚   # usado como biblioteca, porque Ã© obrigatÃ³rio que esteja na raiz do projeto, onde
â”‚   # o nome do mÃ³dulo aponta dentro do repositÃ³rio e que possua o package com o mesmo nome da lib disponibilizada/exposta para importaÃ§Ã£o
â”œâ”€â”€ gobe.go
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum

â”‚   # Toda a lÃ³gica central e outras coisas que demandam encapsulamento
â”‚   # para fixaÃ§Ã£o/injeÃ§Ã£o/envelope/uso de qualquer
â”‚   # dependÃªncia/serviÃ§o/algoritmo/atÃ© embed se precisar, dependendo do que for obviamente...
â”œâ”€â”€ internal
â”‚Â Â  â”œâ”€â”€ common
â”‚Â Â  â”œâ”€â”€ controllers
â”‚Â Â  â”œâ”€â”€ interfaces
â”‚Â Â  â”œâ”€â”€ middlewares
â”‚Â Â  â”œâ”€â”€ routes
â”‚Â Â  â”œâ”€â”€ scheduler
â”‚Â Â  â”œâ”€â”€ security
â”‚Â Â  â”œâ”€â”€ services
â”‚Â Â  â”œâ”€â”€ types
â”‚Â Â  â””â”€â”€ utils

â”‚   # Consumo padronizado do meu logz de forma abstrata, centralizada e reutilizÃ¡vel
â”œâ”€â”€ logger
â”‚Â Â  â””â”€â”€ logger.go

â”‚   # Conformidade com as normas e padrÃµes de cÃ³digo open source
â”œâ”€â”€ LICENSE
â”œâ”€â”€ NOTICE.md
â”œâ”€â”€ ORG_FILES.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ CODE_OF_CONDUCT.md
â”œâ”€â”€ docs
â”‚Â Â  â””â”€â”€ README copy.md

â”‚   # Fluxo de distribuiÃ§Ã£o e outras coisas auxiliares estruturais
â”œâ”€â”€ Makefile
â”œâ”€â”€ support
â”‚Â Â  â”œâ”€â”€ build.sh
â”‚Â Â  â”œâ”€â”€ composer.sh
â”‚Â Â  â”œâ”€â”€ config.sh
â”‚Â Â  â”œâ”€â”€ info.sh
â”‚Â Â  â”œâ”€â”€ install_funcs.sh
â”‚Â Â  â”œâ”€â”€ install.sh
â”‚Â Â  â”œâ”€â”€ platform.sh
â”‚Â Â  â”œâ”€â”€ utils.sh
â”‚Â Â  â””â”€â”€ validate.sh


â”‚   # Testes unitÃ¡rios e de integraÃ§Ã£o, com os arquivos de teste separados dos packages operacionais
â”‚   # e totalmente expostos. Isso permite que os testes acessem diretamente as implementaÃ§Ãµes internas
â”‚   # sem a necessidade de passar por interfaces ou abstraÃ§Ãµes e ao mesmo tempo garante transparÃªncia total
â”‚   # para quem for ler o cÃ³digo, inclusive como referÃªncia de uso e implementaÃ§Ã£o de cada parte do cÃ³digo.
â”œâ”€â”€ tests
â”‚Â Â  â”œâ”€â”€ crt_abs_test.go
â”‚Â Â  â”œâ”€â”€ crypto_service_test.go
â”‚Â Â  â”œâ”€â”€ environment_test.go
â”‚Â Â  â”œâ”€â”€ goroutine_pool_test.go
â”‚Â Â  â”œâ”€â”€ keyring_service_test.go
â”‚Â Â  â”œâ”€â”€ mapper_test.go
â”‚Â Â  â”œâ”€â”€ request_tracer_test.go
â”‚Â Â  â”œâ”€â”€ secure_mapper_test.go
â”‚Â Â  â”œâ”€â”€ token_service_test.go
â”‚Â Â  â””â”€â”€ virus_total.go

â”‚   # UtilitÃ¡rios e helpers que sÃ£o usados em todo o projeto e que tambÃ©m estÃ£o disponÃ­veis
â”‚   # para uso externo, geralmente tanto pela CLI quanto pelos mÃ³dulos internos.
â”œâ”€â”€ utils
â”‚Â Â  â”œâ”€â”€ embed.go
â”‚Â Â  â”œâ”€â”€ pagination.go
â”‚Â Â  â”œâ”€â”€ validator.go
â”‚Â Â  â””â”€â”€ views

â”‚   # VersÃ£o e controle de versÃ£o do projeto. Isso Ã© uma abstraÃ§Ã£o que fiz que TODOS possuem tambÃ©m.
â”‚   # A ideia Ã© que permita self-update, self-install, self-validate e outras coisas do tipo/macro propÃ³sito.
â””â”€â”€ version
    â”œâ”€â”€ CLI_VERSION
    â””â”€â”€ semantic.go

/// README.md ///
# GoBE - Modular & Secure Back-end

![GoBE Banner](docs/assets/top_banner_lg_b.png)

[![Build Status](https://img.shields.io/github/actions/workflow/status/kubex-ecosystem/gobe/release.yml?branch=main)](https://github.com/kubex-ecosystem/gobe/actions)
[![Go](https://img.shields.io/badge/Go-1.24+-00ADD8?logo=go&logoColor=white)](https://go.dev/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/kubex-ecosystem/gobe/blob/main/LICENSE)
[![Automation](https://img.shields.io/badge/automation-zero%20config-blue)](#features)
[![Modular](https://img.shields.io/badge/modular-yes-yellow)](#features)
[![Security](https://img.shields.io/badge/security-high-red)](#features)
[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](https://github.com/kubex-ecosystem/gobe/blob/main/CONTRIBUTING.md)

---

**A modular, secure, and zero-config backend for modern Go applications.**

---

## **Table of Contents**

1. [About the Project](#about-the-project)
2. [Features](#features)
3. [Installation](#installation)
4. [Usage](#usage)
    - [CLI](#cli)
    - [Configuration](#configuration)
5. [Roadmap](#roadmap)
6. [Contributing](#contributing)
7. [Contact](#contact)

---

## **About the Project**

GoBE is a modular backend developed in Go, focused on **security, automation, and flexibility**. It can run as a **main server** or be used **as a module** for managing features like **encryption, certificates, middlewares, logging, and authentication**.

### **Current Status**

- **Zero-config:** No manual configuration required, generates all certificates and securely stores sensitive information in the system keyring.
- **Extensible:** Can be integrated with other systems or run standalone.
- **Modularization:** The project is fully modular, with all logic encapsulated in well-defined interfaces.
- **Integration with `gdbase`:** Database management is handled via Docker, allowing for easy setup and optimization.
- **REST API:** Provides endpoints for authentication, user management, products, clients, and cronjobs.
- **Authentication:** Uses dynamically generated certificates, random passwords, and secure keyring for robust security.
- **CLI:** A powerful command-line interface for managing the server, including commands to start, stop, and monitor services.
- **Logging and Security Management:** Protected routes, secure storage, and request monitoring are implemented to ensure data integrity and security.
- **Multi-database support:** Currently supports PostgreSQL and SQLite, with plans for more databases in the future.
- **Prometheus and Grafana integration:** Planned for monitoring and metrics visualization.
- **Documentation:** Continuous improvement to provide comprehensive documentation for all endpoints and functionalities.
- **Unit Tests:** While all functionalities are operational, unit tests are being developed to ensure reliability and robustness.
- **CI/CD:** Automated tests and continuous integration are in progress to maintain code quality and deployment efficiency.
- **Complete Documentation:** The documentation is being expanded to cover all aspects of the project, including usage examples and detailed endpoint descriptions.
- **Automated Tests:** Although the functionalities are implemented, unit tests are being developed to ensure reliability and robustness.

## **Project Evolution**

The project has undergone significant evolution since its inception. Initially focused on basic functionalities, it has now expanded to include a wide range of features that enhance security, modularity, and ease of use.
The current version of GoBE is a result of continuous improvements and refinements, with a strong emphasis on security and automation. The system is designed to be user-friendly, allowing developers to focus on building applications without worrying about backend complexities.
The modular architecture allows for easy integration with other systems, making GoBE a versatile choice for modern Go applications. The project is actively maintained, with ongoing efforts to enhance its capabilities and ensure it meets the evolving needs of developers.

Documentation and CI/CD are key focus areas for the next updates

---

## **Features**

âœ¨ **Fully modular**

- All logic follows well-defined interfaces, ensuring encapsulation.
- Can be used as a server or as a library/module.

ğŸ”’ **Zero-config, but customizable**

- Runs without initial configuration, but supports customization via files.
- Automatically generates certificates, passwords, and secure settings.

ğŸ”— **Direct integration with `gdbase`**

- Database management via Docker.
- Automatic optimizations for persistence and performance.

ğŸ›¡ï¸ **Advanced authentication**

- Dynamically generated certificates.
- Random passwords and secure keyring.

ğŸŒ **Robust REST API**

- Endpoints for authentication, user management, products, clients, and cronjobs.

ğŸ“‹ **Log and security management**

- Protected routes, secure storage, and request monitoring.

ğŸ§‘â€ğŸ’» **Powerful CLI**

- Commands to start, configure, and monitor the server.

---

## **Installation**

Requirements:

- Go 1.19+
- Docker (for database integration via gdbase)

Clone the repository and build GoBE:

```sh
# Clone the repository
git clone https://github.com/kubex-ecosystem/gobe.git
cd gobe
go build -o gobe .
```

---

## **Usage**

### CLI

Start the main server:

```sh
./gobe start -p 3666 -b "0.0.0.0"
```

This starts the server, generates certificates, sets up databases, and begins listening for requests!

See all available commands:

```sh
./gobe --help
```

**Main commands:**

| Command   | Function                                         |
|-----------|--------------------------------------------------|
| `start`   | Starts the server                                |
| `stop`    | Safely stops the server                          |
| `restart` | Restarts all services                            |
| `status`  | Shows the status of the server and active services|
| `config`  | Generates an initial configuration file          |
| `logs`    | Displays server logs                             |

---

### Configuration

GoBE can run without any initial configuration, but supports customization via YAML/JSON files. By default, everything is generated automatically on first use.

Example configuration:

```yaml
port: 3666
bindAddress: 0.0.0.0
database:
  type: postgres
  host: localhost
  port: 5432
  user: gobe
  password: secure
```

---

## **Roadmap**

- [x] Full modularization and pluggable interfaces
- [x] Zero-config with automatic certificate generation
- [x] Integration with system keyring
- [x] REST API for authentication and management
- [x] Authentication via certificates and secure passwords
- [x] CLI for management and monitoring
- [x] Integration with `gdbase` for database management via Docker
- [â€“] Multi-database support (Partially completed)
- [  ] Prometheus integration for monitoring
- [  ] Support for custom middlewares
- [  ] Grafana integration for metrics visualization
- [â€“] Complete documentation and usage examples (Partially completed)
- [â€“] Automated tests and CI/CD (Partially completed)

---

## **Contributing**

Contributions are welcome! Feel free to open issues or submit pull requests. See the [Contribution Guide](docs/CONTRIBUTING.md) for more details.

---

## **Contact**

ğŸ’Œ **Developer**:
[Rafael Mori](mailto:faelmori@gmail.com)
ğŸ’¼ [Follow me on GitHub](https://github.com/rafa-mori)
I'm open to collaborations and new ideas. If you found the project interesting, get in touch!



/// SECURITY.md ///
# Security Policy

## Supported Versions

Use this section to tell people about which versions of your project are
currently being supported with security updates.

| Version | Supported          |
| ------- | ------------------ |
| 5.1.x   | :white_check_mark: |
| 5.0.x   | :x:                |
| 4.0.x   | :white_check_mark: |
| < 4.0   | :x:                |

## Reporting a Vulnerability

Use this section to tell people how to report a vulnerability.

Tell them where to go, how often they can expect to get an update on a
reported vulnerability, what to expect if the vulnerability is accepted or
declined, etc.

/// api.go ///
package gobe

import (
	. "github.com/kubex-ecosystem/gobe/internal/interfaces"
	. "github.com/kubex-ecosystem/gobe/internal/security/interfaces"

	isc "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	l "github.com/kubex-ecosystem/logz"
)

//func StartGoBE(name string, port string, bind string, logFile string, configFile string, isConfidential bool, logger l.Logger, debug bool) {
//	gl.Log("fatal", "Starting GoBE with name: ", name, " and port: ", port)
//
//	sigChan := make(chan os.Signal, 1)
//	signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
//
//	// Initialize the logger
//	if logger == nil {
//		logger = l.GetLogger("GoBE")
//	}
//	gb, gbErr := NewGoBE(name, port, bind, logFile, configFile, isConfidential, logger, debug)
//	if gbErr != nil {
//		gl.Log("fatal", "Failed to create GoBE instance: ", gbErr.Error())
//	}
//
//	if gb == nil {
//		gl.Log("fatal", "Failed to create GoBE instance: ", "GoBE instance is nil")
//	} else {
//		err := gb.Initialize()
//		if err != nil {
//			gl.Log("fatal", "Failed to initialize GoBE: ", err.Error())
//			return
//		}
//		gb.StartGoBE()
//		gl.Log("success", "GoBE started successfully")
//		gl.Log("notice", "GoBE is running on ", gb.GetReference().GetID().String(), " with PID ", strconv.Itoa(os.Getpid()))
//	}
//
//	// Wait for termination signal
//	select {
//	case sig := <-sigChan:
//		gl.Log("info", "Received signal: ", sig.String())
//		//gb.Shutdown()
//		gl.Log("info", "GoBE shutting down")
//	case <-time.After(60 * time.Second):
//		gl.Log("debug", "No signal received, continuing to run")
//		//gb.SyncMetrics()
//	}
//}

type PropertyValBase[T any] interface{ IPropertyValBase[T] }
type Property[T any] interface{ IProperty[T] }

func NewProperty[T any](name string, v *T, withMetrics bool, cb func(any) (bool, error)) IProperty[T] {
	return t.NewProperty(name, v, withMetrics, cb)
}

type Channel[T any] interface{ IChannelCtl[T] }
type ChannelBase[T any] interface{ IChannelBase[T] }

func NewChannel[T any](name string, logger l.Logger) IChannelCtl[T] {
	return t.NewChannelCtl[T](name, logger)
}
func NewChannelCtlWithProperty[T any, P IProperty[T]](name string, buffers *int, property P, withMetrics bool, logger l.Logger) IChannelCtl[T] {
	return t.NewChannelCtlWithProperty[T, P](name, buffers, property, withMetrics, logger)
}
func NewChannelBase[T any](name string, buffers int, logger l.Logger) IChannelBase[T] {
	return t.NewChannelBase[T](name, buffers, logger)
}

type Validation[T any] interface{ IValidation[T] }

func NewValidation[T any](name string, v *T, withMetrics bool, cb func(any) (bool, error)) IValidation[T] {
	return t.NewValidation[T]()
}

type ValidationFunc[T any] interface{ IValidationFunc[T] }

func NewValidationFunc[T any](priority int, f func(value *T, args ...any) IValidationResult) IValidationFunc[T] {
	return t.NewValidationFunc[T](priority, f)
}

type ValidationResult interface{ IValidationResult }

func NewValidationResult(isValid bool, message string, metadata map[string]any, err error) IValidationResult {
	return t.NewValidationResult(isValid, message, metadata, err)
}

type Environment interface{ IEnvironment }

func NewEnvironment(envFile string, isConfidential bool, logger l.Logger) (IEnvironment, error) {
	return t.NewEnvironment(envFile, isConfidential, logger)
}

type Mapper[T any] interface{ IMapper[T] }

func NewMapper[T any](object *T, filePath string) IMapper[T] {
	return t.NewMapper[T](object, filePath)
}

type Mutexes interface{ IMutexes }

func NewMutexes() IMutexes    { return t.NewMutexes() }
func NewMutexesType() Mutexes { return t.NewMutexesType() }

type Reference interface{ IReference }

func NewReference(name string) IReference { return t.NewReference(name) }

type SignalManager[T chan string] interface{ ISignalManager[T] }

func NewSignalManager[T chan string](signalChan T, logger l.Logger) ISignalManager[T] {
	return t.NewSignalManager[T](signalChan, logger)
}

type CertService interface{ ICertService }

func NewCertService(keyPath string, certPath string) ICertService {
	return isc.NewCertService(keyPath, certPath)
}

type CryptoService interface{ ICryptoService }

func NewCryptoService() ICryptoService {
	return nil //t.NewCryptoService()
}

/// cmd/cli/certificates.go ///
package cli

import (
	"fmt"
	"os"

	gbm "github.com/kubex-ecosystem/gobe"
	crp "github.com/kubex-ecosystem/gobe/internal/security/crypto"
	gl "github.com/kubex-ecosystem/gobe/logger"
	"github.com/spf13/cobra"
)

func CertificatesCmdList() *cobra.Command {
	certificatesCmd := &cobra.Command{
		Use:   "certificates",
		Short: "Certificates commands",
		Long:  "Certificates commands for GoBE or any other service",
		Run: func(cmd *cobra.Command, args []string) {
			err := cmd.Help()
			if err != nil {
				gl.Log("error", fmt.Sprintf("Error displaying help: %v", err))
				return
			}
		},
	}
	cmdList := []*cobra.Command{
		generateCommand(),
		verifyCert(),
		generateRandomKey(),
	}
	certificatesCmd.AddCommand(cmdList...)
	return certificatesCmd
}

func generateCommand() *cobra.Command {
	var keyPath, certFilePath, certPass string
	var debug bool

	short := "Generate certificates for GoBE or any other service"
	long := "Generate certificates for GoBE or any other service using the provided configuration file"

	var startCmd = &cobra.Command{
		Use:         "generate",
		Short:       short,
		Long:        long,
		Annotations: GetDescriptions([]string{short, long}, false),
		Run: func(cmd *cobra.Command, args []string) {
			crtS := gbm.NewCertService(keyPath, certFilePath)
			_, _, err := crtS.GenerateCertificate(certFilePath, keyPath, []byte(certPass))
			if err != nil {
				gl.Log("fatal", fmt.Sprintf("Error generating certificate: %v", err))
			}
			gl.Log("success", "Certificate generated successfully")
		},
	}

	startCmd.Flags().StringVarP(&keyPath, "key-path", "k", "", "Path to the private key file")
	startCmd.Flags().StringVarP(&certFilePath, "cert-file-path", "c", "", "Path to the certificate file")
	startCmd.Flags().StringVarP(&certPass, "cert-pass", "p", "", "Password for the certificate")
	startCmd.Flags().BoolVarP(&debug, "debug", "d", false, "Enable debug mode")

	return startCmd
}

func verifyCert() *cobra.Command {
	var keyPath, certFilePath string
	var debug bool

	short := "Verify certificates for GoBE or any other service"
	long := "Verify certificates for GoBE or any other service using the provided configuration file"

	var startCmd = &cobra.Command{
		Use:         "verify",
		Short:       short,
		Long:        long,
		Annotations: GetDescriptions([]string{short, long}, false),
		Run: func(cmd *cobra.Command, args []string) {
			crtS := gbm.NewCertService(keyPath, certFilePath)
			err := crtS.VerifyCert()
			if err != nil {
				gl.Log("fatal", fmt.Sprintf("Error verifying certificate: %v", err))
			}
			gl.Log("success", "Certificate verified successfully")
		},
	}

	startCmd.Flags().StringVarP(&keyPath, "key-path", "k", "", "Path to the private key file")
	startCmd.Flags().StringVarP(&certFilePath, "cert-file-path", "c", "", "Path to the certificate file")
	startCmd.Flags().BoolVarP(&debug, "debug", "d", false, "Enable debug mode")

	return startCmd
}

func generateRandomKey() *cobra.Command {
	var keyPath string //, fileFormat string
	var length int
	var debug bool

	short := "Generate a random key for GoBE or any other service"
	long := "Generate a random key for GoBE or any other service using the provided configuration file"

	var startCmd = &cobra.Command{
		Use:         "random-key",
		Short:       short,
		Long:        long,
		Annotations: GetDescriptions([]string{short, long}, false),
		Run: func(cmd *cobra.Command, args []string) {
			crtS := crp.NewCryptoService()
			var bts []byte
			var btsErr error
			if length > 0 {
				bts, btsErr = crtS.GenerateKeyWithLength(length)
			} else {
				bts, btsErr = crtS.GenerateKey()
			}
			if btsErr != nil {
				gl.Log("fatal", fmt.Sprintf("Error generating random key: %v", btsErr))
			}
			key := string(bts)
			if keyPath != "" {
				// File cannot exist, because this method will truncate the file
				if f, err := os.Stat(keyPath); f != nil && !os.IsNotExist(err) {
					gl.Log("error", fmt.Sprintf("File already exists: %s", keyPath))
					return
				}
				writeErr := os.WriteFile(keyPath, bts, 0644)
				if writeErr != nil {
					gl.Log("fatal", fmt.Sprintf("Error writing random key to file: %v", writeErr))
					return
				}
			}
			gl.Log("success", fmt.Sprintf("Random key generated successfully: %s", key))
		},
	}

	startCmd.Flags().StringVarP(&keyPath, "key-path", "k", "", "Path to the private key file")
	//startCmd.Flags().StringVarP(&fileFormat, "file-format", "f", "", "File format for the key (e.g., PEM, DER)")
	startCmd.Flags().IntVarP(&length, "length", "l", 16, "Length of the random key")
	startCmd.Flags().BoolVarP(&debug, "debug", "d", false, "Enable debug mode")

	return startCmd
}

/// cmd/cli/common.go ///
package cli

import (
	"math/rand"
	"os"
	"strings"
)

var banners = []string{
	`
  ______           _______  ________
 /      \         |       \|        \
|  â–“â–“â–“â–“â–“â–“\ ______ | â–“â–“â–“â–“â–“â–“â–“\ â–“â–“â–“â–“â–“â–“â–“â–“
| â–“â–“ __\â–“â–“/      \| â–“â–“__/ â–“â–“ â–“â–“__
| â–“â–“|    \  â–“â–“â–“â–“â–“â–“\ â–“â–“    â–“â–“ â–“â–“  \
| â–“â–“ \â–“â–“â–“â–“ â–“â–“  | â–“â–“ â–“â–“â–“â–“â–“â–“â–“\ â–“â–“â–“â–“â–“
| â–“â–“__| â–“â–“ â–“â–“__/ â–“â–“ â–“â–“__/ â–“â–“ â–“â–“_____
 \â–“â–“    â–“â–“\â–“â–“    â–“â–“ â–“â–“    â–“â–“ â–“â–“     \
  \â–“â–“â–“â–“â–“â–“  \â–“â–“â–“â–“â–“â–“ \â–“â–“â–“â–“â–“â–“â–“ \â–“â–“â–“â–“â–“â–“â–“â–“
`,
}

func GetDescriptions(descriptionArg []string, _ bool) map[string]string {
	var description, banner string
	if descriptionArg != nil {
		if strings.Contains(strings.Join(os.Args[0:], ""), "-h") {
			description = descriptionArg[0]
		} else {
			description = descriptionArg[1]
		}
	} else {
		description = ""
	}
	bannerRandLen := len(banners)
	bannerRandIndex := rand.Intn(bannerRandLen)
	banner = banners[bannerRandIndex]
	return map[string]string{"banner": banner, "description": description}
}

/// cmd/cli/service.go ///
package cli

import (
	gb "github.com/kubex-ecosystem/gobe"
	gl "github.com/kubex-ecosystem/gobe/logger"
	l "github.com/kubex-ecosystem/logz"
	"github.com/spf13/cobra"
)

func ServiceCmdList() []*cobra.Command {
	return []*cobra.Command{
		startCommand(),
	}
}

func startCommand() *cobra.Command {
	var name, port, bind, logFile, configFile string
	var isConfidential, debug bool

	var startCmd = &cobra.Command{
		Use: "start",
		Annotations: GetDescriptions([]string{
			"Start a minimal backend service",
			"Start a minimal backend service with GoBE",
		}, false),
		Run: func(cmd *cobra.Command, args []string) {
			gbm, gbmErr := gb.NewGoBE(name, port, bind, logFile, configFile, isConfidential, l.GetLogger("GoBE"), debug)
			if gbmErr != nil {
				gl.Log("fatal", "Failed to create GoBE instance: ", gbmErr.Error())
				return
			}
			if gbm == nil {
				gl.Log("fatal", "Failed to create GoBE instance: ", "GoBE instance is nil")
				return
			}
			gbm.StartGoBE()
			gl.Log("success", "GoBE started successfully")
		},
	}

	startCmd.Flags().StringVarP(&name, "name", "n", "GoBE", "Name of the process")
	startCmd.Flags().StringVarP(&port, "port", "p", ":8666", "Port to listen on")
	startCmd.Flags().StringVarP(&bind, "bind", "b", "0.0.0.0", "Bind address")
	startCmd.Flags().StringVarP(&logFile, "log-file", "l", "", "Log file path")
	startCmd.Flags().StringVarP(&configFile, "config-file", "c", "", "Configuration file path")
	startCmd.Flags().BoolVarP(&isConfidential, "confidential", "C", false, "Enable confidential mode")
	startCmd.Flags().BoolVarP(&debug, "debug", "d", false, "Enable debug mode")

	return startCmd
}

/// cmd/main.go ///
package main

import (
	l "github.com/kubex-ecosystem/logz"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

var logger l.Logger

// main initializes the logger and creates a new GoBE instance.
func main() {
	if err := RegX().Command().Execute(); err != nil {
		gl.Log("fatal", err.Error())
	}
}

/// cmd/usage.go ///
package main

import (
	"github.com/fatih/color"
	"github.com/spf13/cobra"
)

func colorYellow(s string) string {
	return color.New(color.FgYellow).SprintFunc()(s)
}
func colorGreen(s string) string {
	return color.New(color.FgGreen).SprintFunc()(s)
}
func colorBlue(s string) string {
	return color.New(color.FgBlue).SprintFunc()(s)
}
func colorRed(s string) string {
	return color.New(color.FgRed).SprintFunc()(s)
}
func colorHelp(s string) string {
	return color.New(color.FgCyan).SprintFunc()(s)
}
func hasServiceCommands(cmds []*cobra.Command) bool {
	for _, cmd := range cmds {
		if cmd.Annotations["service"] == "true" {
			return true
		}
	}
	return false
}
func hasModuleCommands(cmds []*cobra.Command) bool {
	for _, cmd := range cmds {
		if cmd.Annotations["service"] != "true" {
			return true
		}
	}
	return false
}
func setUsageDefinition(cmd *cobra.Command) {
	cobra.AddTemplateFunc("colorYellow", colorYellow)
	cobra.AddTemplateFunc("colorGreen", colorGreen)
	cobra.AddTemplateFunc("colorRed", colorRed)
	cobra.AddTemplateFunc("colorBlue", colorBlue)
	cobra.AddTemplateFunc("colorHelp", colorHelp)
	cobra.AddTemplateFunc("hasServiceCommands", hasServiceCommands)
	cobra.AddTemplateFunc("hasModuleCommands", hasModuleCommands)

	// Altera o template de uso do cobra
	cmd.SetUsageTemplate(cliUsageTemplate)
}

var cliUsageTemplate = `{{- if index .Annotations "banner" }}{{colorBlue (index .Annotations "banner")}}{{end}}{{- if (index .Annotations "description") }}
{{index .Annotations "description"}}
{{- end }}

{{colorYellow "Usage:"}}{{if .Runnable}}
  {{.UseLine}}{{end}}{{if .HasAvailableSubCommands}}
  {{.CommandPath}} [command] [args]{{end}}{{if gt (len .Aliases) 0}}

{{colorYellow "Aliases:"}}
  {{.NameAndAliases}}{{end}}{{if .HasExample}}

{{colorYellow "Example:"}}
  {{.Example}}{{end}}{{if .HasAvailableSubCommands}}
{{colorYellow "Available Commands:"}}{{range .Commands}}{{if (or .IsAvailableCommand (eq .Name "help"))}}
  {{colorGreen (rpad .Name .NamePadding) }} {{.Short}}{{end}}{{end}}{{end}}{{if .HasAvailableLocalFlags}}

{{colorYellow "Flags:"}}
{{.LocalFlags.FlagUsages | trimTrailingWhitespaces | colorHelp}}{{end}}{{if .HasAvailableInheritedFlags}}

{{colorYellow "Global Options:"}}
  {{.InheritedFlags.FlagUsages | trimTrailingWhitespaces | colorHelp}}{{end}}{{if .HasHelpSubCommands}}

{{colorYellow "Additional help topics:"}}
{{range .Commands}}{{if .IsHelpCommand}}
  {{colorGreen (rpad .CommandPath .CommandPathPadding) }} {{.Short}}{{end}}{{end}}{{end}}{{if .HasSubCommands}}

{{colorYellow (printf "Use \"%s [command] --help\" for more information about a command." .CommandPath)}}{{end}}
`

/// cmd/wrpr.go ///
package main

import (
	cc "github.com/kubex-ecosystem/gobe/cmd/cli"
	gl "github.com/kubex-ecosystem/gobe/logger"
	vs "github.com/kubex-ecosystem/gobe/version"
	"github.com/spf13/cobra"

	"os"
	"strings"
)

type GoBE struct {
	parentCmdName string
	printBanner   bool
}

func (m *GoBE) Alias() string { return "" }
func (m *GoBE) ShortDescription() string {
	return "GoBE is a minimalistic backend service with Go."
}
func (m *GoBE) LongDescription() string {
	return `GoBE: A minimalistic backend service with Go.`
}
func (m *GoBE) Usage() string {
	return "gobe [command] [args]"
}
func (m *GoBE) Examples() []string {
	return []string{"gobe start -p ':8080' -b '0.0.0.0' -n 'MyService' -d"}
}
func (m *GoBE) Active() bool {
	return true
}
func (m *GoBE) Module() string {
	return "gobe"
}
func (m *GoBE) Execute() error { return m.Command().Execute() }
func (m *GoBE) Command() *cobra.Command {
	gl.Log("debug", "Starting GoBE CLI...")

	var rtCmd = &cobra.Command{
		Use:     m.Module(),
		Aliases: []string{m.Alias()},
		Example: m.concatenateExamples(),
		Version: vs.GetVersion(),
		Annotations: cc.GetDescriptions([]string{
			m.LongDescription(),
			m.ShortDescription(),
		}, m.printBanner),
	}

	rtCmd.AddCommand(cc.CertificatesCmdList())
	rtCmd.AddCommand(cc.ServiceCmdList()...)
	rtCmd.AddCommand(vs.CliCommand())

	// Set usage definitions for the command and its subcommands
	setUsageDefinition(rtCmd)
	for _, c := range rtCmd.Commands() {
		setUsageDefinition(c)
		if !strings.Contains(strings.Join(os.Args, " "), c.Use) {
			if c.Short == "" {
				c.Short = c.Annotations["description"]
			}
		}
	}

	return rtCmd
}
func (m *GoBE) SetParentCmdName(rtCmd string) {
	m.parentCmdName = rtCmd
}
func (m *GoBE) concatenateExamples() string {
	examples := ""
	rtCmd := m.parentCmdName
	if rtCmd != "" {
		rtCmd = rtCmd + " "
	}
	for _, example := range m.Examples() {
		examples += rtCmd + example + "\n  "
	}
	return examples
}

func RegX() *GoBE {
	var printBannerV = os.Getenv("GOBEMIN_PRINT_BANNER")
	if printBannerV == "" {
		printBannerV = "true"
	}

	return &GoBE{
		printBanner: strings.ToLower(printBannerV) == "true",
	}
}

/// docs/README.pt-BR.md ///
# GoBE - Modular & Secure Back-end

![GoBE Banner](/docs/assets/top_banner_lg_b.png)

[![Build Status](https://img.shields.io/github/actions/workflow/status/kubex-ecosystem/gobe/release.yml?branch=main)](https://github.com/kubex-ecosystem/gobe/actions)
[![Go](https://img.shields.io/badge/Go-1.24+-00ADD8?logo=go&logoColor=white)](https://go.dev/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/kubex-ecosystem/gobe/blob/main/LICENSE)
[![Automation](https://img.shields.io/badge/automation-zero%20config-blue)](#features)
[![Modular](https://img.shields.io/badge/modular-yes-yellow)](#features)
[![Security](https://img.shields.io/badge/security-high-red)](#features)
[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](https://github.com/kubex-ecosystem/gobe/blob/main/CONTRIBUTING.md)

---

## **Table of Contents**

1. [About the Project](#about-the-project)
2. [Features](#features)
3. [Installation](#installation)
4. [Usage](#usage)
    - [CLI](#cli)
    - [Configuration](#configuration)
5. [Roadmap](#roadmap)
6. [Contributing](#contributing)
7. [Contact](#contact)

---

## **About the Project**

GoBE Ã© um back-end modular desenvolvido em Go, focado em **seguranÃ§a, automaÃ§Ã£o e flexibilidade**. Pode rodar como **servidor principal** ou ser utilizado **como mÃ³dulo** para gerenciamento de funcionalidades como **criptografia, certificados, middlewares, logging e autenticaÃ§Ã£o**.

- **Zero-config:** NÃ£o exige configuraÃ§Ã£o manual, gera todos os certificados e armazena informaÃ§Ãµes sensÃ­veis de forma segura no keyring do sistema.
- **ExtensÃ­vel:** Pode ser integrado a outros sistemas ou rodar standalone.

---

## **Features**

âœ¨ **Totalmente modular**

- Todas as lÃ³gicas seguem interfaces bem definidas, garantindo encapsulamento.
- Pode ser usado como servidor ou como biblioteca/mÃ³dulo.

ğŸ”’ **Zero-config, mas personalizÃ¡vel**

- Roda sem configuraÃ§Ã£o inicial, mas aceita customizaÃ§Ã£o via arquivos.
- Gera certificados, senhas e configuraÃ§Ãµes seguras automaticamente.

ğŸ”— **IntegraÃ§Ã£o direta com `gdbase`**

- Gerenciamento de bancos de dados via Docker.
- OtimizaÃ§Ãµes automÃ¡ticas para persistÃªncia e performance.

ğŸ›¡ï¸ **AutenticaÃ§Ã£o avanÃ§ada**

- Certificados gerados dinamicamente.
- Senhas aleatÃ³rias e keyring seguro.

ğŸŒ **API REST robusta**

- Endpoints para autenticaÃ§Ã£o, gerenciamento de usuÃ¡rios, produtos, clientes e cronjobs.

ğŸ“‹ **Gerenciamento de logs e seguranÃ§a**

- Rotas protegidas, armazenamento seguro e monitoramento de requisiÃ§Ãµes.

ğŸ§‘â€ğŸ’» **CLI poderosa**

- Comandos para iniciar, configurar e monitorar o servidor.

---

## **Installation**

Requisitos:

- Go 1.19+
- Docker (para integraÃ§Ã£o com bancos via gdbase)

Clone o repositÃ³rio e compile o GoBE:

```sh
# Clone o repositÃ³rio
git clone https://github.com/kubex-ecosystem/gobe.git
cd gobe
go build -o gobe .
```

---

## **Usage**

### CLI

Inicie o servidor principal:

```sh
./gobe start -p 3666 -b "0.0.0.0"
```

Isso inicializa o servidor, gera certificados, configura bancos de dados e comeÃ§a a escutar requisiÃ§Ãµes!

Veja todos os comandos disponÃ­veis:

```sh
./gobe --help
```

**Principais comandos:**

| Comando   | FunÃ§Ã£o                                             |
|-----------|----------------------------------------------------|
| `start`   | Inicializa o servidor                              |
| `stop`    | Encerra o servidor de forma segura                 |
| `restart` | Reinicia todos os serviÃ§os                         |
| `status`  | Exibe o status do servidor e dos serviÃ§os ativos   |
| `config`  | Gera um arquivo de configuraÃ§Ã£o inicial            |
| `logs`    | Exibe os logs do servidor                          |

---

### Configuration

O GoBE pode rodar sem configuraÃ§Ã£o inicial, mas aceita customizaÃ§Ã£o via arquivos YAML/JSON. Por padrÃ£o, tudo Ã© gerado automaticamente no primeiro uso.

Exemplo de configuraÃ§Ã£o:

```yaml
port: 3666
bindAddress: 0.0.0.0
database:
  type: postgres
  host: localhost
  port: 5432
  user: gobe
  password: secure
```

---

## **Roadmap**

- [x] ModularizaÃ§Ã£o total e interfaces plugÃ¡veis
- [x] Zero-config com geraÃ§Ã£o automÃ¡tica de certificados
- [x] IntegraÃ§Ã£o com keyring do sistema
- [x] API REST para autenticaÃ§Ã£o e gerenciamento
- [x] AutenticaÃ§Ã£o via certificados e senhas seguras
- [x] CLI para gerenciamento e monitoramento
- [x] IntegraÃ§Ã£o com `gdbase` para gerenciamento de bancos via Docker
- [â€“] Suporte a mÃºltiplos bancos de dados (Parcial concluÃ­do)
- [&nbsp;&nbsp;] IntegraÃ§Ã£o com Prometheus para monitoramento
- [&nbsp;&nbsp;] Suporte a middlewares personalizados
- [&nbsp;&nbsp;] IntegraÃ§Ã£o com Grafana para visualizaÃ§Ã£o de mÃ©tricas
- [â€“] DocumentaÃ§Ã£o completa e exemplos de uso (Parcial concluÃ­do)
- [â€“] Testes automatizados e CI/CD (Parcial concluÃ­do)

---

## **Contributing**

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou enviar pull requests. Veja o [Guia de ContribuiÃ§Ã£o](docs/CONTRIBUTING.md) para mais detalhes.

---

## **Contact**

ğŸ’Œ **Developer**:
[Rafael Mori](mailto:rafa-mori@gmail.com)
ğŸ’¼ [Follow me on GitHub](https://github.com/rafa-mori)
Estou aberto a colaboraÃ§Ãµes e novas ideias. Se achou o projeto interessante, entre em contato!



/// factory/gateway/authentication.go ///
package gateway

import (
	ii "github.com/kubex-ecosystem/gobe/internal/security/authentication"
	fsi "github.com/kubex-ecosystem/gobe/internal/security/certificates"
)

type AuthManager = ii.AuthManager

func NewAuthManager(certService fsi.CertService) (*AuthManager, error) {
	return ii.NewAuthManager(certService)
}

/// factory/gobemin.go ///
package factory

import (
	"fmt"
	"log"
	"time"

	l "github.com/kubex-ecosystem/logz"
	gb "github.com/kubex-ecosystem/gobe"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	"github.com/streadway/amqp"
)

type GoBE interface {
	ci.IGoBE
}

func NewGoBE(name, port, bind, logFile, configFile string, isConfidential bool, logger l.Logger, debug bool) (ci.IGoBE, error) {
	return gb.NewGoBE(name, port, bind, logFile, configFile, isConfidential, logger, debug)
}

var rabbitMQConn *amqp.Connection

func initRabbitMQ() error {
	var err error
	rabbitMQConn, err = amqp.Dial(getRabbitMQURL())
	if err != nil {
		log.Printf("Erro ao conectar ao RabbitMQ: %s", err)
		return err
	}
	log.Println("ConexÃ£o com RabbitMQ estabelecida com sucesso.")
	return nil
}

func getRabbitMQURL() string {
	return "amqp://guest:guest@localhost:5672/"
}

func closeRabbitMQ() {
	if rabbitMQConn != nil {
		rabbitMQConn.Close()
		log.Println("ConexÃ£o com RabbitMQ encerrada.")
	}
}

func ConsumeMessages(queueName string) {
	conn, err := amqp.Dial("amqp://guest:guest@localhost:5672/")
	if err != nil {
		log.Printf("Erro ao conectar ao RabbitMQ: %s", err)
		return
	}
	defer conn.Close()

	ch, err := conn.Channel()
	if err != nil {
		log.Printf("Erro ao abrir um canal: %s", err)
		return
	}
	defer ch.Close()

	msgs, err := ch.Consume(
		queueName,
		"",
		true,
		false,
		false,
		false,
		nil,
	)
	if err != nil {
		log.Printf("Erro ao registrar um consumidor: %s", err)
		return
	}

	forever := make(chan bool)

	go func() {
		for d := range msgs {
			log.Printf("Mensagem recebida: %s", d.Body)
			// Processar a mensagem aqui
		}
	}()

	log.Printf("Aguardando mensagens na fila %s. Para sair pressione CTRL+C", queueName)
	<-forever
}

func retry(attempts int, sleep time.Duration, fn func() error) error {
	for i := 0; i < attempts; i++ {
		if err := fn(); err != nil {
			log.Printf("Tentativa %d falhou: %s", i+1, err)
			time.Sleep(sleep)
			continue
		}
		return nil
	}
	return fmt.Errorf("todas as tentativas falharam")
}

func PublishMessageWithRetry(queueName string, message string) error {
	return retry(3, 2*time.Second, func() error {
		return PublishMessage(queueName, message)
	})
}

func PublishMessage(queueName, message string) error {
	conn, err := amqp.Dial(getRabbitMQURL())
	if err != nil {
		log.Printf("Erro ao conectar ao RabbitMQ: %s", err)
		return err
	}
	defer conn.Close()

	ch, err := conn.Channel()
	if err != nil {
		log.Printf("Erro ao abrir um canal: %s", err)
		return err
	}
	defer ch.Close()

	err = ch.Publish(
		"",
		queueName,
		false,
		false,
		amqp.Publishing{
			ContentType: "text/plain",
			Body:        []byte(message),
		},
	)
	if err != nil {
		log.Printf("Erro ao publicar mensagem: %s", err)
		return err
	}

	log.Printf("Mensagem publicada na fila %s: %s", queueName, message)
	return nil
}

/// factory/gobjects/prototype.go ///
package gobjects

type GobJect interface{}

/// factory/security/cert_service.go ///
package security

import (
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
)

type CertService interface{ sci.ICertService }

func NewCertService(keyPath, certPath string) CertService {
	return crt.NewCertService(keyPath, certPath)
}

/// factory/security/crypto_service.go ///
package security

import (
	crp "github.com/kubex-ecosystem/gobe/internal/security/crypto"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
)

type CryptoService interface {
	sci.ICryptoService
}

func NewCryptoService() CryptoService {
	return crp.NewCryptoService()
}

/// factory/security/keyring_service.go ///
package security

import (
	krs "github.com/kubex-ecosystem/gobe/internal/security/external"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
)

type KeyringService interface{ sci.IKeyringService }

func NewKeyringService(service, name string) KeyringService {
	return krs.NewKeyringService(service, name)
}

/// factory/security/secure_mapper.go ///
package security

import (
	"fmt"
	"os"
	"path/filepath"
	"strings"

	ut "github.com/kubex-ecosystem/gdbase/utils"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	crp "github.com/kubex-ecosystem/gobe/internal/security/crypto"
	krs "github.com/kubex-ecosystem/gobe/internal/security/external"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type ISecureMapper[T any] interface {
	Serialize(format string) ([]byte, error)
	Deserialize(encryptedData []byte, format string) (*T, error)
	WriteDataFile(format string) error
	ReadDataFile(format string) (*T, error)
	GetFilePath() string
	SetFilePath(filePath string)
	SetKey(name string, key []byte)
	LoadOrGenerateKey(name string) ([]byte, error)
}

type SecureMapper[T any] struct {
	*t.Reference
	object        ci.IProperty[T]
	cryptoService sci.ICryptoService
	keyring       sci.IKeyringService
	filePath      string
	key           []byte
}

func NewSecureMapper[T any](name string, mapperObject *T, key []byte, filePath string) *SecureMapper[T] {
	var err error
	cryptoService := crp.NewCryptoService()
	if key == nil {
		key, err = cryptoService.GenerateKey()
		if err != nil {
			gl.Log("fatal", fmt.Sprintf("Failed to generate key: %v", err))
		}
	}
	keyring := krs.NewKeyringService(name, strings.ToValidUTF8(string(key), ""))
	if err := keyring.StorePassword(string(key)); err != nil {
		gl.Log("fatal", fmt.Sprintf("Failed to store key: %v", err))
	}
	return &SecureMapper[T]{
		Reference:     t.NewReference(name).GetReference(),
		key:           key,
		keyring:       keyring,
		filePath:      filePath,
		cryptoService: cryptoService,
		object:        t.NewProperty[T](name, mapperObject, false, nil),
	}
}

func (s *SecureMapper[T]) Serialize(format string) (string, error) {
	value := s.object.GetValue()
	mapper := t.NewMapper[T](&value, s.filePath)
	data, err := mapper.Serialize(format)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to serialize data: %v", err))
		return "", err
	}
	//encryptedData, encodedEncryptedData, err := s.cryptoService.Encrypt(data, s.key)
	encryptedData, _, err := s.cryptoService.Encrypt(data, s.key)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to encrypt data: %v", err))
		return "", err
	}
	gl.Log("success", fmt.Sprintf("data encrypted successfully: %s", s.filePath))
	return encryptedData, nil
}

func (s *SecureMapper[T]) Deserialize(encryptedData []byte, format string) (*T, error) {
	var err error
	var decryptedData string
	if s.cryptoService.IsEncrypted(encryptedData) {
		//decryptedData, encodedDecryptedData, err = s.cryptoService.Decrypt(encryptedData, s.key)
		decryptedData, _, err = s.cryptoService.Decrypt(encryptedData, s.key)
		if err != nil {
			gl.Log("error", fmt.Sprintf("failed to decrypt data: %v", err))
			return nil, err
		}
	} else {
		gl.Log("debug", "data is not encrypted, skipping decryption")
		decryptedData = string(encryptedData)
	}
	if len(decryptedData) == 0 {
		gl.Log("error", "decrypted data is empty")
		return nil, fmt.Errorf("decrypted data is empty")
	}
	var data *T
	mapper := t.NewMapper[T](data, s.filePath)
	data, err = mapper.Deserialize([]byte(decryptedData), format)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to deserialize data: %v", err))
		return nil, err
	}
	if data == nil {
		gl.Log("error", "deserialized data is nil")
		return nil, fmt.Errorf("deserialized data is nil")
	}
	return data, nil
}

func (s *SecureMapper[T]) WriteDataFile(format string) error {
	if s.filePath == "" {
		gl.Log("error", "file path is not initialized")
		return fmt.Errorf("file path is not initialized")
	}
	value := s.object.GetValue()

	t.NewMapper[T](&value, s.filePath).SerializeToFile(format)

	if _, statErr := os.Stat(s.filePath); os.IsNotExist(statErr) {
		gl.Log("error", fmt.Sprintf("failed to write data to file: %v", statErr))
		return fmt.Errorf("failed to write data to file: %v", statErr)
	}

	gl.Log("success", fmt.Sprintf("data written to file: %s", s.filePath))

	return nil
}

func (s *SecureMapper[T]) ReadDataFile(format string) (*T, error) {
	if s.filePath == "" {
		gl.Log("error", "file path is not initialized")
		return nil, fmt.Errorf("file path is not initialized")
	}
	if _, statErr := os.Stat(s.filePath); os.IsNotExist(statErr) {
		gl.Log("error", fmt.Sprintf("file does not exist: %v", statErr))
		return nil, fmt.Errorf("file does not exist: %v", statErr)
	}
	value := s.object.GetValue()
	if data, err := t.NewMapper[T](&value, s.filePath).DeserializeFromFile(format); err != nil {
		gl.Log("error", fmt.Sprintf("failed to read data from file: %v", err))
		return nil, fmt.Errorf("failed to read data from file: %v", err)
	} else {
		return data, nil
	}
}

func (s *SecureMapper[T]) GetFilePath() string {
	if s.filePath == "" {
		gl.Log("error", "file path is not initialized")
		return ""
	}
	return s.filePath
}

func (s *SecureMapper[T]) SetFilePath(filePath string) {
	if filePath == "" {
		gl.Log("error", "file path is empty")
		return
	}
	s.filePath = filePath
	if _, err := os.Stat(filePath); os.IsNotExist(err) {
		if err := os.MkdirAll(filepath.Dir(filePath), os.ModePerm); err != nil {
			gl.Log("error", fmt.Sprintf("failed to create directory: %v", err))
		}
		if err := ut.EnsureFile(s.filePath, 0644, []string{}); err != nil {
			gl.Log("error", fmt.Sprintf("failed to create file: %v", err))
		}
	}
}

func (s *SecureMapper[T]) SetKey(name string, key []byte) {
	if key == nil {
		gl.Log("error", "key is nil")
		return
	}
	if name != s.Reference.Name {
		gl.Log("error", "keyring name does not match the mapper name")
		return
	}
	s.key = key
	err := s.keyring.StorePassword(string(key))
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to store key: %v", err))
	}
}

func (s *SecureMapper[T]) LoadOrGenerateKey(name string) ([]byte, error) {
	// Check if the keyring service is initialized
	if s.keyring == nil {
		gl.Log("error", "keyring service is not initialized")
		return nil, fmt.Errorf("keyring service is not initialized")
	}
	// Check if the name matches the mapper name
	if name != s.Reference.Name {
		gl.Log("error", "keyring name does not match the mapper name")
		return nil, fmt.Errorf("keyring name does not match the mapper name")
	}
	// Check if the keyring service has a stored key
	storedKey, err := s.keyring.RetrievePassword()
	if err != nil || storedKey == "" {
		newKey, genErr := s.cryptoService.GenerateKey()
		if genErr != nil {
			return nil, fmt.Errorf("erro ao gerar chave: %v", genErr)
		}
		s.key = newKey
		err = s.keyring.StorePassword(string(newKey))
		if err != nil {
			gl.Log("error", fmt.Sprintf("erro ao armazenar chave de criptografia: %v", err))
			return nil, fmt.Errorf("erro ao armazenar chave de criptografia: %v", err)
		}
	} else {
		s.key = []byte(storedKey)
	}
	return s.key, nil
}

func (s *SecureMapper[T]) GetValue() T { return s.object.GetValue() }

func (s *SecureMapper[T]) SetValue(value *T) { s.object.SetValue(value) }

/// factory/security/token_client.go ///
package security

import (
	s "github.com/kubex-ecosystem/gdbase/factory"
	sau "github.com/kubex-ecosystem/gobe/internal/security/authentication"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
)

func NewTokenClient(certService sci.ICertService, db s.DBService) sci.TokenClient {
	return sau.NewTokenClient(certService, db)
}

/// factory/security/token_repo.go ///
package security

import (
	sau "github.com/kubex-ecosystem/gobe/internal/security/authentication"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	"gorm.io/gorm"
)

func NewTokenRepo(db *gorm.DB) sci.TokenRepo { return sau.NewTokenRepo(db) }

/// factory/security/token_service.go ///
package security

import (
	sau "github.com/kubex-ecosystem/gobe/internal/security/authentication"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
)

func NewTokenService(c *sci.TSConfig) sci.TokenService {
	return sau.NewTokenService(c)
}

/// gobe.go ///
package gobe

import (
	"bytes"
	"errors"
	"fmt"
	"net"
	"os"
	"path/filepath"
	"reflect"
	"time"

	gdbf "github.com/kubex-ecosystem/gdbase/factory"
	ut "github.com/kubex-ecosystem/gdbase/utils"
	crp "github.com/kubex-ecosystem/gobe/factory/security"
	cm "github.com/kubex-ecosystem/gobe/internal/common"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	"github.com/kubex-ecosystem/gobe/internal/routes"
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	is "github.com/kubex-ecosystem/gobe/internal/services"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	l "github.com/kubex-ecosystem/logz"

	gl "github.com/kubex-ecosystem/gobe/logger"
)

type GoBECertData struct {
	Cert string `json:"cert" yaml:"cert" xml:"cert" csv:"cert" toml:"cert" gorm:"cert"`
	Key  string `json:"key" yaml:"key" xml:"key" csv:"key" toml:"key" gorm:"key"`
}

type GoBE struct {
	Logger      l.Logger
	environment ci.IEnvironment

	*t.Mutexes
	*t.Reference

	SignalManager ci.ISignalManager[chan string]

	requestWindow   time.Duration
	requestLimit    int
	requestsTracers map[string]ci.IRequestsTracer

	configDir  string
	configFile string
	LogFile    string

	chanCtl    chan string
	emailQueue chan ci.ContactForm

	Properties  map[string]any
	Metadata    map[string]any
	Routes      map[string]map[string]any
	Middlewares map[string]any
}

func NewGoBE(name, port, bind, logFile, configFile string, isConfidential bool, logger l.Logger, debug bool) (ci.IGoBE, error) {
	if logger == nil {
		logger = l.GetLogger("GoBE")
	}
	if debug {
		gl.SetDebug(debug)
	}

	chanCtl := make(chan string, 3)
	signamManager := t.NewSignalManager(chanCtl, logger)

	defaultDir := filepath.Dir(os.ExpandEnv(cm.DefaultGodoBaseConfigPath))
	if _, err := os.Stat(defaultDir); err != nil {
		if os.IsNotExist(err) {
			if err := ut.EnsureDir(defaultDir, 0644, []string{}); err != nil {
				gl.Log("fatal", fmt.Sprintf("Error creating directory: %v", err))
			}
		}
	}

	if configFile == "" {
		configFile = os.ExpandEnv(cm.DefaultGoBEConfigPath)
		if _, err := os.Stat(configFile); err != nil {
			if os.IsNotExist(err) {
				if err := ut.EnsureDir(filepath.Dir(configFile), 0644, []string{}); err != nil {
					gl.Log("fatal", fmt.Sprintf("Error creating directory: %v", err))
				}
				if err := ut.EnsureFile(configFile, 0644, []string{}); err != nil {
					gl.Log("fatal", fmt.Sprintf("Error creating config file: %v", err))
				}
			}
		}
	}
	if logFile == "" {
		logFile = filepath.Join(defaultDir, "request_tracer.json")
	}

	gbm := &GoBE{
		Logger:    logger,
		Mutexes:   t.NewMutexesType(),
		Reference: t.NewReference(name).GetReference(),

		SignalManager: signamManager,
		Properties:    make(map[string]any),
		Metadata:      make(map[string]any),
		Middlewares:   make(map[string]any),

		configFile: configFile,
		LogFile:    logFile,
		configDir:  filepath.Dir(configFile),

		chanCtl:    chanCtl,
		emailQueue: make(chan ci.ContactForm, 20),

		requestWindow:   t.RequestWindow,
		requestLimit:    t.RequestLimit,
		requestsTracers: make(map[string]ci.IRequestsTracer),
	}

	var err error
	gbm.environment, err = t.NewEnvironment(configFile, isConfidential, logger)
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Error creating environment: %v", err))
	}
	if gbm.environment == nil {
		gl.Log("fatal", fmt.Sprintf("Error creating environment: %v", fmt.Errorf("environment is nil")))
	}

	gbm.Properties["env"] = t.NewProperty("env", &gbm.environment, true, nil)
	gbm.Properties["port"] = t.NewProperty("port", &port, true, nil)
	gbm.Properties["bind"] = t.NewProperty("bind", &bind, true, nil)
	address := net.JoinHostPort(bind, port)
	gbm.Properties["address"] = t.NewProperty("address", &address, true, nil)

	pubCertKeyPath := gbm.environment.Getenv("CERT_FILE_PATH")
	if pubCertKeyPath == "" {
		pubCertKeyPath = os.ExpandEnv(cm.DefaultGoBECertPath)
	}
	pubKeyPath := gbm.environment.Getenv("KEY_FILE_PATH")
	if pubKeyPath == "" {
		pubKeyPath = os.ExpandEnv(cm.DefaultGoBEKeyPath)
	}

	var pwd string

	pwd = gbm.environment.Getenv("KEYRING_PASS")
	if pwd == "" {
		var pwdErr error
		// THIS SECRET WILL BE PASSED AS A PASSWORD TO ENCRYPT THE PRIVATE KEY
		// (jwt_secret is just a temporary fix) AND IT WILL BE STORED IN THE KEYRING
		// FOR FUTURE USE. TO DECRYPT THE PRIVATE KEY, THE SAME PASSWORD MUST BE USED!
		pwd, pwdErr = crt.GetOrGenPasswordKeyringPass("jwt_secret")
		if pwdErr != nil {
			gl.Log("fatal", fmt.Sprintf("Error reading keyring password: %v", pwdErr))
		}
	}

	crptService := crp.NewCryptoService()
	crtService := crt.NewCertService(pubKeyPath, pubCertKeyPath)
	if _, err := os.Stat(pubKeyPath); err != nil {
		decodedPwd, decodeErr := crptService.DecodeBase64(pwd)
		if decodeErr != nil {
			gl.Log("error", fmt.Sprintf("Error decoding keyring password: %v", decodeErr))
			return nil, decodeErr
		}
		certBytes, keyBytes, err := crtService.GenerateCertificate(pubCertKeyPath, pubKeyPath, decodedPwd)
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error generating certificate: %v", err))
			return nil, err
		}

		var keyEncodedBytes, certEncodedBytes []byte
		var keyString, certString string

		isEncoded := crptService.IsBase64String(string(bytes.TrimSpace(certBytes)))
		if !isEncoded {
			certEncodedBytes = bytes.TrimSpace([]byte(crptService.EncodeBase64(certBytes)))
		}
		isEncoded = crptService.IsBase64String(string(bytes.TrimSpace(keyBytes)))
		if !isEncoded {
			keyEncodedBytes = bytes.TrimSpace([]byte(crptService.EncodeBase64(keyBytes)))
		}
		certObj := GoBECertData{Cert: certString, Key: keyString}

		gl.Log("info", fmt.Sprintf("Certificate generated at %s", pubCertKeyPath))
		gl.Log("info", fmt.Sprintf("Private key generated at %s", pubKeyPath))
		gl.Log("info", fmt.Sprintf("Certificate: %s", certString))
		gl.Log("info", fmt.Sprintf("Private key: %s", keyString))
		certObj.Cert = string(certEncodedBytes)
		certObj.Key = string(keyEncodedBytes)
		gbm.Properties["cert"] = t.NewProperty("cert", &certObj.Cert, true, nil)

		mapper := t.NewMapper(&certObj, filepath.Join(gbm.configDir, "cert.json"))
		mapper.SerializeToFile("json")
		gl.Log("info", fmt.Sprintf("Certificate generated at %s", pubCertKeyPath))
		gbm.Properties["privKey"] = t.NewProperty("privKey", &keyEncodedBytes, true, nil)
	} else {
		certObj := &GoBECertData{}
		mapper := t.NewMapper[*GoBECertData](&certObj, filepath.Join(gbm.configDir, "cert.json"))
		if _, err := mapper.DeserializeFromFile("json"); err != nil {
			gl.Log("error", fmt.Sprintf("Error reading certificate: %v", err))
			return nil, err
		}
		key := certObj.Key
		gbm.Properties["privKey"] = t.NewProperty("privKey", &key, true, nil)
	}
	if _, err := os.Stat(pubKeyPath); err != nil {
		gl.Log("error", fmt.Sprintf("Error generating certificate: %v", err))
		return nil, err
	}

	gbm.Properties["certPath"] = t.NewProperty("certPath", &pubCertKeyPath, true, nil)
	gbm.Properties["keyPath"] = t.NewProperty("keyPath", &pubKeyPath, true, nil)
	gbm.Properties["certService"] = crtService

	// Start listening for signals since the beginning, so we can handle them
	// gracefully even if the server is not started yet.

	go func(chan string, ci.ISignalManager[chan string], *GoBE) {
		signamManager.ListenForSignals()
		gl.Log("info", "Listening for signals...")
		for {
			select {
			case <-chanCtl:
				gbm.StopGoBE()
				gl.Log("info", "Server stopped gracefully")
				return
			}
		}
	}(chanCtl, signamManager, gbm)

	return gbm, nil
}

func (g *GoBE) GetReference() ci.IReference {
	return g.Reference
}
func (g *GoBE) Environment() ci.IEnvironment {
	return g.environment
}

func (g *GoBE) InitializeResources() error {
	gl.Log("notice", "Initializing GoBE...")

	if g.Logger == nil {
		g.Logger = l.GetLogger("GoBE")
	}
	envT := g.Properties["env"].(*t.Property[ci.IEnvironment])
	env := envT.GetValue()
	var err error
	if env == nil {
		env, err = t.NewEnvironment(g.configFile, false, g.Logger)
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error creating environment: %v", err))
			return err
		}
		g.Properties["env"] = t.NewProperty("env", &env, true, nil)
	}

	dbService, initResourcesErr := is.InitializeAllServices(g.environment, g.Logger, g.environment.Getenv("DEBUG") == "true")
	if initResourcesErr != nil {
		return initResourcesErr
	}

	if dbService == nil {
		gl.Log("error", "Database service is nil")
		return errors.New("database service is nil")
	}
	g.Properties["dbService"] = t.NewProperty("dbService", &dbService, true, nil)

	g.SetDatabaseService(dbService)

	return nil
}
func (g *GoBE) InitializeServer() (ci.IRouter, error) {
	gl.Log("notice", "Initializing server...")

	portT := g.Properties["port"].(*t.Property[string])
	port := portT.GetValue()
	bindT := g.Properties["bind"].(*t.Property[string])
	bind := bindT.GetValue()
	if !reflect.ValueOf(port).IsValid() {
		gl.Log("warn", "No port specified, using default port 8666")
		port = ":8666"
		portT.SetValue(&port)
	}
	if !reflect.ValueOf(bind).IsValid() {
		gl.Log("warn", "Binding to all interfaces (default/IPv4)")
		bind = "0.0.0.0"
		bindT.SetValue(&bind)
	}
	addressT := g.Properties["address"].(*t.Property[string])
	address := addressT.GetValue()
	if !reflect.ValueOf(address).IsValid() {
		gl.Log("warn", "No address specified, using default address %s", net.JoinHostPort(bind, port))
		address = net.JoinHostPort(bind, port)
		addressT.SetValue(&address)
	}

	gobeminConfig := t.NewGoBEConfig(g.Name, g.configFile, "yaml", bind, port)
	if _, err := os.Stat(g.configFile); err != nil {
		if os.IsNotExist(err) {
			if err := ut.EnsureDir(filepath.Dir(g.configFile), 0644, []string{}); err != nil {
				gl.Log("error", fmt.Sprintf("Error creating directory: %v", err))
				return nil, err
			}
			if err := ut.EnsureFile(g.configFile, 0644, []string{}); err != nil {
				gl.Log("error", fmt.Sprintf("Error creating config file: %v", err))
				return nil, err
			}
			mapper := t.NewMapper(gobeminConfig, g.configFile)
			mapper.SerializeToFile("yaml")
		} else {
			gl.Log("error", fmt.Sprintf("Error reading config file: %v", err))
			return nil, err
		}
	}
	if gobeminConfig == nil {
		gl.Log("error", "Failed to create config file")
		return nil, fmt.Errorf("failed to create config file")
	}

	if gobeminConfig.GetJWTSecretKey() == "" {
		jwtSecret, jwtSecretErr := crt.GetOrGenPasswordKeyringPass("jwt_secret")
		if jwtSecretErr != nil {
			gl.Log("fatal", fmt.Sprintf("Error reading JWT secret key: %v", jwtSecretErr))
		}
		if jwtSecret == "" {
			gl.Log("error", "JWT secret key is empty")
			return nil, fmt.Errorf("jwt secret key is empty")
		}
		gobeminConfig.SetJWTSecretKey(jwtSecret)
	}

	rateLimitLimit := gobeminConfig.RateLimitLimit
	rateLimitBurst := gobeminConfig.RateLimitBurst
	requestWindow := gobeminConfig.RequestWindow
	if rateLimitLimit == 0 {
		rateLimitLimit = cm.DefaultRateLimitLimit
	}
	if rateLimitBurst == 0 {
		rateLimitBurst = cm.DefaultRateLimitBurst
	}
	if requestWindow == 0 {
		requestWindow = cm.DefaultRequestWindow
	}

	dbServiceT := g.Properties["dbService"].(*t.Property[gdbf.DBService])
	dbService := dbServiceT.GetValue()
	if dbService == nil {
		gl.Log("error", "Database service is nil")
		return nil, errors.New("database service is nil")
	}

	_, kubexErr := crt.GetOrGenPasswordKeyringPass(cm.KeyringService)
	if kubexErr != nil {
		gl.Log("error", fmt.Sprintf("Error reading kubex keyring password: %v", kubexErr))
		return nil, kubexErr
	}

	//gobeminConfig.Set

	router, err := routes.NewRouter(gobeminConfig, dbService, g.Logger, g.environment.Getenv("DEBUG") == "true")
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error initializing router: %v", err))
		return nil, err
	}

	g.Properties["router"] = t.NewProperty("router", &router, true, nil)
	if router == nil {
		gl.Log("error", "Router is nil")
		return nil, errors.New("router is nil")
	}

	return router, nil
}
func (g *GoBE) GetLogger() l.Logger {
	return g.Logger
}
func (g *GoBE) StartGoBE() {
	gl.Log("info", "Starting server...")

	if err := g.InitializeResources(); err != nil {
		gl.Log("fatal", fmt.Sprintf("Error initializing GoBE: %v", err))
		return
	}

	router, err := g.InitializeServer()
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Error initializing server: %v", err))
		return
	}
	if router == nil {
		gl.Log("fatal", "Router is nil")
		return
	}
	gl.Log("debug", "Loading request tracers...")
	g.Mutexes.MuAdd(1)
	go func(g *GoBE) {
		defer g.Mutexes.MuDone()
		var err error
		g.requestsTracers, err = t.LoadRequestsTracerFromFile(g)
		if err != nil {
			gl.Log("error", "Error loading request tracers: %v", err.Error())
		}
	}(g)
	gl.Log("notice", "Waiting for persisted request tracers to load...")
	g.Mutexes.MuWait()

	gl.Log("debug", fmt.Sprintf("Server started on port %s", g.Properties["port"].(*t.Property[string]).GetValue()))

	if err := router.Start(); err != nil {
		gl.Log("fatal", "Error starting server: %v", err.Error())
	}
}
func (g *GoBE) StopGoBE() {
	gl.Log("info", "Stopping server...")

	g.Mutexes.MuAdd(1)
	defer g.Mutexes.MuDone()

	routerT := g.Properties["router"].(*t.Property[ci.IRouter])
	router := routerT.GetValue()
	if router == nil {
		gl.Log("error", "Router is nil")
		return
	}

	router.ShutdownServerGracefully()
}
func (g *GoBE) GetChanCtl() chan string {
	//g.Mutexes.MuRLock()
	//defer g.Mutexes.MuRUnlock()
	return g.chanCtl
}

func (g *GoBE) GetLogFilePath() string {
	return g.LogFile
}
func (g *GoBE) GetConfigFilePath() string {
	return g.configFile
}
func (g *GoBE) SetDatabaseService(dbService gdbf.DBService) {
	//g.Mutexes.MuAdd(1)
	//defer g.Mutexes.MuDone()
	g.Properties["dbService"] = t.NewProperty[gdbf.DBService]("dbService", &dbService, true, nil)
}
func (g *GoBE) GetDatabaseService() gdbf.DBService {
	//g.Mutexes.MuRLock()
	//defer g.Mutexes.MuRUnlock()
	dbT := g.Properties["db"].(*t.Property[gdbf.DBService])
	return dbT.GetValue()
}

/// internal/common/defaults.go ///
package common

const (
	KeyringService            = "kubex"
	DefaultGoBEConfigPath     = "$HOME/.kubex/gobe/config/config.json"
	DefaultGoBEKeyPath        = "$HOME/.kubex/gobe/gobe-key.pem"
	DefaultGoBECertPath       = "$HOME/.kubex/gobe/gobe-cert.pem"
	DefaultGodoBaseConfigPath = "$HOME/.kubex/gdbase/config/config.json"
)

const (
	DefaultRateLimitLimit  = 100
	DefaultRateLimitBurst  = 100
	DefaultRequestWindow   = 1 * 60 * 1000 // 1 minute
	DefaultRateLimitJitter = 0.1
)

const (
	DefaultMaxRetries = 3
	DefaultRetryDelay = 1 * 1000 // 1 second
)

const (
	DefaultMaxIdleConns          = 100
	DefaultMaxIdleConnsPerHost   = 100
	DefaultIdleConnTimeout       = 90 * 1000 // 90 seconds
	DefaultTLSHandshakeTimeout   = 10 * 1000 // 10 seconds
	DefaultExpectContinueTimeout = 1 * 1000  // 1 second
	DefaultResponseHeaderTimeout = 5 * 1000  // 5 seconds
	DefaultTimeout               = 30 * 1000 // 30 seconds
	DefaultKeepAlive             = 30 * 1000 // 30 seconds
	DefaultMaxConnsPerHost       = 100
)

/// internal/controllers/contacts/contact.go ///
package contacts

import (
	"fmt"
	"net/http"

	"github.com/gin-gonic/gin"

	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type SMTPConfig struct {
	Host string
	Port string
	User string
	Pass string
}

type ContactController struct {
	queue      chan ci.ContactForm
	properties map[string]any
	ApiWrapper *t.ApiWrapper[ci.ContactForm]
}

func NewContactController(properties map[string]any) *ContactController {
	return &ContactController{
		queue:      make(chan ci.ContactForm, 100),
		properties: properties,
		ApiWrapper: t.NewApiWrapper[ci.ContactForm](),
	}
}

func (c *ContactController) HandleContact(ctx *gin.Context) {
	var form t.ContactForm
	if err := ctx.ShouldBindJSON(&form); err != nil {
		ctx.JSON(http.StatusBadRequest, gin.H{"error": "Error processing data"})
		gl.Log("debug", fmt.Sprintf("Error processing data: %v", err.Error()))
		return
	}

	envT := c.properties["env"].(*t.Property[ci.IEnvironment])
	env := envT.GetValue()
	secretToken := env.Getenv("SECRET_TOKEN")

	if form.Token != secretToken {
		ctx.JSON(http.StatusForbidden, gin.H{"error": "Invalid token"})
		gl.Log("warn", fmt.Sprintf("Invalid token: %s", form.Token))
		return
	}

	if err := sendEmailWithRetry(c, form, 2); err != nil {
		ctx.JSON(http.StatusInternalServerError, gin.H{"error": "Error sending email"})
		gl.Log("debug", fmt.Sprintf("Error sending email: %v", err.Error()))
		return
	}

	ctx.JSON(http.StatusOK, gin.H{"message": "Message sent successfully!"})
	gl.Log("success", "Message sent successfully!")
}

func (c *ContactController) GetContact(ctx *gin.Context) {
	var form t.ContactForm
	if err := ctx.ShouldBindJSON(&form); err != nil {
		ctx.JSON(http.StatusBadRequest, gin.H{"error": "Error processing data"})
		gl.Log("debug", fmt.Sprintf("Error processing data: %v", err.Error()))
		return
	}

	envT := c.properties["env"].(*t.Property[ci.IEnvironment])
	env := envT.GetValue()
	secretToken := env.Getenv("SECRET_TOKEN")

	if form.Token != secretToken {
		ctx.JSON(http.StatusForbidden, gin.H{"error": "Invalid token"})
		gl.Log("warn", fmt.Sprintf("Invalid token: %s", form.Token))
		return
	}

	if err := sendEmailWithRetry(c, form, 2); err != nil {
		ctx.JSON(http.StatusInternalServerError, gin.H{"error": "Error sending email"})
		gl.Log("debug", fmt.Sprintf("Error sending email: %v", err.Error()))
		return
	}

	ctx.JSON(http.StatusOK, gin.H{"message": "Message sent successfully!"})
	gl.Log("success", "Message sent successfully!")
}

func (c *ContactController) PostContact(ctx *gin.Context) {
	var form t.ContactForm
	if err := ctx.ShouldBindJSON(&form); err != nil {
		ctx.JSON(http.StatusBadRequest, gin.H{"error": "Error processing data"})
		gl.Log("debug", fmt.Sprintf("Error processing data: %v", err.Error()))
		return
	}

	envT := c.properties["env"].(*t.Property[ci.IEnvironment])
	env := envT.GetValue()
	secretToken := env.Getenv("SECRET_TOKEN")

	if form.Token != secretToken {
		ctx.JSON(http.StatusForbidden, gin.H{"error": "Invalid token"})
		gl.Log("warn", fmt.Sprintf("Invalid token: %s", form.Token))
		return
	}

	if err := sendEmailWithRetry(c, form, 2); err != nil {
		ctx.JSON(http.StatusInternalServerError, gin.H{"error": "Error sending email"})
		gl.Log("debug", fmt.Sprintf("Error sending email: %v", err.Error()))
		return
	}

	ctx.JSON(http.StatusOK, gin.H{"message": "Message sent successfully!"})
	gl.Log("success", "Message sent successfully!")
}

func (c *ContactController) GetContactForm(ctx *gin.Context) {
	var form t.ContactForm
	if err := ctx.ShouldBindJSON(&form); err != nil {
		ctx.JSON(http.StatusBadRequest, gin.H{"error": "Error processing data"})
		gl.Log("debug", fmt.Sprintf("Error processing data: %v", err.Error()))
		return
	}

	envT := c.properties["env"].(*t.Property[ci.IEnvironment])
	env := envT.GetValue()
	secretToken := env.Getenv("SECRET_TOKEN")

	if form.Token != secretToken {
		ctx.JSON(http.StatusForbidden, gin.H{"error": "Invalid token"})
		gl.Log("warn", fmt.Sprintf("Invalid token: %s", form.Token))
		return
	}

	if err := sendEmailWithRetry(c, form, 2); err != nil {
		ctx.JSON(http.StatusInternalServerError, gin.H{"error": "Error sending email"})
		gl.Log("debug", fmt.Sprintf("Error sending email: %v", err.Error()))
		return
	}

	ctx.JSON(http.StatusOK, gin.H{"message": "Message sent successfully!"})
	gl.Log("success", "Message sent successfully!")
}

func (c *ContactController) GetContactFormByID(ctx *gin.Context) {
	var form t.ContactForm
	if err := ctx.ShouldBindJSON(&form); err != nil {
		ctx.JSON(http.StatusBadRequest, gin.H{"error": "Error processing data"})
		gl.Log("debug", fmt.Sprintf("Error processing data: %v", err.Error()))
		return
	}

	envT := c.properties["env"].(*t.Property[ci.IEnvironment])
	env := envT.GetValue()
	secretToken := env.Getenv("SECRET_TOKEN")

	if form.Token != secretToken {
		ctx.JSON(http.StatusForbidden, gin.H{"error": "Invalid token"})
		gl.Log("warn", fmt.Sprintf("Invalid token: %s", form.Token))
		return
	}

	if err := sendEmailWithRetry(c, form, 2); err != nil {
		ctx.JSON(http.StatusInternalServerError, gin.H{"error": "Error sending email"})
		gl.Log("debug", fmt.Sprintf("Error sending email: %v", err.Error()))
		return
	}

	ctx.JSON(http.StatusOK, gin.H{"message": "Message sent successfully!"})
	gl.Log("success", "Message sent successfully!")
}

/// internal/controllers/contacts/mailing.go ///
package contacts

import (
	"context"
	"errors"
	"fmt"
	"math"
	"net/smtp"
	"strings"
	"time"

	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

func enqueueEmail(cc *ContactController, emailQueue chan t.ContactForm) {
	if cc.properties == nil {
		gl.Log("error", "Properties not set in contact controller")
		return
	}
	formT, ok := cc.properties["contactForm"]
	if !ok {
		gl.Log("error", "Invalid contact form type")
		return
	}
	form, ok := formT.(*t.Property[t.ContactForm])
	if !ok {
		gl.Log("error", "Invalid contact form type")
		return
	}
	go func(form t.ContactForm) {
		emailQueue <- form
	}(form.GetValue())
}
func processQueue(cc *ContactController, attempts int, emailQueue chan t.ContactForm) {
	for form := range emailQueue {
		go func(f t.ContactForm) {
			if err := sendEmailWithRetry(cc, f, attempts); err != nil {
				gl.Log("error", "Failed to send email after 3 attempts:", err.Error())
			}
		}(form)
	}
}

func getSMTPConfig(env ci.IEnvironment) SMTPConfig {
	host := env.Getenv("SMTP_HOST")
	if host == "" {
		host = "smtp.gmail.com" // valor padrÃ£o para Gmail
	}
	port := env.Getenv("SMTP_PORT")
	if port == "" {
		port = "587"
	}
	user := env.Getenv("EMAIL_USR")
	pass := env.Getenv("EMAIL_PWD")
	return SMTPConfig{
		Host: host,
		Port: port,
		User: user,
		Pass: pass,
	}
}

func sendEmail(cc *ContactController, form t.ContactForm) error {
	if cc.properties == nil {
		gl.Log("error", "Properties not set in contact controller")
		return errors.New("properties not set in contact controller")
	}

	env, ok := cc.properties["environment"]
	if !ok {
		gl.Log("error", "Environment not set in properties")
		return errors.New("environment not set in properties")
	}
	envT, ok := env.(*t.Property[ci.IEnvironment])
	if !ok {
		gl.Log("error", "Invalid environment type")
		return errors.New("invalid environment type")
	}
	envF := envT.GetValue()

	// ObtÃ©m as configuraÃ§Ãµes SMTP parametrizadas
	smtpConfig := getSMTPConfig(envF)
	if smtpConfig.User == "" || smtpConfig.Pass == "" {
		gl.Log("error", "Email user or password not set in environment variables")
		gl.Log("notice", fmt.Sprintf("User: %s", smtpConfig.User))
		gl.Log("notice", fmt.Sprintf("Password: %s", smtpConfig.Pass))
		return errors.New("email user or password not set in environment variables")
	}

	// Montagem dos detalhes do email:
	from := smtpConfig.User
	// Em um cenÃ¡rio real, o destinatÃ¡rio pode ser um campo dinÃ¢mico,
	// mas neste exemplo, vamos continuar enviando para o prÃ³prio remetente.
	to := []string{smtpConfig.User}

	// Corpo do email
	subject := "PROFILE PAGE - New contact form submission"
	body := fmt.Sprintf("Name: %s\nEmail: %s\nMessage: %s", form.Name, form.Email, form.Message)
	// CabeÃ§alho: observe o uso de \r\n para compatibilidade com SMTP
	msg := []byte("Subject: " + subject + "\r\n" +
		"From: " + from + "\r\n" +
		"To: " + strings.Join(to, ",") + "\r\n\r\n" + body)

	gl.Log("info", fmt.Sprintf("Sending email contact from %s to %s", form.Email, smtpConfig.User))

	// AutenticaÃ§Ã£o SMTP PadrÃ£o:
	auth := smtp.PlainAuth("", smtpConfig.User, smtpConfig.Pass, smtpConfig.Host)

	// ConfiguraÃ§Ã£o inicial utilizando SendMail (que utiliza STARTTLS automaticamente para a maioria dos servidores na porta 587)
	address := smtpConfig.Host + ":" + smtpConfig.Port
	err := smtp.SendMail(address, auth, from, to, msg)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Failed to send email via %s: %v", smtpConfig.Host, err.Error()))
		return err
	}

	gl.Log("success", "Email sent successfully")
	return nil
}

func sendEmailWithTimeout(cc *ContactController, form t.ContactForm) error {
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) // Timeout definido
	defer cancel()

	errChan := make(chan error, 1)
	go func() {
		errChan <- sendEmail(cc, form)
	}()

	select {
	case <-ctx.Done():
		if ctx.Err() != nil {
			gl.Log("error", fmt.Sprintf("Timeout error: %v", ctx.Err().Error()))
			return errors.New("error: " + ctx.Err().Error())
		}
	case err := <-errChan:
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error sending email: %v", err.Error()))
			return err // Falha ao enviar
		}
	}

	gl.Log("success", "Email sent successfully within timeout")
	return nil // Sucesso no envio
}

func sendEmailWithRetry(cc *ContactController, form t.ContactForm, attempts int) error {
	var err error
	for attemptsCounter := 0; attemptsCounter < attempts; attemptsCounter++ {
		err = sendEmailWithTimeout(cc, form)
		if err == nil {
			gl.Log("success", fmt.Sprintf("Email sent successfully after %d attempt(s)", attemptsCounter+1))
			return nil // Sucesso
		}
		// Implementa uma estratÃ©gia de retry exponencial:
		randomDelay := time.Duration(math.Pow(2, float64(attemptsCounter))) * time.Second
		time.Sleep(randomDelay)
	}
	return fmt.Errorf("failed to send email after %d attempts: %v", attempts, err)
}

/// internal/controllers/controller.go ///
package controllers

import (
	"fmt"
	"net/http"

	"github.com/gin-gonic/gin"
	whk "github.com/kubex-ecosystem/gdbase/factory/models"
	"github.com/kubex-ecosystem/gobe/internal/types"
	"github.com/streadway/amqp"
)

type WebhookController struct {
	Service      whk.WebhookService
	RabbitMQConn *amqp.Connection
	ApiWrapper   *types.ApiWrapper[any]
}

func NewWebhookController(service whk.WebhookService, rabbitMQConn *amqp.Connection) *WebhookController {
	return &WebhookController{
		Service:      service,
		RabbitMQConn: rabbitMQConn,
		ApiWrapper:   types.NewApiWrapper[any](),
	}
}

func (wc *WebhookController) RegisterWebhook(ctx *gin.Context) {
	var request whk.RegisterWebhookRequest
	if err := ctx.ShouldBindJSON(&request); err != nil {
		wc.ApiWrapper.JSONResponseWithError(ctx, fmt.Errorf("Invalid request: %v", err))
		return
	}

	// if _, err := wc.Service.RegisterWebhook(request); err != nil {
	// 	wc.ApiWrapper.JSONResponseWithError(ctx, http.StatusInternalServerError, err)
	// 	return
	// }

	wc.ApiWrapper.JSONResponseWithSuccess(ctx, "Webhook registered successfully", "", http.StatusCreated)
}

/// internal/controllers/cron/cron_controller.go ///
package cron

import (
	"context"
	"fmt"
	"net/http"

	"github.com/gin-gonic/gin"
	"github.com/google/uuid"
	cron "github.com/kubex-ecosystem/gdbase/factory/models"
	"github.com/kubex-ecosystem/gobe/internal/types"
	gl "github.com/kubex-ecosystem/gobe/logger"
	"gorm.io/gorm"
)

type CronController struct {
	ICronService cron.CronJobService
	ApiWrapper   *types.ApiWrapper[cron.CronJobModel]
}

func NewCronJobController(db *gorm.DB) *CronController {
	return &CronController{

		ICronService: cron.NewCronJobService(cron.NewCronJobRepo(context.Background(), db)),
		ApiWrapper:   types.NewApiWrapper[cron.CronJobModel](),
	}
}

func (cc *CronController) RegisterRoutes(router *gin.Engine) {
	api := router.Group("/cron")
	{
		api.GET("/", cc.GetAllCronJobs)
		api.GET("/:id", cc.GetCronJobByID)
		api.POST("/", cc.CreateCronJob)
		api.PUT("/:id", cc.UpdateCronJob)
		api.DELETE("/:id", cc.DeleteCronJob)
		api.POST("/:id/enable", cc.EnableCronJob)
		api.POST("/:id/disable", cc.DisableCronJob)
		api.POST("/:id/execute", cc.ExecuteCronJobManually)
		api.POST("/:id/reschedule", cc.RescheduleCronJob)
		api.GET("/queue", cc.GetJobQueue)
		api.POST("/reprocess-failed", cc.ReprocessFailedJobs)
		api.GET("/:id/logs", cc.GetExecutionLogs)
	}
}

func (cc *CronController) GetAllCronJobs(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	jobs, err := cc.ICronService.ListCronJobs(ctx)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to fetch cron jobs", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron jobs fetched successfully", "", jobs, nil, http.StatusOK)
}

func (cc *CronController) GetCronJobByID(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cronId, ok := ctx.Value("cronID").(uuid.UUID)
	if !ok {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron job ID", "", nil, nil, http.StatusBadRequest)
		return
	}
	job, err := cc.ICronService.GetCronJobByID(ctx, cronId)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job not found", "", nil, nil, http.StatusNotFound)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron job fetched successfully", "", job, nil, http.StatusOK)
}

func (cc *CronController) CreateCronJob(c *gin.Context) {
	var job *cron.CronJobModel
	if err := c.ShouldBindJSON(&job); err != nil {
		gl.Log("error", fmt.Sprintf("Failed to bind JSON: %s", err))
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid request payload", "", nil, nil, http.StatusBadRequest)
		return
	}
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	job.ID, err = uuid.NewRandom()
	if err != nil {
		gl.Log("error", fmt.Sprintf("Failed to generate UUID: %s", err))
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to generate UUID", "", nil, nil, http.StatusInternalServerError)
		return
	}
	job.UserID = ctx.Value("userID").(uuid.UUID)
	if job.UserID == uuid.Nil {
		gl.Log("error", "User ID is required")
		cc.ApiWrapper.JSONResponse(c, "error", "User ID is required", "", nil, nil, http.StatusBadRequest)
		return
	}
	job.LastRunStatus = "pending"
	createdJob, err := cc.ICronService.CreateCronJob(ctx, job)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to create cron job", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron job created successfully", "", createdJob, nil, http.StatusCreated)
}

func (cc *CronController) UpdateCronJob(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cronId, ok := ctx.Value("cronID").(uuid.UUID)
	if !ok {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron job ID", "", nil, nil, http.StatusBadRequest)
		return
	}
	var job cron.CronJobModel
	if err := c.ShouldBindJSON(&job); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid request payload", "", nil, nil, http.StatusBadRequest)
		return
	}
	if cronId == uuid.Nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job ID is required", "", nil, nil, http.StatusBadRequest)
		return
	}
	job.ID = cronId
	updatedJob, err := cc.ICronService.UpdateCronJob(ctx, &job)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to update cron job", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron job updated successfully", "", updatedJob, nil, http.StatusOK)
}

func (cc *CronController) DeleteCronJob(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cronId, ok := ctx.Value("cronID").(uuid.UUID)
	if !ok {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron job ID", "", nil, nil, http.StatusBadRequest)
		return
	}
	job, err := cc.ICronService.GetCronJobByID(ctx, cronId)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job not found", "", nil, nil, http.StatusNotFound)
		return
	}
	if job.UserID != uuid.Nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job is associated with a user and cannot be deleted", "", nil, nil, http.StatusBadRequest)
		return
	}
	// Check if the cron job is currently running
	if job.LastRunStatus == "running" {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job is currently running and cannot be deleted", "", nil, nil, http.StatusBadRequest)
		return
	}
	// Check if the cron job has any pending executions
	if job.LastRunStatus == "pending" {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job has pending executions and cannot be deleted", "", nil, nil, http.StatusBadRequest)
		return
	}

	if err := cc.ICronService.DeleteCronJob(ctx, cronId); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to delete cron job", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron job deleted successfully", "", nil, nil, http.StatusOK)
}

func (cc *CronController) EnableCronJob(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cronId, ok := ctx.Value("cronID").(uuid.UUID)
	if !ok {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron job ID", "", nil, nil, http.StatusBadRequest)
		return
	}
	if err := cc.ICronService.EnableCronJob(ctx, cronId); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to enable cron job", "", nil, nil, http.StatusInternalServerError)
		return
	}

	cc.ApiWrapper.JSONResponse(c, "success", "Cron job enabled successfully", "", nil, nil, http.StatusOK)
}

func (cc *CronController) DisableCronJob(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cronId, ok := ctx.Value("cronID").(uuid.UUID)
	if !ok {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron job ID", "", nil, nil, http.StatusBadRequest)
		return
	}
	if err := cc.ICronService.DisableCronJob(ctx, cronId); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to disable cron job", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron job disabled successfully", "", nil, nil, http.StatusOK)
}

func (cc *CronController) ExecuteCronJobManually(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cronId, ok := ctx.Value("cronID").(uuid.UUID)
	if !ok {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron job ID", "", nil, nil, http.StatusBadRequest)
		return
	}
	if err := cc.ICronService.ExecuteCronJobManually(ctx, cronId); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to execute cron job manually", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron job executed successfully", "", nil, nil, http.StatusOK)
}

func (cc *CronController) ExecuteCronJobManuallyByID(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cronId, ok := ctx.Value("cronID").(uuid.UUID)
	if !ok {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron job ID", "", nil, nil, http.StatusBadRequest)
		return
	}
	// Check if the cron job is currently running
	job, err := cc.ICronService.GetCronJobByID(ctx, cronId)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job not found", "", nil, nil, http.StatusNotFound)
		return
	}
	if job.LastRunStatus == "running" {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job is currently running and cannot be executed manually", "", nil, nil, http.StatusBadRequest)
		return
	}
	if err := cc.ICronService.ExecuteCronJobManually(ctx, cronId); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to execute cron job manually", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron job executed successfully", "", nil, nil, http.StatusOK)
}

func (cc *CronController) RescheduleCronJob(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cronId, ok := ctx.Value("cronID").(uuid.UUID)
	if !ok {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron job ID", "", nil, nil, http.StatusBadRequest)
		return
	}
	var payload struct {
		NewExpression string `json:"new_expression" binding:"required"`
	}
	if err := c.ShouldBindJSON(&payload); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid request payload", "", nil, nil, http.StatusBadRequest)
		return
	}
	if cronId == uuid.Nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job ID is required", "", nil, nil, http.StatusBadRequest)
		return
	}
	job, err := cc.ICronService.GetCronJobByID(ctx, cronId)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job not found", "", nil, nil, http.StatusNotFound)
		return
	}
	if job.UserID != uuid.Nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Cron job is associated with a user and cannot be rescheduled", "", nil, nil, http.StatusBadRequest)
		return
	}
	if err := cc.ICronService.RescheduleCronJob(ctx, cronId, payload.NewExpression); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to reschedule cron job", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron job rescheduled successfully", "", nil, nil, http.StatusOK)
}

func (cc *CronController) ListCronJobs(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	jobs, err := cc.ICronService.ListCronJobs(ctx)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to list cron jobs", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron jobs listed successfully", "", jobs, nil, http.StatusOK)
}

func (cc *CronController) ListActiveCronJobs(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	jobs, err := cc.ICronService.ListActiveCronJobs(ctx)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to list active cron jobs", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Active cron jobs listed successfully", "", jobs, nil, http.StatusOK)
}

func (cc *CronController) ValidateCronExpression(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	var payload struct {
		Expression string `json:"expression" binding:"required"`
	}
	if err := c.ShouldBindJSON(&payload); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid request payload", "", nil, nil, http.StatusBadRequest)
		return
	}
	if err := cc.ICronService.ValidateCronExpression(ctx, payload.Expression); err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron expression", "", nil, nil, http.StatusBadRequest)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Cron expression is valid", "", nil, nil, http.StatusOK)
}

// GetJobQueue retrieves the current state of the job queue.
func (cc *CronController) GetJobQueue(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	queue, err := cc.ICronService.GetJobQueue(ctx)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	c.JSON(http.StatusOK, queue)
}

// ReprocessFailedJobs reprocesses all failed jobs in the queue.
func (cc *CronController) ReprocessFailedJobs(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	err = cc.ICronService.ReprocessFailedJobs(ctx)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	c.JSON(http.StatusOK, gin.H{"message": "Failed jobs reprocessed successfully"})
}

// GetExecutionLogs retrieves execution logs for a specific cron job.
func (cc *CronController) GetExecutionLogs(c *gin.Context) {
	ctx, err := cc.ApiWrapper.GetContext(c)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to get context", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cronId, ok := ctx.Value("cronID").(uuid.UUID)
	if !ok {
		cc.ApiWrapper.JSONResponse(c, "error", "Invalid cron job ID", "", nil, nil, http.StatusBadRequest)
		return
	}
	logs, err := cc.ICronService.GetExecutionLogs(ctx, cronId)
	if err != nil {
		cc.ApiWrapper.JSONResponse(c, "error", "Failed to retrieve execution logs", "", nil, nil, http.StatusInternalServerError)
		return
	}
	cc.ApiWrapper.JSONResponse(c, "success", "Execution logs retrieved successfully", "", logs, nil, http.StatusOK)
}

/// internal/controllers/customers/customers_controller.go ///
package customers

import (
	"encoding/json"
	"net/http"

	fscm "github.com/kubex-ecosystem/gdbase/factory/models"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	"gorm.io/gorm"
)

type CustomerController struct {
	customerService fscm.ClientService
	ApiWrapper      *t.ApiWrapper[fscm.ClientModel]
}

func NewCustomerController(db *gorm.DB) *CustomerController {
	return &CustomerController{
		customerService: fscm.NewClientService(fscm.NewClientRepo(db)),
		ApiWrapper:      t.NewApiWrapper[fscm.ClientModel](),
	}
}

func (cc *CustomerController) GetAllCustomers(w http.ResponseWriter, r *http.Request) {
	customers, err := cc.customerService.ListClients()
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	json.NewEncoder(w).Encode(customers)
}

func (cc *CustomerController) GetCustomerByID(w http.ResponseWriter, r *http.Request) {
	id := r.URL.Query().Get("id")
	customer, err := cc.customerService.GetClientByID(id)
	if err != nil {
		http.Error(w, err.Error(), http.StatusNotFound)
		return
	}
	json.NewEncoder(w).Encode(customer)
}

func (cc *CustomerController) CreateCustomer(w http.ResponseWriter, r *http.Request) {
	var customerRequest fscm.ClientModel
	if err := json.NewDecoder(r.Body).Decode(&customerRequest); err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}
	createdCustomer, err := cc.customerService.CreateClient(&customerRequest)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	json.NewEncoder(w).Encode(createdCustomer)
}

func (cc *CustomerController) UpdateCustomer(w http.ResponseWriter, r *http.Request) {
	var customerRequest fscm.ClientModel
	if err := json.NewDecoder(r.Body).Decode(&customerRequest); err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}
	updatedCustomer, err := cc.customerService.UpdateClient(&customerRequest)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	json.NewEncoder(w).Encode(updatedCustomer)
}

func (cc *CustomerController) DeleteCustomer(w http.ResponseWriter, r *http.Request) {
	id := r.URL.Query().Get("id")
	if err := cc.customerService.DeleteClient(id); err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	w.WriteHeader(http.StatusNoContent)
}

/// internal/controllers/products/products_controller.go ///
package products

import (
	"encoding/json"
	"net/http"

	fscm "github.com/kubex-ecosystem/gdbase/factory/models"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	"gorm.io/gorm"
)

type ProductController struct {
	productService fscm.ProductService
	ApiWrapper     *t.ApiWrapper[fscm.ProductModel]
}

func NewProductController(db *gorm.DB) *ProductController {
	return &ProductController{
		productService: fscm.NewProductService(fscm.NewProductRepo(db)),
		ApiWrapper:     t.NewApiWrapper[fscm.ProductModel](),
	}
}

func (pc *ProductController) GetAllProducts(w http.ResponseWriter, r *http.Request) {
	products, err := pc.productService.ListProducts()
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	json.NewEncoder(w).Encode(products)
}

func (pc *ProductController) GetProductByID(w http.ResponseWriter, r *http.Request) {
	id := r.URL.Query().Get("id")
	product, err := pc.productService.GetProductByID(id)
	if err != nil {
		http.Error(w, err.Error(), http.StatusNotFound)
		return
	}
	json.NewEncoder(w).Encode(product)
}

func (pc *ProductController) CreateProduct(w http.ResponseWriter, r *http.Request) {
	var productRequest fscm.ProductModel
	if err := json.NewDecoder(r.Body).Decode(&productRequest); err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}
	createdProduct, err := pc.productService.CreateProduct(&productRequest)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	json.NewEncoder(w).Encode(createdProduct)
}

func (pc *ProductController) UpdateProduct(w http.ResponseWriter, r *http.Request) {
	var productRequest fscm.ProductModel
	if err := json.NewDecoder(r.Body).Decode(&productRequest); err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}
	updatedProduct, err := pc.productService.UpdateProduct(&productRequest)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	json.NewEncoder(w).Encode(updatedProduct)
}

func (pc *ProductController) DeleteProduct(w http.ResponseWriter, r *http.Request) {
	id := r.URL.Query().Get("id")
	if err := pc.productService.DeleteProduct(id); err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	w.WriteHeader(http.StatusNoContent)
}

/// internal/controllers/users/user_controller.go ///
package users

import (
	"fmt"
	"net/http"
	"os"
	"strings"

	user "github.com/kubex-ecosystem/gdbase/factory/models"
	cm "github.com/kubex-ecosystem/gobe/internal/common"
	sau "github.com/kubex-ecosystem/gobe/internal/security/authentication"
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"

	gl "github.com/kubex-ecosystem/gobe/logger"

	"github.com/gin-gonic/gin"
	"github.com/kubex-ecosystem/gobe/internal/types"
	"gorm.io/gorm"
)

type UserController struct {
	userService    user.UserService
	ApiWrapper     *types.ApiWrapper[user.UserModel]
	ApiAuthWrapper *types.ApiWrapper[user.AuthRequestDTO]
}

func NewUserController(db *gorm.DB) *UserController {
	return &UserController{
		userService:    user.NewUserService(user.NewUserRepo(db)),
		ApiWrapper:     types.NewApiWrapper[user.UserModel](),
		ApiAuthWrapper: types.NewApiWrapper[user.AuthRequestDTO](),
	}
}

func (uc *UserController) RegisterRoutes(router *gin.Engine) {
	api := router.Group("/users")
	{
		api.GET("/", uc.GetAllUsers)
		api.GET("/:id", uc.GetUserByID)
		api.POST("/", uc.CreateUser)
		api.POST("/:id", uc.UpdateUser)
		api.DELETE("/:id", uc.DeleteUser)
		api.POST("/sign-in", uc.AuthenticateUser)
		api.POST("/refresh-token", uc.RefreshToken)
		api.POST("/logout", uc.Logout)
		api.GET("/email/:email", uc.GetUserByEmail)
		api.GET("/username/:username", uc.GetUserByUsername)
	}
}

func (uc *UserController) GetAllUsers(c *gin.Context) {
	users, err := uc.userService.ListUsers()
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	c.JSON(http.StatusOK, users)
}

func (uc *UserController) GetUserByID(c *gin.Context) {
	id := c.Param("id")
	user, err := uc.userService.GetUserByID(id)
	if err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": err.Error()})
		return
	}
	c.JSON(http.StatusOK, user)
}

func (uc *UserController) CreateUser(c *gin.Context) {
	var userRequest user.UserModel
	if err := c.ShouldBindJSON(&userRequest); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}
	createdUser, err := uc.userService.CreateUser(userRequest)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	c.JSON(http.StatusCreated, createdUser)
}

func (uc *UserController) AuthenticateUser(c *gin.Context) {
	// Define a DTO for authentication requests
	type UserRequestDTO struct {
		// If no username is provided, use email (will be required in this case)
		//Email string `json:"email" binding:"required,email"`
		// If no email is provided, use username (will be required in this case)
		Username string `json:"username" binding:"required,min=3,max=32"`
		Password string `json:"password" binding:"required,min=8,max=32"`
		Remember bool   `json:"remember,omitempty"`
	}
	type AuthRequestDTO struct {
		User UserRequestDTO `json:"user"`
	}
	var authReqT *AuthRequestDTO = &AuthRequestDTO{}
	if err := c.ShouldBindJSON(&authReqT); err != nil && authReqT == nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}
	// Validate the request
	if authReqT == nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request"})
		return
	}
	// Check if the request contains a valid username and password
	if authReqT.User.Username == "" && authReqT.User.Password == "" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Username and password are required"})
		return
	}
	// Check if the request contains a valid email and password
	authReq := authReqT.User
	if authReq.Username == "" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Username is required"})
		return
	}
	if authReq.Password == "" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Password is required"})
		return
	}

	userRequest := user.NewUserModel(authReq.Username, authReq.Username, "" /* authReq.Email */)
	userRequest.SetPassword(authReq.Password)
	user, err := uc.userService.GetUserByUsername(userRequest.GetUsername())
	if err != nil || user == nil {
		c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid username or password"})
		return
	}

	pwdValidation := !user.CheckPasswordHash(userRequest.GetPassword())
	if !pwdValidation {
		c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid username or password"})
		return
	}

	tokenClient := sau.NewTokenClient(
		crt.NewCertService(
			os.ExpandEnv(cm.DefaultGoBEKeyPath),
			os.ExpandEnv(cm.DefaultGoBECertPath),
		),
		uc.userService.GetContextDbService(),
	)

	tokenService, idExpirationSecs, refreshExpirationSecs, err := tokenClient.LoadTokenCfg() // Ta vindo zerado aqui os tempos de expiraÃ§Ã£o
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	// Check if the user is already logged in
	prevTokenID := c.GetHeader("Authorization")
	if prevTokenID != "" {
		prevTokenID = strings.ReplaceAll(prevTokenID, "Bearer ", "")
		userM, userMErr := tokenService.ValidateIDToken(prevTokenID)
		if userMErr != nil {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid token"})
			return
		}

		if userM == nil {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Token not found"})
			return
		}

		user = userM
	}

	// Generate a new token pair
	token, err := tokenService.NewPairFromUser(c, user, prevTokenID)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	if idExpirationSecs <= 0 || refreshExpirationSecs <= 0 {
		gl.Log("error", fmt.Sprintf("Invalid token expiration times: %d, %d", idExpirationSecs, refreshExpirationSecs))
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Invalid token expiration time"})
		return
	}

	if token == nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to generate token"})
		return
	}

	// Insert the refresh token into user context
	c.Set("refresh_token", token.RefreshToken.ID)
	c.Set("user_id", user.GetID())

	// Set the refresh token in the response header
	c.Header("Authorization", "Bearer "+token.RefreshToken.ID)
	// Set the ID token in the response header
	c.Header("X-ID-Token", token.IDToken.SS)
	// Set the refresh token in the response header
	c.Header("X-Refresh-Token", token.RefreshToken.SS)
	// Set the user ID in the response header
	c.Header("X-User-ID", user.GetID())
	// Set the user role in the response header
	c.Header("X-User-Role", user.GetRoleID())

	uc.ApiAuthWrapper.JSONResponse(
		c,
		"success",
		"User authenticated successfully",
		"",
		gin.H{
			"user_id":            user.GetID(),
			"username":           user.GetUsername(),
			"email":              user.GetEmail(),
			"name":               user.GetName(),
			"role":               user.GetRoleID(),
			"expires_in":         idExpirationSecs,
			"refresh_expires_in": refreshExpirationSecs,
			"token_type":         "Bearer",
			"refresh_token":      token.RefreshToken.SS,
			"id_token":           token.IDToken.SS,
		},
		nil,
		http.StatusOK,
	)

	// Uncomment the following line if you want to return the token in the response body
	//c.JSON(http.StatusOK, gin.H{"token": token.IDToken, "refresh_token": token.RefreshToken})
}

func (uc *UserController) RefreshToken(c *gin.Context) {
	prevTokenID := strings.ReplaceAll(c.GetHeader("Authorization"), "Bearer ", "")
	if prevTokenID == "" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Missing refresh token"})
		return
	}
	refreshTk := c.GetHeader("X-Refresh-Token")
	if refreshTk == "" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Missing refresh token"})
		return
	}
	tokenString := c.GetHeader("X-ID-Token")
	if tokenString == "" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Missing ID token"})
		return
	}

	tokenClient := sau.NewTokenClient(crt.NewCertService("", ""), uc.userService.GetContextDbService())
	tokenService, idExpirationSecs, refreshExpirationSecs, err := tokenClient.LoadTokenCfg()
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	user, err := tokenService.ValidateIDToken(tokenString)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error validating ID token: %v", err))
		c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid ID token"})
		return
	}
	if user == nil {
		c.JSON(http.StatusUnauthorized, gin.H{"error": "ID token not found"})
		return
	}
	// Generate a new token pair
	token, err := tokenService.NewPairFromUser(c, user, refreshTk)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	if token == nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to generate token"})
		return
	}

	// Set the refresh token in the response header
	c.Header("Authorization", "Bearer "+token.RefreshToken.ID)
	// Set the ID token in the response header
	c.Header("X-ID-Token", token.IDToken.SS)
	// Set the refresh token in the response header
	c.Header("X-Refresh-Token", token.RefreshToken.SS)
	// Set the user ID in the response header
	c.Header("X-User-ID", user.GetID())
	// Set the user role in the response header
	c.Header("X-User-Role", user.GetRoleID())
	// Set the user ID in the response body
	uc.ApiAuthWrapper.JSONResponse(
		c,
		"success",
		"User authenticated successfully",
		"",
		gin.H{
			"user_id":            user.GetID(),
			"username":           user.GetUsername(),
			"email":              user.GetEmail(),
			"name":               user.GetName(),
			"role":               user.GetRoleID(),
			"expires_in":         idExpirationSecs,
			"refresh_expires_in": refreshExpirationSecs,
			"token_type":         "Bearer",
			"refresh_token":      token.RefreshToken.SS,
			"id_token":           token.IDToken.SS,
		},
		nil,
		http.StatusOK,
	)
	//c.JSON(http.StatusOK, gin.H{"token": token.IDToken, "refresh_token": token.RefreshToken})
}

func (uc *UserController) Logout(c *gin.Context) {
	refreshTk := strings.ReplaceAll(c.GetHeader("Authorization"), "Bearer ", "")
	if refreshTk == "" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Missing refresh token"})
		return
	}

	tkClient := sau.NewTokenClient(crt.NewCertService("", ""), uc.userService.GetContextDbService())
	tokenService, _, _, err := tkClient.LoadTokenCfg()
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	err = tokenService.SignOut(c, refreshTk)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	c.Status(http.StatusNoContent)
}

func (uc *UserController) GetUserByEmail(c *gin.Context) {
	email := c.Param("email")
	user, err := uc.userService.GetUserByEmail(email)
	if err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": err.Error()})
		return
	}
	c.JSON(http.StatusOK, user)
}

func (uc *UserController) GetUserByUsername(c *gin.Context) {
	username := c.Param("username")
	user, err := uc.userService.GetUserByUsername(username)
	if err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": err.Error()})
		return
	}
	c.JSON(http.StatusOK, user)
}

func (uc *UserController) UpdateUser(c *gin.Context) {
	id := c.Param("id")
	var userRequest user.UserModel
	if err := c.ShouldBindJSON(&userRequest); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}
	userRequest.SetID(id)
	updatedUser, err := uc.userService.UpdateUser(userRequest)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	c.JSON(http.StatusOK, updatedUser)
}

func (uc *UserController) DeleteUser(c *gin.Context) {
	id := c.Param("id")
	err := uc.userService.DeleteUser(id)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	c.Status(http.StatusNoContent)
}

/// internal/controllers/webhooks/webhook_controller.go ///
package webhooks

import (
	"net/http"

	"github.com/gin-gonic/gin"
	"github.com/google/uuid"
	whk "github.com/kubex-ecosystem/gdbase/factory/models"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	"github.com/streadway/amqp"
)

type WebhookController struct {
	Service      whk.WebhookService
	RabbitMQConn *amqp.Connection
	ApiWrapper   *t.ApiWrapper[any]
}

func NewWebhookController(service whk.WebhookService, rabbitMQConn *amqp.Connection) *WebhookController {
	return &WebhookController{
		Service:      service,
		RabbitMQConn: rabbitMQConn,
		ApiWrapper:   t.NewApiWrapper[any](),
	}
}

func (wc *WebhookController) RegisterWebhook(ctx *gin.Context) {
	var webhook whk.Webhook
	if err := ctx.ShouldBindJSON(&webhook); err != nil {
		ctx.JSON(http.StatusBadRequest, gin.H{"error": "Invalid data"})
		return
	}
	created, err := wc.Service.RegisterWebhook(webhook)
	if err != nil {
		ctx.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to register webhook"})
		return
	}

	// Publish event to RabbitMQ
	if wc.RabbitMQConn != nil {
		channel, err := wc.RabbitMQConn.Channel()
		if err == nil {
			defer channel.Close()
			channel.Publish(
				"webhook_events",  // exchange
				"webhook.created", // routing key
				false,             // mandatory
				false,             // immediate
				amqp.Publishing{
					ContentType: "application/json",
					Body:        []byte(created.GetID().String()),
				},
			)
		}
	}

	ctx.JSON(http.StatusCreated, created)
}

func (wc *WebhookController) ListWebhooks(ctx *gin.Context) {
	webhooks, err := wc.Service.ListWebhooks()
	if err != nil {
		ctx.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to list webhooks"})
		return
	}
	ctx.JSON(http.StatusOK, webhooks)
}

func (wc *WebhookController) DeleteWebhook(ctx *gin.Context) {
	idStr := ctx.Param("id")
	id, err := uuid.Parse(idStr)
	if err != nil || id == uuid.Nil {
		// Invalid ID
		ctx.JSON(http.StatusBadRequest, gin.H{"error": "Invalid ID"})
		return
	}
	if err = wc.Service.RemoveWebhook(id); err != nil {
		ctx.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to delete webhook"})
		return
	}
	ctx.JSON(http.StatusOK, gin.H{"message": "Webhook deleted"})
}

/// internal/interfaces/channels.go ///
package interfaces

import (
	"github.com/google/uuid"
	"reflect"
)

type IChannelBase[T any] interface {
	IMutexes

	GetName() string                 // The name of the channel.
	GetChannel() (any, reflect.Type) // The channel for the value. Main channel for this struct.
	GetType() reflect.Type           // The type of the channel.
	GetBuffers() int                 // The number of buffers for the channel.

	SetName(name string) string       // Set the name of the channel.
	SetChannel(reflect.Type, int) any // The channel for the value. Main channel for this struct.
	SetBuffers(buffers int) int       // The number of buffers for the channel.

	Close() error // Close the channel.
	Clear() error // Clear the channel.
}

type IChannelCtl[T any] interface {
	IMutexes

	// Structure management

	GetID() uuid.UUID
	GetName() string
	SetName(name string) string

	// Property query

	GetProperty() IProperty[T]

	// SubChannels management

	GetSubChannels() map[string]interface{}
	SetSubChannels(channels map[string]interface{}) map[string]interface{}

	GetSubChannelByName(name string) (any, reflect.Type, bool)
	SetSubChannelByName(name string, channel any) (any, error)

	GetSubChannelTypeByName(name string) (reflect.Type, bool)

	GetSubChannelBuffersByName(name string) (int, bool)
	SetSubChannelBuffersByName(name string, buffers int) (int, error)

	// Main channel management

	GetMainChannel() any
	SetMainChannel(channel chan T) chan T
	GetMainChannelType() reflect.Type

	GetHasMetrics() bool
	SetHasMetrics(hasMetrics bool) bool
	GetBufferSize() int
	SetBufferSize(size int) int

	Close() error

	// Chainable methods

	WithProperty(property IProperty[T]) IChannelCtl[T]
	WithChannel(channel chan T) IChannelCtl[T]
	WithBufferSize(size int) IChannelCtl[T]
	WithMetrics(metrics bool) IChannelCtl[T]
}

/// internal/interfaces/environment.go ///
package interfaces

import "context"

type IEnvironment interface {
	Mu() IMutexes
	CpuCount() int
	MemTotal() int
	Hostname() string
	Os() string
	Kernel() string
	LoadEnvFile(watchFunc func(ctx context.Context, chanCbArg chan any) <-chan any) error
	GetEnvFilePath() string
	Getenv(key string) string
	Setenv(key, value string) error
	GetEnvCache() map[string]string
	ParseEnvVar(s string) (string, string)
	LoadEnvFromShell() error
	MemAvailable() int
	GetShellName(s string) (string, int)
	BackupEnvFile() error
	EncryptEnvFile() error
	DecryptEnvFile() (string, error)
	EncryptEnv(value string) (string, error)
	DecryptEnv(encryptedValue string) (string, error)
	IsEncrypted(envFile string) bool
	IsEncryptedValue(value string) bool
	EnableEnvFileEncryption() error
	DisableEnvFileEncryption() error
}

/// internal/interfaces/gobemin.go ///
package interfaces

import (
	gdbf "github.com/kubex-ecosystem/gdbase/factory"
	l "github.com/kubex-ecosystem/logz"
)

type ContactForm struct {
	Token                string `json:"token"`
	Name                 string `json:"name"`
	Email                string `json:"email"`
	Message              string `json:"message"`
	IMapper[ContactForm] `json:"-" yaml:"-" xml:"-" toml:"-" gorm:"-"`
}

type IGoBE interface {
	GetReference() IReference
	Environment() IEnvironment
	InitializeResources() error
	InitializeServer() (IRouter, error)
	GetLogger() l.Logger
	StartGoBE()
	StopGoBE()
	GetChanCtl() chan string
	GetLogFilePath() string
	GetConfigFilePath() string
	SetDatabaseService(dbService gdbf.DBService)
	GetDatabaseService() gdbf.DBService
}

/// internal/interfaces/gobemin_config.go ///
package interfaces

import "time"

type ITLSConfig interface {
	GetCertFile() string
	GetKeyFile() string
	GetCAFile() string
	GetEnabled() bool
	GetSkipVerify() bool
	GetStrictHostKey() bool
	GetMinVersion() string
	SetCertFile(string)
	SetKeyFile(string)
	SetCAFile(string)
	SetEnabled(bool)
	SetSkipVerify(bool)
	SetStrictHostKey(bool)
	SetMinVersion(string)
	GetTLSConfig() ITLSConfig
	SetTLSConfig(ITLSConfig)
	GetReference() IReference
	GetMutexes() IMutexes
	SetReference(IReference)
	SetMutexes(IMutexes)
	Save() error
	Load() error
}

type IGoBEConfig interface {
	GetFilePath() string
	GetWorkerThreads() int
	GetRateLimitLimit() int
	GetRateLimitBurst() int
	GetRequestWindow() time.Duration
	GetProxyEnabled() bool
	GetProxyHost() string
	GetProxyPort() string
	GetBindAddress() string
	GetPort() string
	GetTimeouts() time.Duration
	GetMaxConnections() int
	GetLogLevel() string
	GetLogFormat() string
	GetLogDir() string
	GetRequestLogging() bool
	GetMetricsEnabled() bool
	GetJWTSecretKey() string
	GetRefreshTokenExpiration() time.Duration
	GetAccessTokenExpiration() time.Duration
	GetTLSConfig() ITLSConfig
	GetAllowedOrigins() []string
	GetAPIKeyAuth() bool
	GetAPIKey() string
	GetConfigFormat() string
	GetMapper() IMapper[IGoBEConfig]
	SetFilePath(string)
	SetWorkerThreads(int)
	SetRateLimitLimit(int)
	SetRateLimitBurst(int)
	SetRequestWindow(time.Duration)
	SetProxyEnabled(bool)
	SetProxyHost(string)
	SetProxyPort(string)
	SetBindAddress(string)
	SetPort(string)
	SetTimeouts(time.Duration)
	SetMaxConnections(int)
	SetLogLevel(string)
	SetLogFormat(string)
	SetLogFile(string)
	SetRequestLogging(bool)
	SetMetricsEnabled(bool)
	SetJWTSecretKey(string)
	SetRefreshTokenExpiration(time.Duration)
	SetAccessTokenExpiration(time.Duration)
	SetTLSConfig(ITLSConfig)
	SetAllowedOrigins([]string)
	SetAPIKeyAuth(bool)
	SetAPIKey(string)
	SetConfigFormat(string)
	SetMapper(IMapper[IGoBEConfig])
	Save() error
	Load() error
}

/// internal/interfaces/mapper.go ///
package interfaces

// IMapper is a generic interface for serializing and deserializing objects of type T.
type IMapper[T any] interface {
	// SerializeToFile serializes an object of type T to a file in the specified format.
	SerializeToFile(format string)
	// DeserializeFromFile deserializes an object of type T from a file in the specified format.
	DeserializeFromFile(format string) (*T, error)
	// Serialize converts an object of type T to a byte array in the specified format.
	Serialize(format string) ([]byte, error)
	// Deserialize converts a byte array in the specified format to an object of type T.
	Deserialize(data []byte, format string) (*T, error)
}

/// internal/interfaces/mutexes.go ///
package interfaces

import "time"

type IMutexes interface {
	MuLock()
	MuUnlock()
	MuRLock()
	MuRUnlock()
	MuTryLock() bool
	MuTryRLock() bool

	MuWaitCond()
	MuSignalCond()
	MuBroadcastCond()

	GetMuSharedCtx() any
	SetMuSharedCtx(ctx any)
	GetMuSharedCtxValidate() func(any) (bool, error)
	SetMuSharedCtxValidate(validate func(any) (bool, error))
	MuWaitCondWithTimeout(timeout time.Duration) bool

	MuAdd(delta int)
	MuDone()
	MuWait()
}

/// internal/interfaces/property.go ///
package interfaces

import (
	"github.com/google/uuid"
	l "github.com/kubex-ecosystem/logz"
)

// IProperty is an interface that defines the methods for a property.
type IProperty[T any] interface {
	GetName() string
	GetValue() T
	SetValue(v *T)
	GetReference() (uuid.UUID, string)
	Prop() IPropertyValBase[T]
	GetLogger() l.Logger
	Serialize(format, filePath string) ([]byte, error)
	Deserialize(data []byte, format, filePath string) error
	SaveToFile(filePath string, format string) error
	LoadFromFile(filename, format string) error
	// Telemetry() *ITelemetry
}

/// internal/interfaces/property_base.go ///
package interfaces

import (
	"github.com/google/uuid"
	l "github.com/kubex-ecosystem/logz"
	"reflect"
)

// IPropertyValBase is an interface that defines the methods for a property value.
type IPropertyValBase[T any] interface {
	GetLogger() l.Logger
	GetID() uuid.UUID
	GetName() string
	Value() *T
	StartCtl() <-chan string
	Type() reflect.Type
	Get(async bool) any
	Set(t *T) bool
	Clear() bool
	IsNil() bool
	Serialize(format, filePath string) ([]byte, error)
	Deserialize(data []byte, format, filePath string) error
}

/// internal/interfaces/reference.go ///
package interfaces

import "github.com/google/uuid"

type IReference interface {
	GetID() uuid.UUID
	GetName() string
	SetName(name string)
	String() string
}

/// internal/interfaces/request_tracer.go ///
package interfaces

import "time"

type IRequestsTracer interface {
	GetIP() string
	GetPort() string
	GetLastUserAgent() string
	GetUserAgents() []string
	GetEndpoint() string
	GetMethod() string
	GetTimeList() []time.Time
	GetCount() int
	GetError() error
	GetMutexes() IMutexes
	IsValid() bool
	GetOldFilePath() string

	GetFilePath() string
	SetFilePath(filePath string)
	GetMapper() IMapper[IRequestsTracer]
	SetMapper(mapper IMapper[IRequestsTracer])
	GetRequestWindow() time.Duration
	SetRequestWindow(window time.Duration)
	GetRequestLimit() int
	SetRequestLimit(limit int)
	Mu() IMutexes
}

/// internal/interfaces/signal_manager.go ///
package interfaces

type ISignalManager[T chan string] interface {
	ListenForSignals() (<-chan string, error)
	StopListening()
}

/// internal/interfaces/validation.go ///
package interfaces

type IValidation[T any] interface {
	CheckIfWillValidate() bool
	Validate(value *T, args ...any) IValidationResult
	AddValidator(validator IValidationFunc[T]) error
	RemoveValidator(priority int) error
	GetValidator(priority int) (any, error)
	GetValidators() map[int]IValidationFunc[T]
	GetResults() map[int]IValidationResult
	ClearResults()
	IsValid() bool
}

/// internal/interfaces/validation_func.go ///
package interfaces

type IValidationFunc[T any] interface {
	GetPriority() int
	SetPriority(priority int)
	GetFunction() func(value *T, args ...any) IValidationResult
	SetFunction(function func(value *T, args ...any) IValidationResult)
	GetResult() IValidationResult
	SetResult(result IValidationResult)
}

/// internal/interfaces/validation_result.go ///
package interfaces

import "github.com/google/uuid"

type IValidationResult interface {
	String() string
	GetID() uuid.UUID
	GetName() string
	GetIsValid() bool
	GetMessage() string
	GetError() error
	GetMetadata(key string) (any, bool)
	SetMetadata(key string, value any)
	GetAllMetadataKeys() []string
}

/// internal/middlewares/authentication.go ///
package middlewares

import (
	"context"
	"fmt"
	"net/http"
	"os"
	"strings"

	//"github.com/golang-jwt/jwt/v4"
	"github.com/golang-jwt/jwt/v4"

	"github.com/gin-gonic/gin"

	"github.com/hyperledger/fabric-contract-api-go/contractapi"

	l "github.com/kubex-ecosystem/logz"

	sau "github.com/kubex-ecosystem/gobe/factory/security"
	cm "github.com/kubex-ecosystem/gobe/internal/common"
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	srv "github.com/kubex-ecosystem/gobe/internal/services"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type AuthenticationMiddleware struct {
	contractapi.Contract
	CertService  sci.ICertService
	TokenService sci.TokenService
}

func NewTokenService(config *srv.IDBConfig, logger l.Logger) (sci.TokenService, sci.ICertService, error) {
	if logger == nil {
		logger = l.GetLogger("GoBE")
	}
	crtService := crt.NewCertService(os.ExpandEnv(cm.DefaultGoBEKeyPath), os.ExpandEnv(cm.DefaultGoBECertPath))

	dbService, dbServiceErr := srv.NewDBService(config, logger)
	if dbServiceErr != nil {
		gl.Log("error", fmt.Sprintf("âŒ Erro ao inicializar DBService: %v", dbServiceErr))
		return nil, nil, fmt.Errorf("âŒ Erro ao inicializar DBService: %v", dbServiceErr)
	}

	tkClient := sau.NewTokenClient(crtService, dbService)
	if tkClient == nil {
		gl.Log("error", "âŒ Erro ao inicializar TokenClient")
		return nil, nil, fmt.Errorf("âŒ Erro ao inicializar TokenClient")
	}
	tkService, _, _, tkServiceErr := tkClient.LoadTokenCfg()
	if tkServiceErr != nil {
		gl.Log("error", fmt.Sprintf("âŒ Erro ao inicializar TokenService: %v", tkServiceErr))
		return nil, nil, fmt.Errorf("âŒ Erro ao inicializar TokenService: %v", tkServiceErr)
	}

	return tkService, crtService, nil
}

func NewAuthenticationMiddleware(tokenService sci.TokenService, certService sci.ICertService, err error) gin.HandlerFunc {
	authMiddleware := &AuthenticationMiddleware{
		CertService:  certService,
		TokenService: tokenService,
	}

	if authMiddleware.CertService == nil || authMiddleware.TokenService == nil {
		return func(c *gin.Context) {
			if err != nil {
				c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to initialize authentication middleware"})
				c.Abort()
				return
			} else {
				gl.Log("error", "âŒ Erro ao inicializar AuthenticationMiddleware: CertService or TokenService is nil")
				c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to initialize authentication middleware"})
				c.Next()
			}
		}
	}

	return func(c *gin.Context) {
		if err != nil {
			c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to initialize authentication middleware"})
			c.Abort()
		} else {
			c.Next()
		}
	}
}

func (a *AuthenticationMiddleware) ValidateJWT(next gin.HandlerFunc) gin.HandlerFunc {
	return func(c *gin.Context) {
		authHeader := c.GetHeader("Authorization")
		if authHeader == "" {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Authorization header is missing"})
			c.Abort()
			return
		}

		tokenString := strings.TrimPrefix(authHeader, "Bearer ")
		claims, err := a.validateToken(tokenString)
		if err != nil {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid token"})
			c.Abort()
			return
		}

		// Criando um contexto com o usuÃ¡rio autenticado
		ctx := context.WithValue(c.Request.Context(), "user", claims)
		c.Request = c.Request.WithContext(ctx)
		c.Next()
	}
}

func (a *AuthenticationMiddleware) validateToken(tokenString string) (*jwt.RegisteredClaims, error) {
	publicK, publicKErr := a.CertService.GetPublicKey()
	if publicKErr != nil {
		gl.Log("error", fmt.Sprintf("Error getting public key: %v", publicKErr))
		return nil, publicKErr
	}

	token, err := jwt.ParseWithClaims(tokenString, &jwt.RegisteredClaims{}, func(token *jwt.Token) (interface{}, error) {
		return publicK, nil
	})

	if err != nil {
		return nil, err
	}

	if claims, ok := token.Claims.(*jwt.RegisteredClaims); ok && token.Valid {
		return claims, nil
	}

	return nil, fmt.Errorf("invalid token")
}

/// internal/middlewares/limiter.go ///
package middlewares

import (
	"github.com/gin-gonic/gin"
	"golang.org/x/time/rate"
)

func RateLimiter(limit rate.Limit, burst int) gin.HandlerFunc {
	// limiter := rate.NewLimiter(limit, burst)

	return func(c *gin.Context) {
		// if !limiter.Allow() {
		// 	c.JSON(http.StatusTooManyRequests, gin.H{"error": "Too many requests"})
		// 	c.Abort()
		// 	return
		// }
		c.Next()
	}
}

/// internal/middlewares/logging.go ///
package middlewares

import (
	gl "github.com/kubex-ecosystem/gobe/logger"
	l "github.com/kubex-ecosystem/logz"

	"github.com/gin-gonic/gin"

	"fmt"
)

func Logger(logger l.Logger) gin.HandlerFunc {
	var lgr struct {
		Logger l.Logger
	}
	if logger == nil {
		lgr = struct {
			Logger l.Logger
		}{
			Logger: l.GetLogger("GoBE"),
		}
	} else {
		lgr = struct {
			Logger l.Logger
		}{
			Logger: logger,
		}
	}
	return func(c *gin.Context) {
		gl.Log("info", "Request", c.Request.Proto, c.Request.Method, c.Request.URL.Path)
		gl.LogObjLogger(&lgr, "info", fmt.Sprintf("Request: %s %s %s", c.Request.Proto, c.Request.Method, c.Request.URL.Path))
		c.Next()
	}
}

/// internal/middlewares/rate_limit.go ///
package middlewares

import (
	"fmt"
	"net"
	"net/http"
	"time"

	srv "github.com/kubex-ecosystem/gobe/internal/services"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type RateLimitMiddleware struct {
	dbConfig      *srv.IDBConfig
	LogFile       string
	requestLimit  int
	requestWindow time.Duration
}

func NewRateLimitMiddleware(dbConfig srv.IDBConfig, logDir string, limit int, window time.Duration) (*RateLimitMiddleware, error) {
	return &RateLimitMiddleware{
		dbConfig:      &dbConfig,
		LogFile:       logDir,
		requestLimit:  limit,
		requestWindow: window,
	}, nil
}

func (rl *RateLimitMiddleware) RateLimit(w http.ResponseWriter, r *http.Request) bool {
	ip, port, splitHostPortErr := net.SplitHostPort(r.RemoteAddr)
	if splitHostPortErr != nil {
		http.Error(w, "Internal server error", http.StatusInternalServerError)
		gl.Log("warn", fmt.Sprintf("Error splitting host and port: %v", splitHostPortErr.Error()))
		return false
	}

	requestTracer := t.NewRequestsTracer(ip, port, r.URL.Path, r.Method, r.UserAgent(), rl.LogFile)
	requestTracer.GetMutexes().MuRLock()
	defer requestTracer.GetMutexes().MuRUnlock()

	if !requestTracer.IsValid() {
		http.Error(w, "Request limit exceeded", http.StatusTooManyRequests)
		gl.Log("warn", fmt.Sprintf("Invalid request tracer: %v", requestTracer.GetError()))
		return false
	}

	return true
}
func (rl *RateLimitMiddleware) GetRequestLimit() int {
	return rl.requestLimit
}
func (rl *RateLimitMiddleware) SetRequestLimit(limit int) {
	rl.requestLimit = limit
}
func (rl *RateLimitMiddleware) GetRequestWindow() time.Duration {
	return rl.requestWindow
}
func (rl *RateLimitMiddleware) SetRequestWindow(window time.Duration) {
	rl.requestWindow = window
}

/// internal/middlewares/request_tracer.go ///
package middlewares

import (
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
)

type RequestTracerMiddleware struct {
	requestsTracers map[string]ci.IRequestsTracer
}

func NewRequestTracerMiddleware() *RequestTracerMiddleware {
	return &RequestTracerMiddleware{
		requestsTracers: make(map[string]ci.IRequestsTracer),
	}
}

func (g *RequestTracerMiddleware) GetRequestTracers() map[string]ci.IRequestsTracer {
	//g.Mutexes.MuRLock()
	//defer g.Mutexes.MuRUnlock()
	return g.requestsTracers
}
func (g *RequestTracerMiddleware) SetRequestTracers(tracers map[string]ci.IRequestsTracer) {
	/*g.Mutexes.MuAdd(1)
	defer g.Mutexes.MuDone()*/
	g.requestsTracers = tracers
}

/// internal/middlewares/sanitize.go ///
package middlewares

import (
	"github.com/gin-gonic/gin"
)

func ValidateAndSanitize() gin.HandlerFunc {
	return func(c *gin.Context) {
		// var input map[string]interface{}
		// if err := c.ShouldBindJSON(&input); err != nil {
		// 	c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid input"})
		// 	c.Abort()
		// 	return
		// }

		// for key, value := range input {
		// 	if str, ok := value.(string); ok {
		// 		input[key] = au.SanitizeInput(str)
		// 	}
		// }

		// if err := au.ValidateStruct(input); err != nil {
		// 	c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		// 	c.Abort()
		// 	return
		// }

		// c.Set("sanitizedInput", input)
		c.Next()
	}
}

/// internal/scheduler/cron/chain.go ///
package cron

import (
	"fmt"
	"runtime"
	"sync"
	"time"

	l "github.com/kubex-ecosystem/logz"
)

// JobWrapper decorates the given Job with some behavior.
type JobWrapper func(Job) Job

// Chain is a sequence of JobWrappers that decorates submitted jobs with
// cross-cutting behaviors like logging or synchronization.
type Chain struct {
	wrappers []JobWrapper
}

// NewChain returns a Chain consisting of the given JobWrappers.
func NewChain(c ...JobWrapper) Chain {
	return Chain{c}
}

// Then decorates the given job with all JobWrappers in the chain.
//
// This:
//
//	NewChain(m1, m2, m3).Then(job)
//
// is equivalent to:
//
//	m1(m2(m3(job)))
func (c Chain) Then(j Job) Job {
	for i := range c.wrappers {
		j = c.wrappers[len(c.wrappers)-i-1](j)
	}
	return j
}

// Recover panics in wrapped jobs and log them with the provided logger.
func Recover(logger l.Logger) JobWrapper {
	return func(j Job) Job {
		return FuncJob(func() {
			defer func() {
				if r := recover(); r != nil {
					const size = 64 << 10
					buf := make([]byte, size)
					buf = buf[:runtime.Stack(buf, false)]
					err, ok := r.(error)
					if !ok {
						err = fmt.Errorf("%v", r)
					}
					logger.ErrorCtx(err.Error(), map[string]any{
						"stack": string(buf),
						"job":   j,
					})
				}
			}()
			j.Run()
		})
	}
}

// DelayIfStillRunning serializes jobs, delaying subsequent runs until the
// previous one is complete. Jobs running after a delay of more than a minute
// have the delay logged at Info.
func DelayIfStillRunning(logger l.Logger) JobWrapper {
	return func(j Job) Job {
		var mu sync.Mutex
		return FuncJob(func() {
			start := time.Now()
			mu.Lock()
			defer mu.Unlock()
			if dur := time.Since(start); dur > time.Minute {
				logger.InfoCtx("delay", map[string]any{
					"duration": dur,
				})
			}
			j.Run()
		})
	}
}

// SkipIfStillRunning skips an invocation of the Job if a previous invocation is
// still running. It logs skips to the given logger at Info level.
func SkipIfStillRunning(logger l.Logger) JobWrapper {
	return func(j Job) Job {
		var ch = make(chan struct{}, 1)
		ch <- struct{}{}
		return FuncJob(func() {
			select {
			case v := <-ch:
				defer func() { ch <- v }()
				j.Run()
			default:
				logger.InfoCtx("skip", nil)
			}
		})
	}
}

/// internal/scheduler/cron/constantdelay.go ///
package cron

import "time"

// ConstantDelaySchedule represents a simple recurring duty cycle, e.g. "Every 5 minutes".
// It does not support jobs more frequent than once a second.
type ConstantDelaySchedule struct {
	Delay time.Duration
}

// Every returns a crontab Schedule that activates once every duration.
// Delays of less than a second are not supported (will round up to 1 second).
// Any fields less than a Second are truncated.
func Every(duration time.Duration) ConstantDelaySchedule {
	if duration < time.Second {
		duration = time.Second
	}
	return ConstantDelaySchedule{
		Delay: duration - time.Duration(duration.Nanoseconds())%time.Second,
	}
}

// Next returns the next time this should be run.
// This rounds so that the next activation time will be on the second.
func (schedule ConstantDelaySchedule) Next(t time.Time) time.Time {
	return t.Add(schedule.Delay - time.Duration(t.Nanosecond())*time.Nanosecond)
}

/// internal/scheduler/cron/cron.go ///
package cron

import (
	"context"
	"sort"
	"sync"
	"time"

	l "github.com/kubex-ecosystem/logz"
)

// Cron keeps track of any number of entries, invoking the associated func as
// specified by the schedule. It may be started, stopped, and the entries may
// be inspected while running.
type Cron struct {
	entries   []*Entry
	chain     Chain
	stop      chan struct{}
	add       chan *Entry
	remove    chan EntryID
	snapshot  chan chan []Entry
	running   bool
	logger    l.Logger
	runningMu sync.Mutex
	location  *time.Location
	parser    ScheduleParser
	nextID    EntryID
	jobWaiter sync.WaitGroup
}

// ScheduleParser is an interface for schedule spec parsers that return a Schedule
type ScheduleParser interface {
	Parse(spec string) (Schedule, error)
}

// Job is an interface for submitted cron jobs.
type Job interface {
	Run()
}

// Schedule describes a job's duty cycle.
type Schedule interface {
	// Next returns the next activation time, later than the given time.
	// Next is invoked initially, and then each time the job is run.
	Next(time.Time) time.Time
}

// EntryID identifies an entry within a Cron instance
type EntryID int

// Entry consists of a schedule and the func to execute on that schedule.
type Entry struct {
	// ID is the cron-assigned ID of this entry, which may be used to look up a
	// snapshot or remove it.
	ID EntryID

	// Schedule on which this job should be run.
	Schedule Schedule

	// Next time the job will run, or the zero time if Cron has not been
	// started or this entry's schedule is unsatisfiable
	Next time.Time

	// Prev is the last time this job was run, or the zero time if never.
	Prev time.Time

	// WrappedJob is the thing to run when the Schedule is activated.
	WrappedJob Job

	// Job is the thing that was submitted to cron.
	// It is kept around so that user code that needs to get at the job later,
	// e.g. via Entries() can do so.
	Job Job
}

// Valid returns true if this is not the zero entry.
func (e Entry) Valid() bool { return e.ID != 0 }

// byTime is a wrapper for sorting the entry array by time
// (with zero time at the end).
type byTime []*Entry

func (s byTime) Len() int      { return len(s) }
func (s byTime) Swap(i, j int) { s[i], s[j] = s[j], s[i] }
func (s byTime) Less(i, j int) bool {
	// Two zero times should return false.
	// Otherwise, zero is "greater" than any other time.
	// (To sort it at the end of the list.)
	if s[i].Next.IsZero() {
		return false
	}
	if s[j].Next.IsZero() {
		return true
	}
	return s[i].Next.Before(s[j].Next)
}

// New returns a new Cron job runner, modified by the given options.
//
// Available Settings
//
//	Time Zone
//	  Description: The time zone in which schedules are interpreted
//	  Default:     time.Local
//
//	Parser
//	  Description: Parser converts cron spec strings into cron.Schedules.
//	  Default:     Accepts this spec: https://en.wikipedia.org/wiki/Cron
//
//	Chain
//	  Description: Wrap submitted jobs to customize behavior.
//	  Default:     A chain that recovers panics and logs them to stderr.
//
// See "cron.With*" to modify the default behavior.
func New(opts ...Option) *Cron {
	c := &Cron{
		entries:   nil,
		chain:     NewChain(),
		add:       make(chan *Entry),
		stop:      make(chan struct{}),
		snapshot:  make(chan chan []Entry),
		remove:    make(chan EntryID),
		running:   false,
		runningMu: sync.Mutex{},
		logger:    l.GetLogger("cron"),
		location:  time.Local,
		parser:    standardParser,
	}
	for _, opt := range opts {
		opt(c)
	}
	return c
}

// FuncJob is a wrapper that turns a func() into a cron.Job
type FuncJob func()

func (f FuncJob) Run() { f() }

// AddFunc adds a func to the Cron to be run on the given schedule.
// The spec is parsed using the time zone of this Cron instance as the default.
// An opaque ID is returned that can be used to later remove it.
func (c *Cron) AddFunc(spec string, cmd func()) (EntryID, error) {
	return c.AddJob(spec, FuncJob(cmd))
}

// AddJob adds a Job to the Cron to be run on the given schedule.
// The spec is parsed using the time zone of this Cron instance as the default.
// An opaque ID is returned that can be used to later remove it.
func (c *Cron) AddJob(spec string, cmd Job) (EntryID, error) {
	schedule, err := c.parser.Parse(spec)
	if err != nil {
		return 0, err
	}
	return c.Schedule(schedule, cmd), nil
}

// Schedule adds a Job to the Cron to be run on the given schedule.
// The job is wrapped with the configured Chain.
func (c *Cron) Schedule(schedule Schedule, cmd Job) EntryID {
	c.runningMu.Lock()
	defer c.runningMu.Unlock()
	c.nextID++
	entry := &Entry{
		ID:         c.nextID,
		Schedule:   schedule,
		WrappedJob: c.chain.Then(cmd),
		Job:        cmd,
	}
	if !c.running {
		c.entries = append(c.entries, entry)
	} else {
		c.add <- entry
	}
	return entry.ID
}

// Entries returns a snapshot of the cron entries.
func (c *Cron) Entries() []Entry {
	c.runningMu.Lock()
	defer c.runningMu.Unlock()
	if c.running {
		replyChan := make(chan []Entry, 1)
		c.snapshot <- replyChan
		return <-replyChan
	}
	return c.entrySnapshot()
}

// Location gets the time zone location
func (c *Cron) Location() *time.Location {
	return c.location
}

// Entry returns a snapshot of the given entry, or nil if it couldn't be found.
func (c *Cron) Entry(id EntryID) Entry {
	for _, entry := range c.Entries() {
		if id == entry.ID {
			return entry
		}
	}
	return Entry{}
}

// Remove an entry from being run in the future.
func (c *Cron) Remove(id EntryID) {
	c.runningMu.Lock()
	defer c.runningMu.Unlock()
	if c.running {
		c.remove <- id
	} else {
		c.removeEntry(id)
	}
}

// Start the cron scheduler in its own goroutine, or no-op if already started.
func (c *Cron) Start() {
	c.runningMu.Lock()
	defer c.runningMu.Unlock()
	if c.running {
		return
	}
	c.running = true
	go c.run()
}

// Run the cron scheduler, or no-op if already running.
func (c *Cron) Run() {
	c.runningMu.Lock()
	if c.running {
		c.runningMu.Unlock()
		return
	}
	c.running = true
	c.runningMu.Unlock()
	c.run()
}

// run the scheduler.. this is private just due to the need to synchronize
// access to the 'running' state variable.
func (c *Cron) run() {
	c.logger.InfoCtx("start", nil)

	// Figure out the next activation times for each entry.
	now := c.now()
	for _, entry := range c.entries {
		entry.Next = entry.Schedule.Next(now)
		c.logger.InfoCtx("schedule", map[string]any{
			"now":   now,
			"entry": entry.ID,
			"next":  entry.Next,
		})
	}

	for {
		// Determine the next entry to run.
		sort.Sort(byTime(c.entries))

		var timer *time.Timer
		if len(c.entries) == 0 || c.entries[0].Next.IsZero() {
			// If there are no entries yet, just sleep - it still handles new entries
			// and stop requests.
			timer = time.NewTimer(100000 * time.Hour)
		} else {
			timer = time.NewTimer(c.entries[0].Next.Sub(now))
		}

		for {
			select {
			case now = <-timer.C:
				now = now.In(c.location)
				c.logger.InfoCtx("wake", map[string]any{
					"now": now,
				})

				// Run every entry whose next time was less than now
				for _, e := range c.entries {
					if e.Next.After(now) || e.Next.IsZero() {
						break
					}
					c.startJob(e.WrappedJob)
					e.Prev = e.Next
					e.Next = e.Schedule.Next(now)
					c.logger.InfoCtx("run", map[string]any{
						"now":   now,
						"entry": e.ID,
						"next":  e.Next,
					})
				}

			case newEntry := <-c.add:
				timer.Stop()
				now = c.now()
				newEntry.Next = newEntry.Schedule.Next(now)
				c.entries = append(c.entries, newEntry)
				c.logger.InfoCtx("added", map[string]any{
					"now":   now,
					"entry": newEntry.ID,
					"next":  newEntry.Next,
				})

			case replyChan := <-c.snapshot:
				replyChan <- c.entrySnapshot()
				continue

			case <-c.stop:
				timer.Stop()
				c.logger.InfoCtx("stop", nil)
				return

			case id := <-c.remove:
				timer.Stop()
				now = c.now()
				c.removeEntry(id)
				c.logger.InfoCtx("removed", map[string]any{
					"entry": id,
				})
			}

			break
		}
	}
}

// startJob runs the given job in a new goroutine.
func (c *Cron) startJob(j Job) {
	c.jobWaiter.Add(1)
	go func() {
		defer c.jobWaiter.Done()
		j.Run()
	}()
}

// now returns current time in c location
func (c *Cron) now() time.Time {
	return time.Now().In(c.location)
}

// Stop stops the cron scheduler if it is running; otherwise it does nothing.
// A context is returned so the caller can wait for running jobs to complete.
func (c *Cron) Stop() context.Context {
	c.runningMu.Lock()
	defer c.runningMu.Unlock()
	if c.running {
		c.stop <- struct{}{}
		c.running = false
	}
	ctx, cancel := context.WithCancel(context.Background())
	go func() {
		c.jobWaiter.Wait()
		cancel()
	}()
	return ctx
}

// entrySnapshot returns a copy of the current cron entry list.
func (c *Cron) entrySnapshot() []Entry {
	var entries = make([]Entry, len(c.entries))
	for i, e := range c.entries {
		entries[i] = *e
	}
	return entries
}

func (c *Cron) removeEntry(id EntryID) {
	var entries []*Entry
	for _, e := range c.entries {
		if e.ID != id {
			entries = append(entries, e)
		}
	}
	c.entries = entries
}

/// internal/scheduler/cron/option.go ///
package cron

import (
	"time"

	l "github.com/kubex-ecosystem/logz"
)

// Option represents a modification to the default behavior of a Cron.
type Option func(*Cron)

// WithLocation overrides the timezone of the cron instance.
func WithLocation(loc *time.Location) Option {
	return func(c *Cron) {
		c.location = loc
	}
}

// WithSeconds overrides the parser used for interpreting job schedules to
// include a seconds field as the first one.
func WithSeconds() Option {
	return WithParser(NewParser(
		Second | Minute | Hour | Dom | Month | Dow | Descriptor,
	))
}

// WithParser overrides the parser used for interpreting job schedules.
func WithParser(p ScheduleParser) Option {
	return func(c *Cron) {
		c.parser = p
	}
}

// WithChain specifies Job wrappers to apply to all jobs added to this cron.
// Refer to the Chain* functions in this package for provided wrappers.
func WithChain(wrappers ...JobWrapper) Option {
	return func(c *Cron) {
		c.chain = NewChain(wrappers...)
	}
}

// WithLogger uses the provided logger.
func WithLogger(logger l.Logger) Option {
	return func(c *Cron) {
		c.logger = logger
	}
}

/// internal/scheduler/cron/parser.go ///
package cron

import (
	"fmt"
	"math"
	"strconv"
	"strings"
	"time"
)

// Configuration options for creating a parser. Most options specify which
// fields should be included, while others enable features. If a field is not
// included the parser will assume a default value. These options do not change
// the order fields are parse in.
type ParseOption int

const (
	Second         ParseOption = 1 << iota // Seconds field, default 0
	SecondOptional                         // Optional seconds field, default 0
	Minute                                 // Minutes field, default 0
	Hour                                   // Hours field, default 0
	Dom                                    // Day of month field, default *
	Month                                  // Month field, default *
	Dow                                    // Day of week field, default *
	DowOptional                            // Optional day of week field, default *
	Descriptor                             // Allow descriptors such as @monthly, @weekly, etc.
)

var places = []ParseOption{
	Second,
	Minute,
	Hour,
	Dom,
	Month,
	Dow,
}

var defaults = []string{
	"0",
	"0",
	"0",
	"*",
	"*",
	"*",
}

// A custom Parser that can be configured.
type Parser struct {
	options ParseOption
}

// NewParser creates a Parser with custom options.
//
// It panics if more than one Optional is given, since it would be impossible to
// correctly infer which optional is provided or missing in general.
//
// Examples
//
//  // Standard parser without descriptors
//  specParser := NewParser(Minute | Hour | Dom | Month | Dow)
//  sched, err := specParser.Parse("0 0 15 */3 *")
//
//  // Same as above, just excludes time fields
//  specParser := NewParser(Dom | Month | Dow)
//  sched, err := specParser.Parse("15 */3 *")
//
//  // Same as above, just makes Dow optional
//  specParser := NewParser(Dom | Month | DowOptional)
//  sched, err := specParser.Parse("15 */3")
//
func NewParser(options ParseOption) Parser {
	optionals := 0
	if options&DowOptional > 0 {
		optionals++
	}
	if options&SecondOptional > 0 {
		optionals++
	}
	if optionals > 1 {
		panic("multiple optionals may not be configured")
	}
	return Parser{options}
}

// Parse returns a new crontab schedule representing the given spec.
// It returns a descriptive error if the spec is not valid.
// It accepts crontab specs and features configured by NewParser.
func (p Parser) Parse(spec string) (Schedule, error) {
	if len(spec) == 0 {
		return nil, fmt.Errorf("empty spec string")
	}

	// Extract timezone if present
	var loc = time.Local
	if strings.HasPrefix(spec, "TZ=") || strings.HasPrefix(spec, "CRON_TZ=") {
		var err error
		i := strings.Index(spec, " ")
		eq := strings.Index(spec, "=")
		if loc, err = time.LoadLocation(spec[eq+1 : i]); err != nil {
			return nil, fmt.Errorf("provided bad location %s: %v", spec[eq+1:i], err)
		}
		spec = strings.TrimSpace(spec[i:])
	}

	// Handle named schedules (descriptors), if configured
	if strings.HasPrefix(spec, "@") {
		if p.options&Descriptor == 0 {
			return nil, fmt.Errorf("parser does not accept descriptors: %v", spec)
		}
		return parseDescriptor(spec, loc)
	}

	// Split on whitespace.
	fields := strings.Fields(spec)

	// Validate & fill in any omitted or optional fields
	var err error
	fields, err = normalizeFields(fields, p.options)
	if err != nil {
		return nil, err
	}

	field := func(field string, r bounds) uint64 {
		if err != nil {
			return 0
		}
		var bits uint64
		bits, err = getField(field, r)
		return bits
	}

	var (
		second     = field(fields[0], seconds)
		minute     = field(fields[1], minutes)
		hour       = field(fields[2], hours)
		dayofmonth = field(fields[3], dom)
		month      = field(fields[4], months)
		dayofweek  = field(fields[5], dow)
	)
	if err != nil {
		return nil, err
	}

	return &SpecSchedule{
		Second:   second,
		Minute:   minute,
		Hour:     hour,
		Dom:      dayofmonth,
		Month:    month,
		Dow:      dayofweek,
		Location: loc,
	}, nil
}

// normalizeFields takes a subset set of the time fields and returns the full set
// with defaults (zeroes) populated for unset fields.
//
// As part of performing this function, it also validates that the provided
// fields are compatible with the configured options.
func normalizeFields(fields []string, options ParseOption) ([]string, error) {
	// Validate optionals & add their field to options
	optionals := 0
	if options&SecondOptional > 0 {
		options |= Second
		optionals++
	}
	if options&DowOptional > 0 {
		options |= Dow
		optionals++
	}
	if optionals > 1 {
		return nil, fmt.Errorf("multiple optionals may not be configured")
	}

	// Figure out how many fields we need
	max := 0
	for _, place := range places {
		if options&place > 0 {
			max++
		}
	}
	min := max - optionals

	// Validate number of fields
	if count := len(fields); count < min || count > max {
		if min == max {
			return nil, fmt.Errorf("expected exactly %d fields, found %d: %s", min, count, fields)
		}
		return nil, fmt.Errorf("expected %d to %d fields, found %d: %s", min, max, count, fields)
	}

	// Populate the optional field if not provided
	if min < max && len(fields) == min {
		switch {
		case options&DowOptional > 0:
			fields = append(fields, defaults[5]) // TODO: improve access to default
		case options&SecondOptional > 0:
			fields = append([]string{defaults[0]}, fields...)
		default:
			return nil, fmt.Errorf("unknown optional field")
		}
	}

	// Populate all fields not part of options with their defaults
	n := 0
	expandedFields := make([]string, len(places))
	copy(expandedFields, defaults)
	for i, place := range places {
		if options&place > 0 {
			expandedFields[i] = fields[n]
			n++
		}
	}
	return expandedFields, nil
}

var standardParser = NewParser(
	Minute | Hour | Dom | Month | Dow | Descriptor,
)

// ParseStandard returns a new crontab schedule representing the given
// standardSpec (https://en.wikipedia.org/wiki/Cron). It requires 5 entries
// representing: minute, hour, day of month, month and day of week, in that
// order. It returns a descriptive error if the spec is not valid.
//
// It accepts
//   - Standard crontab specs, e.g. "* * * * ?"
//   - Descriptors, e.g. "@midnight", "@every 1h30m"
func ParseStandard(standardSpec string) (Schedule, error) {
	return standardParser.Parse(standardSpec)
}

// getField returns an Int with the bits set representing all of the times that
// the field represents or error parsing field value.  A "field" is a comma-separated
// list of "ranges".
func getField(field string, r bounds) (uint64, error) {
	var bits uint64
	ranges := strings.FieldsFunc(field, func(r rune) bool { return r == ',' })
	for _, expr := range ranges {
		bit, err := getRange(expr, r)
		if err != nil {
			return bits, err
		}
		bits |= bit
	}
	return bits, nil
}

// getRange returns the bits indicated by the given expression:
//   number | number "-" number [ "/" number ]
// or error parsing range.
func getRange(expr string, r bounds) (uint64, error) {
	var (
		start, end, step uint
		rangeAndStep     = strings.Split(expr, "/")
		lowAndHigh       = strings.Split(rangeAndStep[0], "-")
		singleDigit      = len(lowAndHigh) == 1
		err              error
	)

	var extra uint64
	if lowAndHigh[0] == "*" || lowAndHigh[0] == "?" {
		start = r.min
		end = r.max
		extra = starBit
	} else {
		start, err = parseIntOrName(lowAndHigh[0], r.names)
		if err != nil {
			return 0, err
		}
		switch len(lowAndHigh) {
		case 1:
			end = start
		case 2:
			end, err = parseIntOrName(lowAndHigh[1], r.names)
			if err != nil {
				return 0, err
			}
		default:
			return 0, fmt.Errorf("too many hyphens: %s", expr)
		}
	}

	switch len(rangeAndStep) {
	case 1:
		step = 1
	case 2:
		step, err = mustParseInt(rangeAndStep[1])
		if err != nil {
			return 0, err
		}

		// Special handling: "N/step" means "N-max/step".
		if singleDigit {
			end = r.max
		}
		if step > 1 {
			extra = 0
		}
	default:
		return 0, fmt.Errorf("too many slashes: %s", expr)
	}

	if start < r.min {
		return 0, fmt.Errorf("beginning of range (%d) below minimum (%d): %s", start, r.min, expr)
	}
	if end > r.max {
		return 0, fmt.Errorf("end of range (%d) above maximum (%d): %s", end, r.max, expr)
	}
	if start > end {
		return 0, fmt.Errorf("beginning of range (%d) beyond end of range (%d): %s", start, end, expr)
	}
	if step == 0 {
		return 0, fmt.Errorf("step of range should be a positive number: %s", expr)
	}

	return getBits(start, end, step) | extra, nil
}

// parseIntOrName returns the (possibly-named) integer contained in expr.
func parseIntOrName(expr string, names map[string]uint) (uint, error) {
	if names != nil {
		if namedInt, ok := names[strings.ToLower(expr)]; ok {
			return namedInt, nil
		}
	}
	return mustParseInt(expr)
}

// mustParseInt parses the given expression as an int or returns an error.
func mustParseInt(expr string) (uint, error) {
	num, err := strconv.Atoi(expr)
	if err != nil {
		return 0, fmt.Errorf("failed to parse int from %s: %s", expr, err)
	}
	if num < 0 {
		return 0, fmt.Errorf("negative number (%d) not allowed: %s", num, expr)
	}

	return uint(num), nil
}

// getBits sets all bits in the range [min, max], modulo the given step size.
func getBits(min, max, step uint) uint64 {
	var bits uint64

	// If step is 1, use shifts.
	if step == 1 {
		return ^(math.MaxUint64 << (max + 1)) & (math.MaxUint64 << min)
	}

	// Else, use a simple loop.
	for i := min; i <= max; i += step {
		bits |= 1 << i
	}
	return bits
}

// all returns all bits within the given bounds.  (plus the star bit)
func all(r bounds) uint64 {
	return getBits(r.min, r.max, 1) | starBit
}

// parseDescriptor returns a predefined schedule for the expression, or error if none matches.
func parseDescriptor(descriptor string, loc *time.Location) (Schedule, error) {
	switch descriptor {
	case "@yearly", "@annually":
		return &SpecSchedule{
			Second:   1 << seconds.min,
			Minute:   1 << minutes.min,
			Hour:     1 << hours.min,
			Dom:      1 << dom.min,
			Month:    1 << months.min,
			Dow:      all(dow),
			Location: loc,
		}, nil

	case "@monthly":
		return &SpecSchedule{
			Second:   1 << seconds.min,
			Minute:   1 << minutes.min,
			Hour:     1 << hours.min,
			Dom:      1 << dom.min,
			Month:    all(months),
			Dow:      all(dow),
			Location: loc,
		}, nil

	case "@weekly":
		return &SpecSchedule{
			Second:   1 << seconds.min,
			Minute:   1 << minutes.min,
			Hour:     1 << hours.min,
			Dom:      all(dom),
			Month:    all(months),
			Dow:      1 << dow.min,
			Location: loc,
		}, nil

	case "@daily", "@midnight":
		return &SpecSchedule{
			Second:   1 << seconds.min,
			Minute:   1 << minutes.min,
			Hour:     1 << hours.min,
			Dom:      all(dom),
			Month:    all(months),
			Dow:      all(dow),
			Location: loc,
		}, nil

	case "@hourly":
		return &SpecSchedule{
			Second:   1 << seconds.min,
			Minute:   1 << minutes.min,
			Hour:     all(hours),
			Dom:      all(dom),
			Month:    all(months),
			Dow:      all(dow),
			Location: loc,
		}, nil

	}

	const every = "@every "
	if strings.HasPrefix(descriptor, every) {
		duration, err := time.ParseDuration(descriptor[len(every):])
		if err != nil {
			return nil, fmt.Errorf("failed to parse duration %s: %s", descriptor, err)
		}
		return Every(duration), nil
	}

	return nil, fmt.Errorf("unrecognized descriptor: %s", descriptor)
}

/// internal/scheduler/cron/spec.go ///
package cron

import (
	"time"
)

// SpecSchedule specifies a duty cycle (to the second granularity), based on a
// traditional crontab specification. It is computed initially and stored as bit sets.
type SpecSchedule struct {
	Second, Minute, Hour, Dom, Month, Dow uint64

	// Override location for this schedule.
	Location *time.Location
}

// bounds provides a range of acceptable values (plus a map of name to value).
type bounds struct {
	min, max uint
	names    map[string]uint
}

// The bounds for each field.
var (
	seconds = bounds{0, 59, nil}
	minutes = bounds{0, 59, nil}
	hours   = bounds{0, 23, nil}
	dom     = bounds{1, 31, nil}
	months  = bounds{1, 12, map[string]uint{
		"jan": 1,
		"feb": 2,
		"mar": 3,
		"apr": 4,
		"may": 5,
		"jun": 6,
		"jul": 7,
		"aug": 8,
		"sep": 9,
		"oct": 10,
		"nov": 11,
		"dec": 12,
	}}
	dow = bounds{0, 6, map[string]uint{
		"sun": 0,
		"mon": 1,
		"tue": 2,
		"wed": 3,
		"thu": 4,
		"fri": 5,
		"sat": 6,
	}}
)

const (
	// Set the top bit if a star was included in the expression.
	starBit = 1 << 63
)

// Next returns the next time this schedule is activated, greater than the given
// time.  If no time can be found to satisfy the schedule, return the zero time.
func (s *SpecSchedule) Next(t time.Time) time.Time {
	// General approach
	//
	// For Month, Day, Hour, Minute, Second:
	// Check if the time value matches.  If yes, continue to the next field.
	// If the field doesn't match the schedule, then increment the field until it matches.
	// While incrementing the field, a wrap-around brings it back to the beginning
	// of the field list (since it is necessary to re-verify previous field
	// values)

	// Convert the given time into the schedule's timezone, if one is specified.
	// Save the original timezone so we can convert back after we find a time.
	// Note that schedules without a time zone specified (time.Local) are treated
	// as local to the time provided.
	origLocation := t.Location()
	loc := s.Location
	if loc == time.Local {
		loc = t.Location()
	}
	if s.Location != time.Local {
		t = t.In(s.Location)
	}

	// Start at the earliest possible time (the upcoming second).
	t = t.Add(1*time.Second - time.Duration(t.Nanosecond())*time.Nanosecond)

	// This flag indicates whether a field has been incremented.
	added := false

	// If no time is found within five years, return zero.
	yearLimit := t.Year() + 5

WRAP:
	if t.Year() > yearLimit {
		return time.Time{}
	}

	// Find the first applicable month.
	// If it's this month, then do nothing.
	for 1<<uint(t.Month())&s.Month == 0 {
		// If we have to add a month, reset the other parts to 0.
		if !added {
			added = true
			// Otherwise, set the date at the beginning (since the current time is irrelevant).
			t = time.Date(t.Year(), t.Month(), 1, 0, 0, 0, 0, loc)
		}
		t = t.AddDate(0, 1, 0)

		// Wrapped around.
		if t.Month() == time.January {
			goto WRAP
		}
	}

	// Now get a day in that month.
	//
	// NOTE: This causes issues for daylight savings regimes where midnight does
	// not exist.  For example: Sao Paulo has DST that transforms midnight on
	// 11/3 into 1am. Handle that by noticing when the Hour ends up != 0.
	for !dayMatches(s, t) {
		if !added {
			added = true
			t = time.Date(t.Year(), t.Month(), t.Day(), 0, 0, 0, 0, loc)
		}
		t = t.AddDate(0, 0, 1)
		// Notice if the hour is no longer midnight due to DST.
		// Add an hour if it's 23, subtract an hour if it's 1.
		if t.Hour() != 0 {
			if t.Hour() > 12 {
				t = t.Add(time.Duration(24-t.Hour()) * time.Hour)
			} else {
				t = t.Add(time.Duration(-t.Hour()) * time.Hour)
			}
		}

		if t.Day() == 1 {
			goto WRAP
		}
	}

	for 1<<uint(t.Hour())&s.Hour == 0 {
		if !added {
			added = true
			t = time.Date(t.Year(), t.Month(), t.Day(), t.Hour(), 0, 0, 0, loc)
		}
		t = t.Add(1 * time.Hour)

		if t.Hour() == 0 {
			goto WRAP
		}
	}

	for 1<<uint(t.Minute())&s.Minute == 0 {
		if !added {
			added = true
			t = t.Truncate(time.Minute)
		}
		t = t.Add(1 * time.Minute)

		if t.Minute() == 0 {
			goto WRAP
		}
	}

	for 1<<uint(t.Second())&s.Second == 0 {
		if !added {
			added = true
			t = t.Truncate(time.Second)
		}
		t = t.Add(1 * time.Second)

		if t.Second() == 0 {
			goto WRAP
		}
	}

	return t.In(origLocation)
}

// dayMatches returns true if the schedule's day-of-week and day-of-month
// restrictions are satisfied by the given time.
func dayMatches(s *SpecSchedule, t time.Time) bool {
	var (
		domMatch bool = 1<<uint(t.Day())&s.Dom > 0
		dowMatch bool = 1<<uint(t.Weekday())&s.Dow > 0
	)
	if s.Dom&starBit > 0 || s.Dow&starBit > 0 {
		return domMatch && dowMatch
	}
	return domMatch || dowMatch
}

/// internal/scheduler/interfaces.go ///
package scheduler

import (
	tp "github.com/kubex-ecosystem/gobe/internal/scheduler/types"
)

type IScheduler interface {
	// ScheduleJob adds a new job to the scheduler.
	ScheduleJob(job tp.Job) error

	// CancelJob removes a job from the scheduler by its ID.
	CancelJob(jobID string) error

	// GetJobStatus retrieves the current status of a job by its ID.
	GetJobStatus(jobID string) (tp.JobStatus, error)

	// ListScheduledJobs returns a list of all scheduled jobs.
	ListScheduledJobs() ([]tp.Job, error)

	// RescheduleJob updates the schedule of an existing job.
	RescheduleJob(jobID string, newSchedule string) error

	// StartScheduler starts the scheduler to process jobs.
	StartScheduler() error

	// StopScheduler stops the scheduler gracefully.
	StopScheduler() error
}

/// internal/scheduler/manager/cron_scheduler.go ///
package manager

import (
	"log"
	"time"

	pl "github.com/kubex-ecosystem/gobe/internal/scheduler/services"
)

// CronJobScheduler gerencia a execuÃ§Ã£o de cronjobs usando o GoroutinePool.
type CronJobScheduler struct {
	pool         *pl.GoroutinePool
	ICronService pl.ICronService // Interface para interagir com o serviÃ§o de cronjobs
}

// NewCronJobScheduler cria uma nova instÃ¢ncia do CronJobScheduler.
func NewCronJobScheduler(pool *pl.GoroutinePool, ICronService pl.ICronService) *CronJobScheduler {
	return &CronJobScheduler{
		pool:         pool,
		ICronService: ICronService,
	}
}

// Start inicia o loop de verificaÃ§Ã£o e execuÃ§Ã£o de cronjobs.
func (s *CronJobScheduler) Start() {
	go func() {
		ticker := time.NewTicker(1 * time.Minute) // Verifica os cronjobs a cada minuto
		defer ticker.Stop()
		for range ticker.C {
			cronJobs, err := s.ICronService.GetScheduledCronJobs()
			if err != nil {
				log.Printf("Error fetching scheduled cronjobs: %v", err)
				continue
			}
			for _, job := range cronJobs {
				s.pool.Submit(job)
			}
		}
	}()
}

/// internal/scheduler/manager/scheduler_manager.go ///
package manager

import (
	"fmt"

	tp "github.com/kubex-ecosystem/gobe/internal/scheduler/types"
)

type Scheduler struct {
	// Implement the scheduler fields
	jobs map[string]tp.Job
}

// ScheduleJob adds a new job to the scheduler.
func (s *Scheduler) ScheduleJob(job tp.Job) error {
	if s.jobs == nil {
		s.jobs = make(map[string]tp.Job)
	}
	jobID := job.Ref().ID.String() // Convertendo UUID para string
	s.jobs[jobID] = job
	return nil
}

// CancelJob removes a job from the scheduler by its ID.
func (s *Scheduler) CancelJob(jobID string) error {
	if _, exists := s.jobs[jobID]; !exists {
		return fmt.Errorf("job with ID %s not found", jobID)
	}
	delete(s.jobs, jobID)
	return nil
}

// GetJobStatus retrieves the current status of a job by its ID.
func (s *Scheduler) GetJobStatus(jobID string) (tp.JobStatus, error) {
	job, exists := s.jobs[jobID]
	if !exists {
		return "", fmt.Errorf("job with ID %s not found", jobID)
	}
	return job.Status, nil
}

// ListScheduledJobs returns a list of all scheduled jobs.
func (s *Scheduler) ListScheduledJobs() ([]tp.Job, error) {
	jobs := make([]tp.Job, 0, len(s.jobs))
	for _, job := range s.jobs {
		jobs = append(jobs, job)
	}
	return jobs, nil
}

// RescheduleJob updates the schedule of an existing job.
func (s *Scheduler) RescheduleJob(jobID string, newSchedule string) error {
	job, exists := s.jobs[jobID]
	if !exists {
		return fmt.Errorf("job with ID %s not found", jobID)
	}
	job.Schedule = newSchedule
	s.jobs[jobID] = job
	return nil
}

// StartScheduler starts the scheduler to process jobs.
func (s *Scheduler) StartScheduler() error {
	// Implementation for starting the scheduler
	return nil
}

// StopScheduler stops the scheduler gracefully.
func (s *Scheduler) StopScheduler() error {
	// Implementation for stopping the scheduler
	return nil
}

/// internal/scheduler/monitor/checker.go ///
package monitor

import (
	"errors"
	"fmt"
	"runtime"
	"syscall"
)

func PreLaunchChecks() error {
	// Check file descriptors
	var rLimit syscall.Rlimit
	if err := syscall.Getrlimit(syscall.RLIMIT_NOFILE, &rLimit); err != nil {
		return err
	}
	if rLimit.Cur < 10000 {
		return fmt.Errorf("Need more file descriptors: got %d", rLimit.Cur)
	}

	// Check CPU
	if runtime.NumCPU() < 2 {
		return errors.New("Need at least 2 cores")
	}
	return nil
}

/// internal/scheduler/monitor/metrics.go ///
package monitor

import "runtime"

type Metrics struct {
	Goroutines int
	HeapMB     float64
}

func GetMetrics() Metrics {
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	return Metrics{
		Goroutines: runtime.NumGoroutine(),
		HeapMB:     float64(m.HeapAlloc) / 1024 / 1024,
	}
}

/// internal/scheduler/monitor/watcher.go ///
package monitor

import (
	"log"
	"runtime"
	"time"
)

func watchGoroutines() {
	go func() {
		for range time.Tick(5 * time.Second) {
			if n := runtime.NumGoroutine(); n > 100 {
				log.Printf("Warning: %d goroutines runningâ€”possible leak?", n)
			}
		}
	}()
}

/// internal/scheduler/services/cron_service.go ///
package services

import (
	tp "github.com/kubex-ecosystem/gobe/internal/scheduler/types"
)

// ICronService define os mÃ©todos necessÃ¡rios para interagir com o serviÃ§o de cronjobs.
type ICronService interface {
	// GetScheduledCronJobs retorna os cronjobs agendados para execuÃ§Ã£o.
	GetScheduledCronJobs() ([]tp.IJob, error)
}

// CronService implements the ICronService interface to fetch scheduled cronjobs from the database.
type CronService struct {
	db tp.Database // Assume a Database interface is defined elsewhere for database operations.
}

// NewCronService creates a new instance of CronService.
func NewCronService(db tp.Database) ICronService {
	return &CronService{db: db}
}

// GetScheduledCronJobs fetches the scheduled cronjobs from the database.
func (s *CronService) GetScheduledCronJobs() ([]tp.IJob, error) {
	// Example query to fetch cronjobs. Adjust the query and mapping as per your database schema.
	rows, err := s.db.Query("SELECT id, name, schedule, command FROM cronjobs WHERE active = true")
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var jobs []tp.IJob
	for rows.Next() {
		var jobID int
		var name, schedule, command string
		if err := rows.Scan(&jobID, &name, &schedule, &command); err != nil {
			return nil, err
		}

		// Create a concrete implementation of IJob for each row.
		job := tp.NewJob(jobID, name, schedule, command)
		jobs = append(jobs, job)
	}

	if err := rows.Err(); err != nil {
		return nil, err
	}

	return jobs, nil
}

/// internal/scheduler/services/pipeline.go ///
package services

type Pipeline struct {
	buffer int
}

func (p *Pipeline) Run(data []int) []int {
	in := make(chan int, p.buffer)
	out := make(chan int, p.buffer)

	// Stage 1: Feed data
	go func() {
		for _, d := range data {
			in <- d
		}
		close(in)
	}()

	// Stage 2: Process
	go func() {
		for d := range in {
			out <- d * 2
		}
		close(out)
	}()

	// Collect
	var results []int
	for r := range out {
		results = append(results, r)
	}
	return results
}

/// internal/scheduler/services/pool.go ///
package services

import (
	"log"
	"sync"
	"time"

	m "github.com/kubex-ecosystem/gobe/internal/scheduler/monitor"

	tp "github.com/kubex-ecosystem/gobe/internal/scheduler/types"
)

// GoroutinePool gerencia a execuÃ§Ã£o de tarefas usando um pool de goroutines.
// Ele suporta monitoramento avanÃ§ado e aÃ§Ãµes automÃ¡ticas para resiliÃªncia.
//
// MÃ©todos principais:
// - Start: Inicia o pool de goroutines sem monitoramento.
// - StartWithMonitoring: Inicia o pool com monitoramento bÃ¡sico.
// - StartWithEnhancedMonitoring: Adiciona limites configurÃ¡veis e alertas.
// - StartWithResilientMonitoring: Inclui aÃ§Ãµes automÃ¡ticas para reiniciar o pool.
// - Submit: Adiciona uma tarefa ao pool.
// - Stop: Para o pool de goroutines.
// - Restart: Reinicia o pool de forma segura.
//
// Exemplo de uso:
//
// pool := NewGoroutinePool(5)
// pool.StartWithResilientMonitoring(100, 500)
// pool.Submit(myJob)
// pool.Stop()
//
// ParÃ¢metros de monitoramento:
// - maxGoroutines: Limite mÃ¡ximo de goroutines antes de acionar alertas.
// - maxHeapMB: Limite mÃ¡ximo de memÃ³ria heap em MB antes de acionar alertas.
//
// AÃ§Ãµes automÃ¡ticas:
// - ReinÃ­cio do pool ao exceder limites configurados.
// - Logs detalhados para rastreamento de aÃ§Ãµes e mÃ©tricas.
type GoroutinePool struct {
	maxWorkers int
	jobs       chan tp.IJob
	wg         sync.WaitGroup
}

func NewGoroutinePool(maxWorkers int) *GoroutinePool {
	return &GoroutinePool{
		maxWorkers: maxWorkers,
		jobs:       make(chan tp.IJob),
	}
}

func (p *GoroutinePool) Start() {
	for i := 0; i < p.maxWorkers; i++ {
		go func() {
			for job := range p.jobs {
				if err := job.Run(); err != nil {
					log.Printf("Job failed: %v", err)
				}
				p.wg.Done()
			}
		}()
	}
}

func (p *GoroutinePool) StartWithMonitoring() {
	for i := 0; i < p.maxWorkers; i++ {
		go func(workerID int) {
			for job := range p.jobs {
				start := time.Now()
				if err := job.Run(); err != nil {
					log.Printf("Worker %d: Job failed: %v", workerID, err)
				}
				duration := time.Since(start)
				log.Printf("Worker %d: Job completed in %v", workerID, duration)
				p.wg.Done()
			}
		}(i)
	}

	// Monitorando goroutines e memÃ³ria
	go func() {
		ticker := time.NewTicker(5 * time.Second)
		defer ticker.Stop()
		for range ticker.C {
			metrics := m.GetMetrics()
			log.Printf("Monitoring: Goroutines: %d, Heap: %.2f MB", metrics.Goroutines, metrics.HeapMB)
		}
	}()
}

// Aprimorando o monitoramento com limites configurÃ¡veis e alertas
func (p *GoroutinePool) StartWithEnhancedMonitoring(maxGoroutines int, maxHeapMB float64) {
	for i := 0; i < p.maxWorkers; i++ {
		go func(workerID int) {
			for job := range p.jobs {
				start := time.Now()
				if err := job.Run(); err != nil {
					log.Printf("Worker %d: Job failed: %v", workerID, err)
				}
				duration := time.Since(start)
				log.Printf("Worker %d: Job completed in %v", workerID, duration)
				p.wg.Done()
			}
		}(i)
	}

	// Monitorando goroutines e memÃ³ria com limites configurÃ¡veis
	go func() {
		ticker := time.NewTicker(5 * time.Second)
		defer ticker.Stop()
		for range ticker.C {
			metrics := m.GetMetrics()
			if metrics.Goroutines > maxGoroutines {
				log.Printf("ALERT: Goroutines exceeded limit! Current: %d, Limit: %d", metrics.Goroutines, maxGoroutines)
			}
			if metrics.HeapMB > maxHeapMB {
				log.Printf("ALERT: Heap memory exceeded limit! Current: %.2f MB, Limit: %.2f MB", metrics.HeapMB, maxHeapMB)
			}
			log.Printf("Monitoring: Goroutines: %d, Heap: %.2f MB", metrics.Goroutines, metrics.HeapMB)
		}
	}()
}

// Aprimorando alertas com aÃ§Ãµes automÃ¡ticas para resiliÃªncia
func (p *GoroutinePool) StartWithResilientMonitoring(maxGoroutines int, maxHeapMB float64) {
	for i := 0; i < p.maxWorkers; i++ {
		go func(workerID int) {
			for job := range p.jobs {
				start := time.Now()
				if err := job.Run(); err != nil {
					log.Printf("Worker %d: Job failed: %v", workerID, err)
				}
				duration := time.Since(start)
				log.Printf("Worker %d: Job completed in %v", workerID, duration)
				p.wg.Done()
			}
		}(i)
	}

	// Monitorando goroutines e memÃ³ria com aÃ§Ãµes automÃ¡ticas
	go func() {
		ticker := time.NewTicker(5 * time.Second)
		defer ticker.Stop()
		for range ticker.C {
			metrics := m.GetMetrics()
			if metrics.Goroutines > maxGoroutines {
				log.Printf("ALERT: Goroutines exceeded limit! Current: %d, Limit: %d", metrics.Goroutines, maxGoroutines)
				log.Println("ACTION: Restarting GoroutinePool to recover...")
				p.Restart()
			}
			if metrics.HeapMB > maxHeapMB {
				log.Printf("ALERT: Heap memory exceeded limit! Current: %.2f MB, Limit: %.2f MB", metrics.HeapMB, maxHeapMB)
				log.Println("ACTION: Restarting GoroutinePool to recover...")
				p.Restart()
			}
			log.Printf("Monitoring: Goroutines: %d, Heap: %.2f MB", metrics.Goroutines, metrics.HeapMB)
		}
	}()
}

// Restart reinicia o pool de goroutines
func (p *GoroutinePool) Restart() {
	log.Println("Restarting GoroutinePool...")
	p.Stop()
	p.jobs = make(chan tp.IJob, cap(p.jobs)) // Recria o canal com o mesmo buffer
	p.StartWithResilientMonitoring(100, 500) // Valores padrÃ£o para reinÃ­cio
}

func (p *GoroutinePool) Submit(job tp.IJob) {
	p.wg.Add(1)
	p.jobs <- job
}

func (p *GoroutinePool) Stop() {
	close(p.jobs)
	p.wg.Wait()
}

/// internal/scheduler/types/job.go ///
package types

import (
	"log"

	"github.com/google/uuid"
	t "github.com/kubex-ecosystem/gobe/internal/types"
)

type IJob interface {
	Mu() *t.Mutexes
	Ref() *t.Reference
	GetUserID() uuid.UUID
	Run() error
	Retry() error
	Cancel() error
}

type Job struct {
	*t.Mutexes
	*t.Reference

	ID       int
	Name     string
	Schedule string
	Command  string

	userID uuid.UUID
	Status JobStatus // Adicionado para rastrear o status do job
}

func NewJob(id int, name, schedule, command string) IJob {
	return &Job{
		ID:       id,
		Name:     name,
		Schedule: schedule,
		Command:  command,
	}
}

func (j *Job) Mu() *t.Mutexes {
	return j.Mutexes
}
func (j *Job) Ref() *t.Reference {
	return j.Reference
}
func (j *Job) GetUserID() uuid.UUID {
	return j.userID
}
func (j *Job) Run() error {
	log.Printf("Running job: %s (ID: %d)", j.Name, j.ID)
	// Implement the logic to execute the command.
	return nil
}
func (j *Job) Retry() error {
	log.Printf("Retrying job: %s (ID: %d)", j.Name, j.ID)

	return nil
}
func (j *Job) Cancel() error {
	log.Printf("Cancelling job: %s (ID: %d)", j.Name, j.ID)
	// Implement cancel logic.
	return nil
}

/// internal/scheduler/types/job_status.go ///
package types

type JobStatus string

const (
	JobStatusPending   JobStatus = "pending"
	JobStatusRunning   JobStatus = "running"
	JobStatusCompleted JobStatus = "completed"
	JobStatusFailed    JobStatus = "failed"
)

// JobStatusMap is a map of job statuses to their string representations.
var JobStatusMap = map[JobStatus]string{
	JobStatusPending:   "pending",
	JobStatusRunning:   "running",
	JobStatusCompleted: "completed",
	JobStatusFailed:    "failed",
}

// JobStatusList is a list of all possible job statuses.
var JobStatusList = []JobStatus{
	JobStatusPending,
	JobStatusRunning,
	JobStatusCompleted,
	JobStatusFailed,
}

type JobStatusType struct {
	JobID     string    `json:"job_id"`
	JobStatus JobStatus `json:"job_status"`
}

type JobStatusResponse struct {
	JobID               string    `json:"job_id"`
	JobStatus           JobStatus `json:"job_status"`
	JobMessage          string    `json:"job_message"`
	JobTime             string    `json:"job_time"`
	JobDuration         string    `json:"job_duration"`
	JobRetries          int       `json:"job_retries"`
	JobMaxRetries       int       `json:"job_max_retries"`
	JobExecTimeout      int       `json:"job_exec_timeout"`
	JobMaxExecutionTime int       `json:"job_max_execution_time"`
	JobCreatedAt        string    `json:"job_created_at"`
	JobUpdatedAt        string    `json:"job_updated_at"`
	JobLastExecutedAt   string    `json:"job_last_executed_at"`
	JobLastExecutedBy   string    `json:"job_last_executed_by"`
	JobCreatedBy        string    `json:"job_created_by"`
	JobUpdatedBy        string    `json:"job_updated_by"`
	JobUserID           string    `json:"job_user_id"`
	JobCronType         string    `json:"job_cron_type"`
	JobCronExpression   string    `json:"job_cron_expression"`
	JobCommand          string    `json:"job_command"`
	JobMethod           string    `json:"job_method"`
	JobAPIEndpoint      string    `json:"job_api_endpoint"`
	JobLastRunStatus    string    `json:"job_last_run_status"`
	JobLastRunMessage   string    `json:"job_last_run_message"`
}

/// internal/scheduler/types/persistence.go ///
package types

// Database is an interface for database operations.
type Database interface {
	Query(query string, args ...interface{}) (Rows, error)
}

// Rows is an interface for iterating over database query results.
type Rows interface {
	Next() bool
	Scan(dest ...interface{}) error
	Close() error
	Err() error
}

/// internal/security/authentication/auth_manager.go ///
package authentication

import (
	"crypto/rsa"
	"fmt"
	"time"

	//"github.com/golang-jwt/jwt/v4"
	"github.com/golang-jwt/jwt/v4"

	"github.com/google/uuid"
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	"github.com/kubex-ecosystem/gobe/logger"
)

type AuthManager struct {
	privKey               *rsa.PrivateKey
	pubKey                *rsa.PublicKey
	refreshSecret         string
	idExpirationSecs      int64
	refreshExpirationSecs int64
}

func NewAuthManager(certService crt.CertService) (*AuthManager, error) {
	privKey, err := certService.GetPrivateKey()
	if err != nil {
		logger.Log("error", fmt.Sprintf("Failed to load private key: %v", err))
		return nil, err
	}

	pubKey, err := certService.GetPublicKey()
	if err != nil {
		logger.Log("error", fmt.Sprintf("Failed to load public key: %v", err))
		return nil, err
	}

	return &AuthManager{
		privKey:               privKey,
		pubKey:                pubKey,
		refreshSecret:         "default_refresh_secret", // Replace with a secure secret
		idExpirationSecs:      3600,                     // 1 hour
		refreshExpirationSecs: 604800,                   // 7 days
	}, nil
}

func (am *AuthManager) GenerateIDToken(userID string) (string, error) {

	claims := jwt.RegisteredClaims{
		Subject:   userID,
		ExpiresAt: &jwt.NumericDate{time.Now().Add(time.Duration(am.idExpirationSecs) * time.Second)},
		IssuedAt:  &jwt.NumericDate{time.Now()},
		ID:        uuid.New().String(),
	}
	token := jwt.NewWithClaims(jwt.SigningMethodRS256, claims)
	return token.SignedString(am.privKey)
}

func (am *AuthManager) GenerateRefreshToken(userID string) (string, error) {
	claims := jwt.RegisteredClaims{
		Subject:   userID,
		ExpiresAt: &jwt.NumericDate{time.Now().Add(time.Duration(am.refreshExpirationSecs) * time.Second)},
		IssuedAt:  &jwt.NumericDate{time.Now()},
		ID:        uuid.New().String(),
	}
	token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
	return token.SignedString([]byte(am.refreshSecret))
}

func (am *AuthManager) ValidateIDToken(tokenString string) (*jwt.RegisteredClaims, error) {
	token, err := jwt.ParseWithClaims(tokenString, &jwt.RegisteredClaims{}, func(token *jwt.Token) (interface{}, error) {
		return am.pubKey, nil
	})
	if err != nil {
		return nil, err
	}

	claims, ok := token.Claims.(*jwt.RegisteredClaims)
	if !ok || !token.Valid {
		return nil, fmt.Errorf("invalid token")
	}

	return claims, nil
}

func (am *AuthManager) ValidateRefreshToken(tokenString string) (*jwt.RegisteredClaims, error) {
	token, err := jwt.ParseWithClaims(tokenString, &jwt.RegisteredClaims{}, func(token *jwt.Token) (interface{}, error) {
		return []byte(am.refreshSecret), nil
	})
	if err != nil {
		return nil, err
	}

	claims, ok := token.Claims.(*jwt.RegisteredClaims)
	if !ok || !token.Valid {
		return nil, fmt.Errorf("invalid token")
	}

	return claims, nil
}

/// internal/security/authentication/token_client.go ///
package authentication

import (
	"crypto/rsa"
	"fmt"

	s "github.com/kubex-ecosystem/gdbase/factory"
	"github.com/kubex-ecosystem/gobe/internal/common"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	kri "github.com/kubex-ecosystem/gobe/internal/security/external"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type TokenClientImpl struct {
	mapper                ci.IMapper[sci.TSConfig]
	dbSrv                 s.DBService
	crtSrv                sci.ICertService
	keyringService        sci.IKeyringService
	TokenService          sci.TokenService
	IDExpirationSecs      int64
	RefreshExpirationSecs int64
}

func (t *TokenClientImpl) LoadPublicKey() *rsa.PublicKey {
	pubKey, err := t.crtSrv.GetPublicKey()
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error reading public key file: %v", err))
		return nil
	}
	return pubKey
}

func (t *TokenClientImpl) LoadPrivateKey() (*rsa.PrivateKey, error) {
	return t.crtSrv.GetPrivateKey()
}
func (t *TokenClientImpl) LoadTokenCfg() (sci.TokenService, int64, int64, error) {
	if t == nil {
		gl.Log("error", fmt.Sprintf("TokenClient is nil, trying to create a new one"))
		t = &TokenClientImpl{}
	}
	if t.crtSrv == nil {
		gl.Log("error", fmt.Sprintf("crtService is nil, trying to create a new one"))
		t.crtSrv = crt.NewCertService(common.DefaultGoBEKeyPath, common.DefaultGoBECertPath)
		if t.crtSrv == nil {
			gl.Log("fatal", fmt.Sprintf("crtService is nil, unable to create a new one"))
		}
	}
	privKey, err := t.crtSrv.GetPrivateKey()
	if err != nil {
		gl.Log("fatal", fmt.Sprintf("Error reading private key file: %v", err))
		return nil, 0, 0, err
	}
	pubKey, pubKeyErr := t.crtSrv.GetPublicKey()
	if pubKeyErr != nil {
		gl.Log("error", fmt.Sprintf("Error reading public key file: %v", pubKeyErr))
		return nil, 0, 0, pubKeyErr
	}

	dB, dbErr := t.dbSrv.GetDB()
	if dbErr != nil {
		gl.Log("error", fmt.Sprintf("Error getting DB: %v", dbErr))
		return nil, 0, 0, dbErr
	}

	// Garantir valores padrÃ£o seguros
	if t.IDExpirationSecs == 0 {
		t.IDExpirationSecs = 3600 // 1 hora
	}
	if t.RefreshExpirationSecs == 0 {
		t.RefreshExpirationSecs = 604800 // 7 dias
	}
	if t.keyringService == nil {
		t.keyringService = kri.NewKeyringService(common.KeyringService, fmt.Sprintf("gobe-%s", "jwt_secret"))
		if t.keyringService == nil {
			gl.Log("error", fmt.Sprintf("Error creating keyring service: %v", err))
			return nil, 0, 0, err
		}
	}

	tokenService := NewTokenService(&sci.TSConfig{
		TokenRepository:  NewTokenRepo(dB),
		IDExpirationSecs: t.IDExpirationSecs,
		PubKey:           pubKey,
		PrivKey:          privKey,
		TokenClient:      t,
		DBService:        &t.dbSrv,
		KeyringService:   t.keyringService,
	})

	return tokenService, t.IDExpirationSecs, t.RefreshExpirationSecs, nil
}

func NewTokenClient(crtService sci.ICertService, dbService s.DBService) sci.TokenClient {
	if crtService == nil {
		gl.Log("error", fmt.Sprintf("error reading private key file: %v", "crtService is nil"))
		return nil
	}
	tokenClient := &TokenClientImpl{
		crtSrv: crtService,
		dbSrv:  dbService,
	}

	return tokenClient
}

/// internal/security/authentication/token_repo.go ///
package authentication

import (
	"context"
	"fmt"
	"time"

	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	"github.com/kubex-ecosystem/gobe/internal/security/models"
	"gorm.io/gorm"
)

type TokenRepoImpl struct{ *gorm.DB }

func NewTokenRepo(db *gorm.DB) sci.TokenRepo { return &TokenRepoImpl{db} }

func (g *TokenRepoImpl) TableName() string {
	return "refresh_tokens"
}

func (g *TokenRepoImpl) SetRefreshToken(ctx context.Context, userID string, tokenID string, expiresIn time.Duration) error {
	expirationTime := time.Now().Add(expiresIn)
	token := &models.RefreshTokenModel{
		UserID:    userID,
		TokenID:   tokenID,
		ExpiresAt: expirationTime,
	}
	if err := g.WithContext(ctx).Create(token).Error; err != nil {
		return fmt.Errorf("failed to save refresh token: %w", err)
	}
	return nil
}

func (g *TokenRepoImpl) DeleteRefreshToken(ctx context.Context, userID string, prevTokenID string) error {
	if err := g.WithContext(ctx).Where("user_id = ? AND token_id = ?", userID, prevTokenID).Delete(&models.RefreshTokenModel{}).Error; err != nil && err != gorm.ErrRecordNotFound {
		// Ignore ErrRecordNotFound as it indicates no tokens were found for the user and is not an error condition.
		return fmt.Errorf("failed to delete refresh token: %w", err)
	}
	return nil
}

func (g *TokenRepoImpl) DeleteUserRefreshTokens(ctx context.Context, userID string) error {
	if err := g.WithContext(ctx).Where("user_id = ?", userID).Delete(&models.RefreshTokenModel{}).Error; err != nil && err != gorm.ErrRecordNotFound {
		// Ignore ErrRecordNotFound as it indicates no tokens were found for the user and is not an error condition.
		return fmt.Errorf("failed to delete user refresh tokens: %w", err)
	}
	return nil
}

func (g *TokenRepoImpl) GetRefreshToken(ctx context.Context, tokenID string) (*models.RefreshTokenModel, error) {
	var token models.RefreshTokenModel
	if err := g.WithContext(ctx).Where("token_id = ?", tokenID).First(&token).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			return nil, nil
		}
		return nil, fmt.Errorf("failed to fetch refresh token: %w", err)
	}
	return &token, nil
}

/// internal/security/authentication/token_service.go ///
package authentication

import (
	"context"
	"crypto/rsa"
	"fmt"
	"strings"
	"time"

	"github.com/golang-jwt/jwt/v4"
	"github.com/google/uuid"
	m "github.com/kubex-ecosystem/gdbase/factory/models"
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type idTokenCustomClaims struct {
	User *m.UserModelType `json:"UserImpl"`
	jwt.RegisteredClaims
}
type TokenServiceImpl struct {
	TokenRepository       sci.TokenRepo
	PrivKey               *rsa.PrivateKey
	PubKey                *rsa.PublicKey
	RefreshSecret         string
	IDExpirationSecs      int64
	RefreshExpirationSecs int64
}

func NewTokenService(c *sci.TSConfig) sci.TokenService {
	if c == nil {
		gl.Log("error", "TokenService config is nil")
		return nil
	}
	var idExpirationSecs, refreshExpirationSecs int64
	if c.IDExpirationSecs == 0 {
		idExpirationSecs = 3600 // Default to 1 hour
	} else {
		idExpirationSecs = c.IDExpirationSecs
	}
	if c.RefreshExpirationSecs == 0 {
		refreshExpirationSecs = 604800 // Default to 7 days
	} else {
		refreshExpirationSecs = c.RefreshExpirationSecs
	}
	tsrv := &TokenServiceImpl{
		TokenRepository:       c.TokenRepository,
		PrivKey:               c.PrivKey,
		PubKey:                c.PubKey,
		RefreshSecret:         c.RefreshSecret,
		IDExpirationSecs:      idExpirationSecs,
		RefreshExpirationSecs: refreshExpirationSecs,
	}
	return tsrv
}

func (s *TokenServiceImpl) NewPairFromUser(ctx context.Context, u m.UserModel, prevTokenID string) (*sci.TokenPair, error) {
	if prevTokenID != "" {
		if err := s.TokenRepository.DeleteRefreshToken(ctx, u.GetID(), prevTokenID); err != nil {
			return nil, fmt.Errorf("could not delete previous refresh token for uid: %v, tokenID: %v", u.GetID(), prevTokenID)
		}
	}

	idToken, err := generateIDToken(u, s.PrivKey, s.IDExpirationSecs)
	if err != nil {
		return nil, fmt.Errorf("error generating id token for uid: %v: %v", u.GetID(), err)
	}

	if s.RefreshSecret == "" {
		jwtSecret, jwtSecretErr := crt.GetOrGenPasswordKeyringPass("jwt_secret")
		if jwtSecretErr != nil {
			gl.Log("fatal", fmt.Sprintf("Error retrieving JWT secret key: %v", jwtSecretErr))
			return nil, jwtSecretErr
		}
		s.RefreshSecret = jwtSecret
	}

	refreshToken, err := generateRefreshToken(u.GetID(), s.RefreshSecret, s.RefreshExpirationSecs)
	if err != nil {
		return nil, fmt.Errorf("error generating refresh token for uid: %v: %v", u.GetID(), err)
	}

	if err := s.TokenRepository.SetRefreshToken(ctx, u.GetID(), refreshToken.ID, refreshToken.ExpiresIn); err != nil {
		return nil, fmt.Errorf("error storing token ID for uid: %v: %v", u.GetID(), err)
	}

	return &sci.TokenPair{
		IDToken:      sci.IDToken{SS: idToken},
		RefreshToken: sci.RefreshToken{SS: refreshToken.SS, ID: refreshToken.ID, UID: u.GetID()},
	}, nil
}
func (s *TokenServiceImpl) SignOut(ctx context.Context, uid string) error {
	return s.TokenRepository.DeleteUserRefreshTokens(ctx, uid)
}
func (s *TokenServiceImpl) ValidateIDToken(tokenString string) (m.UserModel, error) {
	// Garantir que o segredo de atualizaÃ§Ã£o esteja configurado
	if s.RefreshSecret == "" || len(s.RefreshSecret) < 32 {
		jwtSecret, jwtSecretErr := crt.GetOrGenPasswordKeyringPass("jwt_secret")
		if jwtSecretErr != nil {
			gl.Log("fatal", fmt.Sprintf("Error retrieving JWT secret key: %v", jwtSecretErr))
			return nil, fmt.Errorf("error retrieving JWT secret key: %v", jwtSecretErr)
		}
		s.RefreshSecret = jwtSecret
	}

	// Validar o token usando a chave pÃºblica
	claims, err := validateIDToken(tokenString, s.PubKey)
	if err != nil {
		return nil, fmt.Errorf("unable to validate or parse ID token: %v", err)
	}

	return claims.User, nil
}
func (s *TokenServiceImpl) ValidateRefreshToken(tokenString string) (*sci.RefreshToken, error) {
	claims, claimsErr := validateRefreshToken(tokenString, s.RefreshSecret)
	if claimsErr != nil {
		return nil, fmt.Errorf("unable to validate or parse refresh token for token string %s: %v", tokenString, claimsErr)
	}
	tokenUUID, tokenUUIDErr := uuid.Parse(claims.ID)
	if tokenUUIDErr != nil {
		return nil, fmt.Errorf("claims ID could not be parsed as UUID: %s: %v", claims.UID, tokenUUIDErr)
	}
	return &sci.RefreshToken{
		SS:  tokenString,
		ID:  tokenUUID.String(),
		UID: claims.UID,
	}, nil
}
func (s *TokenServiceImpl) RenewToken(ctx context.Context, refreshToken string) (*sci.TokenPair, error) {
	if len(strings.Split(refreshToken, ".")) != 3 {
		return nil, fmt.Errorf("invalid refresh token format for token string: %s", refreshToken)
	}

	claims, err := validateRefreshToken(refreshToken, s.RefreshSecret)
	if err != nil {
		return nil, fmt.Errorf("unable to validate or parse refresh token for token string %s: %v", refreshToken, err)
	}
	if err := s.TokenRepository.DeleteRefreshToken(ctx, claims.UID, claims.ID); err != nil {
		return nil, fmt.Errorf("error deleting refresh token: %v", err)
	}
	idCClaims, idCClaimsErr := validateIDToken(claims.UID, s.PubKey)
	if idCClaimsErr != nil {
		return nil, fmt.Errorf("error validating id token: %v", idCClaimsErr)
	}
	return s.NewPairFromUser(ctx, idCClaims.User, claims.ID)
}

type refreshTokenData struct {
	SS        string
	ID        string
	ExpiresIn time.Duration
}
type refreshTokenCustomClaims struct {
	UID string `json:"uid"`
	jwt.RegisteredClaims
}

func generateIDToken(u m.UserModel, key *rsa.PrivateKey, exp int64) (string, error) {
	if key == nil {
		gl.Log("error", "Private key is nil")
		return "", fmt.Errorf("private key is nil")
	}
	if u == nil {
		gl.Log("error", "User model is nil")
		return "", fmt.Errorf("user model is nil")
	}
	if exp <= 0 {
		exp = 3600 // Default to 1 hour
	}
	unixTime := time.Now().Unix()
	tokenExp := unixTime + exp
	claims := idTokenCustomClaims{
		User: u.GetUserObj(),
		RegisteredClaims: jwt.RegisteredClaims{
			IssuedAt:  jwt.NewNumericDate(time.Unix(unixTime, 0)),
			ExpiresAt: jwt.NewNumericDate(time.Unix(tokenExp, 0)),
		},
	}

	token := jwt.NewWithClaims(jwt.SigningMethodRS256, claims)
	ss, err := token.SignedString(key)
	if err != nil {
		gl.Log("error", "Error signing ID token: %v", err)
		return "", fmt.Errorf("failed to sign ID token: %w", err)
	}

	gl.Log("info", "ID token generated successfully for user: %s", u.GetID())
	return ss, nil
}
func generateRefreshToken(uid string, key string, exp int64) (*refreshTokenData, error) {
	currentTime := time.Now()
	tokenExp := currentTime.Add(time.Duration(exp) * time.Second)
	tokenID, err := uuid.NewRandom()
	if err != nil {
		return nil, fmt.Errorf("failed to generate refresh token ID")
	}

	claims := refreshTokenCustomClaims{
		UID: uid,
		RegisteredClaims: jwt.RegisteredClaims{
			IssuedAt:  jwt.NewNumericDate(currentTime),
			ExpiresAt: jwt.NewNumericDate(tokenExp),
			ID:        tokenID.String(),
		},
	}

	// Create the token using the signing method and claims
	// Note: The signing method is not used in the JWT token, but it's required for signing
	// the token with the secret key.
	// The key is used to sign the token, and the signing method is used to verify it.
	if key == "" {
		return nil, fmt.Errorf("refresh token secret key is empty")
	}

	token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
	ss, err := token.SignedString([]byte(key))
	if err != nil {
		return nil, fmt.Errorf("failed to sign refresh token: %v", err)
	}

	return &refreshTokenData{
		SS:        ss,
		ID:        tokenID.String(),
		ExpiresIn: tokenExp.Sub(currentTime),
	}, nil
}
func validateIDToken(tokenString string, key *rsa.PublicKey) (*idTokenCustomClaims, error) {
	claims := &idTokenCustomClaims{}

	// Check if the token string is empty
	if tokenString == "" {
		gl.Log("error", "Token string is empty")
		return nil, fmt.Errorf("token string is empty")
	}
	// Check if the key is nil
	if key == nil {
		gl.Log("error", "Public key is nil")
		return nil, fmt.Errorf("public key is nil")
	}

	// Check if the token string is in the correct format
	if len(strings.Split(tokenString, ".")) != 3 {
		gl.Log("error", "Invalid token format")
		return nil, fmt.Errorf("invalid token format")
	}

	// Check if the token string is a valid JWT token
	if !strings.HasPrefix(tokenString, "ey") {
		gl.Log("error", "Invalid JWT token")
		return nil, fmt.Errorf("invalid JWT token")
	}
	token, err := jwt.ParseWithClaims(tokenString, claims, func(token *jwt.Token) (interface{}, error) {
		if _, ok := token.Method.(*jwt.SigningMethodRSA); !ok {
			gl.Log("error", fmt.Sprintf("Unexpected signing method: %v", token.Header["alg"]))
			return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
		}
		return key, nil
	})
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error parsing token: %v", err))
		return nil, fmt.Errorf("error parsing token: %v", err)
	}
	if !token.Valid {
		gl.Log("error", "Token is invalid")
		return nil, fmt.Errorf("token is invalid")
	}
	claims, ok := token.Claims.(*idTokenCustomClaims)
	if !ok {
		gl.Log("error", "Token valid but couldn't parse claims")
		return nil, fmt.Errorf("token valid but couldn't parse claims")
	}
	if claims.User == nil {
		gl.Log("error", "User claims are nil")
		return nil, fmt.Errorf("user claims are nil")
	}
	if claims.User.GetID() == "" {
		gl.Log("error", "User ID is empty")
		return nil, fmt.Errorf("user ID is empty")
	}
	if claims.User.GetRoleID() == "" {
		gl.Log("error", "User role ID is empty")
		return nil, fmt.Errorf("user role ID is empty")
	}
	if claims.User.GetEmail() == "" {
		gl.Log("error", "User email is empty")
		return nil, fmt.Errorf("user email is empty")
	}
	if claims.User.GetUsername() == "" {
		gl.Log("error", "User username is empty")
		return nil, fmt.Errorf("user username is empty")
	}
	if claims.ExpiresAt.Time.Unix() < time.Now().Unix() || claims.ExpiresAt.Time.Unix() <= 0 {
		return nil, fmt.Errorf("token has expired")
	}
	if claims.IssuedAt.Time.Unix() > claims.ExpiresAt.Time.Unix() || claims.IssuedAt.Time.Unix() <= 0 {
		return nil, fmt.Errorf("token issued at time is greater than expiration time")
	}
	if claims.IssuedAt.Time.Unix() <= 0 {
		return nil, fmt.Errorf("token issued at time is less than or equal to zero")
	}

	return claims, nil

}
func validateRefreshToken(tokenString string, key string) (*refreshTokenCustomClaims, error) {
	claims := &refreshTokenCustomClaims{}
	token, err := jwt.ParseWithClaims(tokenString, claims, func(token *jwt.Token) (interface{}, error) {
		return []byte(key), nil
	})
	if err != nil {
		return nil, err
	}
	if !token.Valid {
		return nil, fmt.Errorf("refresh token is invalid")
	}
	claims, ok := token.Claims.(*refreshTokenCustomClaims)
	if !ok {
		return nil, fmt.Errorf("refresh token valid but couldn't parse claims")
	}
	return claims, nil
}

/// internal/security/certificates/cert_manager.go ///
package certificates

type ICertManager interface {
	GenerateCertificate(certPath, keyPath string, password []byte) ([]byte, []byte, error)
	VerifyCert() error
	GetCertAndKeyFromFile() ([]byte, []byte, error)
}

/// internal/security/certificates/cert_service.go ///
package certificates

import (
	"crypto/rand"
	"crypto/rsa"
	"crypto/x509"
	"crypto/x509/pkix"
	"encoding/pem"
	"errors"
	"fmt"
	"math/big"
	"os"
	"path/filepath"
	"time"

	cm "github.com/kubex-ecosystem/gobe/internal/common"
	crp "github.com/kubex-ecosystem/gobe/internal/security/crypto"
	krs "github.com/kubex-ecosystem/gobe/internal/security/external"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
	"golang.org/x/crypto/chacha20poly1305"
)

// CertService provides methods for managing certificates and private keys.
// It supports generating, encrypting, decrypting, and verifying certificates.
type CertService struct {
	keyPath  string             // Path to the private key file.
	certPath string             // Path to the certificate file.
	security *crp.CryptoService // Service for cryptographic operations.
}

// GenerateCertificate generates a self-signed certificate and encrypts the private key.
// Parameters:
// - certPath: Path to save the certificate.
// - keyPath: Path to save the private key.
// - password: Password used to encrypt the private key.
// Returns: The encrypted private key, the certificate bytes, and an error if any.
func (c *CertService) GenerateCertificate(certPath, keyPath string, password []byte) ([]byte, []byte, error) {
	priv, generateKeyErr := rsa.GenerateKey(rand.Reader, 2048)
	if generateKeyErr != nil {
		gl.Log("error", fmt.Sprintf("error generating private key: %v", generateKeyErr))
		return nil, nil, fmt.Errorf("error generating private key: %v", generateKeyErr)
	}

	sn, _ := rand.Int(rand.Reader, big.NewInt(1<<62))
	template := x509.Certificate{
		SerialNumber: sn,
		Subject:      pkix.Name{CommonName: "Kubex Self-Signed"},
		NotBefore:    time.Now(),
		NotAfter:     time.Now().AddDate(1, 0, 0),
		KeyUsage:     x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature,
		ExtKeyUsage:  []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth},
		IsCA:         true,
	}

	certDER, certDERErr := x509.CreateCertificate(rand.Reader, &template, &template, &priv.PublicKey, priv)
	if certDERErr != nil {
		gl.Log("error", fmt.Sprintf("error creating certificate: %v", certDERErr))
		return nil, nil, fmt.Errorf("error creating certificate: %v", certDERErr)
	}

	var pwd string
	var pwdErr error
	if len(password) == 0 {
		pwd, pwdErr = GetOrGenPasswordKeyringPass("jwt_secret")

		if pwdErr != nil {
			gl.Log("error", fmt.Sprintf("error retrieving password: %v", pwdErr))
			return nil, nil, fmt.Errorf("error retrieving password: %w", pwdErr)
		}
		password = []byte(pwd)
	} else {
		pwd = string(password)
	}

	isEncoded := c.security.IsBase64String(pwd)
	var decodedPassword []byte
	var err error
	if isEncoded {
		decodedPassword, err = c.security.DecodeIfEncoded(password)
		if err != nil {
			gl.Log("error", fmt.Sprintf("error decoding password: %v", err))
			return nil, nil, fmt.Errorf("error decoding password: %w", err)
		}
	} else {
		decodedPassword = []byte(pwd)
	}
	pkcs1PrivBytes := x509.MarshalPKCS1PrivateKey(priv)

	block, err := chacha20poly1305.NewX(decodedPassword)
	if err != nil {
		gl.Log("error", fmt.Sprintf("error creating cipher: %v, %d", err, len(decodedPassword)))
		return nil, nil, fmt.Errorf("error creating cipher: %w", err)
	}

	nonce := make([]byte, block.NonceSize())
	if _, err := rand.Read(nonce); err != nil {
		gl.Log("error", fmt.Sprintf("error generating nonce: %v", err))
		return nil, nil, fmt.Errorf("error generating nonce: %w", err)
	}

	ciphertext := block.Seal(nonce, nonce, pkcs1PrivBytes, nil)
	if err := os.MkdirAll(filepath.Dir(keyPath), 0755); err != nil {
		gl.Log("error", fmt.Sprintf("error creating directory for key file: %v", err))
		return nil, nil, fmt.Errorf("error creating directory for key file: %w", err)
	}

	certFile, err := os.OpenFile(certPath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0644)
	if err != nil {
		gl.Log("error", fmt.Sprintf("error opening certificate file: %v", err))
		return nil, nil, fmt.Errorf("error opening certificate file: %w", err)
	}
	defer func(certFile *os.File) {
		_ = certFile.Close()
	}(certFile)

	pemBlock := pem.Block{Type: "CERTIFICATE", Bytes: certDER}
	if err := pem.Encode(certFile, &pemBlock); err != nil {
		gl.Log("error", fmt.Sprintf("error encoding certificate: %v", err))
		return nil, nil, fmt.Errorf("error encoding certificate: %w", err)
	}

	keyFile, err := os.OpenFile(keyPath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)
	if err != nil {
		gl.Log("error", fmt.Sprintf("error opening key file: %v", err))
		return nil, nil, fmt.Errorf("error opening key file: %w", err)
	}
	defer func(keyFile *os.File) {
		_ = keyFile.Close()
	}(keyFile)

	pemBlock = pem.Block{Type: "RSA PRIVATE KEY", Bytes: ciphertext}
	if err := pem.Encode(keyFile, &pemBlock); err != nil {
		gl.Log("error", fmt.Sprintf("error encoding private key: %v", err))
		return nil, nil, fmt.Errorf("error encoding private key: %w", err)
	}

	return ciphertext, certDER, nil
}

// GenSelfCert generates a self-signed certificate and stores it in the configured paths.
// Returns: The encrypted private key, the certificate bytes, and an error if any.
func (c *CertService) GenSelfCert() ([]byte, []byte, error) {

	// HERE WE ARE USING THE KEYRING TO STORE THE PASSWORD
	// FOR THE CERTIFICATE AND PRIVATE KEY!!! THE NAME GIVEN
	// TO THE SECRET IS "jwt_secret" AND IT WILL BE USED TO
	// ENCRYPT THE PRIVATE KEY AND STORE IT IN THE KEYRING
	key, keyErr := GetOrGenPasswordKeyringPass("jwt_secret")

	if keyErr != nil {
		gl.Log("error", fmt.Sprintf("error retrieving password: %v", keyErr))
		return nil, nil, fmt.Errorf("error retrieving password: %w", keyErr)
	}
	return c.GenerateCertificate(c.certPath, c.keyPath, []byte(key))
}

// DecryptPrivateKey decrypts an encrypted private key using the provided password.
// Parameters:
// - ciphertext: The encrypted private key.
// - password: The password used for decryption.
// Returns: The decrypted private key and an error if any.
func (c *CertService) DecryptPrivateKey(privKeyBytes []byte, password []byte) (*rsa.PrivateKey, error) {
	if c == nil {
		gl.Log("fatal", "CertService is nil, trying to create a new one")
	}
	if password == nil {
		strPassword, passwordErr := GetOrGenPasswordKeyringPass("jwt_secret")
		if passwordErr != nil {
			gl.Log("error", fmt.Sprintf("error retrieving password: %v", passwordErr))
			return nil, fmt.Errorf("error retrieving password: %w", passwordErr)
		}
		password = []byte(strPassword)
	}

	privKeyDecrypted, _, err := crp.NewCryptoServiceType().Decrypt(privKeyBytes, password)
	if err != nil {
		return nil, fmt.Errorf("erro ao descriptografar chave privada: %w", err)
	}
	if len(privKeyDecrypted) == 0 {
		return nil, fmt.Errorf("erro ao descriptografar chave privada: %w", err)
	}

	return x509.ParsePKCS1PrivateKey([]byte(privKeyDecrypted))
}

// GetCertAndKeyFromFile reads the certificate and private key from their respective files.
// Returns: The certificate bytes, the private key bytes, and an error if any.
func (c *CertService) GetCertAndKeyFromFile() ([]byte, []byte, error) {
	if c == nil {
		gl.Log("warn", "CertService is nil, trying to create a new one")
		c = new(CertService)
	}
	if c.keyPath == "" {
		c.keyPath = os.ExpandEnv(cm.DefaultGoBEKeyPath)
	}
	if c.certPath == "" {
		c.certPath = os.ExpandEnv(cm.DefaultGoBECertPath)
	}
	certBytes, err := os.ReadFile(os.ExpandEnv(c.certPath))
	if err != nil {
		return nil, nil, fmt.Errorf("error reading certificate file: %w", err)
	}

	keyBytes, err := os.ReadFile(os.ExpandEnv(c.keyPath))
	if err != nil {
		return nil, nil, fmt.Errorf("error reading key file: %w", err)
	}

	return certBytes, keyBytes, nil
}

// VerifyCert verifies the validity of the certificate stored in the configured path.
// Returns: An error if the certificate is invalid or cannot be read.
func (c *CertService) VerifyCert() error {
	if c == nil {
		gl.Log("warn", "CertService is nil, trying to create a new one")
		c = new(CertService)
	}
	if c.keyPath == "" {
		c.keyPath = os.ExpandEnv(cm.DefaultGoBEKeyPath)
	}
	if c.certPath == "" {
		c.certPath = os.ExpandEnv(cm.DefaultGoBECertPath)
	}
	certFile, err := os.Open(c.certPath)
	if err != nil {
		return fmt.Errorf("error opening certificate file: %w", err)
	}
	defer func(certFile *os.File) {
		_ = certFile.Close()
	}(certFile)

	certBytes, err := os.ReadFile(c.certPath)
	if err != nil {
		return fmt.Errorf("error reading certificate file: %w", err)
	}

	block, _ := pem.Decode(certBytes)
	if block == nil {
		return fmt.Errorf("error decoding certificate")
	}

	_, err = x509.ParseCertificate(block.Bytes)
	if err != nil {
		return fmt.Errorf("error parsing certificate: %w", err)
	}

	return nil
}

// GetPublicKey retrieves the public key from the certificate file.
// Returns: The public key and an error if any.
func (c *CertService) GetPublicKey() (*rsa.PublicKey, error) {
	if c == nil {
		gl.Log("warn", "CertService is nil, trying to create a new one")
		c = new(CertService)
	}
	if c.keyPath == "" {
		c.keyPath = os.ExpandEnv(cm.DefaultGoBEKeyPath)
	}
	if c.certPath == "" {
		c.certPath = os.ExpandEnv(cm.DefaultGoBECertPath)
	}
	certBytes, err := os.ReadFile(os.ExpandEnv(c.certPath))
	if err != nil {
		gl.Log("error", fmt.Sprintf("error reading certificate file: %v", err))
		return nil, fmt.Errorf("error reading certificate file: %w", err)
	}

	block, _ := pem.Decode(certBytes)
	if block == nil {
		gl.Log("error", "error decoding certificate")
		return nil, fmt.Errorf("error decoding certificate")
	}

	cert, err := x509.ParseCertificate(block.Bytes)
	if err != nil {
		gl.Log("error", fmt.Sprintf("error parsing certificate: %v", err))
		return nil, fmt.Errorf("error parsing certificate: %w", err)
	}

	pubKey, ok := cert.PublicKey.(*rsa.PublicKey)
	if !ok {
		gl.Log("error", "error asserting public key type")
		return nil, fmt.Errorf("error asserting public key type")
	}

	return pubKey, nil
}

// GetPrivateKey retrieves the private key from the key file.
// Returns: The private key and an error if any.
func (c *CertService) GetPrivateKey() (*rsa.PrivateKey, error) {
	var err error
	if c.keyPath == "" {
		c.keyPath = os.ExpandEnv(cm.DefaultGoBEKeyPath)
	}
	keyBytes, err := os.ReadFile(c.keyPath)
	if err != nil {
		return nil, fmt.Errorf("error reading certificate file: %w", err)
	}
	privateKeyBlock, _ := pem.Decode(keyBytes)
	if privateKeyBlock == nil {
		return nil, fmt.Errorf("error decoding private key")
	}
	// pwd, err := GetOrGenPasswordKeyringPass(cm.KeyringService)
	pwd, err := GetOrGenPasswordKeyringPass("jwt_secret")
	if err != nil {
		return nil, fmt.Errorf("error retrieving password: %w", err)
	}

	isEncoded := c.security.IsBase64String(pwd)
	var decodedPassword []byte
	if isEncoded {
		decodedPassword, err = c.security.DecodeBase64(pwd)
		if err != nil {
			return nil, fmt.Errorf("error decoding password: %w", err)
		}
	} else {
		decodedPassword = []byte(pwd)
	}

	copyKey := make([]byte, len(privateKeyBlock.Bytes))
	copy(copyKey, privateKeyBlock.Bytes)
	privKeyDecrypted, privKeyDecryptedDecoded, err := c.security.Decrypt(copyKey, decodedPassword)
	if err != nil {
		gl.Log("error", fmt.Sprintf("error decrypting private key: %v", err))
		return nil, fmt.Errorf("erro ao descriptografar chave privada: %w", err)
	}
	if len(privKeyDecrypted) == 0 {
		gl.Log("error", "error decrypting private key: empty result")
		return nil, fmt.Errorf("erro ao descriptografar chave privada: %w", err)
	}

	isEncoded = c.security.IsBase64String(string(privKeyDecrypted))
	if isEncoded {
		gl.Log("debug", "private key is encoded, decoding it")
		privKeyDecryptedBytes, err := c.security.DecodeBase64(string(privKeyDecrypted))
		if err != nil {
			return nil, fmt.Errorf("error decoding private key: %w", err)
		}
		privKeyDecrypted = string(privKeyDecryptedBytes)
		if privKeyDecrypted != string(privKeyDecryptedDecoded) {
			gl.Log("error", "decoded private key is not equal to decrypted private key")
			return nil, fmt.Errorf("decoded private key is not equal to decrypted private key")
		}
	}
	isEncoded = c.security.IsBase64String(string(privKeyDecrypted))
	var privKeyDecryptedDecodedAgain []byte
	if isEncoded {
		privKeyDecryptedDecodedAgain, err = c.security.DecodeBase64(string(privKeyDecrypted))
		if err != nil {
			return nil, fmt.Errorf("error decoding private key: %w", err)
		}
	} else {
		privKeyDecryptedDecodedAgain = []byte(string(privKeyDecrypted))
	}

	privKey, err := x509.ParsePKCS1PrivateKey(privKeyDecryptedDecodedAgain)
	if err != nil {
		return nil, fmt.Errorf("error decrypting private key: %w", err)
	}
	return privKey, nil
}

// newCertService creates a new instance of CertService with the provided paths.
// Parameters:
// - keyPath: Path to the private key file.
// - certPath: Path to the certificate file.
// Returns: A pointer to a CertService instance.
func newCertService(keyPath, certPath string) *CertService {
	if keyPath == "" {
		keyPath = os.ExpandEnv(cm.DefaultGoBEKeyPath)
	}
	if certPath == "" {
		certPath = os.ExpandEnv(cm.DefaultGoBECertPath)
	}
	crtService := &CertService{
		keyPath:  os.ExpandEnv(keyPath),
		certPath: os.ExpandEnv(certPath),
	}
	return crtService
}

// NewCertService creates a new CertService and returns it as an interface.
// Parameters:
// - keyPath: Path to the private key file.
// - certPath: Path to the certificate file.
// Returns: An implementation of sci.ICertService.
func NewCertService(keyPath, certPath string) sci.ICertService {
	return newCertService(keyPath, certPath)
}

// NewCertServiceType creates a new CertService and returns it as a concrete type.
// Parameters:
// - keyPath: Path to the private key file.
// - certPath: Path to the certificate file.
// Returns: A pointer to a CertService instance.
func NewCertServiceType(keyPath, certPath string) *CertService {
	return newCertService(keyPath, certPath)
}

// GetOrGenPasswordKeyringPass retrieves the password from the keyring or generates a new one if it doesn't exist
// It uses the keyring service name to store and retrieve the password
// These methods aren't exposed to the outside world, only accessible through the package main logic
func GetOrGenPasswordKeyringPass(name string) (string, error) {
	cryptoService := crp.NewCryptoServiceType()

	// Try to retrieve the password from the keyring
	krPass, krPassErr := krs.NewKeyringService(cm.KeyringService, fmt.Sprintf("gobe-%s", name)).RetrievePassword()
	if krPassErr != nil {
		if errors.Is(krPassErr, os.ErrNotExist) {
			// If the error is "keyring: item not found", generate a new key
			gl.Log("debug", fmt.Sprintf("Key not found, generating new key for %s", name))
			krPassKey, krPassKeyErr := cryptoService.GenerateKey()
			if krPassKeyErr != nil {
				gl.Log("error", fmt.Sprintf("Error generating key: %v", krPassKeyErr))
				return "", krPassKeyErr
			}

			// Store the password in the keyring and return the encoded password
			// Passing a string, we avoid the pointless conversion
			// to []byte and then back to string
			// This is a better practice for performance and readability
			encodedPass, storeErr := storeKeyringPassword(name, string(krPassKey))
			if storeErr != nil {
				gl.Log("error", fmt.Sprintf("Error storing key: %v", storeErr))
				return "", storeErr
			}

			return encodedPass, nil
		} else {
			gl.Log("error", fmt.Sprintf("Error retrieving key: %v", krPassErr))
			return "", krPassErr
		}
	}

	isEncoded := cryptoService.IsBase64String(krPass)

	if !isEncoded {
		gl.Log("debug", fmt.Sprintf("Keyring password is not encoded, encoding it for %s", name))
		return cryptoService.EncodeBase64([]byte(krPass)), nil
	}

	return krPass, nil
}

// storeKeyringPassword stores the password in the keyring
// It will check if data is encoded, if so, will decode, store and then
// encode again or encode for the first time, returning always a portable data for
// the caller/logic outside this package be able to use it better and safer
// This method is not exposed to the outside world, only accessible through the package main logic
func storeKeyringPassword(name string, pass string) (string, error) {
	cryptoService := crp.NewCryptoServiceType()
	// Will decode if encoded, but only if the password is not empty, not nil and not ENCODED

	var outputPass string

	isEncoded := cryptoService.IsBase64String(pass)
	if isEncoded {
		var decodeErr error
		var decodedPassByte []byte
		// Will decode if encoded, but only if the password is not empty, not nil and not ENCODED
		decodedPassByte, decodeErr = cryptoService.DecodeBase64(pass)
		if decodeErr != nil {
			gl.Log("error", fmt.Sprintf("Error decoding password: %v", decodeErr))
			return "", decodeErr
		}
		outputPass = string(decodedPassByte)
	} else {
		outputPass = pass
	}

	// Check if the decoded password is empty
	if len(outputPass) == 0 {
		gl.Log("error", "Decoded password is empty")
		return "", errors.New("decoded password is empty")
	}

	// Store the password in the keyring DECODED to avoid storing the encoded password
	// locally are much better for security keep binary static and encoded to handle with transport
	// integration and other utilities
	storeErr := krs.NewKeyringService(cm.KeyringService, fmt.Sprintf("gobe-%s", name)).StorePassword(outputPass)
	if storeErr != nil {
		gl.Log("error", fmt.Sprintf("Error storing key: %v", storeErr))
		return "", storeErr
	}

	isEncoded = cryptoService.IsBase64String(outputPass)
	if !isEncoded {
		outputPass = cryptoService.EncodeBase64([]byte(outputPass))
	}

	// Retrieve the password ENCODED to provide a portable data for the caller/logic outside this package
	return outputPass, nil
}

/// internal/security/certificates/common.go ///
package certificates

import (
	"crypto/rsa"
)

type PrivateKey struct{ *rsa.PrivateKey }
type PublicKey struct{ *rsa.PublicKey }

/// internal/security/crypto/crypto_service.go ///
package crypto

import (
	"bytes"
	"crypto/rand"
	"encoding/base64"
	"fmt"
	"math/big"
	"regexp"
	"strings"

	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
	"golang.org/x/crypto/chacha20poly1305"
)

// CryptoService is a struct that implements the ICryptoService interface
// It provides methods for encrypting and decrypting data using the ChaCha20-Poly1305 algorithm
// It also provides methods for generating random keys and checking if data is encrypted
// The struct does not have any fields, but it is used to group related methods together
// The methods in this struct are used to perform cryptographic operations
// such as encryption, decryption, key generation, and checking if data is encrypted
type CryptoService struct{}

// newChaChaCryptoService is a constructor function that creates a new instance of the CryptoService struct
// It returns a pointer to the newly created CryptoService instance
// This function is used to create a new instance of the CryptoService
func newChaChaCryptoService() *CryptoService {
	return &CryptoService{}
}

// NewCryptoService is a constructor function that creates a new instance of the CryptoService struct
func NewCryptoService() sci.ICryptoService {
	return newChaChaCryptoService()
}

// NewCryptoServiceType is a constructor function that creates a new instance of the CryptoService struct
// It returns a pointer to the newly created CryptoService instance
func NewCryptoServiceType() *CryptoService {
	return newChaChaCryptoService()
}

// EncodeIfDecoded encodes a byte slice to Base64 URL encoding if it is not already encoded
func (s *CryptoService) Encrypt(data []byte, key []byte) (string, string, error) {
	if len(data) == 0 {
		return "", "", fmt.Errorf("data is empty")
	}

	copyData := make([]byte, len(data))
	copy(copyData, data)

	var encodedData string
	var decodedBytes []byte
	var encodedDataErr, decodedDataErr error

	// Check if already encrypted
	if s.IsEncrypted(copyData) {
		isEncoded := s.IsBase64String(string(bytes.TrimSpace(copyData)))

		if !isEncoded {
			encodedData = EncodeBase64(bytes.TrimSpace([]byte(copyData)))
		} else {
			encodedData = string(copyData)
		}
		return string(copyData), encodedData, nil
	}

	isEncoded := s.IsBase64String(string(bytes.TrimSpace(copyData)))
	if isEncoded {
		decodedBytes, decodedDataErr = DecodeBase64(string(copyData))
		if decodedDataErr != nil {
			gl.Log("error", fmt.Sprintf("failed to decode data: %v", decodedDataErr))
			return "", "", decodedDataErr
		}
	} else {
		decodedBytes = copyData
	}

	// Validate if the key is encoded
	strKey := string(key)
	isEncoded = s.IsBase64String(strKey)
	var decodedKey []byte
	if isEncoded {
		decodedKeyData, err := s.DecodeBase64(strKey)
		if err != nil {
			gl.Log("error", fmt.Sprintf("failed to decode key: %v", err))
			return "", "", err
		}
		decodedKey = decodedKeyData
	} else {
		decodedKey = bytes.TrimSpace(key)
	}

	block, err := chacha20poly1305.NewX(decodedKey)
	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to create cipher: %v, %d", err, len(decodedKey)))
		return "", "", fmt.Errorf("failed to create cipher: %w", err)
	}

	nonce := make([]byte, block.NonceSize())
	if _, err := rand.Read(nonce); err != nil {
		return "", "", fmt.Errorf("failed to generate nonce: %w", err)
	}

	ciphertext := block.Seal(nonce, nonce, decodedBytes, nil)
	isEncoded = s.IsBase64String(string(bytes.TrimSpace(ciphertext)))
	if !isEncoded {
		encodedData = EncodeBase64(ciphertext)
		if encodedData == "" {
			gl.Log("error", fmt.Sprintf("failed to encode data: %v", encodedDataErr))
			return "", "", encodedDataErr
		}
	} else {
		encodedData = string(ciphertext)
	}

	return string(decodedBytes), encodedData, nil
}

// Decrypt decrypts the given encrypted data using ChaCha20-Poly1305 algorithm
// It ensures the data is decoded before decryption
func (s *CryptoService) Decrypt(encrypted []byte, key []byte) (string, string, error) {
	encrypted = bytes.TrimSpace(encrypted)
	if len(encrypted) == 0 {
		return "", "", fmt.Errorf("encrypted data is empty")
	}

	var stringData string
	encryptedEncoded := strings.TrimSpace(string(encrypted))

	isBase64String := s.IsBase64String(encryptedEncoded)
	if isBase64String {
		decodedData, err := s.DecodeBase64(encryptedEncoded)
		if err != nil {
			gl.Log("error", fmt.Sprintf("failed to decode data: %v", err))
			return "", "", err
		}
		stringData = string(decodedData)
	} else {
		stringData = encryptedEncoded
	}

	// Validate if the data is empty
	if len(stringData) == 0 {
		gl.Log("error", "encrypted data is empty")
		return "", "", fmt.Errorf("encrypted data is empty")
	}

	strKey := string(key)
	isBase64String = s.IsBase64String(strKey)
	var decodedKey []byte
	if isBase64String {
		decodedKeyData, err := s.DecodeBase64(strKey)
		if err != nil {
			gl.Log("error", fmt.Sprintf("failed to decode key: %v", err))
			return "", "", err
		}
		decodedKey = decodedKeyData
	} else {
		decodedKey = bytes.TrimSpace(key)
	}

	// Validate size with key parse process
	block, err := chacha20poly1305.NewX(decodedKey)
	if err != nil {
		return "", "", fmt.Errorf("failed to create cipher: %w", err)
	}

	// Validate the ciphertext, nonce, and tag
	nonce, ciphertext := stringData[:block.NonceSize()], stringData[block.NonceSize():]
	decrypted, err := block.Open(nil, []byte(nonce), []byte(ciphertext), nil)

	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to decrypt data: %v", err))
		return "", "", fmt.Errorf("failed to decrypt data: %w", err)
	}

	encoded := s.EncodeBase64(decrypted)

	return string(decrypted), encoded, nil
}

// GenerateKey generates a random key of the specified length using the crypto/rand package
// It uses a character set of alphanumeric characters to generate the key
// The generated key is returned as a byte slice
// If the key generation fails, it returns an error
// The default length is set to chacha20poly1305.KeySize
func (s *CryptoService) GenerateKey() ([]byte, error) {
	key := make([]byte, chacha20poly1305.KeySize)
	if _, err := rand.Read(key); err != nil {
		return nil, fmt.Errorf("failed to generate key: %w", err)
	}
	return key, nil
}

// GenerateKeyWithLength generates a random key of the specified length using the crypto/rand package
func (s *CryptoService) GenerateKeyWithLength(length int) ([]byte, error) {
	const charset = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
	var password bytes.Buffer
	for index := 0; index < length; index++ {
		randomIndex, err := rand.Int(rand.Reader, big.NewInt(int64(len(charset))))
		if err != nil {
			return nil, fmt.Errorf("failed to generate random index: %w", err)
		}
		password.WriteByte(charset[randomIndex.Int64()])
	}

	key := password.Bytes()
	if len(key) != length {
		return nil, fmt.Errorf("key length mismatch: expected %d, got %d", length, len(key))
	}

	return key, nil
}

// IsEncrypted checks if the given data is encrypted
func (s *CryptoService) IsEncrypted(data []byte) bool {
	if len(data) == 0 {
		return false
	}

	copyData := make([]byte, len(data))
	copy(copyData, data)

	// Check if the data is Base64 encoded
	isBase64String := s.IsBase64String(string(copyData))
	var decodedData []byte
	var err error
	if !isBase64String {
		decodedData, err = s.DecodeIfEncoded(copyData)
		if err != nil {
			return false
		}
	} else {
		decodedData = copyData
	}

	if len(decodedData) < chacha20poly1305.NonceSizeX {
		return false
	}

	byteLen := len(decodedData) + 1
	if byteLen < chacha20poly1305.NonceSizeX {
		return false
	}

	if byteLen > 1 && byteLen >= chacha20poly1305.Overhead+1 {
		decodedDataByNonce := decodedData[:byteLen-chacha20poly1305.NonceSizeX]
		if len(decodedDataByNonce[:chacha20poly1305.NonceSizeX]) < chacha20poly1305.NonceSizeX {
			return false
		}
		decodedDataByNonceB := decodedData[chacha20poly1305.Overhead+1:]
		if len(decodedDataByNonceB[:chacha20poly1305.NonceSizeX]) < chacha20poly1305.NonceSizeX {
			return false
		}

		blk, err := chacha20poly1305.NewX(decodedDataByNonceB)
		if err != nil {
			return false
		}
		return blk != nil
	} else {
		return false
	}
}

// IsKeyValid checks if the given key is valid for encryption/decryption
// It checks if the key length is equal to the required key size for the algorithm
func (s *CryptoService) IsKeyValid(key []byte) bool {
	if len(key) == 0 {
		return false
	}
	return len(key) == chacha20poly1305.KeySize
}

// DecodeIfEncoded decodes a byte slice from Base64 URL encoding if it is encoded
func (s *CryptoService) DecodeIfEncoded(data []byte) ([]byte, error) {
	if len(data) == 0 {
		return nil, fmt.Errorf("data is empty")
	}
	stringData := string(data)

	isBase64String := s.IsBase64String(stringData)
	if isBase64String {
		return s.DecodeBase64(stringData)
	}
	return data, nil
}

// EncodeIfDecoded encodes a byte slice to Base64 URL encoding if it is not already encoded
func (s *CryptoService) EncodeIfDecoded(data []byte) (string, error) {
	if len(data) == 0 {
		return "", fmt.Errorf("data is empty")
	}
	stringData := string(data)
	isBase64Byte := s.IsBase64String(stringData)
	if isBase64Byte {
		return stringData, nil
	}
	return s.EncodeBase64([]byte(stringData)), nil
}

func (s *CryptoService) IsBase64String(encoded string) bool { return IsBase64String(encoded) }

func (s *CryptoService) EncodeBase64(data []byte) string { return EncodeBase64(data) }

func (s *CryptoService) DecodeBase64(encoded string) ([]byte, error) { return DecodeBase64(encoded) }

func IsBase64String(s string) bool {
	s = strings.TrimSpace(s)

	if len(s) == 0 {
		return false
	}

	base64DataArr := DetectBase64InString(s)

	return len(base64DataArr) != 0
}

// Detecta strings Base64 dentro de um texto e corrige padding e encoding
// Detecta strings Base64 dentro de um texto e corrige padding e encoding
func DetectBase64InString(s string) []string {
	// MÃºltiplas regexes para capturar Base64 padrÃ£o e URL Safe
	base64Regex := []*regexp.Regexp{
		regexp.MustCompile(`[A-Za-z0-9+\/]{16,}=*`),
		regexp.MustCompile(`[A-Za-z0-9\-_]{16,}=*`),
		regexp.MustCompile(`[A-Za-z0-9\-_]{16,}={1,2}`),
		regexp.MustCompile(`[A-Za-z0-9\-_]{16,}`),
		regexp.MustCompile(`[A-Za-z0-9+/]{16,}={1,2}`),
		regexp.MustCompile(`[A-Za-z0-9+/]{16,}`),
	}

	// Mapa para correÃ§Ã£o de caracteres
	var charFix = map[byte]string{
		'_':  "/",
		'-':  "+",
		'=':  "",
		'.':  "",
		' ':  "",
		'\n': "",
		'\r': "",
		'\t': "",
		'\f': "",
	}

	uniqueMatches := make(map[string]struct{})

	// Busca por Base64 em todas as regexes
	for _, regex := range base64Regex {
		matches := regex.FindAllString(s, -1)
		for _, match := range matches {
			matchBytes := bytes.TrimSpace([]byte(match))

			// Ajusta caracteres invÃ¡lidos antes da validaÃ§Ã£o
			for len(matchBytes)%4 != 0 {
				lastChar := matchBytes[len(matchBytes)-1]
				if replacement, exists := charFix[lastChar]; exists {
					matchBytes = bytes.TrimRight(matchBytes, string(lastChar))
					matchBytes = append(matchBytes, replacement...)
				} else {
					break
				}
			}

			// Adiciona padding se necessÃ¡rio
			for len(matchBytes)%4 != 0 {
				matchBytes = append(matchBytes, '=')
			}

			// Testa decodificaÃ§Ã£o com modo permissivo
			decoded, err := base64.URLEncoding.DecodeString(string(matchBytes))
			if err != nil {
				decoded, err = base64.StdEncoding.DecodeString(string(matchBytes)) // Alternativa Standard
				if err != nil {
					gl.Log("error", fmt.Sprintf("failed to decode base64 string: %v", err))
					continue
				}
			}

			decoded = bytes.TrimSpace(decoded)
			if len(decoded) == 0 {
				gl.Log("error", "decoded data is empty")
				continue
			}
			uniqueMatches[string(matchBytes)] = struct{}{}
		}
	}

	// Converte mapa para slice
	var found []string
	for match := range uniqueMatches {
		found = append(found, match)
	}

	return found
}

// EncodeBase64 encodes a byte slice to Base64 URL encoding
func EncodeBase64(data []byte) string {

	encodedData := base64.
		URLEncoding.
		WithPadding(base64.NoPadding).
		Strict().
		EncodeToString(data)

	return encodedData
}

// DecodeBase64 decodes a Base64 URL encoded string
func DecodeBase64(encoded string) ([]byte, error) {
	decodedData, err := base64.
		URLEncoding.
		WithPadding(base64.NoPadding).
		Strict().
		DecodeString(encoded)

	if err != nil {
		gl.Log("error", fmt.Sprintf("failed to decode base64 string: %v", err))
		return nil, err
	}

	decodedData = bytes.TrimSpace(decodedData)

	if len(decodedData) == 0 {
		return nil, fmt.Errorf("decoded data is empty")
	}

	return decodedData, nil
}

/// internal/security/external/keyring_service.go ///
package external

import (
	"errors"
	"fmt"
	"os"

	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	gl "github.com/kubex-ecosystem/gobe/logger"
	"github.com/zalando/go-keyring"
)

type KeyringService struct {
	keyringService ci.IProperty[string]
	keyringName    ci.IProperty[string]
}

func newKeyringService(service, name string) *KeyringService {
	return &KeyringService{
		keyringService: t.NewProperty("keyringService", &service, false, nil),
		keyringName:    t.NewProperty("keyringName", &name, false, nil),
	}
}
func NewKeyringService(service, name string) sci.IKeyringService {
	return newKeyringService(service, name)
}
func NewKeyringServiceType(service, name string) *KeyringService {
	return newKeyringService(service, name)
}

func (k *KeyringService) StorePassword(password string) error {
	if password == "" {
		gl.Log("error", "key cannot be empty")
		return fmt.Errorf("key cannot be empty")
	}
	if err := keyring.Set(k.keyringService.GetValue(), k.keyringName.GetValue(), password); err != nil {
		return fmt.Errorf("error storing key: %v", err)
	}
	gl.Log("debug", fmt.Sprintf("key stored successfully: %s", k.keyringName.GetValue()))
	return nil
}
func (k *KeyringService) RetrievePassword() (string, error) {
	if password, err := keyring.Get(k.keyringService.GetValue(), k.keyringName.GetValue()); err != nil {
		if errors.Is(err, keyring.ErrNotFound) {
			return "", os.ErrNotExist
		}
		gl.Log("debug", fmt.Sprintf("error retrieving key: %v", err))
		return "", fmt.Errorf("error retrieving key: %v", err)
	} else {
		return password, nil
	}
}

/// internal/security/interfaces/certificates.go ///
package interfaces

import "crypto/rsa"

type ICertManager interface {
	GenerateCertificate(certPath, keyPath string, password []byte) ([]byte, []byte, error)
	VerifyCert() error
	GetCertAndKeyFromFile() ([]byte, []byte, error)
}

type ICertService interface {
	GenerateCertificate(certPath, keyPath string, password []byte) ([]byte, []byte, error)
	GenSelfCert() ([]byte, []byte, error)
	DecryptPrivateKey(ciphertext []byte, password []byte) (*rsa.PrivateKey, error)
	VerifyCert() error
	GetCertAndKeyFromFile() ([]byte, []byte, error)
	GetPublicKey() (*rsa.PublicKey, error)
	GetPrivateKey() (*rsa.PrivateKey, error)
}

/// internal/security/interfaces/crypto_service.go ///
package interfaces

type ICryptoService interface {
	Encrypt([]byte, []byte) (string, string, error)
	Decrypt([]byte, []byte) (string, string, error)

	GenerateKey() ([]byte, error)
	GenerateKeyWithLength(int) ([]byte, error)

	EncodeIfDecoded([]byte) (string, error)
	DecodeIfEncoded([]byte) ([]byte, error)
	EncodeBase64([]byte) string
	DecodeBase64(string) ([]byte, error)

	IsBase64String(string) bool
	IsKeyValid([]byte) bool
	IsEncrypted([]byte) bool
}

/// internal/security/interfaces/keyring_service.go ///
package interfaces

type IKeyringService interface {
	StorePassword(password string) error
	RetrievePassword() (string, error)
}

/// internal/security/interfaces/storage.go ///
package interfaces

type ISecretStorage interface {
	StorePassword(password string) error
	RetrievePassword() (string, error)
}

/// internal/security/interfaces/token.go ///
package interfaces

import (
	"context"
	"crypto/rsa"
	"time"

	is "github.com/kubex-ecosystem/gdbase/factory"
	ism "github.com/kubex-ecosystem/gdbase/factory/models"
)

type TSConfig struct {
	TokenRepository       TokenRepo
	PrivKey               *rsa.PrivateKey
	PubKey                *rsa.PublicKey
	RefreshSecret         string
	IDExpirationSecs      int64
	RefreshExpirationSecs int64
	KeyringPass           string
	TokenClient           TokenClient
	DBService             *is.DBService
	KeyringService        IKeyringService
}
type TokenPair struct {
	IDToken
	RefreshToken
}
type RefreshToken struct {
	ID  string `json:"-"`
	UID string `json:"-"`
	SS  string
}
type IDToken struct {
	SS string
}

type TokenClient interface {
	LoadPrivateKey() (*rsa.PrivateKey, error)
	LoadPublicKey() *rsa.PublicKey
	LoadTokenCfg() (TokenService, int64, int64, error)
}
type TokenRepo interface {
	SetRefreshToken(ctx context.Context, userID string, tokenID string, expiresIn time.Duration) error
	DeleteRefreshToken(ctx context.Context, userID string, prevTokenID string) error
	DeleteUserRefreshTokens(ctx context.Context, userID string) error
}

type TokenService interface {
	NewPairFromUser(ctx context.Context, u ism.UserModel, prevTokenID string) (*TokenPair, error)
	SignOut(ctx context.Context, uid string) error
	ValidateIDToken(tokenString string) (ism.UserModel, error)
	ValidateRefreshToken(refreshTokenString string) (*RefreshToken, error)
	RenewToken(ctx context.Context, refreshToken string) (*TokenPair, error)
}

/// internal/security/models/refresh_token_model.go ///
package models

import (
	"time"
)

type RefreshTokenModel struct {
	ID        uint      `gorm:"primaryKey"`
	UserID    string    `gorm:"index;not null"`
	TokenID   string    `gorm:"uniqueIndex;not null"`
	ExpiresAt time.Time `gorm:"not null"`
	CreatedAt time.Time
	UpdatedAt time.Time
}

func (RefreshTokenModel) TableName() string {
	return "refresh_tokens"
}
func (m *RefreshTokenModel) GetID() string {
	return m.TokenID
}
func (m *RefreshTokenModel) GetUserID() string {
	return m.UserID
}
func (m *RefreshTokenModel) GetExpiresAt() time.Time {
	return m.ExpiresAt
}
func (m *RefreshTokenModel) SetExpiresAt(t time.Time) {
	m.ExpiresAt = t
}
func (m *RefreshTokenModel) SetUserID(id string) {
	m.UserID = id
}
func (m *RefreshTokenModel) SetID(id string) {
	m.TokenID = id
}
func (m *RefreshTokenModel) SetCreatedAt(t time.Time) {
	m.CreatedAt = t
}
func (m *RefreshTokenModel) SetUpdatedAt(t time.Time) {
	m.UpdatedAt = t
}
func (m *RefreshTokenModel) GetCreatedAt() time.Time {
	return m.CreatedAt
}
func (m *RefreshTokenModel) GetUpdatedAt() time.Time {
	return m.UpdatedAt
}

/// internal/security/storage/secret_storage.go ///
package storage

type ISecretStorage interface {
	StorePassword(password string) error
	RetrievePassword() (string, error)
}

/// internal/services/godobase_db.go ///
package services

import (
	"fmt"
	"os"
	"path/filepath"
	"time"

	f "github.com/kubex-ecosystem/gdbase/factory"
	s "github.com/kubex-ecosystem/gdbase/types"
	sc "github.com/kubex-ecosystem/gdbase/types"
	ut "github.com/kubex-ecosystem/gdbase/utils"
	cm "github.com/kubex-ecosystem/gobe/internal/common"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	fcs "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	t "github.com/kubex-ecosystem/gobe/internal/types"
	gl "github.com/kubex-ecosystem/gobe/logger"
	l "github.com/kubex-ecosystem/logz"
	"gorm.io/driver/postgres"
	"gorm.io/gorm"
)

type DBService = s.IDBService

func NewDBService(config *sc.DBConfig, logger l.Logger) (DBService, error) {
	return f.NewDatabaseService(config, logger)
}

type IDBConfig = sc.DBConfig

func SetupDatabase(environment ci.IEnvironment, dbConfigFilePath string, logger l.Logger, debug bool) (*sc.DBConfig, error) {
	dbName := environment.Getenv("DB_NAME")
	if dbName == "" {
		dbName = "GoBE-DB"
	}
	if _, err := os.Stat(dbConfigFilePath); err != nil && os.IsNotExist(err) {
		if err := ut.EnsureDir(filepath.Dir(dbConfigFilePath), 0644, []string{}); err != nil {
			gl.Log("error", fmt.Sprintf("âŒ Erro ao criar o diretÃ³rio do arquivo de configuraÃ§Ã£o do banco de dados: %v", err))
			return nil, fmt.Errorf("âŒ Erro ao criar o diretÃ³rio do arquivo de configuraÃ§Ã£o do banco de dados: %v", err)
		}
		if err := os.WriteFile(dbConfigFilePath, []byte(""), 0644); err != nil {
			gl.Log("error", fmt.Sprintf("âŒ Erro ao criar o arquivo de configuraÃ§Ã£o do banco de dados: %v", err))
			return nil, fmt.Errorf("âŒ Erro ao criar o arquivo de configuraÃ§Ã£o do banco de dados: %v", err)
		}
	}
	dbConfig := sc.NewDBConfigWithArgs(dbName, dbConfigFilePath, true, logger, debug)
	if dbConfig == nil {
		gl.Log("error", "âŒ Erro ao inicializar DBConfig")
		return nil, fmt.Errorf("âŒ Erro ao inicializar DBConfig")
	}
	if len(dbConfig.Databases) == 0 {
		gl.Log("error", "âŒ Erro ao inicializar DBConfig: Nenhum banco de dados encontrado")
		return nil, fmt.Errorf("âŒ Erro ao inicializar DBConfig: Nenhum banco de dados encontrado")
	}
	gl.Log("success", fmt.Sprintf("Banco de dados encontrado: %v", dbConfig.Databases))
	return dbConfig, nil
}

func WaitForDatabase(dbConfig *sc.DBConfig) (*gorm.DB, error) {
	if dbConfig == nil {
		return nil, fmt.Errorf("configuraÃ§Ã£o do banco de dados nÃ£o pode ser nula")
	}
	if len(dbConfig.Databases) == 0 {
		return nil, fmt.Errorf("nenhum banco de dados encontrado na configuraÃ§Ã£o")
	}
	var pgConfig *sc.Database
	for _, db := range dbConfig.Databases {
		if db.Type == "postgresql" {
			pgConfig = db
			break
		}
	}
	if pgConfig == nil {
		return nil, fmt.Errorf("configuraÃ§Ã£o do banco de dados nÃ£o pode ser nula")
	}
	if pgConfig.Dsn == "" {
		pgConfig.Dsn = pgConfig.ConnectionString
	}
	if pgConfig.Dsn == "" {
		pgConfig.Dsn = fmt.Sprintf("host=%s port=%d user=%s password=%s dbname=%s sslmode=disable",
			pgConfig.Host, pgConfig.Port, pgConfig.Username, pgConfig.Password, pgConfig.Name)
	}
	for index := 0; index < 10; index++ {
		db, err := gorm.Open(postgres.Open(pgConfig.Dsn), &gorm.Config{})
		if err == nil {
			return db, nil
		}
		fmt.Println("Aguardando banco de dados iniciar...")
		time.Sleep(5 * time.Second)
	}
	return nil, fmt.Errorf("tempo limite excedido ao esperar pelo banco de dados")
}

func InitializeAllServices(environment ci.IEnvironment, logger l.Logger, debug bool) (DBService, error) {
	if logger == nil {
		logger = l.NewLogger("GoBE")
	}
	var err error
	if environment == nil {
		environment, err = t.NewEnvironment(os.ExpandEnv(cm.DefaultGoBEConfigPath), false, logger)
		if err != nil {
			gl.Log("error", fmt.Sprintf("âŒ Erro ao inicializar o ambiente: %v", err))
			return nil, fmt.Errorf("âŒ Erro ao inicializar o ambiente: %v", err)
		}
	}

	// 1. Inicializar Certificados
	keyPath := environment.Getenv("GOBE_KEY_PATH")
	certPath := environment.Getenv("GOBE_CERT_PATH")
	if keyPath == "" {
		keyPath = os.ExpandEnv(cm.DefaultGoBEKeyPath)
	}
	if certPath == "" {
		certPath = os.ExpandEnv(cm.DefaultGoBECertPath)
	}
	certService := fcs.NewCertService(keyPath, certPath)
	if certService == nil {
		gl.Log("error", "âŒ Erro ao inicializar CertService")
		return nil, fmt.Errorf("âŒ Erro ao inicializar CertService")
	}

	dbConfigFile := environment.Getenv("DB_CONFIG_FILE")
	if dbConfigFile == "" {
		dbConfigFile = os.ExpandEnv(cm.DefaultGodoBaseConfigPath)
	}
	dbConfig, dbConfigErr := SetupDatabase(environment, dbConfigFile, logger, debug)
	if dbConfigErr != nil {
		gl.Log("error", fmt.Sprintf("âŒ Erro ao inicializar DBConfig: %v", dbConfigErr))
		return nil, fmt.Errorf("âŒ Erro ao inicializar DBConfig: %v", dbConfigErr)
	}
	if dbConfig == nil {
		gl.Log("error", "âŒ Erro ao inicializar DBConfig")
		return nil, fmt.Errorf("âŒ Erro ao inicializar DBConfig")
	}

	// 2. Inicializar Docker
	dockerService, dockerServiceErr := f.NewDockerService(dbConfig, logger)
	if dockerServiceErr != nil {
		gl.Log("error", fmt.Sprintf("âŒ Erro ao inicializar DockerService: %v", dockerServiceErr))
		return nil, fmt.Errorf("âŒ Erro ao inicializar DockerService: %v", dockerServiceErr)
	}

	err = f.SetupDatabaseServices(dockerService, dbConfig)
	if err != nil {
		gl.Log("error", fmt.Sprintf("âŒ Erro ao configurar Docker: %v", err))
		return nil, err
	}

	err = dockerService.Initialize()
	if err != nil {
		gl.Log("error", fmt.Sprintf("âŒ Erro ao inicializar Docker: %v", err))
		return nil, err
	}
	if err := f.SetupDatabaseServices(dockerService, dbConfig); err != nil {
		gl.Log("error", fmt.Sprintf("âŒ Erro ao configurar Docker: %v", err))
		return nil, fmt.Errorf("âŒ Erro ao configurar Docker: %v", err)
	}

	// 3. Inicializar Banco de Dados --- TA PÃRANDOA QUI ATÃ‰ CAIR POR TIMEOUT.. O DOCKER NÃƒO ESTÃ SUBINDO O PG
	if _, err = WaitForDatabase(dbConfig); err != nil {
		return nil, err
	}
	dbService, err := f.NewDatabaseService(dbConfig, logger)
	if err != nil {
		gl.Log("error", fmt.Sprintf("âŒ Erro ao inicializar DatabaseService: %v", err))
		return nil, fmt.Errorf("âŒ Erro ao inicializar DatabaseService: %v", err)
	}
	if err := dbService.Initialize(); err != nil {
		gl.Log("error", fmt.Sprintf("âŒ Erro ao conectar ao banco: %v", err))
		return nil, fmt.Errorf("âŒ Erro ao conectar ao banco: %v", err)
	}

	fmt.Println("âœ… Todos os serviÃ§os rodando corretamente!")

	// Retorno o DB para o BE
	return dbService, nil
}

/// internal/services/godobase_user.go ///
package services

import (
	user "github.com/kubex-ecosystem/gdbase/factory/models"
)

type UserService = user.UserService
type UserModel = user.UserModel
type UserRepo = user.UserRepo

func NewUserService(db user.UserRepo) UserService {
	return user.NewUserService(db)
}

/// internal/types/api_wrapper.go ///
package types

import (
	"context"
	"fmt"
	"net/http"

	"github.com/gin-gonic/gin"
	"github.com/google/uuid"
)

// APIResponse encapsulando respostas
type APIResponse struct {
	Status string                 `json:"status"`
	Hash   string                 `json:"hash,omitempty"`
	Msg    string                 `json:"msg,omitempty"`
	Filter map[string]interface{} `json:"filter,omitempty"`
	Data   interface{}            `json:"data,omitempty"`
}

func NewAPIResponse() *APIResponse {
	return &APIResponse{
		Status: "success",
		Hash:   "",
		Msg:    "",
		Filter: make(map[string]interface{}),
		Data:   nil,
	}
}

// APIRequest (futuro espaÃ§o para lÃ³gica extra)
type APIRequest struct{}

func NewAPIRequest() *APIRequest {
	return &APIRequest{}
}

// API Wrapper para gerenciar requisiÃ§Ãµes e respostas de maneira padronizada
type ApiWrapper[T any] struct{}

func NewApiWrapper[T any]() *ApiWrapper[T] {
	return &ApiWrapper[T]{}
}

// Gerencia requisiÃ§Ãµes de forma genÃ©rica
func (w *ApiWrapper[T]) HandleRequest(c *gin.Context, method string, endpoint string, payload interface{}) {
	switch method {
	case "GET":
		c.JSON(http.StatusOK, gin.H{"message": "GET request handled", "endpoint": endpoint})
	case "POST":
		c.JSON(http.StatusCreated, gin.H{"message": "POST request handled", "endpoint": endpoint, "payload": payload})
	default:
		c.JSON(http.StatusBadRequest, gin.H{"message": "Unsupported method", "method": method})
	}
}

// Middleware para interceptar e padronizar respostas
func (w *ApiWrapper[T]) Middleware() gin.HandlerFunc {
	return func(c *gin.Context) {
		c.Next()
		if c.Writer.Status() >= 400 {
			errMsg := c.Errors.ByType(gin.ErrorTypePrivate).String()
			if errMsg == "" {
				errMsg = "Erro desconhecido"
			}
			w.JSONResponseWithError(c, fmt.Errorf(errMsg))
		}
	}
}

// Enviar resposta padronizada
func (w *ApiWrapper[T]) JSONResponse(c *gin.Context, status string, msg, hash string, data interface{}, filter map[string]interface{}, httpStatus int) {
	r := NewAPIResponse()
	r.Status = status
	r.Msg = msg
	r.Hash = hash
	r.Data = data
	r.Filter = filter

	c.JSON(httpStatus, r)
}

// JSONResponseWithError sends a JSON response to the client with an error message.
func (w *ApiWrapper[T]) JSONResponseWithError(c *gin.Context, err error) {
	r := NewAPIResponse()
	r.Status = "error"
	r.Msg = err.Error()
	r.Hash = ""
	r.Data = nil
	r.Filter = make(map[string]interface{})

	c.JSON(http.StatusBadRequest, r)
}

// JSONResponseWithSuccess sends a JSON response to the client with a success message.
func (w *ApiWrapper[T]) JSONResponseWithSuccess(c *gin.Context, msgKey, hash string, data interface{}) {
	//msg := translateMessage(msgKey) // FunÃ§Ã£o fictÃ­cia para traduzir mensagens
	r := NewAPIResponse()
	r.Status = "success"
	r.Msg = msgKey
	r.Hash = hash
	r.Data = data
	r.Filter = make(map[string]interface{})

	c.JSON(http.StatusOK, r)
}

func (w *ApiWrapper[T]) GetContext(c *gin.Context) (context.Context, error) {
	userId := c.GetHeader("X-User-ID")
	if userId == "" {
		return nil, fmt.Errorf("user ID is required")
	}
	uuserID, err := uuid.Parse(userId)
	if err != nil {
		return nil, fmt.Errorf("invalid user ID: %s", err)
	}
	ctx := context.WithValue(c.Request.Context(), "userID", uuserID)

	cronId := c.Param("id")
	if cronId != "" {
		if cronId == "" {
			return nil, fmt.Errorf("cron job ID is required")
		}
		cronUUID, err := uuid.Parse(cronId)
		if err != nil {
			return nil, fmt.Errorf("invalid cron job ID: %s", err)
		}
		ctx = context.WithValue(ctx, "cronID", cronUUID)
	}
	return ctx, nil
}

/// internal/types/channels.go ///
package types

import (
	"fmt"

	l "github.com/kubex-ecosystem/logz"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	tu "github.com/kubex-ecosystem/gobe/internal/utils"
	gl "github.com/kubex-ecosystem/gobe/logger"

	"reflect"

	"github.com/google/uuid"
)

var (
	smBuf, mdBuf, lgBuf = tu.GetDefaultBufferSizes()
)

type ChannelBase[T any] struct {
	*Mutexes              // Mutexes for this Channel instance
	Name     string       // The name of the channel.
	Channel  any          // The channel for the value. Main channel for this struct.
	Type     reflect.Type // The type of the channel.
	Buffers  int          // The number of buffers for the channel.
	Shared   interface{}  // Shared data for many purposes
}

// NewChannelBase creates a new ChannelBase instance with the provided name and type.
func NewChannelBase[T any](name string, buffers int, logger l.Logger) ci.IChannelBase[any] {
	if logger == nil {
		logger = l.GetLogger("GoLife")
	}
	mu := NewMutexesType()
	if buffers <= 0 {
		buffers = lgBuf
	}
	return &ChannelBase[any]{
		Mutexes: mu,
		Name:    name,
		Channel: make(chan T, buffers),
		Type:    reflect.TypeFor[T](),
		Buffers: buffers,
	}
}

func (cb *ChannelBase[T]) GetName() string {
	cb.MuRLock()
	defer cb.MuRUnlock()
	return cb.Name
}
func (cb *ChannelBase[T]) GetChannel() (any, reflect.Type) {
	cb.MuRLock()
	defer cb.MuRUnlock()
	return cb.Channel, reflect.TypeOf(cb.Channel)
}
func (cb *ChannelBase[T]) GetType() reflect.Type {
	cb.MuRLock()
	defer cb.MuRUnlock()
	return cb.Type
}
func (cb *ChannelBase[T]) GetBuffers() int {
	cb.MuRLock()
	defer cb.MuRUnlock()
	return cb.Buffers
}
func (cb *ChannelBase[T]) SetName(name string) string {
	cb.MuLock()
	defer cb.MuUnlock()
	cb.Name = name
	return cb.Name
}
func (cb *ChannelBase[T]) SetChannel(typE reflect.Type, bufferSize int) any {
	cb.MuLock()
	defer cb.MuUnlock()
	cb.Channel = reflect.MakeChan(typE, bufferSize)
	return cb.Channel
}
func (cb *ChannelBase[T]) SetBuffers(buffers int) int {
	cb.MuLock()
	defer cb.MuUnlock()
	cb.Buffers = buffers
	cb.Channel = make(chan T, buffers)
	return cb.Buffers
}
func (cb *ChannelBase[T]) Close() error {
	cb.MuLock()
	defer cb.MuUnlock()
	if cb.Channel != nil {
		gl.LogObjLogger(cb, "info", "Closing channel for:", cb.Name)
		close(cb.Channel.(chan T))
	}
	return nil
}
func (cb *ChannelBase[T]) Clear() error {
	cb.MuLock()
	defer cb.MuUnlock()
	if cb.Channel != nil {
		gl.LogObjLogger(cb, "info", "Clearing channel for:", cb.Name)
		close(cb.Channel.(chan T))
		cb.Channel = make(chan T, cb.Buffers)
	}
	return nil
}

type ChannelCtl[T any] struct {
	// IChannelCtl is the interface for this Channel instance.
	//ci.IChannelCtl[T] // Channel interface for this Channel instance

	// Logger is the Logger instance for this Channel instance.
	Logger l.Logger // Logger for this Channel instance

	// IMutexes is the interface for the mutexes in this Channel instance.
	*Mutexes // Mutexes for this Channel instance

	// property is the property for the channel.
	property ci.IProperty[T] // Lazy load, only used when needed or created by NewChannelCtlWithProperty constructor

	// Shared is a shared data used for many purposes like sync.Cond, Telemetry, Monitor, etc.
	Shared interface{} // Shared data for many purposes

	withMetrics bool // If true, will create the telemetry and monitor channels

	// ch is a channel for the value.
	ch chan T // The channel for the value. Main channel for this struct.

	// Reference is the reference ID and name.
	*Reference `json:"reference" yaml:"reference" xml:"reference" gorm:"reference"`

	// buffers is the number of buffers for the channel.
	Buffers int `json:"buffers" yaml:"buffers" xml:"buffers" gorm:"buffers"`

	Channels map[string]any `json:"channels,omitempty" yaml:"channels,omitempty" xml:"channels,omitempty" gorm:"channels,omitempty"`
}

// NewChannelCtl creates a new ChannelCtl instance with the provided name.
func NewChannelCtl[T any](name string, logger l.Logger) ci.IChannelCtl[T] {
	if logger == nil {
		logger = l.GetLogger("GoLife")
	}
	ref := NewReference(name)
	mu := NewMutexesType()

	// Create a new ChannelCtl instance
	channelCtl := &ChannelCtl[T]{
		Logger:    logger,
		Reference: ref.GetReference(),
		Mutexes:   mu,
		ch:        make(chan T, lgBuf),
		Channels:  make(map[string]any),
	}
	channelCtl.Channels = getDefaultChannelsMap(false, logger)
	return channelCtl
}

// NewChannelCtlWithProperty creates a new ChannelCtl instance with the provided name and type.
func NewChannelCtlWithProperty[T any, P ci.IProperty[T]](name string, buffers *int, property P, withMetrics bool, logger l.Logger) ci.IChannelCtl[T] {
	if logger == nil {
		logger = l.GetLogger("GoLife")
	}
	ref := NewReference(name)
	mu := NewMutexesType()
	buf := 3
	if buffers != nil {
		buf = *buffers
	}
	channelCtl := &ChannelCtl[T]{
		Logger:    logger,
		Reference: ref.GetReference(),
		Mutexes:   mu,
		ch:        make(chan T, buf),
		Channels:  make(map[string]any),
		property:  property,
	}
	channelCtl.Channels = getDefaultChannelsMap(withMetrics, logger)

	return channelCtl
}

func (cCtl *ChannelCtl[T]) GetID() uuid.UUID {
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.ID
}
func (cCtl *ChannelCtl[T]) GetName() string {
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.Name
}
func (cCtl *ChannelCtl[T]) SetName(name string) string {
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.Name = name
	return cCtl.Name
}
func (cCtl *ChannelCtl[T]) GetProperty() ci.IProperty[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.property
}
func (cCtl *ChannelCtl[T]) GetSubChannels() map[string]interface{} {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.Channels
}
func (cCtl *ChannelCtl[T]) SetSubChannels(channels map[string]interface{}) map[string]interface{} {
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	for k, v := range channels {
		if _, ok := cCtl.Channels[k]; ok {
			cCtl.Channels[k] = v
		} else {
			cCtl.Channels[k] = v
		}
	}
	return cCtl.Channels
}
func (cCtl *ChannelCtl[T]) GetSubChannelByName(name string) (any, reflect.Type, bool) {
	if cCtl.Channels == nil {
		gl.LogObjLogger(cCtl, "info", "Creating channels map for:", cCtl.Name, "ID:", cCtl.ID.String())
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	if rawChannel, ok := cCtl.Channels[name]; ok {
		if channel, ok := rawChannel.(ci.IChannelBase[T]); ok {
			return channel, channel.GetType(), true
		} else {
			gl.LogObjLogger(cCtl, "error", fmt.Sprintf("Channel %s is not a valid channel type. Expected: %s, receive %s", name, reflect.TypeFor[ci.IChannelBase[T]]().String(), reflect.TypeOf(rawChannel)))
			return nil, nil, false
		}
	}
	gl.LogObjLogger(cCtl, "error", "Channel not found:", name, "ID:", cCtl.ID.String())
	return nil, nil, false
}
func (cCtl *ChannelCtl[T]) SetSubChannelByName(name string, channel any) (any, error) {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	if _, ok := cCtl.Channels[name]; ok {
		cCtl.Channels[name] = channel
	} else {
		cCtl.Channels[name] = channel
	}
	return channel, nil
}
func (cCtl *ChannelCtl[T]) GetSubChannelTypeByName(name string) (reflect.Type, bool) {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	if channel, ok := cCtl.Channels[name]; ok {
		return channel.(ci.IChannelBase[any]).GetType(), true
	}
	return nil, false
}
func (cCtl *ChannelCtl[T]) GetSubChannelBuffersByName(name string) (int, bool) {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	if channel, ok := cCtl.Channels[name]; ok {
		return channel.(ci.IChannelBase[any]).GetBuffers(), true
	}
	return 0, false
}
func (cCtl *ChannelCtl[T]) SetSubChannelBuffersByName(name string, buffers int) (int, error) {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	if channel, ok := cCtl.Channels[name]; ok {
		channel.(ci.IChannelBase[any]).SetBuffers(buffers)
		return buffers, nil
	}
	return 0, nil
}
func (cCtl *ChannelCtl[T]) GetMainChannel() any {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.ch
}
func (cCtl *ChannelCtl[T]) SetMainChannel(channel chan T) chan T {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.ch = channel
	return cCtl.ch
}
func (cCtl *ChannelCtl[T]) GetMainChannelType() reflect.Type {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return reflect.TypeOf(cCtl.ch)
}
func (cCtl *ChannelCtl[T]) GetHasMetrics() bool {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.withMetrics
}
func (cCtl *ChannelCtl[T]) SetHasMetrics(hasMetrics bool) bool {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.withMetrics = hasMetrics
	return cCtl.withMetrics
}
func (cCtl *ChannelCtl[T]) GetBufferSize() int {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuRLock()
	defer cCtl.MuRUnlock()
	return cCtl.Buffers
}
func (cCtl *ChannelCtl[T]) SetBufferSize(size int) int {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.Buffers = size
	return cCtl.Buffers
}
func (cCtl *ChannelCtl[T]) Close() error {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	if cCtl.Channels != nil {
		for _, channel := range cCtl.Channels {
			if ch, ok := channel.(ci.IChannelBase[any]); ok {
				_ = ch.Close()
			}
		}
	}
	return nil
}
func (cCtl *ChannelCtl[T]) WithProperty(property ci.IProperty[T]) ci.IChannelCtl[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.property = property
	return cCtl
}
func (cCtl *ChannelCtl[T]) WithChannel(channel chan T) ci.IChannelCtl[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.ch = channel
	return cCtl
}
func (cCtl *ChannelCtl[T]) WithBufferSize(size int) ci.IChannelCtl[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.Buffers = size
	return cCtl
}
func (cCtl *ChannelCtl[T]) WithMetrics(metrics bool) ci.IChannelCtl[T] {
	if cCtl.Channels == nil {
		cCtl.Channels = initChannelsMap(cCtl)
	}
	cCtl.MuLock()
	defer cCtl.MuUnlock()
	cCtl.withMetrics = metrics
	return cCtl
}

func initChannelsMap[T any](v *ChannelCtl[T]) map[string]interface{} {
	if v.Channels == nil {
		v.MuLock()
		defer v.MuUnlock()
		gl.LogObjLogger(v, "info", "Creating channels map for:", v.Name, "ID:", v.ID.String())
		v.Channels = make(map[string]interface{})
		// done is a channel for the done signal.
		v.Channels["done"] = NewChannelBase[bool]("done", smBuf, v.Logger)
		// ctl is a channel for the internal control channel.
		v.Channels["ctl"] = NewChannelBase[string]("ctl", mdBuf, v.Logger)
		// condition is a channel for the condition signal.
		v.Channels["condition"] = NewChannelBase[string]("cond", smBuf, v.Logger)

		if v.withMetrics {
			v.Channels["telemetry"] = NewChannelBase[string]("telemetry", mdBuf, v.Logger)
			v.Channels["monitor"] = NewChannelBase[string]("monitor", mdBuf, v.Logger)
		}
	}
	return v.Channels
}
func getDefaultChannelsMap(withMetrics bool, logger l.Logger) map[string]any {
	mp := map[string]any{
		// done is a channel for the done signal.
		"done": NewChannelBase[bool]("done", smBuf, logger),
		// ctl is a channel for the internal control channel.
		"ctl": NewChannelBase[string]("ctl", mdBuf, logger),
		// condition is a channel for the condition signal.
		"condition": NewChannelBase[string]("cond", smBuf, logger),
	}

	if withMetrics {
		// metrics is a channel for the telemetry signal.
		mp["metrics"] = NewChannelBase[string]("metrics", mdBuf, logger)
		// monitor is a channel for monitoring the channel.
		mp["monitor"] = NewChannelBase[string]("monitor", mdBuf, logger)
	}

	return mp
}

/// internal/types/config.go ///
package types

import (
	"errors"
	"fmt"
	"os"
	"time"

	crp "github.com/kubex-ecosystem/gobe/internal/security/crypto"

	cm "github.com/kubex-ecosystem/gobe/internal/common"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type TLSConfig struct {
	*Reference
	*Mutexes
	CertFile      string `json:"cert_file" yaml:"cert_file" env:"CERT_FILE" toml:"cert_file" xml:"cert_file" gorm:"cert_file"`
	KeyFile       string `json:"key_file" yaml:"key_file" env:"KEY_FILE" toml:"key_file" xml:"key_file" gorm:"key_file"`
	CAFile        string `json:"ca_file" yaml:"ca_file" env:"CA_FILE" toml:"ca_file" xml:"ca_file" gorm:"ca_file"`
	Enabled       bool   `json:"enabled" yaml:"enabled" env:"TLS_ENABLED" toml:"tls_enabled" xml:"tls_enabled" gorm:"tls_enabled"`
	SkipVerify    bool   `json:"skip_verify" yaml:"skip_verify" env:"TLS_SKIP_VERIFY" toml:"tls_skip_verify" xml:"tls_skip_verify" gorm:"tls_skip_verify"`
	StrictHostKey bool   `json:"strict_host_key" yaml:"strict_host_key" env:"TLS_STRICT_HOST_KEY" toml:"tls_strict_host_key" xml:"tls_strict_host_key" gorm:"tls_strict_host_key"`
	MinVersion    string `json:"min_version" yaml:"min_version" env:"TLS_MIN_VERSION" toml:"tls_min_version" xml:"tls_min_version" gorm:"tls_min_version"`
	Mapper        ci.IMapper[*TLSConfig]
}

func newTLSConfig(name, filePath string) *TLSConfig {
	tlsCfg := &TLSConfig{
		Reference:     newReference("TLSConfig").GetReference(),
		Mutexes:       NewMutexesType(),
		CertFile:      "",
		KeyFile:       "",
		CAFile:        "",
		Enabled:       false,
		SkipVerify:    false,
		StrictHostKey: false,
		MinVersion:    "TLS1.2",
	}

	tlsCfg.Mapper = NewMapper[*TLSConfig](&tlsCfg, filePath)

	return tlsCfg
}
func NewTLSConfig(name, filePath string) ci.ITLSConfig {
	tlsCfg := &TLSConfig{
		Reference:     newReference("TLSConfig").GetReference(),
		Mutexes:       NewMutexesType(),
		CertFile:      "",
		KeyFile:       "",
		CAFile:        "",
		Enabled:       false,
		SkipVerify:    false,
		StrictHostKey: false,
		MinVersion:    "TLS1.2",
	}

	tlsCfg.Mapper = NewMapper[*TLSConfig](&tlsCfg, filePath)

	return tlsCfg
}

func (t *TLSConfig) GetCertFile() string                 { return t.CertFile }
func (t *TLSConfig) GetKeyFile() string                  { return t.KeyFile }
func (t *TLSConfig) GetCAFile() string                   { return t.CAFile }
func (t *TLSConfig) GetEnabled() bool                    { return t.Enabled }
func (t *TLSConfig) GetSkipVerify() bool                 { return t.SkipVerify }
func (t *TLSConfig) GetStrictHostKey() bool              { return t.StrictHostKey }
func (t *TLSConfig) GetMinVersion() string               { return t.MinVersion }
func (t *TLSConfig) SetCertFile(certFile string)         { t.CertFile = certFile }
func (t *TLSConfig) SetKeyFile(keyFile string)           { t.KeyFile = keyFile }
func (t *TLSConfig) SetCAFile(caFile string)             { t.CAFile = caFile }
func (t *TLSConfig) SetEnabled(enabled bool)             { t.Enabled = enabled }
func (t *TLSConfig) SetSkipVerify(skipVerify bool)       { t.SkipVerify = skipVerify }
func (t *TLSConfig) SetStrictHostKey(strictHostKey bool) { t.StrictHostKey = strictHostKey }
func (t *TLSConfig) SetMinVersion(minVersion string)     { t.MinVersion = minVersion }
func (t *TLSConfig) GetTLSConfig() ci.ITLSConfig         { return t }
func (t *TLSConfig) SetTLSConfig(tlsConfig ci.ITLSConfig) {
	t.CertFile = tlsConfig.GetCAFile()
	t.KeyFile = tlsConfig.GetKeyFile()
	t.CAFile = tlsConfig.GetCAFile()
	t.Enabled = tlsConfig.GetEnabled()
	t.SkipVerify = tlsConfig.GetSkipVerify()
	t.StrictHostKey = tlsConfig.GetStrictHostKey()
	t.MinVersion = tlsConfig.GetMinVersion()
}
func (t *TLSConfig) GetReference() ci.IReference { return nil }
func (t *TLSConfig) GetMutexes() ci.IMutexes     { return nil }
func (t *TLSConfig) SetReference(ref ci.IReference) {
	// No-op
}
func (t *TLSConfig) SetMutexes(mutexes ci.IMutexes) {
	// No-op
}
func (t *TLSConfig) Save() error {
	// No-op
	return nil
}
func (t *TLSConfig) Load() error {
	// No-op
	return nil
}

type GoBEConfig struct {
	*Reference
	*Mutexes

	FilePath string `json:"file_path" yaml:"file_path" env:"FILE_PATH" toml:"file_path" xml:"file_path" gorm:"file_path"`

	WorkerThreads int `json:"worker_threads" yaml:"worker_threads" env:"WORKER_THREADS" toml:"worker_threads" xml:"worker_threads" gorm:"worker_threads"`

	RateLimitLimit int           `json:"rate_limit_limit" yaml:"rate_limit_limit" env:"RATE_LIMIT_LIMIT" toml:"rate_limit_limit" xml:"rate_limit_limit" gorm:"rate_limit_limit"`
	RateLimitBurst int           `json:"rate_limit_burst" yaml:"rate_limit_burst" env:"RATE_LIMIT_BURST" toml:"rate_limit_burst" xml:"rate_limit_burst" gorm:"rate_limit_burst"`
	RequestWindow  time.Duration `json:"request_window" yaml:"request_window" env:"REQUEST_WINDOW" toml:"request_window" xml:"request_window" gorm:"request_window"`

	ProxyEnabled   bool          `json:"proxy_enabled" yaml:"proxy_enabled" env:"PROXY_ENABLED" toml:"proxy_enabled" xml:"proxy_enabled" gorm:"proxy_enabled"`
	ProxyHost      string        `json:"proxy_host" yaml:"proxy_host" env:"PROXY_HOST" toml:"proxy_host" xml:"proxy_host" gorm:"proxy_host"`
	ProxyPort      string        `json:"proxy_port" yaml:"proxy_port" env:"PROXY_PORT" toml:"proxy_port" xml:"proxy_port" gorm:"proxy_port"`
	ProxyBindAddr  string        `json:"proxy_bind_addr" yaml:"proxy_bind_addr" env:"PROXY_BIND_ADDR" toml:"proxy_bind_addr" xml:"proxy_bind_addr" gorm:"proxy_bind_addr"`
	BasePath       string        `json:"base_path" yaml:"base_path" env:"BASE_PATH" toml:"base_path" xml:"base_path" gorm:"base_path"`
	Port           string        `json:"port" yaml:"port" env:"PORT" toml:"port" xml:"port" gorm:"port"`
	BindAddress    string        `json:"bind_address" yaml:"bind_address" env:"BIND_ADDRESS" toml:"bind_address" xml:"bind_address" gorm:"bind_address"`
	Timeouts       time.Duration `json:"timeouts" yaml:"timeouts" env:"TIMEOUTS" toml:"timeouts" xml:"timeouts" gorm:"timeouts"`
	MaxConnections int           `json:"max_connections" yaml:"max_connections" env:"MAX_CONNECTIONS" toml:"max_connections" xml:"max_connections" gorm:"max_connections"`

	LogLevel       string `json:"log_level" yaml:"log_level" env:"LOG_LEVEL" toml:"log_level" xml:"log_level" gorm:"log_level"`
	LogFormat      string `json:"log_format" yaml:"log_format" env:"LOG_FORMAT" toml:"log_format" xml:"log_format" gorm:"log_format"`
	LogDir         string `json:"log_file" yaml:"log_file" env:"LOG_FILE" toml:"log_file" xml:"log_file" gorm:"log_file"`
	RequestLogging bool   `json:"request_logging" yaml:"request_logging" env:"REQUEST_LOGGING" toml:"request_logging" xml:"request_logging" gorm:"request_logging"`
	MetricsEnabled bool   `json:"metrics_enabled" yaml:"metrics_enabled" env:"METRICS_ENABLED" toml:"metrics_enabled" xml:"metrics_enabled" gorm:"metrics_enabled"`

	JWTSecretKey           string        `json:"jwt_secret_key" yaml:"jwt_secret"`
	RefreshTokenExpiration time.Duration `json:"refresh_token_expiration" yaml:"refresh_token_expiration" env:"REFRESH_TOKEN_EXPIRATION" toml:"refresh_token_expiration" xml:"refresh_token_expiration" gorm:"refresh_token_expiration"`
	AccessTokenExpiration  time.Duration `json:"access_token_expiration" yaml:"access_token_expiration" env:"ACCESS_TOKEN_EXPIRATION" toml:"access_token_expiration" xml:"access_token_expiration" gorm:"access_token_expiration"`
	TLSConfig              TLSConfig     `json:"tls_config" yaml:"tls_config" env:"TLS_CONFIG" toml:"tls_config" xml:"tls_config" gorm:"tls_config"`
	AllowedOrigins         []string      `json:"allowed_origins" yaml:"allowed_origins" env:"ALLOWED_ORIGINS" toml:"allowed_origins" xml:"allowed_origins" gorm:"allowed_origins"`
	APIKeyAuth             bool          `json:"api_key_auth" yaml:"api_key_auth" env:"API_KEY_AUTH" toml:"api_key_auth" xml:"api_key_auth" gorm:"api_key_auth"`
	APIKey                 string        `json:"api_key" yaml:"api_key" env:"API_KEY" toml:"api_key" xml:"api_key" gorm:"api_key"`

	ConfigFormat string `json:"config_format" yaml:"config_format" env:"CONFIG_FORMAT" toml:"config_format" xml:"config_format" gorm:"config_format"`

	Mapper ci.IMapper[*GoBEConfig]
}

func NewGoBEConfig(name, filePath, configFormat, bind, port string) *GoBEConfig {
	if configFormat == "" {
		configFormat = "yaml"
	}
	if filePath == "" {
		filePath = os.ExpandEnv(cm.DefaultGoBEConfigPath)
	}
	if bind == "" {
		bind = "0.0.0.0"
	}
	if port == "" {
		port = "3666"
	}
	if name == "" {
		name = "GoBE"
	}

	gbmCfg := &GoBEConfig{
		Reference:              newReference(name).GetReference(),
		Mutexes:                NewMutexesType(),
		FilePath:               filePath,
		WorkerThreads:          2,
		RateLimitLimit:         0,
		RateLimitBurst:         0,
		RequestWindow:          time.Minute,
		ProxyEnabled:           false,
		ProxyHost:              "",
		ProxyPort:              "",
		BindAddress:            bind,
		BasePath:               "/",
		Port:                   port,
		Timeouts:               30 * time.Second,
		MaxConnections:         100,
		LogLevel:               "info",
		LogFormat:              "text",
		LogDir:                 "gobe.log",
		RequestLogging:         false,
		MetricsEnabled:         false,
		JWTSecretKey:           "",
		RefreshTokenExpiration: time.Hour * 24,
		AccessTokenExpiration:  time.Hour,
		TLSConfig: TLSConfig{
			CertFile:      "",
			KeyFile:       "",
			CAFile:        "",
			Enabled:       false,
			SkipVerify:    false,
			StrictHostKey: false,
			MinVersion:    "TLS1.2",
		},
		AllowedOrigins: []string{"*"},
		APIKeyAuth:     false,
		APIKey:         "",
		ConfigFormat:   "yaml",
	}

	gbmCfg.Mapper = NewMapper[*GoBEConfig](&gbmCfg, filePath)
	if _, statErr := os.Stat(filePath); statErr != nil {
		if errors.Is(statErr, os.ErrNotExist) {
			gbmCfg.Mapper.SerializeToFile(configFormat)
		} else {
			gl.Log("error", fmt.Sprintf("Failed to stat config file: %v", statErr))
		}
	} else {
		gbmCfg.Mapper.DeserializeFromFile(configFormat)
	}

	return gbmCfg
}

func (c *GoBEConfig) GetFilePath() string                      { return c.FilePath }
func (c *GoBEConfig) GetWorkerThreads() int                    { return c.WorkerThreads }
func (c *GoBEConfig) GetRateLimitLimit() int                   { return c.RateLimitLimit }
func (c *GoBEConfig) GetRateLimitBurst() int                   { return c.RateLimitBurst }
func (c *GoBEConfig) GetRequestWindow() time.Duration          { return c.RequestWindow }
func (c *GoBEConfig) GetProxyEnabled() bool                    { return c.ProxyEnabled }
func (c *GoBEConfig) GetProxyHost() string                     { return c.ProxyHost }
func (c *GoBEConfig) GetProxyPort() string                     { return c.ProxyPort }
func (c *GoBEConfig) GetBindAddress() string                   { return c.BindAddress }
func (c *GoBEConfig) GetPort() string                          { return c.Port }
func (c *GoBEConfig) GetTimeouts() time.Duration               { return c.Timeouts }
func (c *GoBEConfig) GetMaxConnections() int                   { return c.MaxConnections }
func (c *GoBEConfig) GetLogLevel() string                      { return c.LogLevel }
func (c *GoBEConfig) GetLogFormat() string                     { return c.LogFormat }
func (c *GoBEConfig) GetLogDir() string                        { return c.LogDir }
func (c *GoBEConfig) GetRequestLogging() bool                  { return c.RequestLogging }
func (c *GoBEConfig) GetMetricsEnabled() bool                  { return c.MetricsEnabled }
func (c *GoBEConfig) GetJWTSecretKey() string                  { return c.JWTSecretKey }
func (c *GoBEConfig) GetRefreshTokenExpiration() time.Duration { return c.RefreshTokenExpiration }
func (c *GoBEConfig) GetAccessTokenExpiration() time.Duration  { return c.AccessTokenExpiration }
func (c *GoBEConfig) GetTLSConfig() TLSConfig                  { return c.TLSConfig }
func (c *GoBEConfig) GetAllowedOrigins() []string              { return c.AllowedOrigins }
func (c *GoBEConfig) GetAPIKeyAuth() bool                      { return c.APIKeyAuth }
func (c *GoBEConfig) GetAPIKey() string                        { return c.APIKey }
func (c *GoBEConfig) GetConfigFormat() string                  { return c.ConfigFormat }
func (c *GoBEConfig) GetMapper() ci.IMapper[*GoBEConfig]       { return c.Mapper }

func (c *GoBEConfig) SetFilePath(filePath string)          { c.FilePath = filePath }
func (c *GoBEConfig) SetWorkerThreads(workerThreads int)   { c.WorkerThreads = workerThreads }
func (c *GoBEConfig) SetRateLimitLimit(rateLimitLimit int) { c.RateLimitLimit = rateLimitLimit }
func (c *GoBEConfig) SetRateLimitBurst(rateLimitBurst int) { c.RateLimitBurst = rateLimitBurst }
func (c *GoBEConfig) SetRequestWindow(requestWindow time.Duration) {
	c.RequestWindow = requestWindow
}
func (c *GoBEConfig) SetProxyEnabled(proxyEnabled bool)     { c.ProxyEnabled = proxyEnabled }
func (c *GoBEConfig) SetProxyHost(proxyHost string)         { c.ProxyHost = proxyHost }
func (c *GoBEConfig) SetProxyPort(proxyPort string)         { c.ProxyPort = proxyPort }
func (c *GoBEConfig) SetBindAddress(bindAddress string)     { c.BindAddress = bindAddress }
func (c *GoBEConfig) SetPort(port string)                   { c.Port = port }
func (c *GoBEConfig) SetTimeouts(timeouts time.Duration)    { c.Timeouts = timeouts }
func (c *GoBEConfig) SetMaxConnections(maxConnections int)  { c.MaxConnections = maxConnections }
func (c *GoBEConfig) SetLogLevel(logLevel string)           { c.LogLevel = logLevel }
func (c *GoBEConfig) SetLogFormat(logFormat string)         { c.LogFormat = logFormat }
func (c *GoBEConfig) SetLogFile(LogDir string)              { c.LogDir = LogDir }
func (c *GoBEConfig) SetRequestLogging(requestLogging bool) { c.RequestLogging = requestLogging }
func (c *GoBEConfig) SetMetricsEnabled(metricsEnabled bool) { c.MetricsEnabled = metricsEnabled }
func (c *GoBEConfig) SetJWTSecretKey(jwtSecretKey string) {
	cryptoService := crp.NewCryptoService()
	if jwtSecretKey == "" {
		gl.Log("error", "JWT secret key is empty")
		jwtSecretKeyByte, jwtSecretKeyByteErr := cryptoService.GenerateKeyWithLength(32)
		if jwtSecretKeyByteErr != nil {
			jwtSecretKey = ""
			gl.Log("fatal", fmt.Sprintf("Failed to generate JWT secret key: %v", jwtSecretKeyByteErr))
		} else {
			jwtSecretKey = cryptoService.EncodeBase64(jwtSecretKeyByte)
			if jwtSecretKey == "" {
				gl.Log("fatal", "Failed to generate JWT secret key")
			}
		}
	}
	c.JWTSecretKey = jwtSecretKey
}
func (c *GoBEConfig) SetRefreshTokenExpiration(refreshTokenExpiration time.Duration) {
	c.RefreshTokenExpiration = refreshTokenExpiration
}
func (c *GoBEConfig) SetAccessTokenExpiration(accessTokenExpiration time.Duration) {
	c.AccessTokenExpiration = accessTokenExpiration
}
func (c *GoBEConfig) SetTLSConfig(tlsConfig TLSConfig) { c.TLSConfig = tlsConfig }
func (c *GoBEConfig) SetAllowedOrigins(allowedOrigins []string) {
	c.AllowedOrigins = allowedOrigins
}
func (c *GoBEConfig) SetAPIKeyAuth(apiKeyAuth bool)       { c.APIKeyAuth = apiKeyAuth }
func (c *GoBEConfig) SetAPIKey(apiKey string)             { c.APIKey = apiKey }
func (c *GoBEConfig) SetConfigFormat(configFormat string) { c.ConfigFormat = configFormat }
func (c *GoBEConfig) SetMapper(mapper ci.IMapper[*GoBEConfig]) {
	c.Mapper = mapper
}
func (c *GoBEConfig) GetReference() ci.IReference { return c.Reference }

func (c *GoBEConfig) Save() error {
	if c.Mutexes == nil {
		c.Mutexes = NewMutexesType()
	}
	c.Mutexes.MuLock()
	defer c.Mutexes.MuUnlock()

	if c.Mapper == nil {
		c.Mapper = NewMapper[*GoBEConfig](&c, c.FilePath)
	}

	c.Mapper.SerializeToFile(c.ConfigFormat)

	return nil
}

func (c *GoBEConfig) Load() error {
	if c.Mutexes == nil {
		c.Mutexes = NewMutexesType()
	}
	c.Mutexes.MuLock()
	defer c.Mutexes.MuUnlock()

	if c.Mapper == nil {
		c.Mapper = NewMapper[*GoBEConfig](&c, c.FilePath)
	}

	_, err := c.Mapper.DeserializeFromFile(c.ConfigFormat)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Failed to load config: %v", err))
	}
	//c = *newCfg

	return nil
}

/// internal/types/contact_form.go ///
package types

type ContactForm struct {
	Token                string `json:"token"`
	Name                 string `json:"name"`
	Email                string `json:"email"`
	Message              string `json:"message"`
	*Mapper[ContactForm] `json:"-" yaml:"-" xml:"-" toml:"-" gorm:"-"`
}

/// internal/types/environment.go ///
package types

import (
	"bytes"
	"context"
	"encoding/base64"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"reflect"
	"runtime"
	"strings"
	"sync"
	"syscall"
	"time"

	l "github.com/kubex-ecosystem/logz"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	crp "github.com/kubex-ecosystem/gobe/internal/security/crypto"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type EnvCache struct {
	m map[string]string
}

func NewEnvCache() *EnvCache {
	return &EnvCache{
		m: make(map[string]string),
	}
}

type Environment struct {
	isConfidential bool

	Logger l.Logger

	*Reference

	*EnvCache

	*Mutexes

	cpuCount int
	memTotal int
	hostname string
	os       string
	kernel   string
	envFile  string

	// For lazy loading if needed
	properties map[string]any

	mapper ci.IMapper[map[string]string]
}

func newEnvironment(envFile string, isConfidential bool, logger l.Logger) (*Environment, error) {
	if logger == nil {
		logger = l.GetLogger("Environment")
	}
	if envFile == "" {
		envFile = ".env"
		if _, err := os.Stat(envFile); os.IsNotExist(err) {
			if createErr := os.WriteFile(envFile, []byte(""), 0644); createErr != nil {
				gl.Log("error", fmt.Sprintf("Error creating env file: %s", createErr.Error()))
				return nil, fmt.Errorf("error creating env file: %s", createErr.Error())
			}
		}
	} else {
		if _, err := os.Stat(envFile); os.IsNotExist(err) {
			gl.Log("error", fmt.Sprintf("Error checking env file: %s", err.Error()))
			//return nil, fmt.Errorf("error checking env file: %s", err.Error())
			if createErr := os.WriteFile(envFile, []byte(""), 0644); createErr != nil {
				gl.Log("error", fmt.Sprintf("Error creating env file: %s", createErr.Error()))
				return nil, fmt.Errorf("error creating env file: %s", createErr.Error())
			}
		}
	}

	gl.Log("notice", "Creating new Environment instance")
	cpuCount := runtime.NumCPU()
	memTotal := syscall.Sysinfo_t{}.Totalram
	hostname, hostnameErr := os.Hostname()
	if hostnameErr != nil {
		gl.Log("error", fmt.Sprintf("Error getting hostname: %s", hostnameErr.Error()))
		return nil, fmt.Errorf("error getting hostname: %s", hostnameErr.Error())
	}
	oos := runtime.GOOS
	kernel := runtime.GOARCH
	name := filepath.Base(envFile)
	name = strings.TrimSuffix(name, filepath.Ext(name))
	if name == "" {
		name = "default"
	}
	name = strings.Join(filepath.SplitList(name), "_")

	env := &Environment{
		isConfidential: isConfidential,
		Logger:         logger,
		Reference:      NewReference(name).GetReference(),
		Mutexes:        NewMutexesType(),
		cpuCount:       cpuCount,
		memTotal:       int(memTotal),
		hostname:       hostname,
		os:             oos,
		kernel:         kernel,
		envFile:        envFile,
	}

	env.EnvCache = NewEnvCache()
	env.EnvCache.m = make(map[string]string)

	envs := os.Environ()
	for _, ev := range envs {
		parts := strings.SplitN(ev, "=", 2)
		if len(parts) != 2 {
			continue
		}
		key := strings.TrimSpace(parts[0])
		value := strings.TrimSpace(parts[1])
		env.EnvCache.m[key] = value
	}
	env.EnvCache.m["ENV_FILE"] = envFile
	env.EnvCache.m["ENV_CONFIDENTIAL"] = fmt.Sprintf("%t", isConfidential)
	env.EnvCache.m["ENV_HOSTNAME"] = env.Hostname()
	env.EnvCache.m["ENV_OS"] = env.Os()
	env.EnvCache.m["ENV_KERNEL"] = env.Kernel()
	env.EnvCache.m["ENV_CPU_COUNT"] = fmt.Sprintf("%d", env.CpuCount())
	env.EnvCache.m["ENV_MEM_TOTAL"] = fmt.Sprintf("%d", env.MemTotal())
	env.EnvCache.m["ENV_MEM_AVAILABLE"] = fmt.Sprintf("%d", env.MemAvailable())
	env.EnvCache.m["ENV_MEM_USED"] = fmt.Sprintf("%d", env.MemTotal()-env.MemAvailable())

	env.mapper = NewMapperTypeWithObject(&env.EnvCache.m, env.envFile)
	_, err := env.mapper.DeserializeFromFile("env")
	if err != nil {
		return nil, fmt.Errorf("error loading file: %s", err.Error())
	}

	return env, nil
}
func NewEnvironment(envFile string, isConfidential bool, logger l.Logger) (ci.IEnvironment, error) {
	return newEnvironment(envFile, isConfidential, logger)
}
func NewEnvironmentType(envFile string, isConfidential bool, logger l.Logger) (*Environment, error) {
	return newEnvironment(envFile, isConfidential, logger)
}

func (e *Environment) Mu() ci.IMutexes {
	if e.Mutexes == nil {
		e.Mutexes = NewMutexesType()
	}
	return e.Mutexes
}
func (e *Environment) CpuCount() int {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.cpuCount == 0 {
		e.cpuCount = runtime.NumCPU()
	}
	return e.cpuCount
}
func (e *Environment) MemTotal() int {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.memTotal == 0 {
		var mem syscall.Sysinfo_t
		err := syscall.Sysinfo(&mem)
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting memory info: %s", err.Error()))
			return 0
		}
		totalRAM := mem.Totalram * uint64(mem.Unit) / (1024 * 1024)
		e.memTotal = int(totalRAM)
	}
	return e.memTotal
}
func (e *Environment) Hostname() string {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.hostname == "" {
		hostname, err := os.Hostname()
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting hostname: %s", err.Error()))
			return ""
		}
		e.hostname = hostname
	}
	return e.hostname
}
func (e *Environment) Os() string {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.os == "" {
		e.os = runtime.GOOS
	}
	return e.os
}
func (e *Environment) Kernel() string {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	if e.kernel == "" {
		e.kernel = runtime.GOARCH
	}
	return e.kernel
}
func (e *Environment) Getenv(key string) string {
	if val, exists := e.EnvCache.m[key]; exists {
		if val == "" {
			gl.Log("info", fmt.Sprintf("'%s' found in cache, but value is empty", key))
			return ""
		}
		isEncryptedValue := e.IsEncryptedValue(val)
		if isEncryptedValue {
			gl.Log("debug", fmt.Sprintf("'%s' found in cache, value is encrypted", key))
			decryptedVal, err := e.DecryptEnv(val)
			if err != nil {
				gl.Log("error", fmt.Sprintf("Error decrypting value for key '%s': %v", key, err))
				gl.Log("error", fmt.Sprintf("Value for key %s: %s", key, val))
				return ""
			}
			gl.Log("debug", fmt.Sprintf("Decrypted value for key '%s': %s", key, decryptedVal))
			return decryptedVal
		}
		if err := e.Setenv(key, val); err != nil {
			gl.Log("error", fmt.Sprintf("Error setting environment variable '%s': %v", key, err))
			return ""
		}
		return val
	}
	gl.Log("debug", fmt.Sprintf("'%s' not found in cache, checking system env...", key))
	return os.Getenv(key)
}
func (e *Environment) Setenv(key, value string) error {
	if e.EnvCache.m == nil {
		e.EnvCache.m = make(map[string]string)
	}
	isEncrypted := e.IsEncryptedValue(value)
	if e.isConfidential {
		if isEncrypted {
			e.EnvCache.m[key] = value
		} else {
			encryptedValue, err := e.EncryptEnv(value)
			if err != nil {
				gl.Log("error", fmt.Sprintf("Error encrypting value for key '%s': %v", key, err))
				return err
			}
			e.EnvCache.m[key] = encryptedValue
		}
	} else {
		if isEncrypted {
			decryptedValue, err := e.DecryptEnv(value)
			if err != nil {
				gl.Log("error", fmt.Sprintf("Error decrypting value for key '%s': %v", key, err))
			} else if decryptedValue != "" {
				e.EnvCache.m[key] = decryptedValue
			}
		}
		e.EnvCache.m[key] = value
	}

	gl.Log("debug", fmt.Sprintf("Key '%s' value: %s", key, value))

	return os.Setenv(key, value)
}
func (e *Environment) GetEnvCache() map[string]string {
	if e.EnvCache.m == nil {
		gl.Log("debug", "EnvCache is nil, initializing...")
		e.EnvCache.m = make(map[string]string)
	}

	return e.EnvCache.m
}
func (e *Environment) ParseEnvVar(s string) (string, string) {
	name, length := e.GetShellName(s)
	if length == 0 {
		return "", ""
	}
	value := os.Getenv(name)
	return name, value
}
func (e *Environment) LoadEnvFromShell() error {
	cmd := exec.Command("bash", "-c", "env")
	output, err := cmd.Output()
	if err != nil {
		return fmt.Errorf("erro ao carregar env via shell: %v", err)
	}

	lines := strings.Split(string(output), "\n")
	for _, line := range lines {
		parts := strings.SplitN(line, "=", 2)
		if len(parts) != 2 {
			continue
		}
		e.EnvCache.m[parts[0]] = parts[1]
		if setEnvErr := os.Setenv(parts[0], parts[1]); setEnvErr != nil {
			return setEnvErr
		}
	}

	gl.Log("debug", "Environment variables loaded from shell")
	return nil
}
func (e *Environment) MemAvailable() int {
	e.Mutexes.MuRLock()
	defer e.Mutexes.MuRUnlock()

	var mem syscall.Sysinfo_t
	if err := syscall.Sysinfo(&mem); err != nil {
		gl.Log("error", fmt.Sprintf("Erro ao obter RAM disponÃ­vel: %v", err))
		return -1
	}
	return int(mem.Freeram * uint64(mem.Unit) / (1024 * 1024))
}
func (e *Environment) GetShellName(s string) (string, int) {
	switch {
	case s[0] == '{':
		if len(s) > 2 && IsShellSpecialVar(s[1]) && s[2] == '}' {
			return s[1:2], 3
		}
		for i := 1; i < len(s); i++ {
			if s[i] == '}' {
				if i == 1 {
					return "", 2
				}
				return s[1:i], i + 1
			}
		}
		return "", 1
	case IsShellSpecialVar(s[0]):
		return s[0:1], 1
	}
	var i int
	for i = 0; i < len(s) && IsAlphaNum(s[i]); i++ {
	}
	return s[:i], i
}
func (e *Environment) GetEnvFilePath() string { return e.envFile }

func (e *Environment) BackupEnvFile() error {
	backupFile := e.envFile + ".backup"
	if _, err := os.Stat(backupFile); err == nil {
		return nil
	}

	return asyncCopyFile(e.envFile, backupFile)
}
func (e *Environment) EncryptEnvFile() error {
	if !e.isConfidential {
		gl.Log("debug", "Environment is not confidential, skipping encryption")
		return nil
	}
	isEncrypted := e.IsEncrypted(e.envFile)
	if isEncrypted {
		return nil
	}

	if err := e.BackupEnvFile(); err != nil {
		return err
	}

	data, err := os.ReadFile(e.envFile)
	if err != nil {
		return err
	}

	encryptedData, err := e.EncryptEnv(string(data))
	if err != nil {
		return err
	}

	return os.WriteFile(e.envFile, []byte(encryptedData), 0644)
}
func (e *Environment) DecryptEnvFile() (string, error) {
	isEncrypted := e.IsEncrypted(e.envFile)
	if !isEncrypted {
		gl.Log("debug", "Env file is not encrypted, skipping decryption")
		return "", nil
	}

	data, err := os.ReadFile(e.envFile)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error reading env file: %v", err))
		return "", err
	}
	if len(data) == 0 {
		gl.Log("error", "Env file is empty")
		return "", fmt.Errorf("env file is empty")
	}

	return e.DecryptEnv(string(data))
}
func (e *Environment) EncryptEnv(value string) (string, error) {
	if !e.isConfidential || e.IsEncryptedValue(value) {
		return value, nil
	}

	cryptoService, key, err := getKey(e)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error getting key: %v", err))
		return "", err
	}

	if cryptoService == nil {
		gl.Log("error", "CryptoService is nil")
		return "", fmt.Errorf("cryptoService is nil")
	}

	isEncrypted := cryptoService.IsEncrypted([]byte(value))
	if isEncrypted {
		return value, nil
	}

	encrypt, _, err := cryptoService.Encrypt([]byte(value), key)
	if err != nil {
		return "", err
	}

	encoded := cryptoService.EncodeBase64([]byte(encrypt))
	if len(encoded) == 0 {
		gl.Log("error", "Failed to encode the encrypted value")
		return "", fmt.Errorf("failed to encode the encrypted value")
	}

	return encoded, nil
}
func (e *Environment) DecryptEnv(encryptedValue string) (string, error) {
	if !e.isConfidential {
		if !e.IsEncryptedValue(encryptedValue) {
			return encryptedValue, nil
		}
	} else {
		if !e.IsEncryptedValue(encryptedValue) {
			gl.Log("debug", "Value is not encrypted")
			return encryptedValue, nil
		}
	}

	cryptoService, key, err := getKey(e)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error getting key: %v", err))
		return "", err
	}

	isEncrypted := e.IsEncryptedValue(encryptedValue)
	if !isEncrypted {
		return encryptedValue, nil
	}

	isEncoded := cryptoService.IsBase64String(encryptedValue)
	var decodedData string
	if isEncoded {
		decodedBytes, decryptedBytesErr := cryptoService.DecodeBase64(encryptedValue)
		if decryptedBytesErr != nil {
			gl.Log("error", fmt.Sprintf("Error decoding base64 string: %v", decryptedBytesErr))
			return "", decryptedBytesErr
		}
		decodedData = strings.TrimSpace(string(decodedBytes))
	} else {
		decodedData = strings.TrimSpace(encryptedValue)
	}
	trimmedDataBytes := bytes.TrimSpace([]byte(decodedData))

	decrypted, _, err := cryptoService.Decrypt(trimmedDataBytes, key)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error decrypting value: %v", err))
		return "", err
	}

	if len(decrypted) == 0 {
		gl.Log("error", "Decrypted value is empty")
		return "", fmt.Errorf("decrypted value is empty")
	}

	return strings.TrimSpace(string(decrypted)), nil
}
func (e *Environment) IsEncrypted(envFile string) bool {
	if _, err := os.Stat(envFile); os.IsNotExist(err) {
		gl.Log("error", fmt.Sprintf("Arquivo nÃ£o encontrado: %v", err))
		return false
	}
	cryptoService, _, err := getKey(e)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error getting key: %v", err))
		return false
	}
	if cryptoService == nil {
		gl.Log("error", "CryptoService is nil")
		return false
	}
	data, err := os.ReadFile(envFile)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Error reading file: %v", err))
		return false
	}
	if len(data) == 0 {
		gl.Log("error", "File is empty")
		return false
	}
	return cryptoService.IsEncrypted(data)
}
func (e *Environment) IsEncryptedValue(value string) bool {
	if arrB, arrBErr := base64.URLEncoding.DecodeString(value); arrBErr != nil || len(arrB) == 0 {
		return false
	} else {
		return len(arrB) > 0 && arrB[0] == 0x00
	}
}
func (e *Environment) EnableEnvFileEncryption() error {
	if e.isConfidential {
		gl.Log("debug", "Environment is already confidential, skipping encryption")
		return nil
	}

	e.isConfidential = true

	if err := e.EncryptEnvFile(); err != nil {
		return err
	}

	return nil
}
func (e *Environment) DisableEnvFileEncryption() error {
	if !e.isConfidential {
		gl.Log("debug", "Environment is not confidential, skipping decryption")
		return nil
	}

	e.isConfidential = false

	if err := e.EncryptEnvFile(); err != nil {
		return err
	}

	return nil
}
func (e *Environment) LoadEnvFile(watchFunc func(ctx context.Context, chanCbArg chan any) <-chan any) error {
	timeout := 10 * time.Second
	chanErr := make(chan error, 3)
	chanDone := make(chan bool, 3)
	chanCb := make(chan any, 10)

	var contextWithCancel context.Context
	var cancel context.CancelFunc
	if watchFunc != nil {
		gl.Log("debug", "Callback function provided, executing...")
		contextWithCancel, cancel = context.WithTimeout(context.Background(), timeout)
		watchFunc(contextWithCancel, chanCb)
	} else {
		gl.Log("debug", "No callback function provided")
		contextWithCancel, cancel = context.WithTimeout(context.Background(), timeout)
	}

	go func(cancel context.CancelFunc, chanErr chan error, chanDone chan bool) {
		defer func(chanErr chan error, chanDone chan bool, chanCb chan any) {
			cancel()
			close(chanErr)
			close(chanDone)
			close(chanCb)
		}(chanErr, chanDone, chanCb)

		gl.Log("debug", "Loading env file...")
		for {
			select {
			case <-contextWithCancel.Done():
				if err := contextWithCancel.Err(); err != nil {
					gl.Log("error", fmt.Sprintf("Error loading env file: %v", err))
					return
				}
				return
			case <-time.After(timeout):
				if chanErr != nil {
					chanErr <- fmt.Errorf("timeout loading env file")
				}
				return
			case <-chanDone:
				gl.Log("debug", "Env file loaded successfully")
				return
			default:
				continue
			}
		}
	}(cancel, chanErr, chanDone)

	// Will add a wait group to wait for the readEnvFile function to finish inside
	// the goroutine, inside the readEnvFile function and wait for the goroutine to finish here.
	go readEnvFile(e, contextWithCancel, e.MuCtxWg)
	e.MuCtxWg.Wait()

	return nil
}

func readEnvFile(e *Environment, ctx context.Context, wg *sync.WaitGroup) {
	if e.GetEnvFilePath() == "" || e.GetEnvFilePath() == ".env" {
		gl.Log("error", "Env file path is empty or default")
		return
	}

	wg.Add(1)
	go func(e *Environment, ctx context.Context, wg *sync.WaitGroup) {
		defer wg.Done()
		defer ctx.Done()

		// Read the env file
		fileData, err := os.ReadFile(e.GetEnvFilePath())
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error reading env file: %v", err))
			ctx.Value(fmt.Errorf("error reading env file: %v", err))
			return
		}
		if len(fileData) == 0 {
			gl.Log("error", "Env file is empty")
			ctx.Value(fmt.Errorf("env file is empty"))
			return
		}
		// Check if the env file is encrypted, if so, decrypt it
		isEncrypted := e.IsEncryptedValue(string(fileData))
		if isEncrypted {
			gl.Log("debug", "Env file is encrypted, decrypting...")
			var decryptedData string
			decryptedData, err = e.DecryptEnv(string(fileData))
			if err != nil {
				gl.Log("debug", fmt.Sprintf("Error decrypting env file: %v", err))
				return
			}
			if len(decryptedData) == 0 {
				gl.Log("error", "Decrypted env file is empty")
				return
			}
			fileData = []byte(decryptedData)
			if len(fileData) == 0 {
				gl.Log("error", "Decrypted env file is empty")
				return
			}
		}
		// Create a temp copy of the env file with Mktemp with decrypted data
		tmpFile, err := os.CreateTemp("", "env_*.tmp")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error creating temp file: %v", err))
			return
		}

		defer func(tmpFile *os.File) {
			gl.Log("debug", "Closing temp file")
			if closeErr := tmpFile.Close(); closeErr != nil {
				gl.Log("error", fmt.Sprintf("Error closing temp file: %v", closeErr.Error()))
				return
			}
			gl.Log("debug", "Removing temp file")
			if err := os.Remove(tmpFile.Name()); err != nil {
				gl.Log("error", fmt.Sprintf("Error removing temp file: %v", err))
			}
			return
		}(tmpFile)

		if _, err := tmpFile.Write(fileData); err != nil {
			gl.Log("error", fmt.Sprintf("Error writing to temp file: %v", err))
			return
		}

		var ext any
		existing := make(map[string]string)
		mapper := NewMapperTypeWithObject(&existing, tmpFile.Name())
		extT, existingErr := mapper.DeserializeFromFile("env")
		if existingErr != nil {
			gl.Log("error", fmt.Sprintf("Error deserializing env file: %v", existingErr))
			return
		}
		if extT == nil {
			gl.Log("error", "Error loading file: nil value")
		} else {
			ext = reflect.ValueOf(extT).Elem().Interface()
		}
		if oldMap, ok := ext.(map[string]string); ok {
			for key, value := range oldMap {
				gl.Log("debug", fmt.Sprintf("Key '%s' value: %s", key, value))
				if setEnvErr := e.Setenv(key, value); setEnvErr != nil {
					gl.Log("error", fmt.Sprintf("Erro ao definir variÃ¡vel de ambiente '%s': %v", key, setEnvErr))
					continue
				}
			}
			e.EnvCache.m = oldMap
			if err := os.Remove(tmpFile.Name()); err != nil {
				gl.Log("error", fmt.Sprintf("Error removing temp file: %v", err))
				return
			}
			gl.Log("debug", "Temp file removed successfully")
			gl.Log("debug", "Env file read successfully")
			return
		} else {
			gl.Log("error", "Error casting to map[string]string")
			return
		}
	}(e, ctx, wg)

	gl.Log("success", "Env file read successfully")
}
func getKey(e *Environment) (sci.ICryptoService, []byte, error) {
	if e.properties["cryptoService"] == nil {
		cryptoService := crp.NewCryptoService()
		if cryptoService == nil {
			gl.Log("error", "Failed to create crypto service")
			return nil, nil, fmt.Errorf("failed to create crypto service")
		}
		if e.properties == nil {
			e.properties = make(map[string]any)
		}
		e.properties["cryptoService"] = NewProperty("cryptoService", &cryptoService, false, nil)
		if e.properties["cryptoService"] == nil {
			return nil, nil, fmt.Errorf("failed to get crypto service")
		}
	}
	cryptoServiceProperty, ok := e.properties["cryptoService"].(ci.IProperty[sci.ICryptoService])
	if !ok {
		gl.Log("error", "Failed to cast crypto service")
		return nil, nil, fmt.Errorf("failed to cast crypto service")
	}
	cryptoService := cryptoServiceProperty.GetValue()
	if e.properties["key"] == nil {
		key, err := cryptoService.GenerateKey()
		if err != nil {
			return nil, nil, fmt.Errorf("failed to generate key: %v", err)
		}
		e.properties["key"] = NewProperty[[]byte]("key", &key, false, nil)
		if e.properties["key"] == nil {
			return nil, nil, fmt.Errorf("failed to get key")
		}
	}
	key := e.properties["key"].(*Property[[]byte]).GetValue()
	if key == nil {
		gl.Log("error", "Key is nil")
		return nil, nil, fmt.Errorf("key is nil")
	}
	return cryptoService, key, nil
}

/// internal/types/mapper.go ///
package types

import (
	"bufio"
	"encoding/asn1"
	"encoding/json"
	"encoding/xml"
	"fmt"
	"os"
	"reflect"
	"strings"

	"github.com/pelletier/go-toml/v2"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
	"github.com/subosito/gotenv"
	"gopkg.in/yaml.v3"
)

// Mapper is a generic struct that implements the IMapper interface for serializing and deserializing objects.
type Mapper[T any] struct {
	filePath string
	object   T
}

// NewMapperTypeWithObject creates a new instance of Mapper.
func NewMapperTypeWithObject[T any](object *T, filePath string) *Mapper[T] {
	return &Mapper[T]{filePath: filePath, object: *object}
}

// NewMapperType creates a new instance of Mapper.
func NewMapperType[T any](object *T, filePath string) *Mapper[T] {
	return &Mapper[T]{filePath: filePath, object: *object}
}

// NewMapperPtr creates a new instance of Mapper.
func NewMapperPtr[T any](object *T, filePath string) *Mapper[*T] {
	return &Mapper[*T]{filePath: filePath, object: object}
}

// NewMapper creates a new instance of Mapper.
func NewMapper[T any](object *T, filePath string) ci.IMapper[T] {
	return NewMapperType[T](object, filePath)
}

// Serialize converts an object of type T to a byte array in the specified format.
func (m *Mapper[T]) Serialize(format string) ([]byte, error) {
	switch format {
	case "json":
		return json.Marshal(m.object)
	case "yaml":
		return yaml.Marshal(m.object)
	case "xml":
		return xml.Marshal(m.object)
	case "toml":
		return toml.Marshal(m.object)
	case "asn":
		return asn1.Marshal(m.object)
	case "env":
		if env, ok := reflect.ValueOf(m.object).Interface().(map[string]string); ok {
			if strM, strMErr := gotenv.Marshal(env); strMErr != nil {
				return nil, fmt.Errorf("erro ao serializar para env: %v", strMErr)
			} else {
				return []byte(strM), nil
			}
		} else {
			return nil, fmt.Errorf("tipo nÃ£o suportado para env: %T", m.object)
		}
	default:
		return nil, fmt.Errorf("formato nÃ£o suportado: %s", format)
	}
}

// Deserialize converts a byte array in the specified format to an object of type T.
func (m *Mapper[T]) Deserialize(data []byte, format string) (*T, error) {
	if len(data) == 0 {
		return nil, fmt.Errorf("os dados estÃ£o vazios")
	}
	if !reflect.ValueOf(m.object).IsValid() || reflect.ValueOf(m.object).IsNil() {
		m.object = reflect.New(reflect.TypeFor[T]()).Interface().(T)
	}
	var err error
	switch format {
	case "json", "js":
		err = json.Unmarshal(data, m.object)
	case "yaml", "yml":
		err = yaml.Unmarshal(data, m.object)
	case "xml", "html":
		err = xml.Unmarshal(data, m.object)
	case "toml", "tml":
		err = toml.Unmarshal(data, m.object)
	case "asn", "asn1":
		_, err = asn1.Unmarshal(data, m.object)
	case "env", "envs", ".env", "environment":
		value := reflect.ValueOf(m.object)
		envT, ok := value.Interface().(*map[string]string)
		if !ok {
			envTB, ok := value.Interface().(map[string]string)
			if !ok {
				gl.Log("error", fmt.Sprintf("Type not valid for env: %T", m.object))
				return nil, fmt.Errorf("envT nÃ£o Ã© vÃ¡lido")
			} else {
				envT = &envTB
			}
		}
		if envT != nil {
			if !reflect.ValueOf(envT).IsValid() {
				gl.Log("error", fmt.Sprintf("Type not valid for env: %T", m.object))
				return nil, fmt.Errorf("envT nÃ£o Ã© vÃ¡lido")
			}
			env := *envT
			if strM, strMErr := gotenv.Unmarshal(string(data)); strMErr != nil {
				return nil, fmt.Errorf("erro ao desserializar de env: %v", strMErr)
			} else {
				for k, v := range strM {
					env[k] = v
				}
			}
		} else {
			// We not set err to nil, also we not set err to another value here.
			// This is a special case where we want to return nil, to allow the caller to
			// know that the object is really nil.
			gl.Log("error", fmt.Sprintf("Nil type for env: %T", m.object))
		}
	default:
		err = fmt.Errorf("formato nÃ£o suportado: %s", format)
	}
	if err != nil {
		return nil, fmt.Errorf("erro ao desserializar os dados: %v", err)
	}
	return &m.object, nil
}

// SerializeToFile serializes an object of type T to a file in the specified format.
func (m *Mapper[T]) SerializeToFile(format string) {
	if dataSer, dataSerErr := m.Serialize(format); dataSerErr != nil {
		gl.Log("error", fmt.Sprintf("Error serializing object: %v", dataSerErr.Error()))
		return
	} else {
		gl.Log("debug", fmt.Sprintf("Serialized object: %s", string(dataSer)))
		orf, orfErr := os.OpenFile(m.filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
		if orfErr != nil {
			gl.Log("error", fmt.Sprintf("Error opening file: %v", orfErr.Error()))
			return
		}
		defer func() {
			if err := orf.Close(); err != nil {
				gl.Log("error", fmt.Sprintf("Error closing file: %v", err.Error()))
				return
			}
		}()
		if _, err := orf.WriteString(fmt.Sprintf("%s\n", string(dataSer))); err != nil {
			gl.Log("error", fmt.Sprintf("Error writing to file: %v", err.Error()))
			return
		}
	}
}

// DeserializeFromFile deserializes an object of type T from a file in the specified format.
func (m *Mapper[T]) DeserializeFromFile(format string) (*T, error) {
	if _, err := os.Stat(m.filePath); os.IsNotExist(err) {
		gl.Log("error", fmt.Sprintf("File does not exist: %v", err.Error()))
		return nil, err
	}

	inputFile, err := os.Open(m.filePath)
	if err != nil {
		gl.Log("error", "Error opening file: %v", err.Error())
		return nil, err
	}

	defer func(inputFile *os.File) {
		gl.Log("debug", "Closing input file")
		if closeErr := inputFile.Close(); closeErr != nil {
			gl.Log("error", fmt.Sprintf("Error closing file: %v", closeErr.Error()))
			return
		}
		return
	}(inputFile)

	reader := bufio.NewReader(inputFile)
	scanner := bufio.NewScanner(reader)

	scanner.Split(bufio.ScanLines)
	objSlice := make([]T, 0)

	for scanner.Scan() {
		line := scanner.Text()
		if len(line) == 0 {
			continue
		}

		if desObj, desObjErr := m.Deserialize([]byte(line), format); desObjErr != nil {
			gl.Log("error", fmt.Sprintf("Error deserializing line: %v", desObjErr.Error()))
			return nil, err
		} else {
			gl.Log("debug", fmt.Sprintf("Deserialized line: %s", line))
			gl.Log("debug", fmt.Sprintf("Deserialized object: %v", desObj))
			if err = scanner.Err(); err != nil {
				gl.Log("error", fmt.Sprintf("Error reading file: %v", err.Error()))
				return nil, err
			}
			objSlice = append(objSlice, *desObj)
		}
	}
	if err := scanner.Err(); err != nil {
		gl.Log("error", fmt.Sprintf("Error reading file: %v", err.Error()))
		return nil, err
	}
	gl.Log("debug", "File closed successfully")

	var isSliceOrMap int
	value := reflect.ValueOf(m.object)

	switch reflect.TypeFor[T]().Kind() {
	case reflect.Slice, reflect.SliceOf(reflect.TypeFor[map[string]string]()).Kind():
		if value.Len() == 0 {
			// If the slice is empty, assign the deserialized object to the slice
			m.object = reflect.ValueOf(objSlice).Interface().(T)
			return &m.object, nil
		}
		break
	case reflect.Map:
		if value.Len() == 0 {
			// If the map is empty, assign the deserialized object to the map
			m.object = reflect.ValueOf(objSlice).Interface().(T)
			return &m.object, nil
		}
		isSliceOrMap = 1
		break
	default:
		// If the type is neither a slice nor a map, assign the first object to m.object
		if len(objSlice) == 0 {
			gl.Log("debug", "No objects found in the file")
			return nil, fmt.Errorf("nenhum objeto encontrado no arquivo")
		}
		if len(objSlice) > 1 {
			gl.Log("debug", "Multiple objects found in the file")
			return nil, fmt.Errorf("mÃºltiplos objetos encontrados no arquivo")
		}
		m.object = objSlice[0]
		break
	}

	for _, obj := range objSlice {
		if isSliceOrMap == 0 {
			if reflect.TypeOf(m.object).Kind() == reflect.Slice {
				m.object = reflect.AppendSlice(reflect.ValueOf(m.object), reflect.ValueOf(obj)).Interface().(T)
			} else {
				// Check if is a pointer
				if reflect.TypeOf(m.object).Kind() != reflect.Ptr {
					m.object = reflect.Append(reflect.ValueOf(m.object), reflect.ValueOf(obj)).Interface().(T)
				} else {
					// Check if is a map
					if reflect.TypeOf(m.object).Kind() == reflect.Map {
						m.object = reflect.Append(reflect.ValueOf(m.object), reflect.ValueOf(obj)).Interface().(T)
					} else {
						m.object = obj
					}
				}
			}
		} else {
			newMap := reflect.ValueOf(obj)
			iter := newMap.MapRange()
			for iter.Next() {
				value.SetMapIndex(iter.Key(), iter.Value())
			}
		}
	}

	m.object = value.Interface().(T)
	gl.Log("debug", fmt.Sprintf("File %s deserialized successfully", m.filePath))
	return &m.object, nil
}

func SanitizeQuotesAndSpaces(input string) string {
	input = strings.TrimSpace(input)
	input = strings.ReplaceAll(input, "'", "\"")
	input = strings.Trim(input, "\"")
	return input
}

func IsEqual(a, b string) bool {
	a, b = SanitizeQuotesAndSpaces(a), SanitizeQuotesAndSpaces(b)
	ptsEqual := levenshtein(a, b)
	maxLen := maxL(len(a), len(b))
	threshold := maxLen / 4
	return ptsEqual <= threshold
}

func maxL(a, b int) int {
	if a > b {
		return a
	}
	return b
}

func levenshtein(s, t string) int {
	m, n := len(s), len(t)
	if m == 0 {
		return n
	}
	if n == 0 {
		return m
	}
	prevRow := make([]int, n+1)
	for j := 0; j <= n; j++ {
		prevRow[j] = j
	}
	for i := 1; i <= m; i++ {
		currRow := make([]int, n+1)
		currRow[0] = i
		for j := 1; j <= n; j++ {
			cost := 1
			if s[i-1] == t[j-1] {
				cost = 0
			}
			currRow[j] = min(prevRow[j]+1, currRow[j-1]+1, prevRow[j-1]+cost)
		}
		prevRow = currRow
	}
	return prevRow[n]
}

/// internal/types/mapper_exporter.go ///
package types

type DataExporter interface {
	ExportFromYAML(filename string) error
	ExportFromJSON(filename string) error
	ExportFromXML(filename string) error
	ExportFromTOML(filename string) error
	ExportFromENV(filename string) error
	ExportFromINI(filename string) error
	ExportFromCSV(filename string) error
	ExportFromProperties(filename string) error
	ExportFromText(filename string) error
	ExportFromASN(filename string) error
	ExportFromBinary(filename string) error
	ExportFromHTML(filename string) error
	ExportFromExcel(filename string) error
	ExportFromPDF(filename string) error
	ExportFromMarkdown(filename string) error
}
type dataExporter struct{}

func NewDataExporter() DataExporter {
	return &dataExporter{}
}

func (e dataExporter) ExportFromYAML(filename string) error {
	// Implementation for exporting to CSV
	return nil
}
func (e dataExporter) ExportFromJSON(filename string) error {
	// Implementation for exporting to YAML
	return nil
}
func (e dataExporter) ExportFromXML(filename string) error {
	// Implementation for exporting to JSON
	return nil
}
func (e dataExporter) ExportFromTOML(filename string) error {
	// Implementation for exporting to XML
	return nil
}
func (e dataExporter) ExportFromENV(filename string) error {
	// Implementation for exporting to Excel
	return nil
}
func (e dataExporter) ExportFromINI(filename string) error {
	// Implementation for exporting to PDF
	return nil
}

func (e dataExporter) ExportFromCSV(filename string) error {
	// Implementation for exporting to Markdown
	return nil
}
func (e dataExporter) ExportFromProperties(filename string) error {
	return nil
}
func (e dataExporter) ExportFromText(filename string) error {
	return nil
}
func (e dataExporter) ExportFromASN(filename string) error {
	return nil
}
func (e dataExporter) ExportFromHTML(filename string) error {
	return nil
}
func (e dataExporter) ExportFromMarkdown(filename string) error {
	return nil
}

func (e dataExporter) ExportFromBinary(filename string) error {
	return nil
}
func (e dataExporter) ExportFromExcel(filename string) error {
	return nil
}
func (e dataExporter) ExportFromPDF(filename string) error {
	return nil
}

/// internal/types/mapper_importer.go ///
package types

type DataImporter interface {
	ImportFromYAML(filename string) error
	ImportFromJSON(filename string) error
	ImportFromXML(filename string) error
	ImportFromTOML(filename string) error
	ImportFromENV(filename string) error
	ImportFromINI(filename string) error
	ImportFromCSV(filename string) error
	ImportFromProperties(filename string) error
	ImportFromText(filename string) error
	ImportFromASN(filename string) error
	ImportFromBinary(filename string) error
	ImportFromHTML(filename string) error
	ImportFromExcel(filename string) error
	ImportFromPDF(filename string) error
	ImportFromMarkdown(filename string) error
}
type dataImporter struct{}

func NewDataImporter() DataImporter { return &dataImporter{} }

func (d dataImporter) ImportFromYAML(filename string) error {
	return nil
}
func (d dataImporter) ImportFromJSON(filename string) error {
	return nil
}
func (d dataImporter) ImportFromXML(filename string) error {
	return nil
}
func (d dataImporter) ImportFromTOML(filename string) error {
	return nil
}
func (d dataImporter) ImportFromENV(filename string) error {
	return nil
}
func (d dataImporter) ImportFromINI(filename string) error {
	return nil
}

func (d dataImporter) ImportFromCSV(filename string) error {
	return nil
}
func (d dataImporter) ImportFromProperties(filename string) error {
	return nil
}
func (d dataImporter) ImportFromText(filename string) error {
	return nil
}
func (d dataImporter) ImportFromASN(filename string) error {
	return nil
}
func (d dataImporter) ImportFromHTML(filename string) error {
	return nil
}
func (d dataImporter) ImportFromMarkdown(filename string) error {
	return nil
}

func (d dataImporter) ImportFromBinary(filename string) error {
	return nil
}
func (d dataImporter) ImportFromExcel(filename string) error {
	return nil
}
func (d dataImporter) ImportFromPDF(filename string) error {
	return nil
}

/// internal/types/mutexes.go ///
package types

import (
	gl "github.com/kubex-ecosystem/gobe/logger"

	"sync"
	"time"
)

type IMutexes interface {
	MuLock()
	MuUnlock()
	MuRLock()
	MuRUnlock()
	MuTryLock() bool
	MuTryRLock() bool

	MuWaitCond()
	MuSignalCond()
	MuBroadcastCond()

	GetMuSharedCtx() any
	SetMuSharedCtx(ctx any)
	GetMuSharedCtxValidate() func(any) (bool, error)
	SetMuSharedCtxValidate(validate func(any) (bool, error))
	MuWaitCondWithTimeout(timeout time.Duration) bool

	MuAdd(delta int)
	MuDone()
	MuWait()
}

// muCtx is the mutex context map
type muCtx struct {
	// MuCtxM is a mutex for the ctx map.
	MuCtxM *sync.RWMutex
	// MuCtxL is a mutex for sync.Cond in the ctx map.
	MuCtxL *sync.RWMutex
	// MuCtxCond is a condition variable for the ctx map.
	MuCtxCond *sync.Cond
	// MuCtxWg is a wait group for the ctx map.
	MuCtxWg *sync.WaitGroup
}

// newMuCtx creates a new mutex context map
func newMuCtx(mSharedCtxM *sync.RWMutex) *muCtx {
	mu := &muCtx{
		MuCtxM:    &sync.RWMutex{},
		MuCtxCond: sync.NewCond(mSharedCtxM),
		MuCtxWg:   &sync.WaitGroup{},
	}
	return mu
}

// Mutexes is a struct that holds the mutex context map
type Mutexes struct {
	// muCtx is the mutex context map
	*muCtx

	// MuCtxM is a mutex for the ctx map.
	MuCtxM *sync.RWMutex
	// MuCtxL is a mutex for sync.Cond in the ctx map.
	MuCtxL *sync.RWMutex
	// MuCtxCond is a condition variable for the ctx map.
	MuCtxCond *sync.Cond
	// MuCtxWg is a wait group for the ctx map.
	MuCtxWg *sync.WaitGroup

	// muSharedM is a mutex for the shared context.
	muSharedM *sync.RWMutex
	// muSharedCtx is the shared context for Cond. This is used to synchronize states across multiple goroutines.
	muSharedCtx any
	// muSharedCtxValidate is the shared context validation function. This is used to validate the shared context defining if it needs to wait or not.
	muSharedCtxValidate func(any) (bool, error)
}

// NewMutexesType creates a new mutex context map struct pointer.
func NewMutexesType() *Mutexes {
	mu := &Mutexes{
		MuCtxM:              &sync.RWMutex{},
		MuCtxL:              &sync.RWMutex{},
		MuCtxWg:             &sync.WaitGroup{},
		muSharedM:           &sync.RWMutex{},
		muSharedCtx:         nil,
		muSharedCtxValidate: nil,
	}
	mu.muCtx = newMuCtx(mu.muSharedM)
	mu.MuCtxCond = sync.NewCond(mu.muSharedM)
	return mu
}

// NewMutexes creates a new mutex context map interface.
func NewMutexes() IMutexes { return NewMutexesType() }

// MuLock locks the mutex
func (m *Mutexes) MuLock() { m.MuCtxM.Lock() }

// MuUnlock unlocks the mutex
func (m *Mutexes) MuUnlock() { m.MuCtxM.Unlock() }

// MuRLock locks the mutex for reading
func (m *Mutexes) MuRLock() { m.MuCtxL.RLock() }

// MuRUnlock unlocks the mutex for reading
func (m *Mutexes) MuRUnlock() { m.MuCtxL.RUnlock() }

// GetMuSharedCtx returns the shared context
func (m *Mutexes) GetMuSharedCtx() any {
	m.muSharedM.RLock()
	defer m.muSharedM.RUnlock()

	return m.muSharedCtx
}

// SetMuSharedCtx sets the shared context
func (m *Mutexes) SetMuSharedCtx(ctx any) {
	m.muSharedM.Lock()
	defer m.muSharedM.Unlock()

	m.muSharedCtx = ctx
}

// GetMuSharedCtxValidate returns the shared context validation function
func (m *Mutexes) GetMuSharedCtxValidate() func(any) (bool, error) {
	m.muSharedM.RLock()
	defer m.muSharedM.RUnlock()

	return m.muSharedCtxValidate
}

// SetMuSharedCtxValidate sets the shared context validation function
func (m *Mutexes) SetMuSharedCtxValidate(validate func(any) (bool, error)) {
	m.muSharedM.Lock()
	defer m.muSharedM.Unlock()

	m.muSharedCtxValidate = validate
}

// MuWaitCondWithTimeout waits for the condition variable to be signaled with a timeout
func (m *Mutexes) MuWaitCondWithTimeout(timeout time.Duration) bool {
	timer := time.NewTimer(timeout)
	defer timer.Stop()

	ch := make(chan struct{})
	go func() {
		m.MuCtxCond.Wait()
		close(ch)
	}()

	select {
	case <-ch:
		return true
	case <-timer.C:
		return false
	}
}

// MuWaitCond waits for the condition variable to be signaled
func (m *Mutexes) MuWaitCond() {

	m.MuCtxCond.Wait()
}

// MuSignalCond signals the condition variable
func (m *Mutexes) MuSignalCond() {
	m.muSharedM.Lock()
	defer m.muSharedM.Unlock()

	if m.muSharedCtxValidate != nil {
		isValid, err := m.muSharedCtxValidate(m.muSharedCtx)
		if err != nil || !isValid {
			gl.LogObjLogger(m, "warn", "Condition signal aborted due to validation failure")
			return
		}
	}

	gl.LogObjLogger(m, "info", "Signaling condition variable")
	m.MuCtxCond.Signal()
}

// MuBroadcastCond broadcasts the condition variable
func (m *Mutexes) MuBroadcastCond() {
	m.MuCtxCond.Broadcast()
}

// MuAdd adds a delta to the wait group counter
func (m *Mutexes) MuAdd(delta int) { m.MuCtxWg.Add(delta) }

// MuDone signals that the wait group is done
func (m *Mutexes) MuDone() { m.MuCtxWg.Done() }

// MuWait waits for the wait group counter to reach zero
func (m *Mutexes) MuWait() { m.MuCtxWg.Wait() }

func (m *Mutexes) MuTryLock() bool {
	if m.MuCtxM.TryLock() {
		return true
	}
	return false
}

func (m *Mutexes) MuTryRLock() bool {
	if m.MuCtxL.TryRLock() {
		return true
	}
	return false
}

/// internal/types/property.go ///
package types

import (
	"database/sql/driver"
	"encoding/json"
	"os"
	"reflect"

	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
	l "github.com/kubex-ecosystem/logz"

	"github.com/google/uuid"
)

type JsonB map[string]interface{}

// Serializer manual para o GORM
func (m JsonB) Value() (driver.Value, error) { return json.Marshal(m) }

func (m *JsonB) Scan(vl any) error {
	if vl == nil {
		*m = JsonB{}
		return nil
	}
	return json.Unmarshal(vl.([]byte), m)
}

// Property is a struct that holds the properties of the GoLife instance.
type Property[T any] struct {
	// Telemetry is the telemetry for this GoLife instance.
	metrics *Telemetry
	// Prop is the property for this GoLife instance.
	prop ci.IPropertyValBase[T]
	// Cb is the callback function for this GoLife instance.
	cb func(any) (bool, error)
}

// NewProperty creates a new IProperty[T] with the given value and Reference.
func NewProperty[T any](name string, v *T, withMetrics bool, cb func(any) (bool, error)) ci.IProperty[T] {
	p := &Property[T]{
		prop: newVal[T](name, v),
		cb:   cb,
	}
	if withMetrics {
		p.metrics = NewTelemetry()
	}
	return p
}

// GetName returns the name of the property.
func (p *Property[T]) GetName() string {
	return p.prop.GetName()
}

// GetValue returns the value of the property.
func (p *Property[T]) GetValue() T {
	value := p.prop.Get(false)
	if value == nil {
		return *new(T)
	}
	return *value.(*T)
}

// SetValue sets the value of the property.
func (p *Property[T]) SetValue(v *T) {
	p.prop.Set(v)
	if p.cb != nil {
		if _, err := p.cb(v); err != nil {
			//p.metrics.Log("error", "Error in callback function: "+err.Error())
		}
	}
}

// GetReference returns the reference of the property.
func (p *Property[T]) GetReference() (uuid.UUID, string) {
	return p.prop.GetID(), p.prop.GetName()
}

// Prop is a struct that holds the properties of the GoLife instance.
func (p *Property[T]) Prop() ci.IPropertyValBase[T] {
	return p.prop
}

// GetLogger returns the logger of the property.
func (p *Property[T]) GetLogger() l.Logger {

	return p.Prop().GetLogger()

}

// Serialize serializes the ProcessInput instance to the specified format.
func (p *Property[T]) Serialize(format, filePath string) ([]byte, error) {
	value := p.GetValue()
	mapper := NewMapper[T](&value, filePath)
	return mapper.Serialize(format)
}

// Deserialize deserializes the data into the ProcessInput instance.
func (p *Property[T]) Deserialize(data []byte, format, filePath string) error {

	if len(data) == 0 {
		return nil
	}
	value := p.GetValue()
	if !reflect.ValueOf(value).IsValid() {
		p.SetValue(new(T))
	}
	mapper := NewMapper[T](&value, filePath)
	if v, vErr := mapper.Deserialize(data, format); vErr != nil {
		gl.Log("error", "Failed to deserialize data:", vErr.Error())
		return vErr
	} else {
		p.SetValue(v)
	}
	return nil
}

func (p *Property[T]) SaveToFile(filePath string, format string) error {
	if data, err := p.Serialize(format, filePath); err != nil {
		gl.Log("error", "Failed to serialize data:", err.Error())
		return err
	} else {
		if err := os.WriteFile(filePath, data, 0644); err != nil {
			gl.Log("error", "Failed to write to file:", err.Error())
			return err
		}
	}
	return nil
}

func (p *Property[T]) LoadFromFile(filename, format string) error {
	data, err := os.ReadFile(filename)
	if err != nil {
		return err
	}
	return p.Deserialize(data, format, filename)
}

/// internal/types/property_base.go ///
package types

import (
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
	l "github.com/kubex-ecosystem/logz"

	"fmt"
	"reflect"
	"sync/atomic"

	"github.com/google/uuid"
)

// PropertyValBase is a type for the value.
type PropertyValBase[T any] struct {
	// Logger is the logger for this context.
	Logger l.Logger

	// v is the value.
	*atomic.Pointer[T]

	// Reference is the identifiers for the context.
	// IReference
	*Reference

	//muCtx is the mutexes for the context.
	*Mutexes

	// validation is the validation for the value.
	*Validation[T]

	// Channel is the channel for the value.
	ci.IChannelCtl[T]
	channelCtl *ChannelCtl[T]
}

// NewVal is a function that creates a new PropertyValBase instance.
func newVal[T any](name string, v *T) *PropertyValBase[T] {
	ref := NewReference(name)

	// Create a new PropertyValBase instance
	vv := atomic.Pointer[T]{}
	if v != nil {
		vv.Store(v)
	} else {
		vv.Store(new(T))
	}

	// Create a new mutexes instance
	mu := NewMutexesType()

	// Create a new validation instance
	validation := newValidation[T]()

	gl.Log("debug", "Created new PropertyValBase instance for:", name, "ID:", ref.GetID().String())

	return &PropertyValBase[T]{
		Pointer:    &vv,
		Validation: validation,
		Reference:  ref.GetReference(),
		channelCtl: NewChannelCtl[T](name, nil).(*ChannelCtl[T]),
		Mutexes:    mu,
	}
}

func NewVal[T any](name string, v *T) ci.IPropertyValBase[T] {
	ref := NewReference(name)

	// Create a new PropertyValBase instance
	vv := atomic.Pointer[T]{}
	if v != nil {
		vv.Store(v)
	} else {
		vv.Store(new(T))
	}

	// Create a new mutexes instance
	mu := NewMutexesType()

	// Create a new validation instance
	validation := newValidation[T]()

	gl.Log("debug", "Created new PropertyValBase instance for:", name, "ID:", ref.GetID().String())

	return &PropertyValBase[T]{
		Pointer:    &vv,
		Validation: validation,
		Reference:  ref.GetReference(),
		channelCtl: NewChannelCtl[T](name, nil).(*ChannelCtl[T]),
		Mutexes:    mu,
	}
}

// GetLogger is a method that returns the logger for the value.
func (v *PropertyValBase[T]) GetLogger() l.Logger {
	if v == nil {
		gl.Log("error", "GetLogger: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	return v.Logger
}

// GetName is a method that returns the name of the value.
func (v *PropertyValBase[T]) GetName() string {
	if v == nil {
		gl.Log("error", "GetName: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return ""
	}
	return v.Name
}

// GetID is a method that returns the ID of the value.
func (v *PropertyValBase[T]) GetID() uuid.UUID {
	if v == nil {
		gl.Log("error", "GetID: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return uuid.Nil
	}
	return v.ID
}

// Value is a method that returns the value.
func (v *PropertyValBase[T]) Value() *T {
	if v == nil {
		gl.Log("error", "Value: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	return v.Load()
}

// StartCtl is a method that starts the control channel.
func (v *PropertyValBase[T]) StartCtl() <-chan string {
	if v == nil {
		gl.Log("error", "StartCtl: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	if v.channelCtl == nil {
		gl.Log("error", "StartCtl: channel control is nil (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	return v.channelCtl.Channels["ctl"].(<-chan string)
}

// Type is a method that returns the type of the value.
func (v *PropertyValBase[T]) Type() reflect.Type { return reflect.TypeFor[T]() }

// Get is a method that returns the value.
func (v *PropertyValBase[T]) Get(async bool) any {
	if v == nil {
		gl.Log("error", "Get: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return nil
	}
	if async {
		if v.channelCtl != nil {
			gl.Log("debug", "Getting value from channel for:", v.Name, "ID:", v.ID.String())
			v.channelCtl.Channels["get"].(chan T) <- *v.Load()
		}
	} else {
		gl.Log("debug", "Getting value for:", v.Name, "ID:", v.ID.String())
		return v.Load()
	}
	return nil
}

// Set is a method that sets the value.
func (v *PropertyValBase[T]) Set(t *T) bool {
	if v == nil {
		gl.Log("error", "Set: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return false
	}
	if t == nil {
		gl.Log("error", "Set: value is nil (", reflect.TypeFor[T]().String(), ")")
		return false
	}
	if v.Validation != nil {
		if ok := v.Validation.Validate(t); !ok.GetIsValid() {
			gl.Log("error", fmt.Sprintf("Set: validation error (%s): %v", reflect.TypeFor[T]().String(), v.Validation.GetResults()))
			return false
		}
	}
	v.Store(t)
	if v.channelCtl != nil {
		gl.Log("debug", "Setting value for:", v.Name, "ID:", v.ID.String())
		v.channelCtl.Channels["set"].(chan T) <- *t
	}
	return true
}

// Clear is a method that clears the value.
func (v *PropertyValBase[T]) Clear() bool {
	if v == nil {
		gl.Log("error", "Clear: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return false
	}
	if v.channelCtl != nil {
		gl.Log("debug", "Clearing value for:", v.Name, "ID:", v.ID.String())
		v.channelCtl.Channels["clear"].(chan string) <- "clear"
	}
	return true
}

// IsNil is a method that checks if the value is nil.
func (v *PropertyValBase[T]) IsNil() bool {
	if v == nil {
		gl.Log("error", "Get: property does not exist (", reflect.TypeFor[T]().String(), ")")
		return true
	}
	return v.Load() == nil
}

// Serialize is a method that serializes the value.
func (v *PropertyValBase[T]) Serialize(filePath, format string) ([]byte, error) {
	if value := v.Value(); value == nil {
		return nil, fmt.Errorf("value is nil")
	} else {
		mapper := NewMapper[T](value, filePath)
		if data, err := mapper.Serialize(format); err != nil {
			gl.Log("error", "Failed to serialize data:", err.Error())
			return nil, err
		} else {
			return data, nil
		}
	}
}

// Deserialize is a method that deserializes the data into the value.
func (v *PropertyValBase[T]) Deserialize(data []byte, format, filePath string) error {
	if value := v.Value(); value == nil {
		return fmt.Errorf("value is nil")
	} else {
		mapper := NewMapper[T](value, filePath)
		if vl, vErr := mapper.Deserialize(data, format); vErr != nil {
			gl.Log("error", "Failed to deserialize data:", vErr.Error())
			return vErr
		} else {
			v.Store(vl)
			return nil
		}
	}
}

/// internal/types/reference.go ///
package types

import (
	"fmt"
	"reflect"
	"runtime"

	"github.com/google/uuid"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type IReference interface {
	GetID() uuid.UUID
	GetName() string
	SetName(name string)
	String() string
	GetReference() *Reference
}

// Reference is a struct that holds the Reference ID and name.
type Reference struct {
	// refID is the unique identifier for this context.
	ID uuid.UUID
	// refName is the name of the context.
	Name string
}

// newReference is a function that creates a new Reference instance.
func newReference(name string) *Reference {
	if name == "" {
		pc, _, line, ok := runtime.Caller(1)
		if ok {
			fn := runtime.FuncForPC(pc)
			name = fmt.Sprintf("%s:%d", fn.Name(), line)
		} else {
			name = "unknown"
		}
	}
	return &Reference{
		ID:   uuid.New(),
		Name: name,
	}
}

// NewReference is a function that creates a new IReference instance.
func NewReference(name string) IReference {
	return newReference(name)
}

// String is a method that returns the string representation of the reference.
func (r *Reference) String() string {
	return fmt.Sprintf("ID: %s, Name: %s", r.ID.String(), r.Name)
}

// GetID is a method that returns the ID of the reference.
func (r *Reference) GetID() uuid.UUID {
	if r == nil {
		gl.Log("error", "GetID: reference does not exist (", reflect.TypeFor[Reference]().String(), ")")
		return uuid.Nil
	}
	return r.ID
}

// GetName is a method that returns the name of the reference.
func (r *Reference) GetName() string {
	if r == nil {
		gl.Log("error", "GetName: reference does not exist (", reflect.TypeFor[Reference]().String(), ")")
		return ""
	}
	return r.Name
}

// SetName is a method that sets the name of the reference.
func (r *Reference) SetName(name string) {
	if r == nil {
		gl.Log("error", "SetName: reference does not exist (", reflect.TypeFor[Reference]().String(), ")")
		return
	}
	r.Name = name
}

// GetReference is a method that returns the reference struct (non-interface).
func (r *Reference) GetReference() *Reference {
	if r == nil {
		gl.Log("error", "GetReference: reference does not exist (", reflect.TypeFor[Reference]().String(), ")")
		return nil
	}
	return r
}

/// internal/types/reflect.go ///
package types

import (
	"fmt"
	"reflect"

	gl "github.com/kubex-ecosystem/gobe/logger"
)

func AutoEncode[T any](v T, format, filePath string) ([]byte, error) {
	mapper := NewMapper[T](&v, filePath)
	if data, err := mapper.Serialize(format); err != nil {
		gl.Log("error", "AutoEncode: unknown type for serialization (", reflect.TypeOf(v).Name(), "):", err.Error())
		return nil, fmt.Errorf("error: %s", err.Error())
	} else {
		return data, nil
	}
}

func AutoDecode[T any](data []byte, target *T, format string) error {
	mapper := NewMapperTypeWithObject[T](target, "")
	if obj, err := mapper.Deserialize(data, format); err != nil {
		gl.Log("error", "AutoDecode: unknown type for deserialization (", reflect.TypeOf(target).Name(), "):", err.Error())
		return fmt.Errorf("error: %s", err.Error())
	} else {
		if reflect.ValueOf(obj).IsValid() {
			target = obj
			gl.Log("success", "AutoDecode: deserialized object of type ", reflect.TypeOf(obj).Name())
		} else {
			gl.Log("error", "AutoDecode: deserialized object is nil")
			return fmt.Errorf("deserialized object is nil")
		}
		return nil
	}
}

/// internal/types/request_tracer.go ///
package types

import (
	"bufio"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
	l "github.com/kubex-ecosystem/logz"
)

var (
	RequestTracers = make(map[string]ci.IRequestsTracer)
)

const RequestLimit = 5
const RequestWindow = 60 * time.Second

type RequestsTracer struct {
	Mutexes       ci.IMutexes `json:"-" yaml:"-" xml:"-" toml:"-" gorm:"-"`
	IP            string      `json:"ip" yaml:"ip" xml:"ip" toml:"ip" gorm:"ip"`
	Port          string      `json:"port" yaml:"port" xml:"port" toml:"port" gorm:"port"`
	LastUserAgent string      `json:"last_user_agent" yaml:"last_user_agent" xml:"last_user_agent" toml:"last_user_agent" gorm:"last_user_agent"`
	UserAgents    []string    `json:"user_agents" yaml:"user_agents" xml:"user_agents" toml:"user_agents" gorm:"user_agents"`
	Endpoint      string      `json:"endpoint" yaml:"endpoint" xml:"endpoint" toml:"endpoint" gorm:"endpoint"`
	Method        string      `json:"method" yaml:"method" xml:"method" toml:"method" gorm:"method"`
	TimeList      []time.Time `json:"time_list" yaml:"time_list" xml:"time_list" toml:"time_list" gorm:"time_list"`
	Count         int         `json:"count" yaml:"count" xml:"count" toml:"count" gorm:"count"`
	Valid         bool        `json:"-" yaml:"-" xml:"-" toml:"-" gorm:"-"`
	Error         error       `json:"-" yaml:"-" xml:"-" toml:"-" gorm:"-"`
	requestWindow time.Duration
	requestLimit  int
	filePath      string
	oldFilePath   string
	Mapper        ci.IMapper[ci.IRequestsTracer] `json:"-" yaml:"-" xml:"-" toml:"-" gorm:"-"`
}

func newRequestsTracer(ip, port, endpoint, method, userAgent, filePath string) *RequestsTracer {
	var tracer *RequestsTracer
	var exists bool

	if RequestTracers == nil {
		RequestTracers = make(map[string]ci.IRequestsTracer)
	}
	var tracerT ci.IRequestsTracer
	var ok bool
	if tracerT, exists = RequestTracers[ip]; exists {
		tracer, ok = tracerT.(*RequestsTracer)
		if !ok {
			gl.Log("error", fmt.Sprintf("Error casting tracer to RequestsTracer for IP: %s", ip))
			return nil
		}

		//tracer.GetMutexes().MuLock()
		//defer tracer.GetMutexes().MuUnlock()

		tracer.Count++
		tracer.TimeList = append(tracer.TimeList, time.Now())
		tracer.LastUserAgent = userAgent
		tracer.UserAgents = append(tracer.UserAgents, userAgent)

		if len(tracer.TimeList) > 1 {
			if tracer.TimeList[len(tracer.TimeList)-1].Sub(tracer.TimeList[len(tracer.TimeList)-2]) <= RequestWindow {
				gl.Log("info", fmt.Sprintf("Request limit exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count))
				tracer.Valid = false
				tracer.Error = fmt.Errorf("request limit exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count)
			} else if tracer.TimeList[len(tracer.TimeList)-1].Sub(tracer.TimeList[0]) > RequestWindow {
				gl.Log("info", fmt.Sprintf("Request window exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count))
				tracer.Count = 1
				tracer.TimeList = []time.Time{tracer.TimeList[len(tracer.TimeList)-1]}
				tracer.UserAgents = []string{userAgent}
				tracer.Valid = true
				tracer.Error = nil
			} else if tracer.Count > RequestLimit {
				gl.Log("info", fmt.Sprintf("Request limit exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count))
				tracer.Valid = false
				tracer.Error = fmt.Errorf("request limit exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count)
			} else {
				gl.Log("info", fmt.Sprintf("Request limit not exceeded for IP: %s, Count: %d", tracer.IP, tracer.Count))
				tracer.Valid = true
				tracer.Error = nil
			}
		}
		if tracer.filePath != filePath {
			gl.Log("info", fmt.Sprintf("File path changed for IP: %s, Count: %d", tracer.IP, tracer.Count))
			tracer.oldFilePath = tracer.filePath
			tracer.filePath = filePath
		}
	} else {
		tracer = &RequestsTracer{
			IP:            ip,
			Port:          port,
			LastUserAgent: userAgent,
			UserAgents:    []string{userAgent},
			Endpoint:      endpoint,
			Method:        method,
			TimeList:      []time.Time{time.Now()},
			Count:         1,
			Valid:         true,
			Error:         nil,
			Mutexes:       NewMutexesType(),
			filePath:      filePath,
			oldFilePath:   "",

			requestWindow: RequestWindow,
			requestLimit:  RequestLimit,
		}
	}

	RequestTracers[ip] = tracer
	rTracer := ci.IRequestsTracer(tracer)

	tracer.Mapper = NewMapperType[ci.IRequestsTracer](&rTracer, tracer.filePath)

	//tracer.Mutexes.MuAdd(1)
	//go func(tracer *RequestsTracer) {
	//	defer tracer.Mutexes.MuDone()
	//	tracer.Mapper.SerializeToFile("json")
	//}(tracer)
	//tracer.Mutexes.MuWait()

	return tracer
}
func NewRequestsTracerType(ip, port, endpoint, method, userAgent, filePath string) ci.IRequestsTracer {
	return newRequestsTracer(ip, port, endpoint, method, userAgent, filePath)
}
func NewRequestsTracer(ip, port, endpoint, method, userAgent, filePath string) ci.IRequestsTracer {
	return newRequestsTracer(ip, port, endpoint, method, userAgent, filePath)
}

func (r *RequestsTracer) Mu() ci.IMutexes          { return r.Mutexes }
func (r *RequestsTracer) GetIP() string            { return r.IP }
func (r *RequestsTracer) GetPort() string          { return r.Port }
func (r *RequestsTracer) GetLastUserAgent() string { return r.LastUserAgent }
func (r *RequestsTracer) GetUserAgents() []string  { return r.UserAgents }
func (r *RequestsTracer) GetEndpoint() string      { return r.Endpoint }
func (r *RequestsTracer) GetMethod() string        { return r.Method }
func (r *RequestsTracer) GetTimeList() []time.Time { return r.TimeList }
func (r *RequestsTracer) GetCount() int            { return r.Count }
func (r *RequestsTracer) GetError() error          { return r.Error }
func (r *RequestsTracer) GetMutexes() ci.IMutexes  { return r.Mutexes }
func (r *RequestsTracer) IsValid() bool            { return r.Valid }

func (r *RequestsTracer) GetOldFilePath() string {
	if r.oldFilePath == "" {
		abs, err := filepath.Abs(filepath.Join("./", "requests_tracer.json"))
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting absolute path: %v", err))
			return ""
		}
		r.oldFilePath = abs
	}
	return r.oldFilePath
}
func (r *RequestsTracer) GetFilePath() string { return r.filePath }
func (r *RequestsTracer) SetFilePath(filePath string) {
	if filePath == "" {
		abs, err := filepath.Abs(filepath.Join("./", "requests_tracer.json"))
		if err != nil {
			gl.Log("error", fmt.Sprintf("Error getting absolute path: %v", err))
			return
		}
		r.filePath = abs
	} else {
		r.filePath = filePath
	}
}
func (r *RequestsTracer) GetMapper() ci.IMapper[ci.IRequestsTracer] { return r.Mapper }
func (r *RequestsTracer) SetMapper(mapper ci.IMapper[ci.IRequestsTracer]) {
	if mapper == nil {
		gl.Log("error", "Mapper cannot be nil")
		return
	}
	r.Mapper = mapper
}
func (r *RequestsTracer) GetRequestWindow() time.Duration { return r.requestWindow }
func (r *RequestsTracer) SetRequestWindow(window time.Duration) {
	if window <= 0 {
		gl.Log("error", "Request window cannot be negative or zero")
		return
	}
	r.requestWindow = window
}
func (r *RequestsTracer) GetRequestLimit() int { return r.requestLimit }
func (r *RequestsTracer) SetRequestLimit(limit int) {
	if limit <= 0 {
		gl.Log("error", "Request limit cannot be negative or zero")
		return
	}
	r.requestLimit = limit
}

func LoadRequestsTracerFromFile(g ci.IGoBE) (map[string]ci.IRequestsTracer, error) {
	if RequestTracers == nil {
		RequestTracers = make(map[string]ci.IRequestsTracer)
	}

	gl.Log("info", "Loading request tracers from file")
	if _, err := os.Stat(g.GetLogFilePath()); os.IsNotExist(err) {
		gl.Log("warn", fmt.Sprintf("File does not exist: %v, creating new file", err.Error()))
		if _, createErr := os.Create(g.GetLogFilePath()); createErr != nil {
			gl.Log("error", fmt.Sprintf("Error creating file: %v", createErr.Error()))
			return nil, createErr
		} else {
			gl.Log("info", "File created successfully")
		}
		return nil, nil
	}

	gl.Log("info", "File exists, proceeding to load")
	inputFile, err := os.Open(g.GetLogFilePath())
	if err != nil {
		gl.Log("error", "Erro ao abrir arquivo: %v", err.Error())
		return nil, err
	}

	defer func(inputFile *os.File) {
		gl.Log("info", "Closing input file")
		if closeErr := inputFile.Close(); closeErr != nil {
			gl.Log("error", fmt.Sprintf("Erro ao fechar arquivo: %v", err))
		}
	}(inputFile)

	reader := bufio.NewReader(inputFile)
	decoder := json.NewDecoder(reader)
	decoder.DisallowUnknownFields()

	//g.Mu().MuAdd(1)
	go func(g ci.IGoBE) {
		//defer g.Mu().MuDone()
		gl.Log("info", "Decoding request tracers from file")
		for decoder.More() {
			var existing *RequestsTracer
			if err := decoder.Decode(&existing); err != nil || existing == nil {
				if err == nil {
					err = fmt.Errorf("existing nÃ£o inicializado: %v, err: %s", existing, err)
				}
				gl.Log("error", fmt.Sprintf("Erro ao decodificar:%s", err.Error()))
				continue
			}
			gl.Log("info", fmt.Sprintf("Decoded request tracer: %s", existing.IP))
			RequestTracers[existing.IP] = existing
		}
	}(g)

	gl.Log("info", "Waiting for decoding to finish")
	//g.Mu().MuWait()

	if len(RequestTracers) > 0 {
		gl.Log("info", fmt.Sprintf("Loaded %d request tracers", len(RequestTracers)))
	} else {
		gl.Log("warn", "No request tracers loaded from file")
	}

	return RequestTracers, nil
}
func updateRequestTracer(g ci.IGoBE, updatedTracer ci.IRequestsTracer) error {
	var decoder *json.Decoder
	var outputFile *os.File
	var err error
	tmpFilePath := filepath.Join(g.GetConfigFilePath(), "temp"+updatedTracer.GetFilePath())

	if inputFile, inputFileErr := os.Open(updatedTracer.GetFilePath()); inputFileErr != nil || inputFile == nil {
		if inputFileErr == nil {
			inputFileErr = fmt.Errorf("inputFile nÃ£o inicializado")
		}
		return fmt.Errorf("erro ao abrir arquivo: %v", inputFileErr)
	} else {
		defer func(inputFile *os.File) {
			_ = inputFile.Close()
		}(inputFile)

		if outputFile, err = os.Create(tmpFilePath); err != nil || outputFile == nil {
			if err == nil {
				err = fmt.Errorf("outputFile nÃ£o inicializado")
			}
			return fmt.Errorf("erro ao criar arquivo temporÃ¡rio: %v", err)
		} else {
			defer func(outputFile *os.File, tmpFilePath string) {
				_ = outputFile.Close()
				if removeErr := os.Remove(tmpFilePath); removeErr != nil {
					gl.Log("error", fmt.Sprintf("Erro ao remover arquivo temporÃ¡rio: %v", removeErr))
					return
				}
			}(outputFile, tmpFilePath)

			decoder = json.NewDecoder(inputFile)
			decoder.DisallowUnknownFields()

			var existing *RequestsTracer
			for decoder.More() {
				existing = &RequestsTracer{}
				if err = decoder.Decode(&existing); err != nil || existing == nil {
					if err == nil {
						err = fmt.Errorf("existing nÃ£o inicializado")
					}

					gl.Log("error", fmt.Sprintf("Erro ao decodificar linha: %v", err))

					continue
				} else {
					var line []byte

					// If the existing tracer matches the updated tracer, update it
					if existing.IP == updatedTracer.GetIP() && existing.Port == updatedTracer.GetPort() {
						lineBytes, _ := json.Marshal(updatedTracer)
						line = []byte(string(lineBytes) + "\n")
					}

					// Escreve a linha no novo arquivo, em array de bytes (que seria "bufferizado" e mais rÃ¡pido)
					if _, writeErr := outputFile.Write(line); writeErr != nil {
						return writeErr
					}
				}
			}
		}
	}
	if _, tmpFilePathStatErr := os.Stat(tmpFilePath); tmpFilePathStatErr != nil {
		if replaceErr := os.Rename(tmpFilePath, updatedTracer.GetFilePath()); replaceErr != nil {
			return replaceErr
		}
	}
	return nil
}
func isDuplicateRequest(g ci.IGoBE, rt ci.IRequestsTracer, logger l.Logger) bool {
	env := g.Environment()
	strategy := screeningByRAMSize(env, rt.GetFilePath())

	if strategy == "strings" {
		data, err := os.ReadFile(rt.GetFilePath())
		if err != nil {
			gl.Log("error", fmt.Sprintf("Erro ao ler arquivo: %v", err))
			return false
		}

		lines := strings.Split(string(data), "\n")
		for _, line := range lines {
			if strings.Contains(line, rt.GetIP()) && strings.Contains(line, rt.GetPort()) {
				return true
			}
		}
	} else {
		f, err := os.Open(rt.GetFilePath())
		if err != nil {
			gl.Log("error", fmt.Sprintf("Erro ao abrir arquivo: %v", err))
			return false
		}
		defer func(f *os.File) {
			_ = f.Close()
		}(f)

		scanner := bufio.NewScanner(f)
		for scanner.Scan() {
			var existing RequestsTracer
			if err := json.Unmarshal([]byte(scanner.Text()), &existing); err != nil {
				continue
			}
			if existing.IP == rt.GetIP() && existing.Port == rt.GetPort() {
				return true
			}
		}
	}

	return false
}
func updateRequestTracerInMemory(updatedTracer ci.IRequestsTracer) error {
	if data, err := os.ReadFile(updatedTracer.GetFilePath()); err != nil {
		return fmt.Errorf("erro ao ler arquivo: %v", err)
	} else {
		lines := strings.Split(string(data), "\n")
		for i, line := range lines {
			if line == "" {
				continue
			}
			var existing RequestsTracer
			if err := json.Unmarshal([]byte(line), &existing); err != nil {
				continue
			}
			if existing.IP == updatedTracer.GetIP() && existing.Port == updatedTracer.GetPort() {
				lines[i] = func(data ci.IRequestsTracer) string {
					if lineBytes, lineBytesErr := json.Marshal(data); lineBytesErr != nil {
						gl.Log("error", fmt.Sprintf("Error marshalling updated tracer: %v", lineBytesErr))
						return ""
					} else {
						return string(lineBytes)
					}
				}(updatedTracer)
			}
		}
		return os.WriteFile(updatedTracer.GetFilePath(), []byte(strings.Join(lines, "\n")), 0644)
	}
}

/// internal/types/signal_manager.go ///
package types

import (
	"fmt"
	"os"
	"os/signal"
	"syscall"

	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
	l "github.com/kubex-ecosystem/logz"
)

type SignalManager[T chan string] struct {
	// Logger is the Logger instance for this GoLife instance.
	Logger l.Logger
	// Reference is the reference ID and name.
	*Reference
	// SigChan is the channel for the signal.
	SigChan    chan os.Signal
	channelCtl T
}

// NewSignalManager creates a new SignalManager instance.
func newSignalManager[T chan string](channelCtl T, logger l.Logger) *SignalManager[T] {
	if logger == nil {
		logger = l.GetLogger("GoLife")
	}
	return &SignalManager[T]{
		Logger:     logger,
		Reference:  newReference("SignalManager"),
		SigChan:    make(chan os.Signal, 1),
		channelCtl: channelCtl,
	}
}

// NewSignalManager creates a new SignalManager instance.
func NewSignalManager[T chan string](channelCtl chan string, logger l.Logger) ci.ISignalManager[T] {
	return newSignalManager[T](channelCtl, logger)
}

// ListenForSignals sets up the signal channel to listen for specific signals.
func (sm *SignalManager[T]) ListenForSignals() (<-chan string, error) {
	signal.Notify(sm.SigChan, os.Interrupt, syscall.SIGTERM, syscall.SIGHUP)

	go func() {
		for sig := range sm.SigChan {
			fmt.Printf("Sinal recebido: %s\n", sig.String())
			if sm.channelCtl != nil {
				sm.channelCtl <- fmt.Sprintf("{\"context\":\"%s\", \"message\":\"%s\"}", sm.GetName(), ""+sig.String())
			} else {
				fmt.Println("Canal de controle nÃ£o definido.")
			}
		}
	}()
	return sm.channelCtl, nil
}

// StopListening stops listening for signals and closes the channel.
func (sm *SignalManager[T]) StopListening() {
	signal.Stop(sm.SigChan) // ğŸ”¥ Para de escutar sinais
	close(sm.SigChan)       // ğŸ”¥ Fecha o canal para evitar vazamento de goroutines
	gl.LogObjLogger(sm, "info", "Parando escuta de sinais")
}

/// internal/types/telemetry.go ///
package types

import (
	l "github.com/kubex-ecosystem/logz"
	"sync"
	"time"
)

// TelemetryIdentifier is a struct that holds the identifier for telemetry data
type TelemetryIdentifier struct {
	// ID is the unique identifier for this telemetry instance
	ID string
	// Name is the name of the telemetry instance
	Name string
	// Logger is the Logger instance for this telemetry
	Logger l.Logger
	// Type is the type of telemetry (e.g., CPU, Memory, etc.)
	Type string
}

// TelemetryMutex is a struct that holds mutexes for synchronizing access to telemetry data
type TelemetryMutex struct {
	// mutex is a mutex for synchronizing access to the telemetry data
	mutex *sync.RWMutex
	// mutexL is a mutex for synchronizing access to the Logger
	mutexL *sync.RWMutex
	// mutexC is a mutex for synchronizing access to the channels
	mutexC *sync.RWMutex
	// mutexW is a mutex for synchronizing access to the wait group
	mutexW *sync.RWMutex
}

// TelemetryChannel is a struct that holds channels for telemetry data
type TelemetryChannel struct {
	// channelOut is a channel for sending telemetry data
	channelOut chan map[string]float64
	// channelIn is a channel for receiving telemetry data
	channelIn chan map[string]float64
	// channelErr is a channel for sending error messages
	channelErr chan error
	// channelDone is a channel for signaling when the telemetry is done
	channelDone chan struct{}
	// channelExit is a channel for signaling when the telemetry should exit
	channelExit chan struct{}
}

// TelemetryData is a struct that holds telemetry data
type TelemetryData struct {
	// LastUpdated is the last time the telemetry data was updated
	LastUpdated time.Time
	// Metrics is a map of metric names to their values
	Metrics map[string]float64
}

// TelemetryLogger is a struct that holds a Logger for telemetry data
type TelemetryLogger struct {
	// logger is the logger instance
	logger l.Logger
}

// TelemetryProperty is a struct that holds a property for telemetry data
type TelemetryProperty struct {
	// property is the property instance
	property any
}

// TelemetryConfig is a struct that holds the configuration for telemetry data
type TelemetryConfig struct {
	// config is the configuration instance
	config any
}

// Telemetry is a struct that holds telemetry data for a process
type Telemetry struct {
	// TelemetryIdentifier is the identifier for telemetry data
	TelemetryIdentifier
	// TelemetryLogger is the Logger for telemetry data
	TelemetryLogger
	// TelemetryData is the telemetry data
	TelemetryData
	// TelemetryMutex is a mutex for synchronizing access to the telemetry data
	TelemetryMutex
	// TelemetryChannel is a struct that holds channels for telemetry data
	TelemetryChannel
	// TelemetryProperty is a struct that holds a property for telemetry data
	TelemetryProperty
	// TelemetryConfig is a struct that holds the configuration for telemetry data
	TelemetryConfig
}

// NewTelemetry creates a new Telemetry instance
func NewTelemetry() *Telemetry {
	return &Telemetry{
		TelemetryIdentifier: TelemetryIdentifier{
			ID:     "default",
			Name:   "default",
			Logger: l.GetLogger("Telemetry"),
			Type:   "default",
		},
		TelemetryLogger: TelemetryLogger{
			logger: l.GetLogger("Telemetry"),
		},
		TelemetryData: TelemetryData{
			LastUpdated: time.Now(),
			Metrics:     make(map[string]float64),
		},
		TelemetryMutex: TelemetryMutex{
			mutex:  &sync.RWMutex{},
			mutexL: &sync.RWMutex{},
			mutexC: &sync.RWMutex{},
			mutexW: &sync.RWMutex{},
		},
		TelemetryChannel: TelemetryChannel{
			channelOut:  make(chan map[string]float64, 1),
			channelIn:   make(chan map[string]float64, 1),
			channelErr:  make(chan error, 1),
			channelDone: make(chan struct{}, 1),
			channelExit: make(chan struct{}, 1),
		},
	}
}

// UpdateMetrics updates the telemetry metrics with the given data
func (t *Telemetry) UpdateMetrics(data map[string]float64) {
	t.mutex.Lock()
	defer t.mutex.Unlock()
	t.LastUpdated = time.Now()
	for key, value := range data {
		t.Metrics[key] = value
	}
}

// GetMetrics returns the telemetry metrics
func (t *Telemetry) GetMetrics() map[string]float64 {
	t.mutex.RLock()
	defer t.mutex.RUnlock()
	return t.Metrics
}

// GetLastUpdated returns the last updated time of the telemetry
func (t *Telemetry) GetLastUpdated() time.Time {
	t.mutex.RLock()
	defer t.mutex.RUnlock()
	return t.LastUpdated
}

// ResetMetrics resets the telemetry metrics
func (t *Telemetry) ResetMetrics() {
	t.mutex.Lock()
	defer t.mutex.Unlock()
	t.Metrics = make(map[string]float64)
	t.LastUpdated = time.Now()
}

/// internal/types/utils.go ///
package types

import (
	"fmt"
	"io"
	"os"

	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

func IsShellSpecialVar(c uint8) bool {
	switch c {
	case '*', '#', '$', '@', '!', '?', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':
		return true
	}
	return false
}
func IsAlphaNum(c uint8) bool {
	return c == '_' || '0' <= c && c <= '9' || 'a' <= c && c <= 'z' || 'A' <= c && c <= 'Z'
}
func screeningByRAMSize(env ci.IEnvironment, filePath string) string {
	memAvailable := env.MemTotal()

	fileInfo, err := os.Stat(filePath)
	if err != nil {
		gl.Log("error", fmt.Sprintf("Erro ao obter tamanho do arquivo: %v", err))
		return "fallback"
	}

	// Se a memÃ³ria disponÃ­vel for menor que 100MB E arquivo for grande (>5MB), usa strings
	if memAvailable < 100 && fileInfo.Size() > 5*1024*1024 {
		return "strings"
	}
	return "json"
}
func asyncCopyFile(src, dst string) error {
	//go func() {
	_, err := copyFile(src, dst)
	if err != nil {
		fmt.Printf("Erro ao fazer backup do arquivo: %v\n", err)
	}
	//}()
	return nil
}
func copyFile(src, dst string) (int64, error) {
	source, err := os.Open(src)
	if err != nil {
		return 0, err
	}
	defer func(source *os.File) {
		_ = source.Close()
	}(source)

	destination, err := os.Create(dst)
	if err != nil {
		return 0, err
	}
	defer func(destination *os.File) {
		_ = destination.Close()
	}(destination)

	return io.Copy(destination, source)
}

/// internal/types/validation.go ///
package types

import (
	"reflect"

	"github.com/google/uuid"
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"

	"fmt"
	"sort"
	"sync"
)

type ValidationResult struct {
	*Mutexes
	*Reference
	IsValid  bool
	Message  string
	Error    error
	Metadata map[string]any
	Callback func(result *ValidationResult)
}

func newValidationResult(isValid bool, message string, metadata map[string]any, err error) *ValidationResult {
	if metadata == nil {
		metadata = make(map[string]any)
	}
	return &ValidationResult{
		Mutexes:   NewMutexesType(),
		Reference: newReference("ValidationResult"),
		IsValid:   isValid,
		Message:   message,
		Error:     err,
		Metadata:  metadata,
	}
}
func NewValidationResult(isValid bool, message string, metadata map[string]any, err error) ci.IValidationResult {
	return newValidationResult(isValid, message, metadata, err)
}

func (vr *ValidationResult) String() string {
	if vr == nil {
		return ""
	}
	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()
	if vr.IsValid {
		return "Validation is valid"
	}
	if vr.Error != nil {
		return fmt.Sprintf("Validation is invalid: %s", vr.Error.Error())
	}
	return fmt.Sprintf("Validation is invalid: %s", vr.Message)
}
func (vr *ValidationResult) GetID() uuid.UUID {
	if vr == nil {
		return uuid.Nil
	}
	return vr.Reference.GetID()
}
func (vr *ValidationResult) GetName() string {
	if !reflect.ValueOf(vr).IsValid() {
		return ""
	}
	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()
	return vr.Reference.GetName()
}
func (vr *ValidationResult) GetIsValid() bool {
	if vr == nil {
		return false
	}
	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()
	return vr.IsValid
}
func (vr *ValidationResult) GetMessage() string {
	if vr == nil {
		return ""
	}
	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()
	return vr.Message
}
func (vr *ValidationResult) GetMetadata(key string) (any, bool) {
	if !reflect.ValueOf(vr.Metadata).IsValid() {
		vr.Mutexes.MuLock()
		defer vr.Mutexes.MuUnlock()

		vr.Metadata = make(map[string]any)
		return nil, false
	}

	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()

	if key == "" {
		return vr.Metadata, true
	}
	value, exists := vr.Metadata[key]

	return value, exists
}
func (vr *ValidationResult) SetMetadata(key string, value any) {
	if vr == nil {
		return
	}
	vr.Mutexes.MuLock()
	defer vr.Mutexes.MuUnlock()

	if vr.Metadata == nil {
		vr.Metadata = make(map[string]any)
	}
	if !reflect.ValueOf(value).IsValid() {
		return
	}
	if key == "" {
		return
	} else if key == "all" {
		if vl, ok := value.(map[string]any); ok {
			vr.Metadata = vl
			return
		} else if vl, ok := value.(ValidationResult); ok {
			vr.Metadata = vl.Metadata
			return
		}
	}

	vr.Metadata[key] = value
}
func (vr *ValidationResult) GetAllMetadataKeys() []string {
	if vr == nil || vr.Metadata == nil {
		return nil
	}

	vr.Mutexes.MuRLock()
	defer vr.Mutexes.MuRUnlock()

	keys := make([]string, 0, len(vr.Metadata))
	for key := range vr.Metadata {
		keys = append(keys, key)
	}
	return keys
}
func (vr *ValidationResult) GetError() error {
	if vr == nil {
		return nil
	}
	return vr.Error
}

type ValidationFunc[T any] struct {
	Priority int
	Func     func(value *T, args ...any) ci.IValidationResult
	Result   ci.IValidationResult
}

func newValidationFunc[T any](priority int, f func(value *T, args ...any) ci.IValidationResult) *ValidationFunc[T] {
	return &ValidationFunc[T]{
		Priority: priority,
		Func:     f,
		Result:   nil,
	}
}
func NewValidationFunc[T any](priority int, f func(value *T, args ...any) ci.IValidationResult) ci.IValidationFunc[T] {
	validFunc := newValidationFunc[T](priority, nil)
	validFunc.Func = f
	return validFunc
}

func (vf *ValidationFunc[T]) GetPriority() int {
	if vf == nil {
		return -1
	}
	return vf.Priority
}
func (vf *ValidationFunc[T]) SetPriority(priority int) {
	if vf == nil {
		return
	}
	vf.Priority = priority
}
func (vf *ValidationFunc[T]) GetFunction() func(value *T, args ...any) ci.IValidationResult {
	if vf == nil {
		return nil
	}
	return vf.Func
}
func (vf *ValidationFunc[T]) SetFunction(f func(value *T, args ...any) ci.IValidationResult) {
	if vf == nil {
		return
	}
	vf.Func = f
}
func (vf *ValidationFunc[T]) GetResult() ci.IValidationResult {
	if vf == nil {
		return nil
	}
	return vf.Result
}
func (vf *ValidationFunc[T]) SetResult(result ci.IValidationResult) {
	if vf == nil {
		return
	}
	vf.Result = result
}

// Validation is a struct that holds the validation function and the errors.
type Validation[T any] struct {
	mu sync.RWMutex
	// isValid is a boolean that indicates if the value is valid.
	isValid bool
	// hasValidate is a boolean that indicates if the value will be validated.
	hasValidation bool
	// validatorMap is the map of validators.
	validatorMap sync.Map
	// validateFunc is the function that validates the value.
	validateFunc func(value *T, args ...any) ci.IValidationResult
}

// vldtFunc is a function that validates the value.
func vldtFunc[T any](v *Validation[T]) func(value *T, args ...any) ci.IValidationResult {
	return func(value *T, args ...any) ci.IValidationResult {
		if v == nil {
			return newValidationResult(false, "validation is nil", nil, fmt.Errorf("validation is nil"))
		}
		if !v.IsValid() {
			return newValidationResult(false, "validation is invalid", nil, fmt.Errorf("validation is invalid"))
		}

		for _, arg := range args {
			if validator, ok := arg.(*ValidationFunc[T]); ok {
				if validator.Func != nil {
					result := validator.Func(value, args...)
					if result != nil && !result.GetIsValid() {
						return result
					}
				}
			}
		}

		return newValidationResult(true, "validation is valid", nil, nil)
	}
}

func VldtFunc[T any](v ci.IValidation[T]) func(value *T, args ...any) ci.IValidationResult {
	return func(value *T, args ...any) ci.IValidationResult {
		if v == nil {
			return NewValidationResult(false, "validation is nil", nil, fmt.Errorf("validation is nil"))
		}
		if !v.IsValid() {
			return NewValidationResult(false, "validation is invalid", nil, fmt.Errorf("validation is invalid"))
		}

		//v.mu.Lock()
		//defer v.mu.Unlock()

		for _, arg := range args {
			if validator, ok := arg.(ci.IValidationFunc[T]); ok {
				if validator.GetFunction() != nil {
					result := validator.GetFunction()(value, args...)
					if result != nil && !result.GetIsValid() {
						return result
					}
				}
			}
		}

		return NewValidationResult(true, "validation is valid", nil, nil)
	}
}

func newValidation[T any]() *Validation[T] {
	validation := &Validation[T]{
		isValid:      false,
		validatorMap: sync.Map{},
	}
	validation.validateFunc = vldtFunc(validation)
	return validation
}
func NewValidation[T any]() ci.IValidation[T] {
	validation := &Validation[T]{
		isValid:      false,
		validatorMap: sync.Map{},
	}
	validation.validateFunc = vldtFunc(validation)
	return validation
}

func (v *Validation[T]) CheckIfWillValidate() bool {
	if v == nil {
		return false
	}

	v.mu.RLock()
	defer v.mu.RUnlock()

	hasValidator := false
	v.validatorMap.Range(func(key, value any) bool {
		if _, vld := key.(int); vld {
			if _, ok := value.(ValidationFunc[T]); ok {
				hasValidator = true
				return false
			}
		}
		return true
	})
	v.hasValidation = hasValidator
	return hasValidator
}

// Validate is the function that validates the value.
func (v *Validation[T]) Validate(value *T, args ...any) ci.IValidationResult {
	if v == nil {
		return NewValidationResult(false, "validation is nil", nil, fmt.Errorf("validation is nil"))
	}
	if value == nil {
		return NewValidationResult(false, "value is nil", nil, fmt.Errorf("value is nil"))
	}
	if !v.hasValidation {
		return NewValidationResult(false, "validation has no validators", nil, fmt.Errorf("validation has no validators"))
	}

	v.mu.Lock()
	defer v.mu.Unlock()

	results := make([]ci.IValidationResult, 0)
	v.validatorMap.Range(func(key, val any) bool {
		if validator, ok := val.(ValidationFunc[T]); ok {
			result := validator.Func(value, args...)
			results = append(results, result)
			if result != nil && !result.GetIsValid() {
				v.isValid = false
				return false
			}
		}
		return true
	})

	if len(results) > 0 {
		sort.Slice(results, func(i, j int) bool {
			return results[i].GetMessage() < results[j].GetMessage()
		})
	}

	v.isValid = true
	for _, result := range results {
		if result != nil && !result.GetIsValid() {
			v.isValid = false
			break
		}
	}

	return NewValidationResult(v.isValid, "validation is valid", nil, nil)
}

// AddValidator is a function that adds a validator to the map of validators.
func (v *Validation[T]) AddValidator(validator ci.IValidationFunc[T]) error {
	if v == nil {
		return fmt.Errorf("validation is nil")
	}

	// Will update v.hasValidation always, if this method is called.
	v.CheckIfWillValidate()

	if validator.GetFunction() == nil {
		return fmt.Errorf("validator function is nil")
	}
	if validator.GetPriority() < 0 {
		return fmt.Errorf("priority must be greater than or equal to 0")
	}
	if _, ok := v.validatorMap.LoadOrStore(validator.GetPriority(), validator); ok {
		return fmt.Errorf("validator with priority %d already exists", validator.GetPriority())
	}

	// If the validator was added, we need to update v.hasValidation again, just for safety.
	v.CheckIfWillValidate()

	return nil
}

// RemoveValidator is a function that removes a validator from the map of validators.
func (v *Validation[T]) RemoveValidator(priority int) error {
	if v == nil {
		return fmt.Errorf("validation is nil")
	}
	if _, ok := v.validatorMap.LoadAndDelete(priority); !ok {
		return fmt.Errorf("validator with priority %d does not exist", priority)
	}

	// If the validator was removed, we need to update v.hasValidation.
	v.CheckIfWillValidate()

	return nil
}

// GetValidator is a function that gets a validator from the map of validators.
func (v *Validation[T]) GetValidator(priority int) (any, error) {
	if v == nil {
		return nil, fmt.Errorf("validation is nil")
	}
	if !v.hasValidation {
		return nil, fmt.Errorf("validation has no validators")
	}
	if validator, ok := v.validatorMap.Load(priority); ok {
		return validator, nil
	}
	return nil, fmt.Errorf("validator with priority %d does not exist", priority)
}

// GetValidators is a function that gets the map of validators.
func (v *Validation[T]) GetValidators() map[int]ci.IValidationFunc[T] {
	if v == nil {
		return nil
	}
	if !v.hasValidation {
		return nil
	}
	validatorMapSnapshot := make(map[int]ci.IValidationFunc[T])
	v.validatorMap.Range(func(key, value any) bool {
		if validator, ok := value.(ci.IValidationFunc[T]); ok {
			validatorMapSnapshot[validator.GetPriority()] = validator
		}
		return true
	})
	return validatorMapSnapshot
}

// GetResults is a function that gets the map of errors.
func (v *Validation[T]) GetResults() map[int]ci.IValidationResult {
	if v == nil {
		return nil
	}
	if !v.hasValidation {
		return nil
	}
	results := make(map[int]ci.IValidationResult)
	v.validatorMap.Range(func(key, value any) bool {
		if validator, ok := value.(ci.IValidationFunc[T]); ok {
			results[validator.GetPriority()] = validator.GetResult()
		}
		return true
	})
	return results
}

// ClearResults is a function that clears the map of errors.
func (v *Validation[T]) ClearResults() {
	if v == nil {
		return
	}
	if !v.hasValidation {
		return
	}
	v.validatorMap.Range(func(key, value any) bool {
		if validator, ok := value.(ValidationFunc[T]); ok {
			validator.Result = nil
			v.validatorMap.Store(key, validator)
		}
		return true
	})
}

// IsValid is a function that gets the boolean that indicates if the value is valid.
func (v *Validation[T]) IsValid() bool {
	if v == nil {
		// If the validation is nil, we need to return false.
		// But we will Log that the validation is nil.
		return false
	}
	if !v.hasValidation {
		// If the validation has no validators, we need to return false.
		// But we will Log that the validation has no validators.
		return false
	}
	return v.isValid
}

/// internal/types/validation_listener.go ///
package types

import (
	"reflect"

	gl "github.com/kubex-ecosystem/gobe/logger"
)

type ValidationListenerType string

const (
	ValidationListenerTypeBefore  ValidationListenerType = "before"  // Before validation
	ValidationListenerTypeAfter   ValidationListenerType = "after"   // After validation
	ValidationListenerTypeError   ValidationListenerType = "error"   // Error validation
	ValidationListenerTypeSuccess ValidationListenerType = "success" // Success validation
	ValidationListenerTypeDefault ValidationListenerType = "default" // Default validation
)

type ValidationFilterType string

const (
	ValidationFilterTypeEvent    ValidationFilterType = "event"    // Event filter
	ValidationFilterTypeListener ValidationFilterType = "listener" // Listener filter
	ValidationFilterTypeResult   ValidationFilterType = "result"   // Result filter
)

type ValidationListener struct {
	*Mutexes
	Filters   map[ValidationFilterType]func(*ValidationResult) bool
	Handlers  []func(*ValidationResult)
	Listeners map[Reference]map[ValidationListenerType]func(*ValidationResult)
}

func NewValidationListener() *ValidationListener {
	return &ValidationListener{
		Mutexes:   NewMutexesType(),
		Listeners: make(map[Reference]map[ValidationListenerType]func(*ValidationResult)),
		Filters:   make(map[ValidationFilterType]func(*ValidationResult) bool),
		Handlers:  []func(*ValidationResult){},
	}
}

func (vl *ValidationListener) AddFilter(filterType ValidationFilterType, filter func(*ValidationResult) bool) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	if vl.Filters == nil {
		vl.Filters = make(map[ValidationFilterType]func(*ValidationResult) bool)
	}
	if filter == nil {
		gl.Log("error", "RegisterListener: filter is nil")
		return
	}

	vl.Filters[filterType] = filter
}

func (vl *ValidationListener) RemoveFilter(filterType ValidationFilterType) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	delete(vl.Filters, filterType)
}

func (vl *ValidationListener) AddHandler(handler func(*ValidationResult)) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	vl.Handlers = append(vl.Handlers, handler)
}

func (vl *ValidationListener) RemoveHandler(handler func(*ValidationResult)) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	for i, h := range vl.Handlers {
		if reflect.ValueOf(h).Pointer() == reflect.ValueOf(handler).Pointer() {
			vl.Handlers = append(vl.Handlers[:i], vl.Handlers[i+1:]...)
			break
		}
	}
}

func (vl *ValidationListener) AddListener(reference Reference, listenerType ValidationListenerType, handler func(*ValidationResult)) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	if _, exists := vl.Listeners[reference]; !exists {
		vl.Listeners[reference] = make(map[ValidationListenerType]func(*ValidationResult))
	}
	vl.Listeners[reference][listenerType] = handler
}

func (vl *ValidationListener) RemoveListener(reference Reference, listenerType ValidationListenerType) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	if _, exists := vl.Listeners[reference]; exists {
		delete(vl.Listeners[reference], listenerType)
		if len(vl.Listeners[reference]) == 0 {
			delete(vl.Listeners, reference)
		}
	}
}

func (vl *ValidationListener) GetFilters() map[string]func(*ValidationResult) bool {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	filters := make(map[string]func(*ValidationResult) bool)
	for k, v := range vl.Filters {
		if v == nil {
			gl.Log("error", "RegisterListener: filter is nil")
			continue
		}
		filters[string(k)] = v
	}
	return filters
}

func (vl *ValidationListener) GetHandlersByName(name string) []func(*ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	for _, handler := range vl.Handlers {
		if handler == nil {
			gl.Log("error", "RegisterListener: handler is nil")
			continue
		}
		if name == "" {
			gl.Log("error", "RegisterListener: name is empty")
			continue
		}
		if handler == nil {
			gl.Log("error", "RegisterListener: handler is nil")
			continue
		}
		return []func(*ValidationResult){handler}
	}
	return nil
}

func (vl *ValidationListener) GetHandlers() []func(*ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	handlers := make([]func(*ValidationResult), len(vl.Handlers))
	copy(handlers, vl.Handlers)
	return handlers
}

func (vl *ValidationListener) GetListeners() map[Reference]map[ValidationListenerType]func(*ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	listeners := make(map[Reference]map[ValidationListenerType]func(*ValidationResult))
	for k, v := range vl.Listeners {
		listeners[k] = v
	}
	return listeners
}

func (vl *ValidationListener) GetListenersByName(name string) map[ValidationListenerType]func(*ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	for k, v := range vl.Listeners {
		if k.GetName() == name {
			return v
		}
	}
	return nil
}

func (vl *ValidationListener) GetListenersKeys() map[string]Reference {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return nil
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	keys := make(map[string]Reference)
	for k := range vl.Listeners {
		keys[k.GetName()] = k
	}
	return keys
}

func (vl *ValidationListener) RegisterListener(reference Reference, handler func(*ValidationResult)) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}
	vl.Mutexes.MuLock()
	defer vl.Mutexes.MuUnlock()

	if handler == nil {
		gl.Log("error", "RegisterListener: handler is nil")
		return
	}

	if _, exists := vl.Listeners[reference]; !exists {
		vl.Listeners[reference] = make(map[ValidationListenerType]func(*ValidationResult))
	}
	vl.Listeners[reference][ValidationListenerTypeDefault] = handler
}

func (vl *ValidationListener) Trigger(event string, result *ValidationResult) {
	if vl == nil {
		gl.Log("error", "RegisterListener: ValidationListener is nil")
		return
	}

	vl.Mutexes.MuRLock()
	defer vl.Mutexes.MuRUnlock()

	if result == nil {
		gl.Log("error", "RegisterListener: result is nil")
		return
	}
	if event == "" {
		gl.Log("error", "RegisterListener: event is empty")
		return
	}

	if listenerZ := vl.GetListenersByName(event); listenerZ != nil {
		// Check event filters
		for _, filter := range vl.Filters {
			if filter == nil {
				gl.Log("error", "RegisterListener: filter is nil")
				continue
			}
			if !filter(result) {
				gl.Log("info", "RegisterListener: filter failed")
				return
			}
		}
		for _, listener := range listenerZ {
			if listener == nil {
				gl.Log("error", "RegisterListener: listener is nil")
				continue
			}
			// Check listener filters
			for _, filter := range vl.Filters {
				if filter == nil {
					gl.Log("error", "RegisterListener: filter is nil")
					continue
				}
				if !filter(result) {
					gl.Log("info", "RegisterListener: filter failed")
					return
				}
			}
			// Async dispatch
			go listener(result)
		}
	}
}

/// internal/utils/channels.go ///
package utils

import (
	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"

	"fmt"
	"reflect"
)

func chanRoutineCtl[T any](v ci.IChannelCtl[T], chCtl chan string, ch chan T) {
	select {
	case msg := <-chCtl:
		switch msg {
		case "stop":
			if ch != nil {
				gl.Log("debug", "Stopping channel for:", v.GetName(), "ID:", v.GetID().String())
				ch <- v.GetProperty().GetValue()
				return
			}
		case "get":
			if ch != nil {
				gl.Log("debug", "Getting value from channel for:", v.GetName(), "ID:", v.GetID().String())
				ch <- v.GetProperty().GetValue()
			}
		case "set":
			if ch != nil {
				gl.Log("debug", "Waiting for value from channel for:", v.GetName(), "ID:", v.GetID().String())
				nVal := <-ch
				if reflect.ValueOf(nVal).IsValid() {
					if reflect.ValueOf(nVal).CanConvert(reflect.TypeFor[T]()) {
						gl.Log("debug", "Setting value from channel for:", v.GetName(), "ID:", v.GetID().String())
						v.GetProperty().SetValue(&nVal)
					} else {
						gl.Log("error", "Set: invalid type for channel value (", reflect.TypeFor[T]().String(), ")")
					}
				}
			}
		case "save":
			if ch != nil {
				gl.Log("debug", "Saving value from channel for:", v.GetName(), "ID:", v.GetID().String())
				nVal := <-ch
				if reflect.ValueOf(nVal).IsValid() {
					if reflect.ValueOf(nVal).CanConvert(reflect.TypeFor[T]()) {
						gl.Log("debug", "Saving value from channel for:", v.GetName(), "ID:", v.GetID().String())
						v.GetProperty().SetValue(&nVal)
					} else {
						gl.Log("error", "Save: invalid type for channel value (", reflect.TypeFor[T]().String(), ")")
					}
				}
			}
		case "clear":
			if ch != nil {
				gl.Log("debug", "Clearing channel for:", v.GetName(), "ID:", v.GetID().String())
				v.GetProperty().SetValue(nil)
			}
		}
	}
}
func chanRoutineDefer[T any](v ci.IChannelCtl[T], chCtl chan string, ch chan T) {
	if r := recover(); r != nil {
		gl.Log("error", "Recovering from panic in monitor routine for:", v.GetName(), "ID:", v.GetID().String(), "Error:", fmt.Sprintf("%v", r))
		// In recovering from panic, we need to check if the channel is nil.
		// If it is nil, we need to create a new channel.
		if ch == nil {
			gl.Log("debug", "Creating new channel for:", v.GetName(), "ID:", v.GetID().String())
			// If the channel is nil, create a new channel.
			ch = make(chan T, 3)
		}
		if chCtl == nil {
			gl.Log("debug", "Creating new control channel for:", v.GetName(), "ID:", v.GetID().String())
			// If the control channel is nil, create a new control channel.
			chCtl = make(chan string, 2)
		}
	} else {
		gl.Log("debug", "Exiting monitor routine for:", v.GetName(), "ID:", v.GetID().String())
		// When the monitor routine is done, we need to close the channels.
		// If the channel is not nil, close it.
		if ch != nil {
			close(ch)
		}
		if chCtl != nil {
			close(chCtl)
		}
		ch = nil
		chCtl = nil
	}
	// Always check the v mutexes to see if someone is locking the mutex or not on exit (defer).
	if v.MuTryLock() {
		// If the mutex was locked, unlock it.
		v.MuUnlock()
	} else if v.MuTryRLock() {
		// If the mutex was locked, unlock it.
		v.MuRUnlock()
	}
}
func chanRoutineWrapper[T any](v ci.IChannelCtl[T]) {
	gl.Log("debug", "Setting monitor routine for:", v.GetName(), "ID:", v.GetID().String())
	if rawChCtl, chCtlType, chCtlOk := v.GetSubChannelByName("ctl"); !chCtlOk {
		gl.LogObjLogger(&v, "error", "ChannelCtl: no control channel found")
		return
	} else {
		if chCtlType != reflect.TypeOf("string") {
			gl.LogObjLogger(&v, "error", "ChannelCtl: control channel is not a string channel")
			return
		}
		chCtl := reflect.ValueOf(rawChCtl).Interface().(chan string)
		rawCh := v.GetMainChannel()
		ch := reflect.ValueOf(rawCh).Interface().(chan T)

		defer chanRoutineDefer[T](v, chCtl, ch)
		for {
			chanRoutineCtl[T](v, chCtl, ch)
			if ch == nil {
				gl.Log("debug", "Channel is nil for:", v.GetName(), "ID:", v.GetID().String(), "Exiting monitor routine")
				break
			}
			if chCtl == nil {
				gl.Log("debug", "Control channel is nil for:", v.GetName(), "ID:", v.GetID().String(), "Exiting monitor routine")
				break
			}
		}
	}
}

func GetDefaultBufferSizes() (sm, md, lg int) { return 2, 5, 10 }

/// internal/utils/utils.go ///
package utils

import (
	"fmt"
	"os"
	"os/exec"
	"regexp"
	"strings"
	"time"
	"unicode"

	gl "github.com/kubex-ecosystem/gobe/logger"
)

// ValidateWorkerLimit valida o limite de workers
func ValidateWorkerLimit(value any) error {
	if limit, ok := value.(int); ok {
		if limit < 0 {
			return fmt.Errorf("worker limit cannot be negative")
		}
	} else {
		return fmt.Errorf("invalid type for worker limit")
	}
	return nil
}

func generateProcessFileName(processName string, pid int) string {
	bootID, err := GetBootID()
	if err != nil {
		gl.Log("error", fmt.Sprintf("Failed to get boot ID: %v", err))
		return ""
	}
	return fmt.Sprintf("%s_%d_%s.pid", processName, pid, bootID)
}

func createProcessFile(processName string, pid int) (*os.File, error) {
	fileName := generateProcessFileName(processName, pid)
	file, err := os.Create(fileName)
	if err != nil {
		return nil, err
	}

	// Escrever os detalhes do processo no arquivo
	_, err = file.WriteString(fmt.Sprintf("Process Name: %s\nPID: %d\nTimestamp: %d\n", processName, pid, time.Now().Unix()))
	if err != nil {
		file.Close()
		return nil, err
	}

	return file, nil
}

func removeProcessFile(file *os.File) {
	if file == nil {
		return
	}

	fileName := file.Name()
	file.Close()

	// Apagar o arquivo temporÃ¡rio
	if err := os.Remove(fileName); err != nil {
		gl.Log("error", fmt.Sprintf("Failed to remove process file %s: %v", fileName, err))
	} else {
		gl.Log("debug", fmt.Sprintf("Successfully removed process file: %s", fileName))
	}
}

func GetBootID() (string, error) {
	data, err := os.ReadFile("/proc/sys/kernel/random/boot_id")
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(string(data)), nil
}

func GetBootTimeMac() (string, error) {
	cmd := exec.Command("sysctl", "-n", "kern.boottime")
	out, err := cmd.Output()
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(string(out)), nil
}

func GetBootTimeWindows() (string, error) {
	cmd := exec.Command("powershell", "-Command", "(Get-WmiObject Win32_OperatingSystem).LastBootUpTime")
	out, err := cmd.Output()
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(string(out)), nil
}

func IsBase64String(s string) bool {
	matched, _ := regexp.MatchString("^([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{3}=|[A-Za-z0-9+/]{2}==)?$", s)
	return matched
}

func IsBase64ByteSlice(s []byte) bool {
	matched, _ := regexp.Match("^([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{3}=|[A-Za-z0-9+/]{2}==)?$", s)
	return matched
}

func IsBase64ByteSliceString(s string) bool {
	matched, _ := regexp.Match("^([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{3}=|[A-Za-z0-9+/]{2}==)?$", []byte(s))
	return matched
}
func IsBase64ByteSliceStringWithPadding(s string) bool {
	matched, _ := regexp.Match("^([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{3}=|[A-Za-z0-9+/]{2}==)?$", []byte(s))
	return matched
}

func IsUrlEncodeString(s string) bool {
	matched, _ := regexp.MatchString("^[a-zA-Z0-9%_.-]+$", s)
	return matched
}
func IsUrlEncodeByteSlice(s []byte) bool {
	matched, _ := regexp.Match("^[a-zA-Z0-9%_.-]+$", s)
	return matched
}

func IsBase62String(s string) bool {
	if unicode.IsDigit(rune(s[0])) {
		return false
	}
	matched, _ := regexp.MatchString("^[a-zA-Z0-9_]+$", s)
	return matched

}
func IsBase62ByteSlice(s []byte) bool {
	matched, _ := regexp.Match("^[a-zA-Z0-9_]+$", s)
	return matched
}

/// logger/logger.go ///
package logger

import (
	"fmt"
	"reflect"
	"runtime"
	"strings"

	l "github.com/kubex-ecosystem/logz"
)

type gLog struct {
	l.Logger
	gLogLevel LogType
}

var (
	// debug is a boolean that indicates whether to log debug messages.
	debug bool
	// g is the global logger instance.
	g *gLog = &gLog{
		Logger:    l.GetLogger("GoBE - Test"),
		gLogLevel: LogTypeInfo,
	}
)

func init() {
	// Set the debug flag to true for testing purposes.
	debug = false
	// Initialize the global logger instance with a default logger.
	if g.Logger == nil {
		g = &gLog{
			Logger:    l.GetLogger("GoBE - Test"),
			gLogLevel: LogTypeInfo,
		}
	}
}

type LogType string

const (
	LogTypeNotice  LogType = "notice"
	LogTypeInfo    LogType = "info"
	LogTypeDebug   LogType = "debug"
	LogTypeError   LogType = "error"
	LogTypeWarn    LogType = "warn"
	LogTypeFatal   LogType = "fatal"
	LogTypePanic   LogType = "panic"
	LogTypeSuccess LogType = "success"
)

// SetDebug is a function that sets the debug flag for logging.
func SetDebug(d bool) { debug = d }

// LogObjLogger is a function that logs messages with the specified log type.
func LogObjLogger[T any](obj *T, logType string, messages ...string) {
	if obj == nil {
		g.ErrorCtx(fmt.Sprintf("log object (%s) is nil", reflect.TypeFor[T]()), map[string]any{
			"context":  "Log",
			"logType":  logType,
			"object":   obj,
			"msg":      messages,
			"showData": true,
		})
		return
	}
	var lgr l.Logger
	if objValueLogger := reflect.ValueOf(obj).Elem().MethodByName("GetLogger"); !objValueLogger.IsValid() {
		if objValueLogger = reflect.ValueOf(obj).Elem().FieldByName("Logger"); !objValueLogger.IsValid() {
			g.ErrorCtx(fmt.Sprintf("log object (%s) does not have a logger field", reflect.TypeFor[T]()), map[string]any{
				"context":  "Log",
				"logType":  logType,
				"object":   obj,
				"msg":      messages,
				"showData": true,
			})
			return
		} else {
			lgrC := objValueLogger.Convert(reflect.TypeFor[l.Logger]())
			if lgrC.IsNil() {
				lgrC = reflect.ValueOf(g.Logger)
			}
			if lgr = lgrC.Interface().(l.Logger); lgr == nil {
				lgr = g.Logger
			}
		}
	} else {
		//lgrC := objValueLogger.Call(nil)[0].Convert(reflect.TypeFor[l.Logger]())
		//if lgrC.IsNil() {
		//	lgrC = reflect.ValueOf(g.Logger)
		//}
		//if lgr = lgrC.Interface().(l.Logger); lgr == nil {
		lgr = g.Logger
		//}
	}
	pc, file, line, ok := runtime.Caller(1)
	if !ok {
		lgr.ErrorCtx("Log: unable to get caller information", nil)
		return
	}
	funcName := runtime.FuncForPC(pc).Name()
	ctxMessageMap := map[string]any{
		"context":  funcName,
		"file":     file,
		"line":     line,
		"showData": debug,
	}
	fullMessage := strings.Join(messages, " ")
	logType = strings.ToLower(logType)
	if logType != "" {
		if reflect.TypeOf(logType).ConvertibleTo(reflect.TypeFor[LogType]()) {
			lType := LogType(logType)
			ctxMessageMap["logType"] = logType
			logging(lgr, lType, fullMessage, ctxMessageMap)
		} else {
			lgr.ErrorCtx(fmt.Sprintf("logType (%s) is not valid", logType), ctxMessageMap)
		}
	} else {
		lgr.InfoCtx(fullMessage, ctxMessageMap)
	}
}

// Log is a function that logs messages with the specified log type and caller information.
func Log(logType string, messages ...any) {
	pc, file, line, ok := runtime.Caller(1)
	if !ok {
		g.ErrorCtx("Log: unable to get caller information", nil)
		return
	}
	funcName := runtime.FuncForPC(pc).Name()
	ctxMessageMap := map[string]any{
		"context":  funcName,
		"file":     file,
		"line":     line,
		"showData": debug,
	}
	fullMessage := ""
	if len(messages) > 0 {
		fullMessage = fmt.Sprintf("%v", messages[0:])
	}
	logType = strings.ToLower(logType)
	if logType != "" {
		if reflect.TypeOf(logType).ConvertibleTo(reflect.TypeFor[LogType]()) {
			lType := LogType(logType)
			ctxMessageMap["logType"] = logType
			logging(g.Logger, lType, fullMessage, ctxMessageMap)
		} else {
			g.ErrorCtx(fmt.Sprintf("logType (%s) is not valid", logType), ctxMessageMap)
		}
	} else {
		g.InfoCtx(fullMessage, ctxMessageMap)
	}
}

// logging is a helper function that logs messages with the specified log type.
func logging(lgr l.Logger, lType LogType, fullMessage string, ctxMessageMap map[string]interface{}) {
	debugCtx := debug
	if !debugCtx {
		if lType == "error" || lType == "fatal" || lType == "panic" || lType == "debug" {
			// If debug is false, set the debug value based on the logType
			debugCtx = true
		} else {
			debugCtx = false
		}
	}
	ctxMessageMap["showData"] = debugCtx
	switch lType {
	case LogTypeInfo:
		lgr.InfoCtx(fullMessage, ctxMessageMap)
	case LogTypeDebug:
		lgr.DebugCtx(fullMessage, ctxMessageMap)
	case LogTypeError:
		lgr.ErrorCtx(fullMessage, ctxMessageMap)
	case LogTypeWarn:
		lgr.WarnCtx(fullMessage, ctxMessageMap)
	case LogTypeNotice:
		lgr.NoticeCtx(fullMessage, ctxMessageMap)
	case LogTypeSuccess:
		lgr.SuccessCtx(fullMessage, ctxMessageMap)
	case LogTypeFatal:
		lgr.FatalCtx(fullMessage, ctxMessageMap)
	case LogTypePanic:
		lgr.FatalCtx(fullMessage, ctxMessageMap)
	default:
		lgr.InfoCtx(fullMessage, ctxMessageMap)
	}
	debugCtx = debug
}

/// support/composer.sh ///
#!/bin/bash

# Define o diretÃ³rio base
BASE_DIR="lib"

# Lista de arquivos a serem criados
FILES=(
  "config.sh"
  "utils.sh"
  "platform.sh"
  "build.sh"
  "validate.sh"
  "install_funcs.sh"
  "info.sh"
)

# Cria o diretÃ³rio base, se ainda nÃ£o existir
mkdir -p "$BASE_DIR"

# Cria os arquivos dentro do diretÃ³rio
for file in "${FILES[@]}"; do
  FILE_PATH="$BASE_DIR/$file"
  if [[ ! -f "$FILE_PATH" ]]; then
    touch "$FILE_PATH"
    printf '%s' "#!/bin/bash" | tee "$FILE_PATH" >/dev/null
    printf '%s' "# $file - script placeholder" | tee -a "$FILE_PATH" >/dev/null
    chmod +x "$FILE_PATH"
    echo "Criado: $FILE_PATH"
  else
    echo "JÃ¡ existe: $FILE_PATH"
  fi
done


/// support/config.sh ///
#!/usr/bin/env bash

set -euo pipefail
set -o errtrace
set -o functrace
set -o posix
IFS=$'\n\t'

# Define o diretÃ³rio raiz (assumindo que este script estÃ¡ em lib/ no root)
_ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
_APP_NAME="${APP_NAME:-$(basename "${_ROOT_DIR}")}"
_PROJECT_NAME="$_APP_NAME"
_OWNER="${OWNER:-rafa-mori}"
# Tenta ler a versÃ£o, ou define um fallback
_VERSION=$(cat "$_ROOT_DIR/version/CLI_VERSION" 2>/dev/null || echo "v0.0.0")
# Extrai a versÃ£o do Go do go.mod (certifique-se de que este arquivo exista na raiz)
_VERSION_GO=$(grep '^go ' "$_ROOT_DIR/go.mod" | awk '{print $2}')

_LICENSE="MIT"

_ABOUT="################################################################################
  Este script instala o projeto ${_PROJECT_NAME}, versÃ£o ${_VERSION}.
  OS suportados: Linux, MacOS, Windows
  Arquiteturas suportadas: amd64, arm64, 386
  Fonte: https://github.com/${_OWNER}/${_PROJECT_NAME}
  Binary Release: https://github.com/${_OWNER}/${_PROJECT_NAME}/releases/latest
  License: ${_LICENSE}
  Notas:
    - [version] Ã© opcional; se omitido, a Ãºltima versÃ£o serÃ¡ utilizada.
    - Se executado localmente, o script tentarÃ¡ resolver a versÃ£o pelos tags do repositÃ³rio.
    - Instala em ~/.local/bin para usuÃ¡rio nÃ£o-root ou em /usr/local/bin para root.
    - Adiciona o diretÃ³rio de instalaÃ§Ã£o Ã  variÃ¡vel PATH.
    - Instala o UPX se necessÃ¡rio, ou compila o binÃ¡rio (build) conforme o comando.
    - Faz download do binÃ¡rio via URL de release ou efetua limpeza de artefatos.
    - Verifica dependÃªncias e versÃ£o do Go.
################################################################################"

_BANNER="################################################################################

               â–ˆâ–ˆ   â–ˆâ–ˆ â–ˆâ–ˆ     â–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ     â–ˆâ–ˆ
              â–‘â–ˆâ–ˆ  â–ˆâ–ˆ â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–ˆ â–‘â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ â–‘â–‘â–ˆâ–ˆ   â–ˆâ–ˆ
              â–‘â–ˆâ–ˆ â–ˆâ–ˆ  â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆ   â–‘â–ˆâ–ˆ â–‘â–ˆâ–ˆ       â–‘â–‘â–ˆâ–ˆ â–ˆâ–ˆ
              â–‘â–ˆâ–ˆâ–ˆâ–ˆ   â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–‘â–‘â–ˆâ–ˆâ–ˆ
              â–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆ  â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–‘â–‘â–‘â–‘ â–ˆâ–ˆâ–‘â–ˆâ–ˆâ–‘â–‘â–‘â–‘     â–ˆâ–ˆâ–‘â–ˆâ–ˆ
              â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆ â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆ        â–ˆâ–ˆ â–‘â–‘â–ˆâ–ˆ
              â–‘â–ˆâ–ˆ â–‘â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ   â–‘â–‘â–ˆâ–ˆ
              â–‘â–‘   â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â–‘â–‘     â–‘â–‘"

# Caminhos para a compilaÃ§Ã£o
_CMD_PATH="$_ROOT_DIR/cmd"
_BUILD_PATH="$(dirname "$_CMD_PATH")"
_BINARY="$_BUILD_PATH/$_APP_NAME"

# DiretÃ³rios de instalaÃ§Ã£o
_LOCAL_BIN="${HOME:-"~"}/.local/bin"
_GLOBAL_BIN="/usr/local/bin"

# Caso queira, defina o OWNER (use no get_release_url)
_OWNER="rafa-mori"

/// support/info.sh ///
#!/usr/bin/env bash
# lib/info.sh â€“ FunÃ§Ãµes para exibir banners e resumo de instalaÃ§Ã£o

show_about() {
    printf '%s\n\n' "${_ABOUT:-}"
}

show_banner() {
    printf '\n%s\n\n' "${_BANNER:-}"
}

show_headers() {
    show_banner || return 1
    show_about || return 1
}

summary() {
    local install_dir="$_BINARY"
    log success "Build e instalaÃ§Ã£o concluÃ­dos!"
    log success "BinÃ¡rio: $_BINARY"
    log success "Instalado em: ${install_dir}"
    check_path "$install_dir"
}

export -f show_about
export -f show_banner
export -f show_headers
export -f summary


/// support/install.sh ///
#!/usr/bin/env bash
# shellcheck disable=SC2065,SC2015

# Script Metadata
__secure_logic_version="1.0.0"
__secure_logic_date="$( date +%Y-%m-%d )"
__secure_logic_author="Rafael Mori"
__secure_logic_use_type="exec"
__secure_logic_init_timestamp="$(date +%s)"
__secure_logic_elapsed_time=0

# Check if verbose mode is enabled
if [[ "${MYNAME_VERBOSE:-false}" == "true" ]]; then
  set -x  # Enable debugging
fi

IFS=$'\n\t'

__secure_logic_sourced_name() {
  local _self="${BASH_SOURCE-}"
  _self="${_self//${_kbx_root:-$()}/}"
  _self="${_self//\.sh/}"
  _self="${_self//\-/_}"
  _self="${_self//\//_}"
  echo "_was_sourced_${_self//__/_}"
  return 0
}

__first(){
  if [ "$EUID" -eq 0 ] || [ "$UID" -eq 0 ]; then
    echo "Please do not run as root." 1>&2 > /dev/tty
    exit 1
  elif [ -n "${SUDO_USER:-}" ]; then
    echo "Please do not run as root, but with sudo privileges." 1>&2 > /dev/tty
    exit 1
  else
    # shellcheck disable=SC2155
    local _ws_name="$(__secure_logic_sourced_name)"

    if test "${BASH_SOURCE-}" != "${0}"; then
      if test $__secure_logic_use_type != "lib"; then
        echo "This script is not intended to be sourced." 1>&2 > /dev/tty
        echo "Please run it directly." 1>&2 > /dev/tty
        exit 1
      fi
      # If the script is sourced, we set the variable to true
      # and export it to the environment without changing
      # the shell options.
      export "${_ws_name}"="true"
    else
      if test $__secure_logic_use_type != "exec"; then
        echo "This script is not intended to be executed directly." 1>&2 > /dev/tty
        echo "Please source it instead." 1>&2 > /dev/tty
        exit 1
      fi
      # If the script is executed directly, we set the variable to false
      # and export it to the environment. We also set the shell options
      # to ensure a safe execution.
      export "${_ws_name}"="false"
      set -o errexit # Exit immediately if a command exits with a non-zero status
      set -o nounset # Treat unset variables as an error when substituting
      set -o pipefail # Return the exit status of the last command in the pipeline that failed
      set -o errtrace # If a command fails, the shell will exit immediately
      set -o functrace # If a function fails, the shell will exit immediately
      shopt -s inherit_errexit # Inherit the errexit option in functions
    fi
  fi
}

_DEBUG=${DEBUG:-false}
_HIDE_ABOUT=${HIDE_ABOUT:-false}

__first "$@" >/dev/tty || exit 1

# Carrega os arquivos de biblioteca
_SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
#shellcheck source=/dev/null
test -z "${_BANNER:-}" && source "${_SCRIPT_DIR}/config.sh" || true
#shellcheck source=/dev/null
test -z "$(declare -f log)" >/dev/null && source "${_SCRIPT_DIR}/utils.sh" || true
#shellcheck source=/dev/null
test -z "$(declare -f what_platform)" >/dev/null && source "${_SCRIPT_DIR}/platform.sh" || true
#shellcheck source=/dev/null
test -z "$(declare -f check_dependencies)" >/dev/null && source "${_SCRIPT_DIR}/validate.sh" || true
#shellcheck source=/dev/null
test -z "$(declare -f detect_shell_rc)" >/dev/null && source "${_SCRIPT_DIR}/install_funcs.sh" || true
#shellcheck source=/dev/null
test -z "$(declare -f build_binary)" >/dev/null && source "${_SCRIPT_DIR}/build.sh" || true
#shellcheck source=/dev/null
test -z "$(declare -f show_banner)" >/dev/null && source "${_SCRIPT_DIR}/info.sh" || true

# Inicializa os traps
set_trap "$@"

clear_screen

__main() {
  if ! what_platform; then
    log error "Plataforma nÃ£o suportada: ${_PLATFORM}"
    exit 1
  fi

  if [[ "${_DEBUG}" != true ]]; then
    show_headers
    if [[ -z "${_HIDE_ABOUT}" ]]; then
      show_about
    fi
  else
    log info "Modo debug ativado; banner serÃ¡ ignorado..."
    if [[ -z "${_HIDE_ABOUT}" ]]; then
      show_about
    fi
  fi

  _ARGS=( "$@" )
  local default_label='Auto detect'
  local arrArgs=( "${_ARGS[@]:0:$#}" )
  local PLATFORM_ARG
  PLATFORM_ARG=$(_get_os_from_args "${arrArgs[1]:-${_PLATFORM}}")
  local ARCH_ARG
  ARCH_ARG=$(_get_arch_arr_from_args "${arrArgs[2]:-${_ARCH}}")

  log info "Comando: ${arrArgs[0]:-}" true
  log info "Plataforma: ${PLATFORM_ARG:-$default_label}" true
  log info "Arquitetura: ${ARCH_ARG:-$default_label}" true
  log info "Args: ${_ARGS[*]:-}" true

  case "${arrArgs[0]:-}" in
    build|BUILD|-b|-B)
      # validate_versions
      log info "Executando comando de build..."
      build_binary "${PLATFORM_ARG}" "${ARCH_ARG}" || exit 1
      ;;
    install|INSTALL|-i|-I)
      log info "Executando comando de instalaÃ§Ã£o..."
      read -r -p "Deseja baixar o binÃ¡rio prÃ©-compilado? [y/N] (Caso contrÃ¡rio, farÃ¡ build local): " choice </dev/tty
      log info "Escolha do usuÃ¡rio: ${choice}"
      if [[ "$choice" == "y" || "$choice" == "Y" ]]; then
          log info "Baixando binÃ¡rio prÃ©-compilado..."
          install_from_release
      else
          log info "Realizando build local..."
          validate_versions
          build_binary "${PLATFORM_ARG}" "${ARCH_ARG}" || exit 1
          install_binary
      fi
      summary
      ;;
    clear|clean|CLEAN|-c|-C)
      log info "Executando comando de limpeza..."
      clean_artifacts
      log success "Clean executado com sucesso."
      ;;
    *)
      log error "Comando invÃ¡lido: ${arrArgs[0]:-}"
      echo "Uso: $0 {build|install|clean}"
      ;;
  esac
}

# FunÃ§Ã£o para limpar artefatos de build
clean_artifacts() {
    log info "Limpando artefatos de build..."
    local platforms=("windows" "darwin" "linux")
    local archs=("amd64" "386" "arm64")
    for platform in "${platforms[@]}"; do
        for arch in "${archs[@]}"; do
            local output_name
            output_name=$(printf '%s_%s_%s' "${_BINARY}" "${platform}" "${arch}")
            if [[ "${platform}" != "windows" ]]; then
                local compress_name="${output_name}.tar.gz"
            else
                output_name="${output_name}.exe"
                local compress_name="${_BINARY}_${platform}_${arch}.zip"
            fi
            rm -f "${output_name}" || true
            rm -f "${compress_name}" || true
        done
    done
    log success "Artefatos de build removidos."
}

__secure_logic_main() {
  local _ws_name
  _ws_name="$(__secure_logic_sourced_name)"
  local _ws_name_val
  _ws_name_val=$(eval "echo \${$_ws_name}")
  if test "${_ws_name_val}" != "true"; then
    __main "$@"
    return $?
  else
    # If the script is sourced, we export the functions
    log error "This script is not intended to be sourced."
    log error "Please run it directly."
    return 1
  fi
}

# echo "MAKE ARGS: ${ARGS[*]:-}"
log info "Starting installation script..."
__secure_logic_main "$@"

__secure_logic_elapsed_time="$(($(date +%s) - __secure_logic_init_timestamp))"

if [[ "${MYNAME_VERBOSE:-false}" == "true" || "${_DEBUG:-false}" == "true" ]]; then
  log info "Script executed in ${__secure_logic_elapsed_time} seconds."
fi

# End of script logic

/// support/install_funcs.sh ///
#!/usr/bin/env bash
# lib/install_funcs.sh â€“ FunÃ§Ãµes para instalaÃ§Ã£o e manipulaÃ§Ã£o de PATH

install_upx() {
    if ! command -v upx &> /dev/null; then
        if ! sudo -v &> /dev/null; then
            log error "VocÃª nÃ£o tem permissÃµes de superusuÃ¡rio para instalar o empacotador de binÃ¡rios."
            log warn "Se deseja o empacotamento de binÃ¡rios, instale o UPX manualmente."
            log warn "Veja: https://upx.github.io/"
            return 1
        fi
        if [[ "$(uname)" == "Darwin" ]]; then
            brew install upx >/dev/null
        elif command -v apt-get &> /dev/null; then
            sudo apt-get install -y upx >/dev/null
        elif command -v yum &> /dev/null; then
            sudo yum install -y upx >/dev/null
        elif command -v dnf &> /dev/null; then
            sudo dnf install -y upx >/dev/null
        elif command -v pacman &> /dev/null; then
            sudo pacman -S --noconfirm upx >/dev/null
        elif command -v zypper &> /dev/null; then
            sudo zypper install -y upx >/dev/null
        elif command -v apk &> /dev/null; then
            sudo apk add upx >/dev/null
        elif command -v port &> /dev/null; then
            sudo port install upx >/dev/null
        elif command -v snap &> /dev/null; then
            sudo snap install upx >/dev/null
        elif command -v flatpak &> /dev/null; then
            sudo flatpak install flathub org.uptane.upx -y >/dev/null
        else
            log warn "Se deseja o empacotamento de binÃ¡rios, instale o UPX manualmente."
            log warn "Veja: https://upx.github.io/"
            return 1
        fi
    fi

    return 0
}

detect_shell_rc() {
    local shell_rc_file
    local user_shell
    user_shell=$(basename "$SHELL")

    case "$user_shell" in
        bash) shell_rc_file="${HOME:-~}/.bashrc" ;;
        zsh) shell_rc_file="${HOME:-~}/.zshrc" ;;
        sh) shell_rc_file="${HOME:-~}/.profile" ;;
        fish) shell_rc_file="${HOME:-~}/.config/fish/config.fish" ;;
        *)
            log warn "Shell nÃ£o suportado; ajuste o PATH manualmente."
            return 1
            ;;
    esac

    if [ ! -f "$shell_rc_file" ]; then
        log error "Arquivo de configuraÃ§Ã£o nÃ£o encontrado: ${shell_rc_file}"
        return 1
    fi

    echo "$shell_rc_file"

    return 0
}

add_to_path() {
    local target_path="${1:-}"

    local shell_rc_file=""

    local path_expression=""

    path_expression="export PATH=\"${target_path}:\$PATH\""

    shell_rc_file="$(detect_shell_rc)"


    if [ -z "$shell_rc_file" ]; then
        log error "NÃ£o foi possÃ­vel identificar o arquivo de configuraÃ§Ã£o do shell."
        return 1
    fi
    if grep -q "${path_expression}" "$shell_rc_file" 2>/dev/null; then
        log success "$target_path jÃ¡ estÃ¡ no PATH do $shell_rc_file."
        return 0
    fi

    if [[ -z "${target_path}" ]]; then
        log error "Caminho de destino nÃ£o fornecido."
        return 1
    fi

    if [[ ! -d "${target_path}" ]]; then
        log error "Caminho de destino nÃ£o Ã© um diretÃ³rio vÃ¡lido: $target_path"
        return 1
    fi

    if [[ ! -f "${shell_rc_file}" ]]; then
        log error "Arquivo de configuraÃ§Ã£o nÃ£o encontrado: ${shell_rc_file}"
        return 1
    fi

    # echo "export PATH=${target_path}:\$PATH" >> "$shell_rc_file"
    printf '%s\n' "${path_expression}" | tee -a "$shell_rc_file" >/dev/null || {
        log error "Falha ao adicionar $target_path ao PATH em $shell_rc_file."
        return 1
    }

    log success "Adicionado $target_path ao PATH em $shell_rc_file."

    "$SHELL" -c "source ${shell_rc_file}" || {
        log warn "Falha ao recarregar o shell. Por favor, execute 'source ${shell_rc_file}' manualmente."
    }

    return 0
}

install_binary() {
    local SUFFIX="${_PLATFORM_WITH_ARCH}"
    local BINARY_TO_INSTALL="${_BINARY}${SUFFIX:+_${SUFFIX}}"
    log info "Instalando o binÃ¡rio: '${BINARY_TO_INSTALL}' como '$_APP_NAME'"

    if [ "$(id -u)" -ne 0 ]; then
        log info "UsuÃ¡rio nÃ£o-root detectado. Instalando em ${_LOCAL_BIN}..."
        mkdir -p "$_LOCAL_BIN"
        cp "$BINARY_TO_INSTALL" "$_LOCAL_BIN/$_APP_NAME" || exit 1
        add_to_path "$_LOCAL_BIN"
    else
        log info "UsuÃ¡rio root detectado. Instalando em ${_GLOBAL_BIN}..."
        cp "$BINARY_TO_INSTALL" "$_GLOBAL_BIN/$_APP_NAME" || exit 1
        add_to_path "$_GLOBAL_BIN"
    fi
}

download_binary() {
    if ! what_platform; then
        log error "Falha ao detectar a plataforma."
        return 1
    fi
    if [[ -z "${_PLATFORM}" ]]; then
        log error "Plataforma nÃ£o suportada: ${_PLATFORM}"
        return 1
    fi
    local version
    version=$(curl -s "https://api.github.com/repos/${_OWNER}/${_PROJECT_NAME}/releases/latest" | grep "tag_name" | cut -d '"' -f 4 || echo "latest")
    if [ -z "$version" ]; then
        log error "Falha ao determinar a Ãºltima versÃ£o."
        return 1
    fi

    local release_url
    release_url=$(get_release_url)
    log info "Baixando o binÃ¡rio ${_APP_NAME} para OS=${_PLATFORM}, ARCH=${_ARCH}, VersÃ£o=${version}..."
    log info "URL de Release: ${release_url}"

    local archive_path="${_TEMP_DIR}/${_APP_NAME}.tar.gz"
    if ! curl -L -o "${archive_path}" "${release_url}"; then
        log error "Falha ao baixar o binÃ¡rio de: ${release_url}"
        return 1
    fi
    log success "BinÃ¡rio baixado com sucesso."

    log info "Extraindo o binÃ¡rio para: $(dirname "${_BINARY}")"
    if ! tar -xzf "${archive_path}" -C "$(dirname "${_BINARY}")"; then
        log error "Falha ao extrair o binÃ¡rio de: ${archive_path}"
        rm -rf "${_TEMP_DIR}"
        exit 1
    fi

    rm -rf "${_TEMP_DIR}"
    log success "BinÃ¡rio extraÃ­do com sucesso."

    if [ ! -f "$_BINARY" ]; then
        log error "BinÃ¡rio nÃ£o encontrado apÃ³s extraÃ§Ã£o: ${_BINARY}"
        exit 1
    fi
    log success "Download e extraÃ§Ã£o de ${_APP_NAME} concluÃ­dos!"
}

install_from_release() {
    download_binary
    install_binary
}

check_path() {
    log info "Verificando se o diretÃ³rio de instalaÃ§Ã£o estÃ¡ no PATH..."
    if ! echo "$PATH" | grep -q "$1"; then
        log warn "$1 nÃ£o estÃ¡ no PATH."
        log warn "Adicione: export PATH=$1:\$PATH"
    else
        log success "$1 jÃ¡ estÃ¡ no PATH."
    fi
}

export -f install_upx
export -f detect_shell_rc
export -f add_to_path
export -f install_binary
export -f download_binary
export -f install_from_release
export -f check_path

/// support/platform.sh ///
#!/usr/bin/env bash

set -euo pipefail
set -o errtrace
set -o functrace
set -o posix
IFS=$'\n\t'

get_release_url() {
    local os="${_PLATFORM%%-*}"
    local format
    if [[ "$os" == "windows" ]]; then
      format="zip"
    else
      format="tar.gz"
    fi
    echo "'https://github.com/${_OWNER}/${_PROJECT_NAME}/releases/download/${_VERSION}/${_PROJECT_NAME}_.${format}'"
}

what_platform() {
  local _os
  _os="$(uname -s)"
  local _arch
  _arch="$(uname -m)"
  local platform=""

  case "${_os}" in
  *Linux*|*Nix*)
    _os="linux"
    case "${_arch}" in
      "x86_64") _arch="amd64" ;;
      "armv6") _arch="armv6l" ;;
      "armv8"|"aarch64") _arch="arm64" ;;
      *386*) _arch="386" ;;
    esac
    platform="linux-${_arch}"
    ;;
  *Darwin*)
    _os="darwin"
    case "${_arch}" in
      "x86_64") _arch="amd64" ;;
      "arm64") _arch="arm64" ;;
    esac
    platform="darwin-${_arch}"
    ;;
  MINGW*|MSYS*|CYGWIN*|Win*)
    _os="windows"
    case "${_arch}" in
      "x86_64") _arch="amd64" ;;
      "arm64") _arch="arm64" ;;
    esac
    platform="windows-${_arch}"
    ;;
  *)
    log error "Plataforma nÃ£o suportada: ${_os} ${_arch}"
    log error "Informe este problema aos mantenedores do projeto."
    return 1
    ;;
  esac

  export _PLATFORM_WITH_ARCH="${platform//-/_}"
  export _PLATFORM="${_os}"
  export _ARCH="${_arch}"

  return 0
}

_get_os_arr_from_args() {
  local _PLATFORM_ARG=$1
  if [[ "${_PLATFORM_ARG}" == "all" ]]; then
    echo "windows darwin linux"
  else
    echo "${_PLATFORM_ARG}"
  fi
}

_get_arch_arr_from_args() {
  local _ARCH_ARG=$1
  if [[ "${_ARCH_ARG}" == "all" ]]; then
    echo "amd64 386 arm64"
  else
    echo "${_ARCH_ARG}"
  fi
}

_get_os_from_args() {
  local arg=$1
  case "$arg" in
    all|ALL|a|A|-a|-A) echo "all" ;;
    win|WIN|windows|WINDOWS|w|W|-w|-W) echo "windows" ;;
    linux|LINUX|l|L|-l|-L) echo "linux" ;;
    darwin|DARWIN|macOS|MACOS|m|M|-m|-M) echo "darwin" ;;
    *)
      log error "Plataforma invÃ¡lida: '${arg}'. OpÃ§Ãµes vÃ¡lidas: windows, linux, darwin, all."
      exit 1
      ;;
  esac
}

_get_arch_from_args() {
  local arg=$1
  case "$arg" in
    all|ALL|a|A|-a|-A) echo "all" ;;
    amd64|AMD64|x86_64|X86_64|x64|X64) echo "amd64" ;;
    arm64|ARM64|aarch64|AARCH64) echo "arm64" ;;
    386|i386|I386) echo "386" ;;
    *)
      log error "Arquitetura invÃ¡lida: '${arg}'. OpÃ§Ãµes vÃ¡lidas: amd64, arm64, 386."
      exit 1
      ;;
  esac
}

export -f _get_os_arr_from_args
export -f _get_arch_arr_from_args
export -f _get_os_from_args
export -f _get_arch_from_args
export -f get_release_url
export -f what_platform

what_platform "${@}"

/// support/utils.sh ///
#!/usr/bin/env bash
# lib/utils.sh â€“ FunÃ§Ãµes utilitÃ¡rias

set -euo pipefail
set -o errtrace
set -o functrace
set -o posix
IFS=$'\n\t'

# CÃ³digos de cor para logs
_SUCCESS="\033[0;32m"
_WARN="\033[0;33m"
_ERROR="\033[0;31m"
_INFO="\033[0;36m"
_NC="\033[0m"

log() {
  local type=${1:-info}
  local message=${2:-}
  local debug=${3:-${DEBUG:-false}}

  case $type in
    info|_INFO|-i|-I)
      if [[ "$debug" == true ]]; then
        printf '%b[_INFO]%b â„¹ï¸  %s\n' "$_INFO" "$_NC" "$message"
      fi
      ;;
    warn|_WARN|-w|-W)
      if [[ "$debug" == true ]]; then
        printf '%b[_WARN]%b âš ï¸  %s\n' "$_WARN" "$_NC" "$message"
      fi
      ;;
    error|_ERROR|-e|-E)
      printf '%b[_ERROR]%b âŒ  %s\n' "$_ERROR" "$_NC" "$message"
      ;;
    success|_SUCCESS|-s|-S)
      printf '%b[_SUCCESS]%b âœ…  %s\n' "$_SUCCESS" "$_NC" "$message"
      ;;
    *)
      if [[ "$debug" == true ]]; then
        log "info" "$message" "$debug"
      fi
      ;;
  esac
}

clear_screen() {
  printf "\033[H\033[2J"
}

get_current_shell() {
  local shell_proc
  shell_proc=$(cat /proc/$$/comm)
  case "${0##*/}" in
    ${shell_proc}*)
      local shebang
      shebang=$(head -1 "$0")
      printf '%s\n' "${shebang##*/}"
      ;;
    *)
      printf '%s\n' "$shell_proc"
      ;;
  esac
}

# Cria um diretÃ³rio temporÃ¡rio para cache
_TEMP_DIR="${_TEMP_DIR:-$(mktemp -d)}"
if [[ -d "${_TEMP_DIR}" ]]; then
    log info "DiretÃ³rio temporÃ¡rio criado: ${_TEMP_DIR}"
else
    log error "Falha ao criar o diretÃ³rio temporÃ¡rio."
fi

clear_script_cache() {
  trap - EXIT HUP INT QUIT ABRT ALRM TERM
  if [[ ! -d "${_TEMP_DIR}" ]]; then
    exit 0
  fi
  rm -rf "${_TEMP_DIR}" || true
  if [[ -d "${_TEMP_DIR}" ]] && sudo -v 2>/dev/null; then
    sudo rm -rf "${_TEMP_DIR}"
    if [[ -d "${_TEMP_DIR}" ]]; then
      printf '%b[_ERROR]%b âŒ  %s\n' "$_ERROR" "$_NC" "Falha ao remover o diretÃ³rio temporÃ¡rio: ${_TEMP_DIR}"
    else
      printf '%b[_SUCCESS]%b âœ…  %s\n' "$_SUCCESS" "$_NC" "DiretÃ³rio temporÃ¡rio removido: ${_TEMP_DIR}"
    fi
  fi
  exit 0
}

set_trap() {
  local current_shell=""
  current_shell=$(get_current_shell)
  case "${current_shell}" in
    *ksh|*zsh|*bash)
      declare -a FULL_SCRIPT_ARGS=("$@")
      if [[ "${FULL_SCRIPT_ARGS[*]}" =~ -d ]]; then
          set -x
      fi
      if [[ "${current_shell}" == "bash" ]]; then
        set -o errexit
        set -o pipefail
        set -o errtrace
        set -o functrace
        shopt -s inherit_errexit
      fi
      trap 'clear_script_cache' EXIT HUP INT QUIT ABRT ALRM TERM
      ;;
  esac
}

/// support/validate.sh ///
#!/usr/bin/env bash
# lib/validate.sh â€“ ValidaÃ§Ã£o da versÃ£o do Go e dependÃªncias

validate_versions() {
    local REQUIRED_GO_VERSION="${_VERSION_GO:-1.20.0}"
    local GO_VERSION
    GO_VERSION=$(go version | awk '{print $3}' | sed 's/go//')
    if [[ "$(printf '%s\n' "$REQUIRED_GO_VERSION" "$GO_VERSION" | sort -V | head -n1)" != "$REQUIRED_GO_VERSION" ]]; then
        log error "A versÃ£o do Go deve ser >= $REQUIRED_GO_VERSION. Detectado: $GO_VERSION"
        exit 1
    fi
    log success "VersÃ£o do Go vÃ¡lida: $GO_VERSION"
    go mod tidy || return 1
}

check_dependencies() {
    for dep in "$@"; do
        if ! command -v "$dep" > /dev/null; then
            log error "$dep nÃ£o estÃ¡ instalado."
            exit 1
        else
            log success "$dep estÃ¡ instalado."
        fi
    done
}

export -f validate_versions
export -f check_dependencies

/// tests/bkp/files/internal/middlewares/authentication.go ///
package middlewares

import (
	"context"
	"fmt"
	"net/http"
	"os"
	"strings"

	"github.com/gin-gonic/gin"
	"github.com/golang-jwt/jwt/v4"

	"github.com/hyperledger/fabric-contract-api-go/contractapi"

	l "github.com/kubex-ecosystem/logz"

	sau "github.com/kubex-ecosystem/gobe/factory/security"
	cm "github.com/kubex-ecosystem/gobe/internal/common"
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	srv "github.com/kubex-ecosystem/gobe/internal/services"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

// ... resto do arquivo permanece igual,
// mas se houver uso direto de jwt.RegisteredClaims, troque para jwt.RegisteredClaims

/// tests/bkp/files/internal/security/authentication/auth_manager.go ///
package authentication

import (
	"crypto/rsa"
	"fmt"
	"time"

	"github.com/golang-jwt/jwt/v4"
	"github.com/google/uuid"
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	"github.com/kubex-ecosystem/gobe/logger"
)

type AuthManager struct {
	privKey               *rsa.PrivateKey
	pubKey                *rsa.PublicKey
	refreshSecret         string
	idExpirationSecs      int64
	refreshExpirationSecs int64
}

func NewAuthManager(certService crt.CertService) (*AuthManager, error) {
	privKey, err := certService.GetPrivateKey()
	if err != nil {
		logger.Log("error", fmt.Sprintf("Failed to load private key: %v", err))
		return nil, err
	}

	pubKey, err := certService.GetPublicKey()
	if err != nil {
		logger.Log("error", fmt.Sprintf("Failed to load public key: %v", err))
		return nil, err
	}

	return &AuthManager{
		privKey:               privKey,
		pubKey:                pubKey,
		refreshSecret:         "default_refresh_secret", // Replace with a secure secret
		idExpirationSecs:      3600,                     // 1 hour
		refreshExpirationSecs: 604800,                   // 7 days
	}, nil
}

func (am *AuthManager) GenerateIDToken(userID string) (string, error) {
	claims := jwt.RegisteredClaims{
		Subject:   userID,
		ExpiresAt: jwt.NewNumericDate(time.Now().Add(time.Duration(am.idExpirationSecs) * time.Second)),
		IssuedAt:  jwt.NewNumericDate(time.Now()),
		ID:        uuid.New().String(),
	}
	token := jwt.NewWithClaims(jwt.SigningMethodRS256, claims)
	return token.SignedString(am.privKey)
}

func (am *AuthManager) GenerateRefreshToken(userID string) (string, error) {
	claims := jwt.RegisteredClaims{
		Subject:   userID,
		ExpiresAt: jwt.NewNumericDate(time.Now().Add(time.Duration(am.refreshExpirationSecs) * time.Second)),
		IssuedAt:  jwt.NewNumericDate(time.Now()),
		ID:        uuid.New().String(),
	}
	token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
	return token.SignedString([]byte(am.refreshSecret))
}

func (am *AuthManager) ValidateIDToken(tokenString string) (*jwt.RegisteredClaims, error) {
	token, err := jwt.ParseWithClaims(tokenString, &jwt.RegisteredClaims{}, func(token *jwt.Token) (interface{}, error) {
		return am.pubKey, nil
	})
	if err != nil {
		return nil, err
	}

	claims, ok := token.Claims.(*jwt.RegisteredClaims)
	if !ok || !token.Valid {
		return nil, fmt.Errorf("invalid token")
	}

	return claims, nil
}

func (am *AuthManager) ValidateRefreshToken(tokenString string) (*jwt.RegisteredClaims, error) {
	token, err := jwt.ParseWithClaims(tokenString, &jwt.RegisteredClaims{}, func(token *jwt.Token) (interface{}, error) {
		return []byte(am.refreshSecret), nil
	})
	if err != nil {
		return nil, err
	}

	claims, ok := token.Claims.(*jwt.RegisteredClaims)
	if !ok || !token.Valid {
		return nil, fmt.Errorf("invalid token")
	}

	return claims, nil
}

/// tests/bkp/files/internal/security/authentication/token_service.go ///
package authentication

import (
	"context"
	"crypto/rsa"
	"fmt"
	"strings"
	"time"

	"github.com/golang-jwt/jwt/v4"
	"github.com/google/uuid"
	m "github.com/kubex-ecosystem/gdbase/factory/models"
	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	sci "github.com/kubex-ecosystem/gobe/internal/security/interfaces"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

type idTokenCustomClaims struct {
	User *m.UserModelType `json:"UserImpl"`
	jwt.RegisteredClaims
}
type TokenServiceImpl struct {
	TokenRepository       sci.TokenRepo
	PrivKey               *rsa.PrivateKey
	PubKey                *rsa.PublicKey
	RefreshSecret         string
	IDExpirationSecs      int64
	RefreshExpirationSecs int64
}

func NewTokenService(c *sci.TSConfig) sci.TokenService {
	if c == nil {
		gl.Log("error", "TokenService config is nil")
		return nil
	}
	var idExpirationSecs, refreshExpirationSecs int64
	if c.IDExpirationSecs == 0 {
		idExpirationSecs = 3600 // Default to 1 hour
	} else {
		idExpirationSecs = c.IDExpirationSecs
	}
	if c.RefreshExpirationSecs == 0 {
		refreshExpirationSecs = 604800 // Default to 7 days
	} else {
		refreshExpirationSecs = c.RefreshExpirationSecs
	}
	tsrv := &TokenServiceImpl{
		TokenRepository:       c.TokenRepository,
		PrivKey:               c.PrivKey,
		PubKey:                c.PubKey,
		RefreshSecret:         c.RefreshSecret,
		IDExpirationSecs:      idExpirationSecs,
		RefreshExpirationSecs: refreshExpirationSecs,
	}
	return tsrv
}

func generateIDToken(u m.UserModel, privKey *rsa.PrivateKey, idExpirationSecs int64) (string, error) {
	claims := idTokenCustomClaims{
		User: u.GetUserModelType(),
		RegisteredClaims: jwt.RegisteredClaims{
			Subject:   u.GetID(),
			ExpiresAt: jwt.NewNumericDate(time.Now().Add(time.Duration(idExpirationSecs) * time.Second)),
			IssuedAt:  jwt.NewNumericDate(time.Now()),
			ID:        uuid.New().String(),
		},
	}
	token := jwt.NewWithClaims(jwt.SigningMethodRS256, claims)
	return token.SignedString(privKey)
}

func generateRefreshToken(userID string, refreshSecret string, refreshExpirationSecs int64) (*sci.RefreshToken, error) {
	claims := jwt.RegisteredClaims{
		Subject:   userID,
		ExpiresAt: jwt.NewNumericDate(time.Now().Add(time.Duration(refreshExpirationSecs) * time.Second)),
		IssuedAt:  jwt.NewNumericDate(time.Now()),
		ID:        uuid.New().String(),
	}
	token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
	signed, err := token.SignedString([]byte(refreshSecret))
	if err != nil {
		return nil, err
	}
	return &sci.RefreshToken{
		Token:     signed,
		ID:        claims.ID,
		ExpiresIn: claims.ExpiresAt.Time,
	}, nil
}

func (s *TokenServiceImpl) NewPairFromUser(ctx context.Context, u m.UserModel, prevTokenID string) (*sci.TokenPair, error) {
	if prevTokenID != "" {
		if err := s.TokenRepository.DeleteRefreshToken(ctx, u.GetID(), prevTokenID); err != nil {
			return nil, fmt.Errorf("could not delete previous refresh token for uid: %v, tokenID: %v", u.GetID(), prevTokenID)
		}
	}

	idToken, err := generateIDToken(u, s.PrivKey, s.IDExpirationSecs)
	if err != nil {
		return nil, fmt.Errorf("error generating id token for uid: %v: %v", u.GetID(), err)
	}

	if s.RefreshSecret == "" {
		jwtSecret, jwtSecretErr := crt.GetOrGenPasswordKeyringPass("jwt_secret")
		if jwtSecretErr != nil {
			gl.Log("fatal", fmt.Sprintf("Error retrieving JWT secret key: %v", jwtSecretErr))
			return nil, jwtSecretErr
		}
		s.RefreshSecret = jwtSecret
	}

	refreshToken, err := generateRefreshToken(u.GetID(), s.RefreshSecret, s.RefreshExpirationSecs)
	if err != nil {
		return nil, fmt.Errorf("error generating refresh token for uid: %v: %v", u.GetID(), err)
	}

	if err := s.TokenRepository.SetRefreshToken(ctx, u.GetID(), refreshToken.ID, refreshToken.ExpiresIn); err != nil {
		return nil, fmt.Errorf("error storing token ID for uid: %v: %v", u.GetID(), err)
	}

	return &sci.TokenPair{
		IDToken:      idToken,
		RefreshToken: refreshToken.Token,
	}, nil
}

func validateIDToken(tokenString string, pubKey *rsa.PublicKey) (*idTokenCustomClaims, error) {
	token, err := jwt.ParseWithClaims(tokenString, &idTokenCustomClaims{}, func(token *jwt.Token) (interface{}, error) {
		return pubKey, nil
	})
	if err != nil {
		if strings.Contains(err.Error(), "token is expired") {
			return nil, fmt.Errorf("token has expired")
		}
		return nil, fmt.Errorf("invalid token format: %w", err)
	}

	claims, ok := token.Claims.(*idTokenCustomClaims)
	if !ok || !token.Valid {
		return nil, fmt.Errorf("invalid token")
	}

	return claims, nil
}

/// tests/bkp/files/tests/token_service_test.go ///
package tests

// import (
// 	"crypto/rand"
// 	"crypto/rsa"
// 	"testing"
// 	"time"

// 	"github.com/golang-jwt/jwt/v4"
// 	"github.com/kubex-ecosystem/gobe/internal/security/authentication"
// 	"github.com/stretchr/testify/assert"
// )

// func TestValidateIDToken(t *testing.T) {
// 	// Generate RSA keys for testing
// 	privKey, err := rsa.GenerateKey(rand.Reader, 2048)
// 	assert.NoError(t, err)
// 	pubKey := &privKey.PublicKey

// 	// Create a valid token
// 	expiresAt := time.Now().Add(time.Hour)
// 	claims := &authentication.idTokenCustomClaims{
// 		User: &authentication.UserModelType{
// 			ID:       "123",
// 			Username: "testuser",
// 			Email:    "test@example.com",
// 		},
// 		RegisteredClaims: jwt.RegisteredClaims{
// 			ExpiresAt: jwt.NewNumericDate(expiresAt),
// 			IssuedAt:  jwt.NewNumericDate(time.Now()),
// 		},
// 	}
// 	token := jwt.NewWithClaims(jwt.SigningMethodRS256, claims)
// 	tokenString, err := token.SignedString(privKey)
// 	assert.NoError(t, err)

// 	// Validate the token
// 	validatedClaims, err := authentication.validateIDToken(tokenString, pubKey)
// 	assert.NoError(t, err)
// 	assert.NotNil(t, validatedClaims)
// 	assert.Equal(t, "123", validatedClaims.User.GetID())
// 	assert.Equal(t, "testuser", validatedClaims.User.GetUsername())
// 	assert.Equal(t, "test@example.com", validatedClaims.User.GetEmail())

// 	// Test with an expired token
// 	expiredClaims := &authentication.idTokenCustomClaims{
// 		User: &authentication.UserModelType{
// 			ID:       "123",
// 			Username: "testuser",
// 			Email:    "test@example.com",
// 		},
// 		RegisteredClaims: jwt.RegisteredClaims{
// 			ExpiresAt: jwt.NewNumericDate(time.Now().Add(-time.Hour)),
// 			IssuedAt:  jwt.NewNumericDate(time.Now().Add(-2 * time.Hour)),
// 		},
// 	}
// 	expiredToken := jwt.NewWithClaims(jwt.SigningMethodRS256, expiredClaims)
// 	expiredTokenString, err := expiredToken.SignedString(privKey)
// 	assert.NoError(t, err)

// 	_, err = authentication.validateIDToken(expiredTokenString, pubKey)
// 	assert.Error(t, err)
// 	assert.Contains(t, err.Error(), "token has expired")

// 	// Test with an invalid token
// 	invalidTokenString := "invalid.token.string"
// 	_, err = authentication.validateIDToken(invalidTokenString, pubKey)
// 	assert.Error(t, err)
// 	assert.Contains(t, err.Error(), "invalid token format")
// }

/// tests/bkp/old/KUBE_LOCAL_TESTE_A.session.sql ///


/// tests/bkp/old/Makefile.txt ///
# Description: Makefile for building and installing a Go application
# Author: Rafael Mori
# Copyright (c) 2025 Rafael Mori
# License: MIT License

# This Makefile is used to build and install a Go application.
# It provides commands for building the binary, installing it, cleaning up build artifacts,
# and running tests. It also includes a help command to display usage information.
# The Makefile uses color codes for logging messages and provides a consistent interface
# for interacting with the application.

# Define the application name and root directory
APP_NAME := $(shell echo $(basename $(CURDIR)) | tr '[:upper:]' '[:lower:]')
ROOT_DIR := $(dir $(abspath $(lastword $(MAKEFILE_LIST))))
BINARY_NAME := $(ROOT_DIR)$(APP_NAME)
CMD_DIR := $(ROOT_DIR)cmd

# Define the color codes
COLOR_GREEN := \033[32m
COLOR_YELLOW := \033[33m
COLOR_RED := \033[31m
COLOR_BLUE := \033[34m
COLOR_RESET := \033[0m

# Logging Functions
log = @printf "%b%s%b %s\n" "$(COLOR_BLUE)" "[LOG]" "$(COLOR_RESET)" "$(1)"
log_info = @printf "%b%s%b %s\n" "$(COLOR_BLUE)" "[INFO]" "$(COLOR_RESET)" "$(1)"
log_success = @printf "%b%s%b %s\n" "$(COLOR_GREEN)" "[SUCCESS]" "$(COLOR_RESET)" "$(1)"
log_warning = @printf "%b%s%b %s\n" "$(COLOR_YELLOW)" "[WARNING]" "$(COLOR_RESET)" "$(1)"
log_break = @printf "%b%s%b\n" "$(COLOR_BLUE)" "[INFO]" "$(COLOR_RESET)"
log_error = @printf "%b%s%b %s\n" "$(COLOR_RED)" "[ERROR]" "$(COLOR_RESET)" "$(1)"

ARGUMENTS := $(MAKECMDGOALS)
INSTALL_SCRIPT=$(ROOT_DIR)installer/main.sh
CMD_STR := $(strip $(firstword $(ARGUMENTS)))
ARGS := $(filter-out $(strip $(CMD_STR)), $(ARGUMENTS))

# Build the binary using the install script.
build:
$(call log_info, Building $(APP_NAME) binary)
$(call log_info, Args: $(ARGS))
@bash $(INSTALL_SCRIPT) build $(ARGS)
$(shell exit 0)

# Install the binary and configure the environment.
install:
$(call log_info, Installing $(APP_NAME) binary)
$(call log_info, Args: $(ARGS))
@bash $(INSTALL_SCRIPT) install $(ARGS)
$(shell exit 0)

# Clean up build artifacts.
clean:
$(call log_info, Cleaning up build artifacts)
$(call log_info, Args: $(ARGS))
@bash $(INSTALL_SCRIPT) clean $(ARGS)
$(shell exit 0)

# Run tests.
test:
$(call log_info, Running tests)
$(call log_info, Args: $(ARGS))
@bash $(INSTALL_SCRIPT) test $(ARGS)
$(shell exit 0)

## Run dynamic commands with arguments calling the install script.
%:
@:
$(call log_info, Running command: $(CMD_STR))
$(call log_info, Args: $(ARGS))
@bash $(INSTALL_SCRIPT) $(CMD_STR) $(ARGS)
$(shell exit 0)

# Display help message.
help:
$(call log, $(APP_NAME) Makefile)
$(call log_break)
$(call log, Usage:)
$(call log,   make [target] [ARGS='--custom-arg value'])
$(call log_break)
$(call log, Available targets:)
$(call log,   make build      - Build the binary using install script)
$(call log,   make build-dev  - Build the binary without compressing it)
$(call log,   make install    - Install the binary and configure environment)
$(call log,   make clean      - Clean up build artifacts)
$(call log,   make test       - Run tests)
$(call log,   make help       - Display this help message)
$(call log_break)
$(call log, Usage with arguments:)
$(call log,   make install ARGS='--custom-arg value' - Pass custom arguments to the install script)
$(call log_break)
$(call log, Example:)
$(call log,   make install ARGS='--prefix /usr/local')
$(call log_break)
$(call log, $(APP_NAME) is a tool for managing Kubernetes resources)
$(call log_break)
$(call log, For more information, visit:)
$(call log, 'https://github.com/kubex-ecosystem/'$(APP_NAME))
$(call log_break)
$(call log_success, End of help message)
$(shell exit 0)

# End of Makefile

/// tests/bkp/old/scripts/clean.sh ///
#!/usr/bin/env bash


###################################################################################
# __env_sourced_name
#
# This function is used to generate a unique environment variable name
# based on the script name. It will be used to check if the script is sourced
# after all other operations are done and validated. This will prevent
# the script from being run directly and will ensure that the environment
# is set up correctly before running any commands. It is not meant to be run
# directly.
#
###################################################################################
__cleanner_sourced_name() {
  local _self="${BASH_SOURCE-}"
  _self="${_self//${_kbx_root:-$()}/}"
  _self="${_self//\.sh/}"
  _self="${_self//\-/_}"
  _self="${_self//\//_}"
  echo "_was_sourced_${_self//__/_}"
  return 0
}

###############################################################################
# logger.sh load
#
# This line loads the logger.sh script only if the function kbx_log is not already
# defined. This is to prevent loading the script multiple times and causing
# conflicts. The logger.sh script is used to kbx_log messages to the console and
# to a file. It is not meant to be run directly.
#
#################################################################################
# shellcheck disable=SC2065,SC1091
test -z "$(declare -f kbx_log)" >/dev/null && source "${_kbx_path_helpers:-"$(dirname "${0}")"}/logger.sh"


###############################################################################
# __first
#
# This function is the validation entry point for the script. It will trigger
# the unique environment variable name generation and check if the script is
# sourced or run directly. It will also check if the script is run as root
# or with sudo and set the shell options to ensure that the script is run
# correctly. If the script is run as root or with sudo privileges, it will
# print an error message and exit with a non-zero status code.
#
###############################################################################
__first(){
  if [ "$EUID" -eq 0 ] || [ "$UID" -eq 0 ]; then
    echo "Please do not run as root." 1>&2 > /dev/tty
    exit 1 || kill -9 $$ || true
  elif [ -n "${SUDO_USER:-}" ]; then
    echo "Please do not run as root, but with sudo privileges." 1>&2 > /dev/tty
    exit 1 || kill -9 $$ || true
  else
    local _ws_name="$(__cleanner_sourced_name)"

    if test "${BASH_SOURCE-}" != "${0}"; then
      export "${_ws_name}"="true"
    else
      export "${_ws_name}"="false"
      # This script is used to install the project binary and manage its dependencies.
      set -o errexit
      set -o nounset

      #set -euo pipefail
      set -o pipefail

      set -o errtrace
      set -o functrace
      # set -o posix

      shopt -s inherit_errexit
    fi
  fi
}
__first "$@" >/dev/tty || exit 1
## </editor-fold>


###################################################################################
# clear_script_cache
#
# This function is used to clear the script cache. It will remove the
# temporary directory and all its contents. It is not meant to be run
# directly. It is meant to be used as a cleanup function in the script.
# It will be called when the script exits or when the user interrupts
# the script. It will also check if the script is run as root or with
# sudo and will remove the temporary directory with sudo if necessary.
#
###################################################################################
clear_script_cache() {
  # Disable the trap for cleanup
  trap - EXIT HUP INT QUIT ABRT ALRM TERM

  # Check if the temporary directory exists, if not, return
  if [ ! -d "${_TEMP_DIR}" ]; then
    exit 0
  fi

  # Remove the temporary directory
  rm -rf "${_TEMP_DIR}" || true
  # shellcheck disable=SC2046
  if test -d "${_TEMP_DIR}" && test $(sudo -v 2>/dev/null); then
    sudo rm -rf "${_TEMP_DIR}"
    if [[ -d "${_TEMP_DIR}" ]]; then
      printf '%b[_ERROR]%b âŒ  %s\n' "$_ERROR" "$_NC" "Failed to remove temporary directory: ${_TEMP_DIR}"
    else
      printf '%b[_SUCCESS]%b âœ…  %s\n' "$_SUCCESS" "$_NC" "Temporary directory removed: ${_TEMP_DIR}"
    fi
  fi
  exit 0
}

/// tests/bkp/old/scripts/install.sh ///
#!/usr/bin/env bash

###################################################################################
# __inst_sourced_name
#
# This function is used to generate a unique environment variable name
# based on the script name. It will be used to check if the script is sourced
# after all other operations are done and validated. This will prevent
# the script from being run directly and will ensure that the environment
# is set up correctly before running any commands. It is not meant to be run
# directly.
#
###################################################################################
__inst_sourced_name() {
  local _self="${BASH_SOURCE-}"
  _self="${_self//${_kbx_root:-$()}/}"
  _self="${_self//\.sh/}"
  _self="${_self//\-/_}"
  _self="${_self//\//_}"
  echo "_was_sourced_${_self//__/_}"
  return 0
}


###############################################################################
# logger.sh load
#
# This line loads the logger.sh script only if the function kbx_log is not already
# defined. This is to prevent loading the script multiple times and causing
# conflicts. The logger.sh script is used to kbx_log messages to the console and
# to a file. It is not meant to be run directly.
#
#################################################################################
# shellcheck disable=SC2065,SC1091
test -z "$(declare -f kbx_log)" >/dev/null && source "${_kbx_path_helpers:-"$(dirname "${0}")"}/logger.sh"


###############################################################################
# __first
#
# This function is the validation entry point for the script. It will trigger
# the unique environment variable name generation and check if the script is
# sourced or run directly. It will also check if the script is run as root
# or with sudo and set the shell options to ensure that the script is run
# correctly. If the script is run as root or with sudo privileges, it will
# print an error message and exit with a non-zero status code.
#
#################################################################################
__first(){
  if [ "$EUID" -eq 0 ] || [ "$UID" -eq 0 ]; then
    echo "Please do not run as root." 1>&2 > /dev/tty
    exit 1 || kill -9 $$ || true
  elif [ -n "${SUDO_USER:-}" ]; then
    echo "Please do not run as root, but with sudo privileges." 1>&2 > /dev/tty
    exit 1 || kill -9 $$ || true
  else
    local _ws_name="$(__inst_sourced_name)"

    if test "${BASH_SOURCE-}" != "${0}"; then
      export "${_ws_name}"="true"
    else
      export "${_ws_name}"="false"
      # This script is used to install the project binary and manage its dependencies.
      set -o errexit
      set -o nounset

      #set -euo pipefail
      set -o pipefail

      set -o errtrace
      set -o functrace
      # set -o posix

      shopt -s inherit_errexit
    fi
  fi
}
__first "$@" >/dev/tty || exit 1


# Set the field separator to handle spaces and tabs
IFS=$'\n\t'


#################################################################################
# set_trap
#
# This function sets a trap for the script to handle various signals and
# clean up resources. It will also set the shell options for error handling
# and debugging. It is not meant to be run directly. It will be called when
# the script exits or when the user interrupts the script. It will also
# check if the script is run as root or with sudo and will remove the
# temporary directory with sudo if necessary.
#
#################################################################################
# set_trap(){
#   # Get the current shell
#   get_current_shell

#   # Set the trap for the current shell and enable error handling, if applicable
#   case "${_CURRENT_SHELL}" in
#     *ksh|*zsh|*bash)

#       # Collect all arguments passed to the script into an array without modifying or running them
#       # shellcheck disable=SC2124
#       declare -a _FULL_SCRIPT_ARGS=$@

#       # Check if the script is being run in debug mode, if so, enable debug mode on the script output
#       if [[ ${_FULL_SCRIPT_ARGS[*]} =~ ^.*-d.*$ ]]; then
#           set -x
#       fi

#       # Set for the current shell error handling and some other options
#       if [[ "${_CURRENT_SHELL}" == "bash" ]]; then
#         set -o errexit
#         set -o pipefail
#         set -o errtrace
#         set -o functrace
#         shopt -s inherit_errexit
#       fi

#       # Set the trap to clear the script cache on exit.
#       # It will handle the following situations: command line exit, hangup, interrupt, quit, abort, alarm, and termination.
#       trap 'clear_script_cache' EXIT HUP INT QUIT ABRT ALRM TERM
#       ;;
#   esac

#   return 0
# }
# set_trap "$@"


#################################################################################
# what_platform
#
# This function detects the current platform and architecture. It uses the
# uname command to get the operating system and architecture information.
# It is not meant to be run directly. It will be called when the script
# is run to determine the platform and architecture for building the binary.
# It will also set the _PLATFORM and _ARCH variables to the detected values.
# It will also set the _PLATFORM_WITH_ARCH variable to the detected platform
# and architecture in the format of "os_arch".
#
#################################################################################
what_platform() {
  local _platform=""
  _platform="$(uname -o 2>/dev/null || echo "")"

  local _os=""
  _os="$(uname -s)"

  local _arch=""
  _arch="$(uname -m)"

  # Detect the platform and architecture
  case "${_os}" in
  *inux|*nix)
    _os="linux"
    case "${_arch}" in
    "x86_64")
      _arch="amd64"
      ;;
    "armv6")
      _arch="armv6l"
      ;;
    "armv8" | "aarch64")
      _arch="arm64"
      ;;
    .*386.*)
      _arch="386"
      ;;
    esac
    _platform="linux-${_arch}"
    ;;
  *arwin*)
    _os="darwin"
    case "${_arch}" in
    "x86_64")
      _arch="amd64"
      ;;
    "arm64")
      _arch="arm64"
      ;;
    esac
    _platform="darwin-${_arch}"
    ;;
  MINGW|MSYS|CYGWIN|Win*)
    _os="windows"
    case "${_arch}" in
    "x86_64")
      _arch="amd64"
      ;;
    "arm64")
      _arch="arm64"
      ;;
    esac
    _platform="windows-${_arch}"
    ;;
  *)
    _os=""
    _arch=""
    _platform=""
    ;;
  esac

  if [[ -z "${_platform}" ]]; then
    kbx_log "error" "Unsupported platform: ${_os} ${_arch}"
    kbx_log "error" "Please report this issue to the project maintainers."
    return 1
  fi

  # Normalize the platform string
  _PLATFORM_WITH_ARCH="${_platform//\-/\_}"
  _PLATFORM="${_os//\ /}"
  _ARCH="${_arch//\ /}"

  return 0
}

#################################################################################
# _get_os_arr_from_args
#
# This function takes a platform argument and returns an array of supported
# platforms. If the argument is "all", it returns all supported platforms.
# If the argument is not "all", it returns the specified platform.
# It is not meant to be run directly. It will be called when the script
# is run to determine the platform and architecture for building the binary.
#
#################################################################################
_get_os_arr_from_args() {
  local _PLATFORM_ARG=$1
  local _PLATFORM_ARR=()

  if [[ "${_PLATFORM_ARG}" == "all" ]]; then
    _PLATFORM_ARR=( "${__PLATFORMS[@]}" )
  else
    _PLATFORM_ARR=( "${_PLATFORM_ARG}" )
  fi

  for _platform_pos in "${_PLATFORM_ARR[@]}"; do
    echo "${_platform_pos} "
  done

  return 0
}

#################################################################################
# _get_arch_arr_from_args
#
# This function takes an architecture argument and returns an array of supported
# architectures. If the argument is "all", it returns all supported architectures.
# If the argument is not "all", it returns the specified architecture.
# It is not meant to be run directly. It will be called when the script
# is run to determine the platform and architecture for building the binary.
#
#################################################################################
_get_arch_arr_from_args() {
  local _ARCH_ARG=$1
  local _ARCH_ARR=()

  if [[ "${_ARCH_ARG}" == "all" ]]; then
    _ARCH_ARR=( "${__ARCHs[@]}" )
  else
    _ARCH_ARR=( "${_ARCH_ARG}" )
  fi

  echo "${_ARCH_ARR[@]}"

  return 0
}

#################################################################################
# _get_os_from_args
#
# This function takes a platform argument and returns the corresponding
# platform name. It is not meant to be run directly. It will be called when
# the script is run to determine the platform and architecture for building
# the binary. It will also set the _PLATFORM variable to the detected value.
#
#################################################################################
_get_os_from_args() {
  local _PLATFORM_ARG=$1
  case "${_PLATFORM_ARG}" in
    all|ALL|a|A|-a|-A)
      echo "all"
      ;;
    win|WIN|windows|WINDOWS|w|W|-w|-W)
      echo "windows"
      ;;
    linux|LINUX|l|L|-l|-L)
      echo "linux"
      ;;
    darwin|DARWIN|macOS|MACOS|m|M|-m|-M)
      echo "darwin"
      ;;
    *)
      kbx_log "error" "build_and_validate: Unsupported platform: '${_PLATFORM_ARG}'."
      kbx_log "error" "Please specify a valid platform (windows, linux, darwin, all)."
      exit 1
      ;;
  esac
  return 0
}

#################################################################################
# _get_arch_from_args
#
# This function takes an architecture argument and returns the corresponding
# architecture name. It is not meant to be run directly. It will be called when
# the script is run to determine the platform and architecture for building
# the binary. It will also set the _ARCH variable to the detected value.
#
#################################################################################
_get_arch_from_args() {
  local _ARCH_ARG=$1
  case "${_ARCH_ARG}" in
    all|ALL|a|A|-a|-A)
      echo "all"
      ;;
    amd64|AMD64|x86_64|X86_64|x64|X64)
      echo "amd64"
      ;;
    arm64|ARM64|aarch64|AARCH64)
      echo "arm64"
      ;;
    386|i386|I386)
      echo "386"
      ;;
    *)
      kbx_log "error" "build_and_validate: Unsupported architecture: '${_ARCH_ARG}'. Please specify a valid architecture (amd64, arm64, 386)."
      exit 1
      ;;
  esac
  return 0
}


#################################################################################
# detect_shell_rc
#
# Detect the shell configuration file based on the current shell
# It will check for common shell configuration files like .bashrc, .zshrc, etc.
# This function will check if application binary folder is in the PATH
# and if not, it will add it to the PATH in the appropriate shell configuration file.
# It is not meant to be run directly. It will be called when the script
#
# Arguments:
#   $1 - target path to add to PATH
#
#################################################################################
add_to_path() {
    target_path="$1"
    shell_rc_file=$(detect_shell_rc)
    if [ -z "$shell_rc_file" ]; then
        kbx_log "error" "Could not determine shell configuration file."
        return 1
    fi

    if grep -q "export PATH=.*$target_path" "$shell_rc_file" 2>/dev/null; then
        kbx_log "success" "$target_path is already in $shell_rc_file."
        return 0
    fi

    echo "export PATH=$target_path:\$PATH" >> "$shell_rc_file"
    kbx_log "success" "Added $target_path to PATH in $shell_rc_file."
    kbx_log "success" "Run 'source $shell_rc_file' to apply changes."
}

#################################################################################
# install_binary
#
# Install the binary to the appropriate directory.
# It will check if the user is root or not and install the binary
# in the appropriate directory. It will also check if the binary is already
# installed and if so, it will remove the old binary before installing the new one.
# It will also check if the binary is in the PATH and if not, it will add it to the PATH.
# It is not meant to be run directly.
#
#################################################################################
install_binary() {
    local _SUFFIX="${_PLATFORM_WITH_ARCH}"
    local _BINARY_TO_INSTALL="${_BINARY}${_SUFFIX:+_${_SUFFIX}}"
    kbx_log "info" "Installing binary: '$_BINARY_TO_INSTALL' like '$_APP_NAME'"

    if [ "$(id -u)" -ne 0 ]; then
        kbx_log "info" "You are not root. Installing in $_LOCAL_BIN..."
        mkdir -p "$_LOCAL_BIN"
        cp "$_BINARY_TO_INSTALL" "$_LOCAL_BIN/$_APP_NAME" || exit 1
        add_to_path "$_LOCAL_BIN"
    else
        kbx_log "info" "Root detected. Installing in $_GLOBAL_BIN..."
        cp "$_BINARY_TO_INSTALL" "$_GLOBAL_BIN/$_APP_NAME" || exit 1
        add_to_path "$_GLOBAL_BIN"
    fi
    clean
}

#################################################################################
# install_upx
#
# This function checks if UPX is installed and installs it if not.
# It will check if the user is root or not and install UPX in the appropriate
# directory. It will also check if UPX is already installed and if so, it will
# override the old UPX before installing the new one.
#
#################################################################################
install_upx() {
    if ! command -v upx > /dev/null; then
        kbx_log "info" "Installing UPX..."
        if [ "$(uname)" = "Darwin" ]; then
            brew install upx
        elif command -v apt-get > /dev/null; then
            sudo apt-get install -y upx
        else
            kbx_log "error" 'Install UPX manually from https://upx.github.io/'
            exit 1
        fi
    else
        kbx_log "success" ' UPX is already installed.'
    fi
}

#################################################################################
# check_dependencies
#
# Check if the required dependencies are installed, if not, install them.
#
# Arguments:
#   $@ - list of dependencies to check
#
#################################################################################
check_dependencies() {
    # shellcheck disable=SC2317
    for dep in "$@"; do
        if ! command -v "$dep" > /dev/null; then
            kbx_log "error" "$dep is not installed."
            exit 1
        else
            kbx_log "success" "$dep is installed."
        fi
    done
}

#################################################################################
# ensure_folders
#
# Ensure that all required folders exist. This function will create the
# required folders if they do not exist. It will also check if the folders
# are writable and if not, it will print an error message and exit.
#
#################################################################################
ensure_folders(){
    # Create the build directory if it doesn't exist
    local _build_path="$(dirname "$_BINARY")"
    if [ ! -d "$_build_path" ]; then
      kbx_log "info" "Creating build directory: $_build_path"
      mkdir -p $(dirname "$_BINARY") || return 1
    fi
    kbx_log "success" "Build directory created: $_BUILD_PATH"
}

#################################################################################
# build_binary
#
# Build the binary for the specified platform and architecture.
#
###############################################################################
# shellcheck disable=SC2207,SC2116,SC2091,SC2155,SC2005
build_binary() {

  declare -a __platform_arr="$(echo $(_get_os_arr_from_args "$1"))"
  declare -a _platform_arr=()
  eval _platform_arr="( $(echo "${__platform_arr[@]}") )"
  kbx_log "info" "Qty OS's: ${#_platform_arr[@]}"

  declare -a __arch_arr="$(echo $(_get_arch_arr_from_args "$2"))"
  declare -a _arch_arr=()
  eval _arch_arr="( $(echo "${__arch_arr[@]}") )"
  kbx_log "info" "Qty Arch's: ${#_arch_arr[@]}"

  for _platform_pos in "${_platform_arr[@]}"; do
    if test -z "${_platform_pos}"; then
      continue
    fi
    for _arch_pos in "${_arch_arr[@]}"; do
      if test -z "${_arch_pos}"; then
        continue
      fi
      if [[ "${_platform_pos}" != "darwin" && "${_arch_pos}" == "arm64" ]]; then
        continue
      fi
      if [[ "${_platform_pos}" != "windows" && "${_arch_pos}" == "386" ]]; then
        continue
      fi
      local _OUTPUT_NAME="$(printf '%s_%s_%s' "${_BINARY}" "${_platform_pos}" "${_arch_pos}")"
      if [[ "${_platform_pos}" == "windows" ]]; then
        _OUTPUT_NAME="$(printf '%s.exe' "${_OUTPUT_NAME}")"
      fi

      local _build_env=(
        "GOOS=${_platform_pos}"
        "GOARCH=${_arch_pos}"
      )
      local _build_args=(
        "-ldflags '-s -w -X main.version=$(git describe --tags) -X main.commit=$(git rev-parse HEAD) -X main.date=$(date +%Y-%m-%d)' "
        "-trimpath -o \"${_OUTPUT_NAME}\" \"${_CMD_PATH}\""
      )

      local _build_cmd=( "${_build_env[@]}" "go build " "${_build_args[*]}" )
      local _build_cmd_str=$(echo $(printf "%s" "${_build_cmd[*]//\ / }"))
      _build_cmd_str="$(printf '%s\n' "${_build_cmd_str//\ _/_}")"
      kbx_log "info" "$(printf '%s %s/%s' "Building the binary for" "${_platform_pos}" "${_arch_pos}")"
      kbx_log "info" "Command: ${_build_cmd_str}"

      local _cmdExec=$(bash -c "${_build_cmd_str}" 2>&1 && echo "true" || echo "false")

      # Build the binary using the environment variables and arguments
      if [[ "${_cmdExec}" == "false" ]]; then
        kbx_log "error" "Failed to build the binary for ${_platform_pos} ${_arch_pos}"
        kbx_log "error" "Command: ${_build_cmd_str}"
        return 1
      else
        # If the build was successful, check if UPX is installed and compress the binary (if not Windows)
        if [[ "${_platform_pos}" != "windows" ]]; then
            install_upx
            kbx_log "info" "Packing/compressing the binary with UPX..."
            upx "${_OUTPUT_NAME}" --force-overwrite --lzma --no-progress --no-color -qqq || true
            kbx_log "success" "Binary packed/compressed successfully: ${_OUTPUT_NAME}"
        fi
        # Check if the binary was created successfully (if not Windows)
        if [[ ! -f "${_OUTPUT_NAME}" ]]; then
          kbx_log "error" "Binary not found after build: ${_OUTPUT_NAME}"
          kbx_log "error" "Command: ${_build_cmd_str}"
          return 1
        else
          local compress_vars=( "${_platform_pos}" "${_arch_pos}" )
          compress_binary "${compress_vars[@]}" || return 1
          kbx_log "success" "Binary created successfully: ${_OUTPUT_NAME}"
        fi
      fi
    done
  done

  echo ""
  kbx_log "success" "All builds completed successfully!"
  echo ""

  return 0
}

#################################################################################
# compress_binary
#
# Compress the binary into a single tar.gz/zip file.
# It will check user system and architecture and compress the binary
# in the appropriate format. It will also check if the binary is already
# compressed and if so, it will remove the old compressed file before
# compressing the new one.
#
#################################################################################
# shellcheck disable=SC2207,SC2116,SC2091,SC2155,SC2005
compress_binary() {
  declare -a __platform_arr="$(echo $(_get_os_arr_from_args "$1"))"
  declare -a _platform_arr=()
  eval _platform_arr="( $(echo "${__platform_arr[@]}") )"
  kbx_log "info" "Qty OS's: ${#_platform_arr[@]}"

  declare -a __arch_arr="$(echo $(_get_arch_arr_from_args "$2"))"
  declare -a _arch_arr=()
  eval _arch_arr="( $(echo "${__arch_arr[@]}") )"
  kbx_log "info" "Qty Arch's: ${#_arch_arr[@]}"

  for _platform_pos in "${_platform_arr[@]}"; do
    if [[ -z "${_platform_pos}" ]]; then
      continue
    fi
    for _arch_pos in "${_arch_arr[@]}"; do
      if [[ -z "${_arch_pos}" ]]; then
        continue
      fi
      if [[ "${_platform_pos}" != "darwin" && "${_arch_pos}" == "arm64" ]]; then
        continue
      fi
      if [[ "${_platform_pos}" == "linux" && "${_arch_pos}" == "386" ]]; then
        continue
      fi

      local _BINARY_NAME="$(printf '%s_%s_%s' "${_BINARY}" "${_platform_pos}" "${_arch_pos}")"
      if [[ "${_platform_pos}" == "windows" ]]; then
        _BINARY_NAME="$(printf '%s.exe' "${_BINARY_NAME}")"
      fi

      local _OUTPUT_NAME="${_BINARY_NAME//\.exe/}"
      local _compress_cmd_exec=""
      if [[ "${_platform_pos}" != "windows" ]]; then
        _OUTPUT_NAME="${_OUTPUT_NAME}.tar.gz"
        kbx_log "info" "Compressing the binary for ${_platform_pos} ${_arch_pos} into ${_OUTPUT_NAME}..."
        _compress_cmd_exec=$(tar -czf "${_OUTPUT_NAME}" "${_BINARY_NAME}" 2>&1 && echo "true" || echo "false")
      else
        _OUTPUT_NAME="${_OUTPUT_NAME}.zip"
        kbx_log "info" "Compressing the binary for ${_platform_pos} ${_arch_pos} into ${_OUTPUT_NAME}..."
        _compress_cmd_exec=$(zip -r -9 "${_OUTPUT_NAME}" "${_BINARY_NAME}" 2>&1 && echo "true" || echo "false")
      fi
      if [[ "${_compress_cmd_exec}" == "false" ]]; then
        kbx_log "error" "Failed to compress the binary for ${_platform_pos} ${_arch_pos}"
        kbx_log "error" "Command: ${_compress_cmd_exec}"
        return 1
      else
        kbx_log "success" "Binary compressed successfully: ${_OUTPUT_NAME}"
      fi
    done
  done

  kbx_log "success" "All binaries compressed successfully!"

  return 0
}

#################################################################################
# validate_versions
#
# Validate the Go version wich is required to build the binary and check if
# the Go modules are tidy. It will check if the Go version is same or greater
# than the go.mod required version.
#
#################################################################################
validate_versions() {
    REQUIRED_GO_VERSION="${_VERSION_GO:-1.20.0}"
    GO_VERSION=$(go version | awk '{print $3}' | sed 's/go//')
    if [[ "$(printf '%s\n' "$REQUIRED_GO_VERSION" "$GO_VERSION" | sort -V | head -n1)" != "$REQUIRED_GO_VERSION" ]]; then
        kbx_log "error" "Go version must be >= $REQUIRED_GO_VERSION. Detected: $GO_VERSION"
        exit 1
    fi
    kbx_log "success" "Go version is valid: $GO_VERSION"
    go mod tidy || return 1
}

#################################################################################
# sumary
#
# Print a summary of the installation process.
#
#################################################################################
summary() {
    install_dir="$_BINARY"
    kbx_log "success" "Build and installation complete!"
    kbx_log "success" "Binary: $_BINARY"
    kbx_log "success" "Installed in: $install_dir"
    check_path "$install_dir"
}

#################################################################################
# build_and_validate
#
# Is the function tha precede the build process. It will check if the Go version
# is valid and if the Go modules are tidy. It will also check if the user
# provided a platform and architecture. If not, it will use the default values.
#
##################################################################################
build_and_validate() {
    # Check if the Go version is valid
    validate_versions

    local _PLATFORM_ARG="$1"
    # _PLATFORM_ARG="$(_get_os_from_args "${1:-${_PLATFORM}}")"
    local _ARCH_ARG="$2"
    # _ARCH_ARG="$(_get_arch_from_args "${2:-${_ARCH}}")"

    kbx_log "info" "Building for platform: ${_PLATFORM_ARG}, architecture: ${_ARCH_ARG}" true
    local _WHICH_COMPILE_ARG=( "${_PLATFORM_ARG}" "${_ARCH_ARG}" )

    # Call the build function with the platform and architecture arguments
    build_binary "${_WHICH_COMPILE_ARG[@]}" || exit 1

    return 0
}

#################################################################################
# check_path
#
# Check if the installation directory is in the PATH
#
# Arguments:
#   $1 - installation directory
#
#################################################################################
check_path() {
    kbx_log "info" "Checking if the installation directory is in the PATH..."
    if ! echo "$PATH" | grep -q "$1"; then
        kbx_log "warn" "$1 is not in the PATH."
        kbx_log "warn" "Add the following to your ~/.bashrc, ~/.zshrc, or equivalent file:"
        kbx_log "warn" "export PATH=$1:\$PATH"
    else
        kbx_log "success" "$1 is already in the PATH."
    fi
}

#################################################################################
# download_binary
#
# Download the binary from the release URL.
#
#################################################################################
download_binary() {
    # Obtem o sistema operacional e a arquitetura
    if ! what_platform > /dev/null; then
        kbx_log "error" "Failed to detect platform."
        return 1
    fi

    # ValidaÃ§Ã£o: Verificar se o sistema operacional ou a arquitetura sÃ£o suportados
    if [[ -z "${_PLATFORM}" ]]; then
        kbx_log "error" "Unsupported platform: ${_PLATFORM}"
        return 1
    fi

    # Obter a versÃ£o mais recente de forma robusta (fallback para "latest")
    version=$(curl -s "https://api.github.com/repos/${_OWNER}/${_PROJECT_NAME}/releases/latest" | \
        grep "tag_name" | cut -d '"' -f 4 || echo "latest")

    if [ -z "$version" ]; then
        kbx_log "error" "Failed to determine the latest version."
        return 1
    fi

    # Construir a URL de download usando a funÃ§Ã£o customizÃ¡vel
    release_url=$(get_release_url)
    kbx_log "info" "Downloading ${_APP_NAME} binary for OS=$os, ARCH=$arch, Version=$version..."
    kbx_log "info" "Release URL: ${release_url}"

    archive_path="${_TEMP_DIR}/${_APP_NAME}.tar.gz"

    # Realizar o download e validar sucesso
    if ! curl -L -o "${archive_path}" "${release_url}"; then
        kbx_log "error" "Failed to download the binary from: ${release_url}"
        return 1
    fi
    kbx_log "success" "Binary downloaded successfully."

    # ExtraÃ§Ã£o do arquivo para o diretÃ³rio binÃ¡rio
    kbx_log "info" "Extracting binary to: $(dirname "${_BINARY}")"
    if ! tar -xzf "${archive_path}" -C "$(dirname "${_BINARY}")"; then
        kbx_log "error" "Failed to extract the binary from: ${archive_path}"
        rm -rf "${_TEMP_DIR}"
        exit 1
    fi

    # Limpar artefatos temporÃ¡rios
    rm -rf "${_TEMP_DIR}"
    kbx_log "success" "Binary extracted successfully."

    # Verificar se o binÃ¡rio foi extraÃ­do com sucesso
    if [ ! -f "$_BINARY" ]; then
        kbx_log "error" "Binary not found after extraction: $_BINARY"
        exit 1
    fi

    kbx_log "success" "Download and extraction of ${_APP_NAME} completed!"
}

#################################################################################
# install_from_release
#
# Install the downloaded binary from the release URL.
# It will check if the user is root or not and install the binary on the
# appropriate directory. It will also check if the binary is already
# installed and if so, it will remove the old binary before installing the new one.
# It will also check if the binary is in the PATH and if not, it will add it to the PATH.
# It is not meant to be run directly.
#
#################################################################################
install_from_release() {
    download_binary
    install_binary
}

#################################################################################
# show_about
#
# Print the ABOUT message
#
#################################################################################
show_about() {
    # Print the ABOUT message
    printf '%s\n\n' "${_ABOUT:-}"
}

#################################################################################
# show_banner
#
# Print the BANNER message
#
#################################################################################
show_banner() {
    # Print the ABOUT message
    printf '\n%s\n\n' "${_BANNER:-}"
}

#################################################################################
# show_headers
#
# Print the BANNER and ABOUT messages
#
#################################################################################
show_headers() {
    # Print the BANNER message
    show_banner || return 1
    # Print the ABOUT message
    show_about || return 1
}

#################################################################################
# main
#
# Main function that handles the command line arguments and calls the
# appropriate functions based on the command provided. It will also
# check if the user has provided a command and if not, it will print
# an error message and exit. It will also check if the user has provided
# a platform and architecture and if not, it will use the default values.
#
#################################################################################
# shellcheck disable=SC2155
main() {
  # Detect the platform if not provided, will be used in the build command
  what_platform || exit 1

  # Show the banner information
  if [[ "${_DEBUG:-}" != true ]]; then
    show_headers
  else
    kbx_log "info" "Debug mode enabled. Skipping banner..."
    if [[ -z "${_HIDE_ABOUT:-}" ]]; then
      show_about
    fi
  fi

  _ARGS=( "$@" )
  local _default_label='Auto detect'
  local _arrArgs=( "${_ARGS[@]:0:$#}" )
  local _PLATFORM_ARG=$(_get_os_from_args "${_arrArgs[1]:-${_PLATFORM}}")
  local _ARCH_ARG=$(_get_arch_from_args "${_arrArgs[2]:-${_ARCH}}")

  # Check if the user has provided a command
  kbx_log "info" "Command: ${_arrArgs[0]:-}" true
  kbx_log "info" "Platform: ${_PLATFORM_ARG:-$_default_label}" true
  kbx_log "info" "Architecture: ${_ARCH_ARG:-$_default_label}" true

  case "${_arrArgs[0]:-}" in
    build|BUILD|-b|-B)
      # Call the build function with the detected platform
      build_and_validate "$_PLATFORM_ARG" "$_ARCH_ARG" || exit 1
      ;;
    install|INSTALL|-i|-I)
      kbx_log "info" "Executing install command..."
      read -r -p "Do you want to download the precompiled binary? [y/N] (No will build locally): " c </dev/tty
      kbx_log "info" "User choice: ${c}"

      if [ "$c" = "y" ] || [ "$c" = "Y" ]; then
          kbx_log "info" "Downloading precompiled binary..." true
          install_from_release "$_PLATFORM_ARG" "$_ARCH_ARG" || exit 1
      else
          kbx_log "info" "Building locally..." true
          build_and_validate "$_PLATFORM_ARG" "$_ARCH_ARG" || exit 1
          install_binary "$_PLATFORM_ARG" "$_ARCH_ARG" || exit 1
      fi

      summary
      ;;
    clear|clean|CLEAN|-c|-C)
      kbx_log "info" "Executing clean command..."
      clean || exit 1
      kbx_log "success" "Clean command executed successfully."
      ;;
    *)
      kbx_log "error" "Invalid command: $1"
      echo "Usage: $0 {build|install|clean}"
      ;;
  esac
}
# Execute the main function with all script arguments
## echo "MAKE ARGS: ${ARGS[*]:-}"
main "$@"

/// tests/bkp/old/scripts/main.sh ///
#!/usr/bin/env bash
# shellcheck disable=SC1091,SC2154

###############################################################
# __wrapper
#
# This is a wrapper script to run the kubex modules installation,
# building, uninstalling, cleaning and testing.It is not meant to
# be run directly to avoid any issues and protect the environment
# and the user. It is meant to be run by the Makefile or other scripts.
#
#########################################################################
. "$(dirname "$(readlink -e "${0}")")/wrapper.sh"
__wrapper "$@" || exit $?

/// tests/bkp/old/scripts/uninstall.sh ///
#!/usr/bin/env bash

###############################################################################
# logger.sh load
#
# This line loads the logger.sh script only if the function kbx_log is not already
# defined. This is to prevent loading the script multiple times and causing
# conflicts. The logger.sh script is used to kbx_log messages to the console and
# to a file. It is not meant to be run directly.
#
#################################################################################
# shellcheck disable=SC2065,SC1091
test -z "$(declare -f kbx_log)" >/dev/null && source "${_kbx_path_helpers:-"$(dirname "${0}")"}/logger.sh"

/// tests/bkp/old/scripts/wrapper.sh ///
#!/usr/bin/env bash


###############################################################################
# __wrapper
#
# This is a wrapper script to run the kubex modules installation,
# building, uninstalling, cleaning and testing. It is not meant to be run
# directly to avoid any issues and protect the environment and the user.
# It is meant to be run by the Makefile or other scripts.
#
###############################################################################
# shellcheck disable=SC2317,SC2155
__wrapper(){
  # This a secure script to run kubex modules installation, building, uninstalling, cleaning and testing.
  # It is not meant to be run directly to avoid any issues and protect the environment and the user.
  # It is meant to be run by the Makefile or other scripts.
  # __check(){
  #   return 0
  #   # # Check if folders and files exist
  #   # local _current_hash=$(find "${_kbx_path_scripts}" -type f -exec md5sum {} + | md5sum | awk '{ print $1 }')
  #   # local _last_hash=$(cat "${_kbx_path_build}/logs/.hash")
  #   # local _git_hash=$(_ghh=$(git rev-parse HEAD) && curl -s "https://raw.githubusercontent.com/kubex-io/kubex/${_ghh}/support/scripts/.hash" 2>/dev/null || echo "0")
  #   # if test "${_current_hash}" != "${_last_hash}"; then
  #   #   echo "KUBEX: Please, run the script: ${_kbx_path_build}/logs/.hash" > /dev/tty
  #   #   exit 1 || kill -9 $$
  #   # fi

  #   # local _curl_hash_check=$(cat "${_kbx_path_helpers}/curl_hash.txt" 2>/dev/null || echo "0")
  #   # if test "${_current_hash}" != "${_curl_hash_check}"; then
  #   #   echo "KUBEX: Please, run the script: ${_kbx_path_helpers}/curl_hash.sh" > /dev/tty
  #   #   exit 1 || kill -9 $$
  #   # fi

  #   # if test -d "${_kbx_path_source}" && test -d "${_kbx_path_scripts}" && test -d "${_kbx_path_helpers}"; then
  #   #   if test -f "${_kbx_path_source}/main.go" && test -f "${_kbx_path_scripts}/main.sh" && test -f "${_kbx_path_helpers}/logger.sh"; then
  #   #     return 0
  #   #   else
  #   #     return 1
  #   #   fi
  #   # else
  #   #   return 1
  #   # fi
  # }

  _kbx_path_run="$(readlink -e "${0}")" || return 1
  _kbx_path_root="$(realpath "$(dirname "${_kbx_path_run}")/../..")" || return 1
  _kbx_path_build="${_kbx_path_root}/build" || return 1
  _kbx_path_source="${_kbx_path_root}/cmd" || return 1
  _kbx_path_scripts="${_kbx_path_root}/support/scripts" || return 1
  _kbx_path_helpers="${_kbx_path_root}/support/utils" || return 1
  _kbx_path_settings="${_kbx_path_root}/support/settings" || return 1

  if test $EUID && test $UID -eq 0; then
    kbx_log error "KUBEX: Please do not run as root."
    exit 1 || kill -9 $$
  elif test -n "${SUDO_USER:-}"; then
    kbx_log error "KUBEX: Please do not run as root, but with sudo privileges." > /dev/tty
    exit 1 || kill -9 $$
  else
    # shellcheck disable=SC2065,SC1091
    test -z "$(declare -f kbx_log)" >/dev/null && source "${_kbx_path_helpers:-"$(dirname "${0}")"}/logger.sh"

    # if ! __check; then
    #   kbx_log error "KUBEX: Please, this script is not meant to be sourced!" > /dev/tty
    #   exit 1 || kill -9 $$
    # else
      set -o errexit
      set -o nounset
      set -o pipefail
      set -o errtrace
      set -o functrace
      shopt -s inherit_errexit

      readonly _kbx_path_root="${_kbx_path_root}" && export _kbx_path_root || return 1
      readonly _kbx_path_build="${_kbx_path_build}" && export _kbx_path_build || return 1
      readonly _kbx_path_source="${_kbx_path_source}" && export _kbx_path_source || return 1
      readonly _kbx_path_scripts="${_kbx_path_scripts}" && export _kbx_path_scripts || return 1
      readonly _kbx_path_helpers="${_kbx_path_helpers}" && export _kbx_path_helpers || return 1
      readonly _kbx_path_settings="${_kbx_path_settings}" && export _kbx_path_settings || return 1

      local _kbx_args=( "$@" )
      local _kbx_args_len="${#_kbx_args[@]}"
      local _kbx_run_file=""
      if test "${_kbx_args_len}" -gt 0; then
        _kbx_run_file="${_kbx_args[0]}"
        unset "_kbx_args[0]"
      else
        _kbx_run_file="help"
      fi
      _kbx_run_file="${_kbx_path_scripts}/${_kbx_run_file}.sh"

      # Check if the file exists and if it is inside the scripts folder.
      # after that,
      if test ! -f "${_kbx_run_file}"; then
        kbx_log error "KUBEX: File not found: ${_kbx_run_file}" > /dev/tty
        exit 1 || kill -9 $$
      else
        kbx_log debug "KUBEX: File found: ${_kbx_run_file}" > /dev/tty
      fi

      # shellcheck disable=SC1091
      . "${_kbx_path_settings}/loader.sh" || return 1

      declare -a _run_cmd=( "${_kbx_run_file}" "$@" ) || return 1
      kbx_run info "${_run_cmd[@]}" || return 1
    fi
  #fi
}


export -f __wrapper

/// tests/bkp/old/settings/envvars.sh ///
#!/usr/bin/env bash
# shellcheck disable=SC2155,SC2163

###############################################################################
# __env_sourced_name
#
# This function is used to generate a unique environment variable name
# based on the script name. It will be used to check if the script is sourced
# after all other operations are done and validated. This will prevent
# the script from being run directly and will ensure that the environment
# is set up correctly before running any commands. It is not meant to be run
# directly.
#
###############################################################################
__env_sourced_name() {
  local _self="${BASH_SOURCE-}"
  _self="${_self//${_kbx_root:-$(dirname "$(dirname "$(dirname "$(readlink -e "$0")")")")}/}"
  _self="${_self//\.sh/}"
  _self="${_self//\-/_}"
  _self="${_self//\//_}"
  echo "_was_sourced_${_self//__/_}"
  return 0
}


###############################################################################
# logger.sh load
#
# This line loads the logger.sh script only if the function kbx_log is not already
# defined. This is to prevent loading the script multiple times and causing
# conflicts. The logger.sh script is used to kbx_log messages to the console and
# to a file. It is not meant to be run directly.
#
#################################################################################
# shellcheck disable=SC2065,SC1091
test -z "$(declare -f kbx_log)" >/dev/null && source "${_kbx_path_helpers:-"$(dirname "${0}")"}/logger.sh"

###############################################################################
# __first
#
# This function is the validation entry point for the script. It will trigger
# the unique environment variable name generation and check if the script is
# sourced or run directly. It will also check if the script is run as root
# or with sudo and set the shell options to ensure that the script is run
# correctly. If the script is run as root or with sudo privileges, it will
# print an error message and exit with a non-zero status code.
#
###############################################################################
__first(){
  if [ "$EUID" -eq 0 ] || [ "$UID" -eq 0 ]; then
    echo "Please do not run as root." 1>&2 > /dev/tty
    exit 1 || kill -9 $$ || true
  elif [ -n "${SUDO_USER:-}" ]; then
    echo "Please do not run as root, but with sudo privileges." 1>&2 > /dev/tty
    exit 1 || kill -9 $$ || true
  else
    local _ws_name="$(__env_sourced_name)"

    if test "${BASH_SOURCE-}" != "${0}"; then
      export "${_ws_name}"="true"
    else
      export "${_ws_name}"="false"
      # This script is used to install the project binary and manage its dependencies.
      set -o errexit
      set -o nounset

      #set -euo pipefail
      set -o pipefail

      set -o errtrace
      set -o functrace
      # set -o posix

      shopt -s inherit_errexit
    fi
  fi
}
__first "$@" >/dev/tty || exit 1


#############################################################################
# clear_script_cache
#
# This function is used to export only functions without '__' prefix.
# It prevents the script from exporting functions that are not meant to be used
# outside the script. It is used to clean up the environment before running
# any commands. It is not meant to be run directly.
#
############################################################################
# shellcheck disable=SC2207,SC2116,SC2155
__env_list_functions() {
  local _str_functions=$(declare -F | awk '{print $3}' | grep -v "^_") >/dev/null || return 1
  declare -a _functions=( $(echo "$_str_functions") ) > /dev/null || return 1
  echo "${_functions[@]}"
  return 0
}
__env_main_functions() {
  # shellcheck disable=SC2207
  local _exported_functions=( $(__env_list_functions) ) >/dev/null || return 1
  for _exported_function in "${_exported_functions[@]}"; do
    export -f "${_exported_function}" >/dev/null || return 61
  done
  return 0
}
## </editor-fold>


############################################################################
# get_globals
#
# get_globals is a function to get the global variables for the project.
# It is called by the main script to ensure that the environment is set up
# correctly before running any commands. It is not meant to be run directly.
# It transfers the global variables to the caller script without exporting them
# to the environment. This is useful for debugging, testing purposes and security.
#
##############################################################################
get_globals() {


    local _BANNER='################################################################################

    â–ˆâ–ˆ   â–ˆâ–ˆ â–ˆâ–ˆ     â–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ     â–ˆâ–ˆ
    â–‘â–ˆâ–ˆ  â–ˆâ–ˆ â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–ˆ â–‘â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ â–‘â–‘â–ˆâ–ˆ   â–ˆâ–ˆ
    â–‘â–ˆâ–ˆ â–ˆâ–ˆ  â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆ   â–‘â–ˆâ–ˆ â–‘â–ˆâ–ˆ       â–‘â–‘â–ˆâ–ˆ â–ˆâ–ˆ
    â–‘â–ˆâ–ˆâ–ˆâ–ˆ   â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–‘â–‘â–ˆâ–ˆâ–ˆ
    â–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆ  â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–‘â–‘â–‘â–‘ â–ˆâ–ˆâ–‘â–ˆâ–ˆâ–‘â–‘â–‘â–‘     â–ˆâ–ˆâ–‘â–ˆâ–ˆ
    â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆ â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆ        â–ˆâ–ˆ â–‘â–‘â–ˆâ–ˆ
    â–‘â–ˆâ–ˆ â–‘â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ   â–‘â–‘â–ˆâ–ˆ
    â–‘â–‘   â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â–‘â–‘     â–‘â–‘'

    local _DEBUG=${DEBUG:-false}
    local _HIDE_ABOUT=${HIDE_ABOUT:-false}
    # This variable are used to customize the script behavior, like repository url and owner
    local _OWNER="rafa-mori"
    # The _REPO_ROOT variable is set to the root directory of the repository. One above the script directory.
    local _REPO_ROOT="${ROOT_DIR:-$(dirname "$(dirname "$(dirname "$(realpath "$0")")")")}"
    # The _APP_NAME variable is set to the name of the repository. It is used to identify the application.
    local _APP_NAME="${APP_NAME:-$(basename "$_REPO_ROOT")}"
    # The _PROJECT_NAME variable is set to the name of the project. It is used for display purposes.
    local _PROJECT_NAME="$_APP_NAME"
    # The _VERSION variable is set to the version of the project. It is used for display purposes.
    local _VERSION=$(cat "$_REPO_ROOT/version/CLI_VERSION" 2>/dev/null || echo "v0.0.0")
    # The _VERSION_GO variable is set to the version of the Go required by the project.
    local _VERSION_GO=$(grep '^go ' go.mod | awk '{print $2}')
    # The _VERSION variable is set to the version of the project. It is used for display purposes.
    local _LICENSE="MIT"
    # The _ABOUT variable contains information about the script and its usage.
    local _ABOUT="################################################################################
This Script is used to install ${_PROJECT_NAME} project, version ${_VERSION}.
Supported OS: Linux, MacOS, Windows
Supported Architecture: amd64, arm64, 386
Source: https://github.com/${_OWNER}/${_PROJECT_NAME}
Binary Release: https://github.com/${_OWNER}/${_PROJECT_NAME}/releases/latest
License: ${_LICENSE}
Notes:
    - [version] is optional; if omitted, the latest version will be used.
    - If the script is run locally, it will try to resolve the version from the
    repo tags if no version is provided.
    - The script will install the binary in the ~/.local/bin directory if the
    user is not root. Otherwise, it will install in /usr/local/bin.
    - The script will add the installation directory to the PATH in the shell
    configuration file.
    - The script will also install UPX if it is not already installed.
    - The script will build the binary if the build option is provided.
    - The script will download the binary from the release URL
    - The script will clean up build artifacts if the clean option is provided.
    - The script will check if the required dependencies are installed.
    - The script will validate the Go version before building the binary.
    - The script will check if the installation directory is in the PATH.
################################################################################"
    # Variable to store the current running shell
    local _CURRENT_SHELL=""
    # The _CMD_PATH variable is set to the path of the cmd directory. It is used to
    # identify the location of the main application code.
    local _CMD_PATH="${_REPO_ROOT}/cmd"
    # The _BUILD_PATH variable is set to the path of the build directory. It is used
    # to identify the location of the build artifacts.
    local _BUILD_PATH="$(dirname "${_CMD_PATH}")/build"
    # The _BINARY variable is set to the path of the binary file. It is used to
    # identify the location of the binary file.
    local _BINARY="${_BUILD_PATH}/${_APP_NAME}"
    # The _LOCAL_BIN variable is set to the path of the local bin directory. It is
    # used to identify the location of the local bin directory.
    local _LOCAL_BIN="${HOME:-"~"}/.local/bin"
    # The _GLOBAL_BIN variable is set to the path of the global bin directory. It is
    # used to identify the location of the global bin directory.
    local _GLOBAL_BIN="/usr/local/bin"
    # For internal use only
    local __PLATFORMS=( "windows" "darwin" "linux" )
    local __ARCHs=( "amd64" "386" "arm64" )
    # The _PLATFORM variable is set to the platform name. It is used to identify the
    # platform on which the script is running.
    local _PLATFORM_WITH_ARCH=""
    local _PLATFORM=""
    local _ARCH=""
    local __envvars_loaded="1"

    declare -A _envs=(
        ['_DEBUG']="${_DEBUG}"
        ['_HIDE_ABOUT']="${_HIDE_ABOUT}"
        ['_OWNER']="${_OWNER}"
        ['_REPO_ROOT']="${_REPO_ROOT}"
        ['_APP_NAME']="${_APP_NAME}"
        ['_PROJECT_NAME']="${_PROJECT_NAME}"
        ['_VERSION']="${_VERSION}"
        ['_VERSION_GO']="${_VERSION_GO}"
        ['_LICENSE']="${_LICENSE}"
        ['_ABOUT']="${_ABOUT}"
        ['_BANNER']="${_BANNER}"
        ['_CURRENT_SHELL']="${_CURRENT_SHELL}"
        ['_CMD_PATH']="${_CMD_PATH}"
        ['_BUILD_PATH']="${_BUILD_PATH}"
        ['_BINARY']="${_BINARY}"
        ['_LOCAL_BIN']="${_LOCAL_BIN}"
        ['_GLOBAL_BIN']="${_GLOBAL_BIN}"
        ['__PLATFORMS']="${__PLATFORMS}"
        ['__ARCHs']="${__ARCHs}"
        ['_PLATFORM_WITH_ARCH']="${_PLATFORM_WITH_ARCH}"
        ['_PLATFORM']="${_PLATFORM}"
        ['_ARCH']="${_ARCH}"
        ['__envvars_loaded']="${__envvars_loaded}"
    )

    # Export the variables to make them available in the environment
    for _key in "${!_envs[@]}"; do
        echo "${_key}"="${_envs[${_key}]}"
    done
    # Set the _PLATFORM variable based on the current platform
}

################################################################################
# __set_globals
#
# This function is used to set the global variables for the project.
# It is called by the main script to ensure that the environment is set up
# correctly before running any commands. It is not meant to be run directly.
#
##################################################################################
__set_globals() {
    # Set the _PLATFORM variable based on the current platform
    local _globals=()
    _
    # Export the global variables to make them available in the environment
    for _key in "${!_globals[@]}"; do
        export "${_key}"="${_globals[${_key}]}"
    done
}

###############################################################################
# __unset_globals
#
# This function is used to unset exported global variables.
# It isn't exported to the environment, is used internally just if needed.
#
#################################################################################
__unset_globals() {
    # Unset the global variables to clean up the environment
    for _key in "${!_globals[@]}"; do
        unset "${_key}"
    done
}

###############################################################################
# __main
#
# This function is the main entry point for the script. It will call the
# function passed as argument and pass the arguments to it, but only after
# checking all validations and setting up the environment correctly.
#
###############################################################################
_main() {
  local _ws_name="$(__env_sourced_name)"
  eval "local _ws_name=\$${_ws_name}" >/dev/null
  if [ $(echo "$_ws_name") != "true" ]; then
    __env_main_functions "$@"
    exit $?
  else
    kbx_die 33 "This script is not meant to be sourced" || echo "This script is not meant to be sourced" > /dev/tty
    exit 3
  fi
}
_main "$@"

/// tests/bkp/old/settings/loader.sh ///
#!/usr/bin/env bash
# shellcheck disable=SC2155,SC2163



# FunÃ§Ã£o para verificar modificaÃ§Ãµes
__check_modifications() {
    if [[ ! -d "${PWD}/logs" ]]; then
        mkdir -p "${PWD}/logs" || ("$(command -v pretty_log || echo "echo")" "Failed to create the logs directory" "error" && return 1)
    fi

    local _dir=$1
    local _build_file_name=$(basename "${_dir%/*}")
    _build_file_name="${_build_file_name}_$(basename "$_dir")"

    local _hash_file="${PWD}/logs/${_build_file_name}.hash"
    if [[ ! -f $_hash_file ]]; then
        touch "${PWD}/logs/${_build_file_name}.hash" || ("$(command -v pretty_log || echo "echo")" "Failed to create the hash file" "error" && return 1)
    fi

    local _current_hash=$(find "${_dir}" -type f -exec md5sum {} + | md5sum | awk '{ print $1 }')

    if [[ -f "${_hash_file}" ]]; then
        local _last_hash=$(cat "$_hash_file")
        if [[ $_current_hash == "$_last_hash" ]]; then
            echo "Old build hash: $_last_hash"
            echo "New build hash: $_current_hash"
            return 1  # Sem modificaÃ§Ãµes
        else
            echo "$_current_hash" > "$_hash_file"
            echo "Old build hash: $_last_hash"
            echo "New build hash: $_current_hash"
            return 0 # Com modificaÃ§Ãµes
        fi
    else
        echo "$_current_hash" > "$_hash_file"
        echo "New build hash: $_current_hash"
        return 0  # Com modificaÃ§Ãµes
    fi
}

###############################################################################
# __env_sourced_name
#
# This function is used to generate a unique environment variable name
# based on the script name. It will be used to check if the script is sourced
# after all other operations are done and validated. This will prevent
# the script from being run directly and will ensure that the environment
# is set up correctly before running any commands. It is not meant to be run
# directly.
#
###############################################################################
__loader_sourced_name() {
  local _self="${BASH_SOURCE-}"
  _self="${_self//${_kbx_root:-$(git rev-parse --show-toplevel)}/}"
  _self="${_self//\.sh/}"
  _self="${_self//\-/_}"
  _self="${_self//\//_}"
  echo "_was_sourced_${_self//__/_}"
  return 0
}


###############################################################################
# logger.sh load
#
# This line loads the logger.sh script only if the function kbx_log is not already
# defined. This is to prevent loading the script multiple times and causing
# conflicts. The logger.sh script is used to kbx_log messages to the console and
# to a file. It is not meant to be run directly.
#
#################################################################################
# shellcheck disable=SC2065,SC1091
test -z "$(declare -f kbx_log)" >/dev/null && source "${_kbx_path_helpers:-"$(dirname "${0}")"}/logger.sh"

###############################################################################
# __first
#
# This function is the validation entry point for the script. It will trigger
# the unique environment variable name generation and check if the script is
# sourced or run directly. It will also check if the script is run as root
# or with sudo and set the shell options to ensure that the script is run
# correctly. If the script is run as root or with sudo privileges, it will
# print an error message and exit with a non-zero status code.
#
###############################################################################
__first(){
  if [ "$EUID" -eq 0 ] || [ "$UID" -eq 0 ]; then
    echo "Please do not run as root." 1>&2 > /dev/tty
    exit 1 || kill -9 $$ || true
  elif [ -n "${SUDO_USER:-}" ]; then
    echo "Please do not run as root, but with sudo privileges." 1>&2 > /dev/tty
    exit 1 || kill -9 $$ || true
  else
    local _ws_name="$(__loader_sourced_name)"

    if test "${BASH_SOURCE-}" != "${0}"; then
      export "${_ws_name}"="true"
    else
      export "${_ws_name}"="false"
      # This script is used to install the project binary and manage its dependencies.
      set -o errexit
      set -o nounset

      #set -euo pipefail
      set -o pipefail

      set -o errtrace
      set -o functrace
      # set -o posix

      shopt -s inherit_errexit
    fi
  fi
}
__first "$@" >/dev/tty || exit 1


#############################################################################
# clear_script_cache
#
# This function is used to export only functions without '__' prefix.
# It prevents the script from exporting functions that are not meant to be used
# outside the script. It is used to clean up the environment before running
# any commands. It is not meant to be run directly.
#
############################################################################
# shellcheck disable=SC2207,SC2116,SC2155
__loader_list_functions() {
  local _str_functions=$(declare -F | awk '{print $3}' | grep -v "^__") >/dev/null || return 1
  declare -a _functions=( $(echo "$_str_functions") ) > /dev/null || return 1
  echo "${_functions[@]}"
  return 0
}
__loader_main_functions() {
  # shellcheck disable=SC2207
  local _exported_functions=( $(__loader_list_functions) ) >/dev/null || return 1
  for _exported_function in "${_exported_functions[@]}"; do
    export -f "${_exported_function}" >/dev/null || return 61
  done
  return 0
}


#################################################################################
# get_current_shell
#
# This function retrieves the current shell being used. It checks the process
# name and the shebang line of the script to determine the shell. It is not
# meant to be run directly.
#
#################################################################################
get_current_shell() {
  _CURRENT_SHELL="$(cat /proc/$$/comm)"

  case "${0##*/}" in
    ${_CURRENT_SHELL}*)
      shebang="$(head -1 "${0}")"
      _CURRENT_SHELL="${shebang##*/}"
      ;;
  esac

  return 0
}

#########################################################################
# get_release_url
#
# This function is used to get the release URL for the binary.
# It can be customized to change the URL format or add additional parameters.
# Actually im using the default logic to construct the URL with the release version, the platform and the architecture
# with the format .tar.gz or .zip (for windows). Sweet yourself.
#
#############################################################################
get_release_url() {
    # Default logic for constructing the release URL
    local _os="${_PLATFORM%%-*}"
    local _arch="${_PLATFORM##*-}"
    # If os is windows, set the format to .zip, otherwise .tar.gz
    local _format="${_os:zip=tar.gz}"

    local _url=$(printf "https://github.com/%s/%s/releases/download/%s/%s_.%s" "${_OWNER}" "${_PROJECT_NAME}" "${_VERSION}" "${_PROJECT_NAME}" "${_format}")

    echo "${_url}"

    return 0
}


###############################################################################
# detect_shell_rc
#
# This function is used to detect the shell configuration file for the current
# user. It will return the path to the shell configuration file based on the
# current shell. It is used to add the installation directory to the PATH
# in the shell configuration file. It is not meant to be run directly.
# It is used to ensure that the installation directory is added to the PATH
#
#############################################################################
detect_shell_rc() {
    shell_rc_file=""
    user_shell=$(basename "$SHELL")
    case "$user_shell" in
        bash) shell_rc_file="$HOME/.bashrc" ;;
        zsh) shell_rc_file="$HOME/.zshrc" ;;
        sh) shell_rc_file="$HOME/.profile" ;;
        fish) shell_rc_file="$HOME/.config/fish/config.fish" ;;
        *)
            kbx_die "warn" "Unsupported shell, modify PATH manually."
            return 1
            ;;
    esac
    kbx_die "info" "$shell_rc_file"
    if [ ! -f "$shell_rc_file" ]; then
        kbx_die "error" "Shell configuration file not found: $shell_rc_file"
        return 1
    fi
    echo "$shell_rc_file"
    return 0
}


###############################################################################
# __main
#
# This function is the main entry point for the script. It will call the
# function passed as argument and pass the arguments to it, but only after
# checking all validations and setting up the environment correctly.
#
###############################################################################
_main() {
  # if ! __check_modifications "${_kbx_path_source:-$(dirname "${0}")}"; then
  #   echo "No modifications detected, skipping build." > /dev/tty
  #   return 0
  # fi
  local _ws_name="$(__loader_sourced_name)"
  eval "local _ws_name=\$${_ws_name}" >/dev/null
  if [ $(echo "$_ws_name") != "true" ]; then
      kbx_die "error" "This script is not meant to be run directly. Please source it instead."
      exit 1 || kill -9 $$
  else
    __loader_main_functions "$@"
  fi
}

_main "$@"

/// tests/bkp/old/utils/colors.sh ///
#!/usr/bin/env bash
# shellcheck disable=SC2155

########################################################################
# kbx_detect_background_color
#
# Detects the background color of the terminal.
#
###########################################################################
kbx_detect_background_color() {
  local _query_response=""
  local _test="$(printf "\e]11;?\a")" >/dev/null || return 1
  _query_response="$(echo -e "${_test}")" >/dev/null || return 1
  local _detected_background_color="${_query_response//[^0-9;:]/}" >/dev/null || return 1
  _detected_background_color="${_detected_background_color//\;/}" >/dev/null || return 1
  if test -z "$_detected_background_color"; then
    echo "rgb:00"
    return 0
  fi
  _detected_background_color="rgb:${_detected_background_color}"
  echo "${_detected_background_color:-}"
  return 0
}

#########################################################################
# kbx_get_high_contrast_color
#
# Determines the high contrast color based on the background color.
# The function takes a background color as an argument and returns
# either "dark" or "white" based on the brightness of the color.
#
##########################################################################
kbx_get_high_contrast_color() {
  local _bg_color="${1:-}"
  if [[ "${_bg_color}" =~ ^(rgb:ff|rgb:ee|rgb:dd|rgb:cc|rgb:bb|rgb:aa|rgb:99|rgb:88|rgb:77|rgb:66|rgb:55|rgb:44|rgb:33|rgb:22|rgb:11|rgb:00) ]]; then
    echo "dark"
  else
    echo "white"
  fi
  return 0
}

#########################################################################
# kbx_get_colors
#
# Sets up color variables for terminal output.
# The function checks if colors are supported in the terminal and
# sets up color variables accordingly.
# If colors are not supported, it sets the variables to empty strings.
# The function also checks for the background color and sets the
# foreground colors based on the contrast with the background.
#
# The function exports the following variables:
#   - _nocolor: No color
#   - _bold: Bold text
#   - _nobold: Normal text
#   - _underline: Underlined text
#   - _nounderline: Normal text
#   - _red: Red text
#   - _green: Green text
#   - _yellow: Yellow text
#   - _blue: Blue text
#   - _magenta: Magenta text
#   - _cyan: Cyan text
#
############################################################################
kbx_get_colors(){
  # kbx_log levels
  if test -n "${NO_COLOR:-}" || test -n "${ANSI_COLORS_DISABLED:-}"; then
    export _nocolor=""
    export _bold=""
    export _nobold=""
    export _underline=""
    export _nounderline=""
    export _red=""
    export _green=""
    export _yellow=""
    export _blue=""
    export _magenta=""
    export _cyan=""
    return 0
  fi

  local _light_red="\033[38;5;196m"
  local _dark_red="\033[38;5;160m"

  local _light_green="\033[38;5;40m"
  local _dark_green="\033[38;5;34m"

  local _light_yellow="\033[38;5;220m"
  local _dark_yellow="\033[38;5;214m"

  local _light_blue="\033[38;5;39m"
  local _dark_blue="\033[38;5;21m"

  local _light_magenta="\033[38;5;207m"
  local _dark_magenta="\033[38;5;165m"

  local _light_cyan="\033[38;5;116m"
  local _dark_cyan="\033[38;5;45m"

  local _kbx_detected_background_color=$(kbx_detect_background_color) >/dev/null || return 1
  local _kbx_contrast=$(kbx_get_high_contrast_color "$_kbx_detected_background_color") >/dev/null || return 1

  export _nocolor="\033[0m"
  export _bold="\033[1m"
  export _nobold="\033[22m"
  export _underline="\033[4m"
  export _nounderline="\033[24m"

  if test "$_kbx_contrast" == "dark"; then
    export _red="$_light_red"
    export _green="$_light_green"
    export _yellow="$_light_yellow"
    export _blue="$_light_blue"
    export _magenta="$_light_magenta"
    export _cyan="$_light_cyan"
  else
    export _red="$_dark_red"
    export _green="$_dark_green"
    export _yellow="$_dark_yellow"
    export _blue="$_dark_blue"
    export _magenta="$_dark_magenta"
    export _cyan="$_dark_cyan"
  fi
}

# Check if the script is being sourced, if so, load the functions
# if not, exit with an error
if test "${kbx_get_colors_loaded:-0}" != 1; then
  if test "${kbx_detect_bg_color_loaded:-0}" != 1; then
    export kbx_detect_bg_color_loaded=1
    export kbx_detect_background_color
  fi
  if test "${kbx_get_high_contrast_color_loaded:-0}" != 1; then
    export kbx_get_high_contrast_color_loaded=1
    export kbx_detect_background_color
  fi

  export kbx_get_colors_loaded=1

  kbx_get_colors
fi

/// tests/bkp/old/utils/logger.sh ///
#!/usr/bin/env bash
# shellcheck disable=SC2155,SC2163,SC2207


# shellcheck disable=SC2065,SC1091
test -z "$(declare -f log)" >/dev/null && source "${_kbx_path_helpers:-"$(dirname "${0}")"}/colors.sh"


#############################################################################
# clear_script_cache
#
# This function is used to export only functions without '__' prefix.
# It prevents the script from exporting functions that are not meant to be used
# outside the script. It is used to clean up the environment before running
# any commands. It is not meant to be run directly.
#
############################################################################
# shellcheck disable=SC2207,SC2116,SC2155
__log_list_functions() {
  local _str_functions=$(declare -F | awk '{print $3}' | grep -v "^__") >/dev/null || return 61
  declare -a _functions=( $(echo "$_str_functions") ) > /dev/null || return 61
  echo "${_functions[@]}"
  return 0
}
__log_main_functions() {
  local _exported_functions=( $(__log_list_functions) ) >/dev/null || return 61
  for _exported_function in "${_exported_functions[@]}"; do
    export -f "${_exported_function}" || return 61
  done
  return 0
}

##########################################################################
# kbx_create_temp_dir
#
# Creates a temporary directory for logs.
# The function checks if the _TEMP_DIR variable is set and if it points to a
# valid directory. If not, it creates a new temporary directory and sets
# the _TEMP_DIR variable to point to it. The function also creates a kbx_log file
# in the temporary directory and sets the _kbx_log_output variable to point
# to the kbx_log file. The function exports the _TEMP_DIR and _kbx_log_output
# variables for use in other functions.
# The function returns 0 on success and 1 on failure.
#
############################################################################
_kbx_create_temp_dir() {
  # Create a temporary directory for logs
  local _temp_check="$(test "$(test -z "${_TEMP_DIR:-}" || ! test -d "${_TEMP_DIR:-}")" && echo "true" || echo "false")" || return 1
  if [[ ! -d "${_TEMP_DIR:-}" ]]; then
    _TEMP_DIR="$(mktemp -d)" || return 1
    export _TEMP_DIR || return 1
    touch "${_TEMP_DIR}/log.txt" || return 1
    chmod 777 "${_TEMP_DIR}/log.txt" || return 1
  fi
  if test -f "${_TEMP_DIR}/log.txt"; then
    _kbx_log_output="${_TEMP_DIR}/log.txt" || return 1
  else
    _kbx_log_output="$(mktemp -p "${_TEMP_DIR}" log.txt)" || return 1
  fi
  export _kbx_log_output || return 1
}


##########################################################################
# kbx_tail_log
#
# Tails the kbx_log file and waits for it to finish.
# The function runs the tail command in the background and waits for it
# to finish. The function also sets the kbx_tail_pid variable to the
# process ID of the tail command. The function exports the kbx_tail_pid
# variable for use in other functions. The function returns 0 on success
# and 1 on failure.
#
############################################################################
kbx_tail_log(){
  local tail_pid
  tail -f "${_kbx_log_output}" &
  tail_pid=$!
  export kbx_tail_pid="${tail_pid}"
  wait "${tail_pid}"
}

##########################################################################
# kbx_set_trap
#
# Sets up traps for various signals and errors.
# The function sets up traps for various signals (EXIT, HUP, INT, QUIT,
# ABRT, ALRM, TERM) and errors. The function also sets up a trap for
# the kbx_exit_handler function to handle errors and cleanup. The
# function exports the kbx_last_exit variable to store the last exit
# code. The function also sets up a trap for the kbx_end function to
# handle cleanup on exit. The function returns 0 on success and 1 on
# failure.
#
############################################################################
kbx_set_trap(){
  _curr_shell="$(cat /proc/$$/comm)"
  case "${0##*/}" in
    ${_curr_shell}*)
      shebang="$(head -1 "${0}")"
      _curr_shell="${shebang##*/}"
      ;;
  esac
  case "${_curr_shell}" in
    *bash|*ksh|*zsh)
      if test "${_curr_shell}" = "bash"; then
        set -o errtrace
        set -o pipefail
      fi
      trap 'kbx_exit_handler $? ${LINENO:-}' ERR
      ;;
  esac
  trap 'kbx_exit_handler $? ${LINENO:-} ' EXIT HUP INT QUIT ABRT ALRM TERM
}

##########################################################################
# kbx_end
#
#
# Cleans up and exits the script.
# The function resets the exit trap and kills the tail process if it
# is running. The function also sets the kbx_last_exit variable to the
# last exit code. The function returns 0 on success and 1 on failure.
# The function also prints the kbx_log file location and size.
#
############################################################################
kbx_end() {
  ## Reset exit trap.
  trap - EXIT HUP INT QUIT ABRT ALRM TERM
  if test -n "${kbx_tail_pid:-}"; then
    sleep 0.3
    kill -9 ${kbx_tail_pid}
  fi
  exit "${kbx_last_exit:-1}"
}

##########################################################################
# kbx_exit_handler
#
#
# Handles exit signals and errors.
# The function handles exit signals and errors by logging the error
# message and the line number where the error occurred. The function
# also logs the source script and the exit code. The function prints
# the kbx_log file location and size. The function also prints the elapsed
# time and the exit code. The function returns 0 on success and 1 on
# failure.
#
############################################################################
kbx_exit_handler() {
  true "BEGIN kbx_exit_handler() with args: $*"
  export kbx_last_exit="${kbx_last_exit:-${1}}"
  local line_number="${2:-0}"
  local err_source_script="${3:-}"

  ## Exit without errors.
  test "${kbx_last_exit}" = "0" && kbx_end || true

  ## Exit with errors.
  # shellcheck disable=SC3028
  if test -n "${err_source_script:-}"; then
    kbx_log notice "Executed script: '${0}'"
    kbx_log notice "What was being run at the time of the error was: ${err_source_script}"
  fi

  ## some shells have a bug that displays line 1 as LINENO
  if test "${line_number}" -gt 2; then
    kbx_log error "${kubex_pkg_name:-Kubex} aborted due to an error."
    kbx_log error "No need to panic. Nothing is broken. Just some rare condition has been hit."
    kbx_log error "Please report this bug if it has not been already."
    kbx_br || true
    kbx_log error "An error occurred at line: '${line_number}'"

    ## Easy version for wasting resources and better readability.
    line_above="$(pr -tn "${0}" | tail -n+$((line_number - 4)) | head -n4)"
    line_error="$(pr -tn "${0}" | tail -n+$((line_number)) | head -n1)"
    line_below="$(pr -tn "${0}" | tail -n+$((line_number + 1)) | head -n4)"
    printf '%s\n*%s\n%s\n' "${line_above}" "${line_error}" "${line_below}"
    ## Too complex.
    # awk 'NR>L-4 && NR<L+4 { printf " %-5d%3s %s\n",NR,(NR==L?">>>":""),$0 }' L="${line_number}" "${0}" >&2

    kbx_br || true
    kbx_log error "Please include the user kbx_log and the debug kbx_log in your bug report." || true
    kbx_log error "(For file locations where to find these logs, see above.)" || true
    kbx_br || true
  else
    if [ "${kbx_last_exit}" -gt 128 ] && [ "${kbx_last_exit}" -lt 193 ]; then
      signal_code=$((kbx_last_exit-128))
      signal_caught="$(kill -l "${signal_code}")"
      kbx_log error "Signal received: '${signal_caught}'" || true
    fi
  fi

  ## Print exit code.
  if test "${kbx_last_exit}" -gt 0; then
    kbx_log error "Exit code: '${kbx_last_exit}'" || true
  fi
  kbx_log notice "Time elapsed: $(kbx_get_elapsed)s." || true
  kbx_log notice "Exiting with code: '${kbx_last_exit}'" || true

  ## Print the kbx_log file location.
  if test -n "${_kbx_log_output:-}"; then
    kbx_log notice "Log file: '${_kbx_log_output}'" || true
  fi
  kbx_log notice "Log file size: $(du -h "${_kbx_log_output}" | awk '{print $1}')" || true
  kbx_log notice "Log file location: $(dirname "${_kbx_log_output}")" || true

  kbx_end || exit "${kbx_last_exit}" || return 1
}
## </editor-fold>

##############################################################################
# kbx_clear_keeping_buffer
#
# Clears the terminal screen and keeps the buffer.
# The function uses ANSI escape codes to clear the screen and reset the cursor
# position. The function also uses the tput command to clear the screen and
# reset the cursor position. The function returns 0 on success and 1 on failure.
# The function also prints a message to the terminal.
#
##############################################################################
kbx_clear_keeping_buffer(){
  >&2 printf "\033[H\033[2J" >/dev/tty || >&2 tput -x clear >/dev/tty || >&2 clear >/dev/tty
  return 0
}

##############################################################################
# kbx_br
#
# Prints a blank line to the terminal.
# The function uses ANSI escape codes to print a blank line to the terminal.
# The function returns 0 on success and 1 on failure.
# The function also prints a message to the terminal.
#
##############################################################################
kbx_br () {
  >&2 printf "\n" >/dev/tty || >&2 echo "" >/dev/tty
  return 0
}

##############################################################################
# kbx_yes_no_question
#
# Asks a yes/no question and returns the answer.
# The function uses ANSI escape codes to print a yes/no question to the
# terminal. The function also uses the read command to read the answer
# from the user. The function returns 0 on success and 1 on failure.
# The function also prints a message to the terminal.
#
# The function uses a timeout to wait for the user to answer the question.
# The function also uses a default answer if the user does not answer
# Arguments:
#   $1 - question to ask
#   $2 - default answer (y/n)
#   $3 - timeout in seconds
#
##############################################################################
kbx_yes_no_question() {
  local _question="${1}"
  local _default_answer="${2:-}"
  local _timeout="${3:-5}"
  local _answer=""
  local _counter=0
  while [[ ! "$_answer" =~ ^[yYnN]$ ]]; do
    if [ "$_counter" -gt 3 ]; then
      kbx_log error "Maximum number of attempts reached."
      kbx_br || true
      return 1
    else
      _counter=$((_counter + 1))
    fi
    read -rt "${_timeout}" -n 1 -rp "${_question} " _answer || _answer="${_default_answer:-}"
    if [ -z "${_answer}" ]; then
      if [ -n "${_default_answer}" ]; then
        _answer="${_default_answer}"
      fi
    fi
  done
  echo "${_answer}"
  kbx_br || true
  return 0
}

##############################################################################
# kbx_read_secret_with_callback
#
# Reads a secret from the user and calls a callback function with the secret.
# The function uses ANSI escape codes to read a secret from the user.
# The function also uses the read command to read the secret from the user without
# echoing it to the terminal. The function returns 0 on success and 1 on failure.
#
# The function returns 0 on success and 1 on failure.
#
############################################################################
kbx_read_secret_with_callback() {
  local _prompt="${1}"
  local _callback="${2:-}"
  local _secret=""
  local _counter=0
  while [ -z "${_secret}" ]; do
    if [ "$_counter" -gt 3 ]; then
      kbx_log error "Maximum number of attempts reached."
      return 1
    else
      _counter=$((_counter + 1))
    fi
    read -rsp "${_prompt}" _secret >/dev/tty
    kbx_br || true
    if [ -n "${_callback}" ]; then
      "${_callback}" "${_secret}"
    fi
  done
  return 0
}

##############################################################################
# kbx_wait_with_escape
#
# Waits for a specified time and allows the user to escape the wait.
# The function uses ANSI escape codes to wait for a specified time and
# allows the user to escape the wait. The function also uses the read
# command to read the escape key from the user, while waiting for the
# specified time it will print endless dots or the specified character.
# The function returns 0 on success and 1 on failure.
#
# Arguments:
#   $1 - waiting time in seconds
#   $2 - message to display
#   $3 - character to display while waiting
#
############################################################################
kbx_wait_with_escape() {
  local _default_sleep_time=0500e-3
  local _BEAUTY_SLEEP_TIME="${_BEAUTY_SLEEP_TIME:-$_default_sleep_time}"
  local _waiting_char="."
  local _message=""
  local _waiting_time=0
  local _waiting_time_limit=5

  if [[ -n "${1:-}" && "${1:-}" != "" && "$1" =~ ^[0-9]+$ ]]; then
    _waiting_time_limit=$((1 * "${1}"))
  fi
  if [ -n "${2:-}" ] && [ "${2:-}" != "" ]; then
    _message="${2:-}"
  else
    _message=""
  fi
  if [ -n "${3:-}" ] && [ "${3:-}" != "" ]; then
    _waiting_char="${3:-.}"
  fi

  if [ -n "${_message}" ] && [ "${_message}" != "" ]; then
    if [ $_waiting_time_limit -gt 4 ]; then
      _message="${_message}"
    fi
    kbx_log notice "${_message}"
  fi

  local _half_second_marker=""
  local _escape_wait_dummy=""
  local _waiting_char_acum="s) "
  local _remaining_time=$((_waiting_time_limit - _waiting_time))
  local _remaining_message="${_remaining_time}"
  while [ "${_waiting_time}" -lt "${_waiting_time_limit}" ]; do
    printf "\r%s%d%s" "${_message} (" "${_remaining_time}" "${_waiting_char_acum}"
    if read -rt 0.5 -n 1 -s; then
      break
    else
      sleep "${_BEAUTY_SLEEP_TIME}"
      if [[ -z "${_half_second_marker}" ]]; then
        _half_second_marker="1"
        _waiting_char_acum="${_waiting_char_acum:-}${_waiting_char:-}"
      else
        _half_second_marker=""
        _waiting_time=$((1 + _waiting_time))
        _remaining_time=$(( _waiting_time_limit - _waiting_time ))
        _waiting_char_acum+="${_waiting_char:-}"
      fi
    fi
  done

  kbx_br || true

  return 0
}


##############################################################################
# kbx_std_log_selector
#
# Selects the standard kbx_log file based on the kbx_log level and type.
# The function uses ANSI escape codes to select the standard kbx_log file
# based on the kbx_log level and type. The function also uses the kbx_log_level
# and kbx_log_file variables to determine the kbx_log level and file. The
# function returns the kbx_log file path based on the kbx_log level and type.
# The function returns 0 on success and 1 on failure.
#
# Arguments:
#   $1 - kbx_log level (info, error, verbose, debug)
#   $2 - kbx_log type (bug, error, fatal, critical, emergency, warn, alert, info,
#       answer, notice, success, action, debug, trace, verbose)
#
############################################################################
kbx_std_log_selector() {
  local _log_level="${1:-${kbx_log_level:-${log_level:-info}}}"
  local _log_file="${kbx_log_file:-${log_file:-/dev/null}}"
  local _log_type="${2:-notice}"
  #####################
  ## kbx_log LEVELS: INFO ERROR VERBOSE DEBUG
  ## kbx_log TYPES: bug error fatal critical emergency warn alert info answer notice success action debug trace verbose
  ######################
  ## CLI LEVEL VISIBLE TYPES: bug fatal critical emergency
  ## INFO LEVEL VISIBLE TYPES: bug error fatal critical emergency warn alert info answer
  ## ERROR LEVEL VISIBLE TYPES: bug error fatal critical emergency answer
  ## VERBOSE LEVEL VISIBLE TYPES: bug error fatal critical emergency warn alert info answer notice success action verbose
  ## DEBUG LEVEL VISIBLE TYPES: bug error fatal critical emergency warn alert info answer notice success action debug trace verbose
  ######################
  case "${_log_level}" in
    debug)
      case "${_log_type}" in
        bug|error|fatal|critical|emergency|warn|alert|info|answer|notice|success|action|debug|trace|verbose)
          echo "/dev/tty"
          return 0
          ;;
        *)
          echo "/dev/null"
          return 0
          ;;
      esac
      ;;
    verbose)
      case "${_log_type}" in
        bug|error|fatal|critical|emergency|warn|alert|info|answer|notice|success|action|verbose)
          echo "/dev/tty"
          return 0
          ;;
        *)
          echo "/dev/null"
          return 0
          ;;
      esac
      ;;
    info)
      case "${_log_type}" in
        bug|error|fatal|critical|emergency|warn|alert|info|answer)
          echo "/dev/tty"
          return 0
          ;;
        *)
          echo "/dev/null"
          return 0
          ;;
      esac
      ;;
    error)
      case "${_log_type}" in
        bug|error|fatal|critical|emergency|answer)
          echo "/dev/tty"
          return 0
          ;;
        *)
          echo "/dev/null"
          return 0
          ;;
      esac
      ;;
    cli|null)
      case "${_log_type}" in
        bug|error|fatal|critical|emergency)
          echo "/dev/tty"
          return 0
          ;;
        *)
          echo "/dev/null"
          return 0
          ;;
      esac
      ;;
    *)
      export log_level="verbose"
      printf '\n%b\n' "[${_red}ERROR${_nocolor}]: Unsupported kbx_log level specified: ${_yellow}'${_log_level}'${_nocolor}" >/dev/tty
      printf '%b\n\n' "[${_green}VALID${_green}]: ${_blue}debug${_nocolor}, ${_blue}verbose${_nocolor}, ${_blue}info${_nocolor}, ${_blue}error${_nocolor}, ${_blue}cli${_nocolor}" >/dev/tty
      # mata o script enviando um exit 1 para toda Ã¡rvore de processos do kubex usando o exec ou o kill -9
      exit 1 || kill -9 $$
      ;;
  esac
}

##########################################################################
# kbx_log
#
# Logs messages with different levels (info, warn, error, success).
# The function takes a kbx_log level and a message as arguments and logs the
# message to a kbx_log file. The function also supports different output formats
# based on the kbx_log level. The function creates a temporary directory for logs
# if it does not exist and sets the kbx_log file path in the _kbx_log_output
# variable. The function uses colors for different kbx_log levels and formats
# the output accordingly. The function also supports a debug mode that
# logs messages to both the kbx_log file and the console.
#
# kbx_log messages with different levels
# Arguments:
#   $1 - kbx_log level (info, warn, error, success)
#   $2 and above - message to log, can be multiple arguments. It will be
#                 concatenated into a single string.
#
############################################################################
kbx_log(){
  ## Avoid clogging output if kbx_log() is working alright.
  if test "${xtrace:-}" = "1"; then
    set +o xtrace
  else
    case "${-}" in
      *x*)
        xtrace=1
        set +o xtrace
        ;;
    esac
  fi

  # Check if the output folder exists, if not, create a new temporary directory
  # and set the output file into the variable _TEMP_DIR for trap cleanup
  if [ ! -d "${_TEMP_DIR:-}" ]; then
    _kbx_create_temp_dir || return 1
  fi
  # Check if the output file exists, if not, create it
  if [ ! -f "$_kbx_log_output" ]; then
    touch "$_kbx_log_output"
  else
    _kbx_create_temp_dir || return 1
  fi

  local log_type="${1:-notice}"
  ## capitalize kbx_log level
  local log_type_up="$(printf '%s' "${log_type}" | tr "[:lower:]" "[:upper:]")"
  shift 1
  ## set formatting based on kbx_log level
  local log_color=""
  case "${log_type}" in
    bug)
      log_color="${_underline}${_magenta}"
      ;;
    error|fatal|critical|emergency)
      log_color="${_red}"
      ;;
    warn|alert)
      log_color="${_yellow}"
      ;;
    info|answer)
      log_color="${_cyan}"
      ;;
    success|action)
      log_color="${_green}"
      ;;
    notice|verbose)
      log_color="${_nocolor}"
      ;;
    debug|trace)
      log_color="${_blue}"
      ;;
    null)
      log_color=""
      true
      ;;
    *)
      kbx_log bug "Unsupported kbx_log type specified: '${log_type}'"
      kbx_die 1 "Please report this bug."
  esac
  ## uniform kbx_log format
  log_color="${_bold}${log_color}"
  if [ "${kbx_log_source_script:-0}" != 0 ]; then
    local log_source_script="${BASH_SOURCE-}"
  fi
  local log_level_colorized="[${log_color}${log_type_up}${_nocolor}]: "
  local log_content="${*}"
  local log_file="$(kbx_std_log_selector "${kbx_log_level:-info}" "${log_type}")"
  if [ -n "${log_file}" ]; then
    if [ -n "${log_source_script:-}" ]; then
      printf '%b %b %b\n' "$(date +'%Y-%m-%d %H:%M:%S')" "${log_level_colorized}" "${log_content}" >> "${log_file}"
    else
      printf '%b %b\n' "${log_level_colorized}" "${log_content}" >> "${log_file}"
    fi
  fi
  if test "${xtrace:-}" = "1"; then
    set -o xtrace
  fi
  return 0
}

##########################################################################
# kbx_die
#
# Handles all exit codes and errors.
# The function takes an exit code and an error message as arguments
# and logs the error message.
#
###########################################################################
kbx_die(){
  export kbx_start_time="${kbx_start_time:-$(date +%s)}"
  kbx_log error "${2:-An error occurred.}"
  if test "${1:-1}" = "0"; then
    kbx_log notice "Exiting without errors."
    >&2 kbx_br >/dev/tty || true
    kbx_exit_handler 0 || exit 0 || return 0
  fi
  if test "${kbx_allow_errors:-0}" = "1"; then
    kbx_log warn "Skipping termination because of with code '${1}' due to 'kbx_allow_errors' setting."
    return 0
  fi
  case "${1:-1}" in
    0|333|666|999)
      true
      ;;
    *)
      kbx_log error "Kubex aborting..."
      ;;
  esac
  local _line_number=$((1 * "${3:-0}")) || true
  local _error_source="${4:-}"
  export kbx_last_exit=$((1 * "${1:-1}")) || true
  exit ${kbx_last_exit:-1} || kill -9 $$ || return 1
}

##########################################################################
# kbx_run
#
# Runs a command in the background or foreground, logging the output,
# handling errors and registering the time elapsed to run the command.
# The function will sanitize the command before running it, set the
# necessary environment variables and run provided command.
#
##########################################################################
kbx_run(){
  export kbx_start_time="${kbx_start_time:-$(date +%s)}"
  local level="${1:-info}"
  shift

  # shellcheck disable=SC2116
  ## Extra spaces appearing when breaking kbx_log_run on multiple lines.
  local cmd_no_space="$(echo "${@}")"
  cmd_no_space="${cmd_no_space//  / }"
  cmd_no_space="${cmd_no_space/route_exec/kubex}"
  if test "${dry_run:-}" = "1"; then
    kbx_log "${level}" "Skipping command: $ ${cmd_no_space}"
    return 0
  fi
  if test "${kbx_run_background:-}" = "1"; then
    kbx_log "${level}" "Background command starting: "
    kbx_log "${level}" "$ ${cmd_no_space} &"
    "${@}" &
    local kbx_background_pid="$!"
    disown "$kbx_background_pid"
  else
    kbx_log "${level}" "Loading command: " &&\
    kbx_log "${level}" "$ ${cmd_no_space}" &&\
    "${@}"
    kbx_exit_handler $?
  fi
}

##########################################################################
# kbx_get_elapsed
#
# Gets the elapsed time since the start of the script without
# echoing it to the terminal and without resetting the cursor position.
# The function uses ANSI escape codes to get the elapsed time since
# the start of the script. The function also uses the date command
# to get the elapsed time since the start of the script.
#
############################################################################
kbx_get_elapsed(){
  export kbx_start_time="${kbx_start_time:-$(date +%s)}"
  printf '%s\n' "$(($(date +%s) - kbx_start_time))" || return 1
  return 0
}

##########################################################################
# kbx_print_elapsed
#
# Prints the elapsed time since the start of the script to the terminal default stdout.
# The function uses ANSI escape codes to print the elapsed time since
# the start of the script. The function also uses the date command
# to get the elapsed time since the start of the script.
# The function returns 0 on success and 1 on failure.
#
############################################################################
kbx_print_elapsed(){
  export kbx_start_time="${kbx_start_time:-$(date +%s)}"
  kbx_log notice "Time elapsed: $(kbx_get_elapsed)s."
}
## </editor-fold>

# Script entry point
if test "${kbx_log_loaded:-0}" != "1"; then
  export kbx_log_loaded=1
  __log_main_functions
  if test "${BASH_SOURCE-}" = "${0}"; then
    kbx_set_trap
  fi
fi
## </editor-fold>


/// tests/crt_abs_test.go ///
package tests

import (
	"bytes"
	"crypto/rand"
	"crypto/rsa"
	"crypto/x509"
	"fmt"
	"os"
	"testing"

	crt "github.com/kubex-ecosystem/gobe/internal/security/certificates"
	krs "github.com/kubex-ecosystem/gobe/internal/security/external"
	gl "github.com/kubex-ecosystem/gobe/logger"

	"github.com/stretchr/testify/require"
	"golang.org/x/crypto/chacha20poly1305"
)

type MockPasswordStore struct {
	StoredPassword string
}

func (m *MockPasswordStore) StorePassword(password string) {
	m.StoredPassword = password
}

func (m *MockPasswordStore) RetrievePassword() (string, error) {
	if m.StoredPassword == "" {
		return "", fmt.Errorf("senha nÃ£o encontrada")
	}
	return m.StoredPassword, nil
}

type MockCertStorage struct {
	CertBuffer bytes.Buffer
	KeyBuffer  bytes.Buffer
}

func (m *MockCertStorage) StoreCertAndKey(cert []byte, key []byte) {
	m.CertBuffer.Write(cert)
	m.KeyBuffer.Write(key)
}

func (m *MockCertStorage) GetCertAndKey() ([]byte, []byte, error) {
	if m.CertBuffer.Len() == 0 || m.KeyBuffer.Len() == 0 {
		return nil, nil, fmt.Errorf("certificado ou chave nÃ£o encontrados")
	}
	return m.CertBuffer.Bytes(), m.KeyBuffer.Bytes(), nil
}

func TestGenerateCertificateCreatesValidCertificateAndKey(t *testing.T) {
	certService := crt.NewCertServiceType("test.key", "test.crt")
	defer func() {
		err := os.Remove("test.key")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Failed to remove test.key: %v", err))
		}
	}()
	defer func() {
		err := os.Remove("test.crt")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Failed to remove test.crt: %v", err))
		}
	}()

	password := []byte("test-password")
	_, _, err := certService.GenerateCertificate("test.crt", "test.key", password)
	require.NoError(t, err)

	_, err = os.Stat("test.crt")
	require.NoError(t, err)

	_, err = os.Stat("test.key")
	require.NoError(t, err)
}

func TestGenSelfCertGeneratesCertificateAndStoresPassword(t *testing.T) {
	certService := crt.NewCertServiceType("test.key", "test.crt")
	defer func() {
		err := os.Remove("test.key")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Failed to remove test.key: %v", err))
		}
	}()
	defer func() {
		err := os.Remove("test.crt")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Failed to remove test.crt: %v", err))
		}
	}()

	_, _, err := certService.GenSelfCert()
	require.NoError(t, err)

	krServiceName := ""
	krKeyName := ""
	krService := krs.NewKeyringService(krKeyName, krServiceName)

	password, err := krService.RetrievePassword()
	require.NoError(t, err)
	require.NotEmpty(t, password)
}

func TestDecryptPrivateKeyWithValidDataDecryptsSuccessfully(t *testing.T) {
	certService := crt.NewCertServiceType("", "")
	privateKey, _ := rsa.GenerateKey(rand.Reader, 2048)
	privateKeyBytes := x509.MarshalPKCS1PrivateKey(privateKey)

	block, _ := chacha20poly1305.New([]byte("test-password"))
	nonce := make([]byte, block.NonceSize())
	_, _ = rand.Read(nonce)
	ciphertext := block.Seal(nonce, nonce, privateKeyBytes, nil)

	krServiceName := ""
	krKeyName := ""
	krService := krs.NewKeyringService(krKeyName, krServiceName)
	_ = krService.StorePassword("test-password")
	decryptedKey, err := certService.DecryptPrivateKey(ciphertext, []byte("test-password"))
	require.NoError(t, err)
	require.Equal(t, privateKey, decryptedKey)
}

func TestDecryptPrivateKeyWithInvalidPasswordReturnsError(t *testing.T) {
	certService := crt.NewCertServiceType("", "")
	privateKey, _ := rsa.GenerateKey(rand.Reader, 2048)
	privateKeyBytes := x509.MarshalPKCS1PrivateKey(privateKey)

	block, _ := chacha20poly1305.New([]byte("test-password"))
	nonce := make([]byte, block.NonceSize())
	_, _ = rand.Read(nonce)
	ciphertext := block.Seal(nonce, nonce, privateKeyBytes, nil)

	krServiceName := ""
	krKeyName := ""
	krService := krs.NewKeyringService(krKeyName, krServiceName)

	_ = krService.StorePassword("wrong-password")
	_, err := certService.DecryptPrivateKey(ciphertext, []byte("test-password"))
	require.Error(t, err)
}

func TestVerifyCertWithValidCertificateReturnsNoError(t *testing.T) {
	certService := crt.NewCertServiceType("test.key", "test.crt")
	defer func() {
		err := os.Remove("test.key")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Failed to remove test.key: %v", err))
		}
	}()
	defer func() {
		err := os.Remove("test.crt")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Failed to remove test.crt: %v", err))
		}
	}()

	_, _, _ = certService.GenSelfCert()
	err := certService.VerifyCert()
	require.NoError(t, err)
}

func TestVerifyCertWithInvalidCertificateReturnsError(t *testing.T) {
	certService := crt.NewCertServiceType("invalid.key", "invalid.crt")
	_, err := os.Create("invalid.crt")
	require.NoError(t, err)
	defer func() {
		err := os.Remove("invalid.crt")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Failed to remove invalid.crt: %v", err))
		}
	}()

	err = certService.VerifyCert()
	require.Error(t, err)
}

func TestGetCertAndKeyFromFileReturnsCorrectData(t *testing.T) {
	certService := crt.NewCertServiceType("test.key", "test.crt")
	defer func() {
		err := os.Remove("test.key")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Failed to remove test.key: %v", err))
		}
	}()
	defer func() {
		err := os.Remove("test.crt")
		if err != nil {
			gl.Log("error", fmt.Sprintf("Failed to remove test.crt: %v", err))
		}
	}()

	_, _, _ = certService.GenSelfCert()
	certBytes, keyBytes, err := certService.GetCertAndKeyFromFile()
	require.NoError(t, err)
	require.NotEmpty(t, certBytes)
	require.NotEmpty(t, keyBytes)
}

func TestGetCertAndKeyFromFileWithMissingFilesReturnsError(t *testing.T) {
	certService := crt.NewCertServiceType("missing.key", "missing.crt")
	_, _, err := certService.GetCertAndKeyFromFile()
	require.Error(t, err)
}

/// tests/crypto_service_test.go ///
package tests

import (
	"bytes"
	"crypto/rand"
	"encoding/base64"
	"strings"
	"testing"

	crp "github.com/kubex-ecosystem/gobe/internal/security/crypto"
	"github.com/stretchr/testify/require"
	"golang.org/x/crypto/chacha20poly1305"
)

func TestEncryptWithValidDataReturnsEncryptedData(t *testing.T) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()
	data := []byte("test data")

	encrypted, _, err := service.Encrypt(data, key)
	require.NoError(t, err)
	require.NotEmpty(t, encrypted)
}

func TestEncryptWithEmptyDataReturnsError(t *testing.T) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()

	encrypted, _, err := service.Encrypt([]byte{}, key)
	require.Error(t, err)
	require.Nil(t, encrypted)
}

func TestDecryptWithValidEncryptedDataReturnsOriginalData(t *testing.T) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()
	data := []byte("test data")

	encrypted, _, _ := service.Encrypt(data, key)
	decrypted, _, err := service.Decrypt([]byte(encrypted), key)
	require.NoError(t, err)
	require.Equal(t, data, decrypted)
}

func TestDecryptWithInvalidKeyReturnsError(t *testing.T) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()
	invalidKey, _ := service.GenerateKey()
	data := []byte("test data")

	encrypted, _, _ := service.Encrypt(data, key)
	decrypted, _, err := service.Decrypt([]byte(encrypted), invalidKey)
	require.Error(t, err)
	require.Nil(t, decrypted)
}

func TestDecryptWithEmptyDataReturnsError(t *testing.T) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()

	decrypted, _, err := service.Decrypt([]byte{}, key)
	require.Error(t, err)
	require.Nil(t, decrypted)
}

func TestGenerateKeyReturnsValidKey(t *testing.T) {
	service := crp.NewCryptoServiceType()

	key, err := service.GenerateKey()
	require.NoError(t, err)
	require.Len(t, key, chacha20poly1305.KeySize)
}

func TestGenerateKeyWithLengthReturnsKeyOfSpecifiedLength(t *testing.T) {
	service := crp.NewCryptoServiceType()
	length := 32

	key, err := service.GenerateKeyWithLength(length)
	require.NoError(t, err)
	require.Len(t, key, length)
}

func TestIsEncryptedWithEncryptedDataReturnsTrue(t *testing.T) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()
	data := []byte("test data")

	encrypted, _, _ := service.Encrypt(data, key)
	// Simulate the encrypted data
	isEncrypted := service.IsEncrypted([]byte(encrypted))
	require.True(t, isEncrypted)
}

func TestIsEncryptedWithUnencryptedDataReturnsFalse(t *testing.T) {
	service := crp.NewCryptoServiceType()
	data := []byte("test data")

	isEncrypted := service.IsEncrypted(data)
	require.False(t, isEncrypted)
}

func TestDecodeIfEncodedWithBase64EncodedDataReturnsDecodedData(t *testing.T) {
	data := []byte("dGVzdCBkYXRh") // "test data" in Base64
	decoded, err := crp.NewCryptoService().DecodeIfEncoded(data)
	require.NoError(t, err)
	require.Equal(t, "test data", string(decoded))
}

func TestDecodeIfEncodedWithNonBase64DataReturnsOriginalData(t *testing.T) {
	data := []byte("test data")
	decoded, err := crp.NewCryptoService().DecodeIfEncoded(data)
	require.NoError(t, err)
	require.Equal(t, data, decoded)
}

func TestEncodeIfDecodedWithNonBase64DataReturnsEncodedData(t *testing.T) {
	data := []byte("test data")
	encoded, err := crp.NewCryptoService().EncodeIfDecoded(data)
	require.NoError(t, err)
	require.Equal(t, base64.URLEncoding.EncodeToString(data), string(encoded))
}

func TestEncodeIfDecodedWithBase64DataReturnsOriginalData(t *testing.T) {
	data := []byte("dGVzdCBkYXRh") // "test data" in Base64
	encoded, err := crp.NewCryptoService().EncodeIfDecoded(data)
	require.NoError(t, err)
	require.Equal(t, data, encoded)
}

func TestEncryptDecryptLargeData(t *testing.T) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()
	largeData := make([]byte, 100)
	_, err := rand.Read(largeData)
	if err != nil {
		t.Fatalf("failed to read random data: %v", err)
		return
	}

	encodedLargeData, err := service.EncodeIfDecoded(largeData)
	require.NoError(t, err)
	require.NotEmpty(t, encodedLargeData)

	encrypted, encryptedEncoded, err := service.Encrypt(largeData, key)
	require.NoError(t, err)
	require.NotEmpty(t, encrypted)
	require.NotEmpty(t, encryptedEncoded)

	decrypted, decryptedEncoded, err := service.Decrypt([]byte(encrypted), key)
	require.NoError(t, err)
	require.NotEmpty(t, decrypted)
	require.NotEmpty(t, decryptedEncoded)
	require.Equal(t, largeData, decrypted)
}

func TestMultiLayerEncryption(t *testing.T) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()
	data := []byte("test data")

	encryptedOnce, _, err := service.Encrypt(data, key)
	require.NoError(t, err)

	encryptedTwice, _, err := service.Encrypt([]byte(encryptedOnce), key)
	require.NoError(t, err)

	decryptedOnce, _, err := service.Decrypt([]byte(encryptedTwice), key)
	require.NoError(t, err)

	decryptedTwice, _, err := service.Decrypt([]byte(decryptedOnce), key)
	require.NoError(t, err)
	require.Equal(t, data, decryptedTwice)
}

func TestPreventDoubleEncryption(t *testing.T) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()
	data := []byte("test data")

	encrypted, _, errA := service.Encrypt(data, key)
	doubleEncrypted, _, errB := service.Encrypt([]byte(encrypted), key)

	require.NoError(t, errA)
	require.NoError(t, errB)
	require.Equal(t, encrypted, doubleEncrypted)
}

func BenchmarkEncryption(b *testing.B) {
	service := crp.NewCryptoServiceType()
	key, _ := service.GenerateKey()
	data := make([]byte, 100000) // 100KB de dados
	_, err := rand.Read(data)
	if err != nil {
		b.Fatalf("failed to read random data: %v", err)
		return
	}

	for i := 0; i < b.N; i++ {
		_, _, _ = service.Encrypt(data, key)
	}
}

// TestEncodeBase62 verifica se a funÃ§Ã£o EncodeBase62 estÃ¡ funcionando corretamente
func TestEncodeBase62(t *testing.T) {
	data := []byte("TesteUnitario")
	encoded := crp.EncodeBase64(data)

	if len(encoded) == 0 {
		t.Errorf("Falha ao codificar Base62, resultado vazio")
	}
}

// TestDecodeBase62 verifica se a funÃ§Ã£o DecodeBase62 retorna os bytes corretos
func TestDecodeBase62(t *testing.T) {
	data := []byte("TesteUnitario")
	encoded := crp.EncodeBase64(data)
	decoded, err := crp.DecodeBase64(encoded)

	require.NoError(t, err)
	require.NotEmpty(t, decoded)
	require.Equal(t, data, decoded)
	require.Equal(t, strings.TrimSpace(string(data)), strings.TrimSpace(string(decoded)))
}

// TestEncryptDecrypt verifica se o fluxo de criptografia e descriptografia funciona corretamente
func TestEncryptDecrypt(t *testing.T) {
	key, err := crp.NewCryptoService().GenerateKey()
	if err != nil {
		t.Fatalf("Erro ao gerar chave: %v", err)
	}

	originalData := []byte("Dados Sigilosos")
	encryptedData, encryptedDataEncoded, err := crp.NewCryptoService().Encrypt(originalData, key)
	if err != nil {
		t.Fatalf("Erro na criptografia: %v", err)
	}
	require.NotEmpty(t, encryptedData)
	require.NotEmpty(t, encryptedDataEncoded)

	decryptedData, decryptedDataEncoded, err := crp.NewCryptoService().Decrypt([]byte(encryptedData), key)
	if err != nil {
		t.Fatalf("Erro na descriptografia: %v", err)
	}
	require.NotEmpty(t, decryptedData)
	require.NotEmpty(t, decryptedDataEncoded)

	if !bytes.Equal(originalData, []byte(decryptedData)) {
		t.Errorf("Dados nÃ£o correspondem apÃ³s descriptografia. Esperado: %s, Obtido: %s", originalData, decryptedData)
	}
}

// TestEncryptDecrypt verifica se o fluxo de criptografia e descriptografia funciona corretamente
func TestEncryptDecryptSimpleStringA(t *testing.T) {
	key, err := crp.NewCryptoService().GenerateKey()
	if err != nil {
		t.Fatalf("Erro ao gerar chave: %v", err)
	}

	originalData := []byte("Dados Sigilosos Para")
	originalDataEncoded, err := crp.NewCryptoService().EncodeIfDecoded(originalData)
	if err != nil {
		t.Fatalf("Erro ao codificar Base62: %v", err)
	}
	require.NotEmpty(t, originalDataEncoded)

	encryptedData, encryptedDataEncoded, err := crp.NewCryptoService().Encrypt(originalData, key)
	if err != nil {
		t.Fatalf("Erro na criptografia: %v", err)
	}
	require.NotEmpty(t, encryptedData)
	require.NotEmpty(t, encryptedDataEncoded)

	decryptedData, decryptedDataEncoded, err := crp.NewCryptoService().Decrypt([]byte(encryptedData), key)
	if err != nil {
		t.Fatalf("Erro na descriptografia: %v", err)
	}
	require.NotEmpty(t, decryptedData)
	require.NotEmpty(t, decryptedDataEncoded)

	if !bytes.Equal(originalData, []byte(decryptedData)) {
		t.Errorf("Dados nÃ£o correspondem apÃ³s descriptografia. Esperado: %s, Obtido: %s", originalData, decryptedData)
	}
	if !bytes.Equal([]byte(originalDataEncoded), []byte(decryptedDataEncoded)) {
		t.Errorf("Dados codificados nÃ£o correspondem apÃ³s descriptografia. Esperado: %s, Obtido: %s", originalDataEncoded, decryptedDataEncoded)
	}
}

// TestEncryptDecrypt verifica se o fluxo de criptografia e descriptografia funciona corretamente
func TestEncryptDecryptComplexStringA(t *testing.T) {
	key, err := crp.NewCryptoService().GenerateKey()
	if err != nil {
		t.Fatalf("Erro ao gerar chave: %v", err)
	}

	originalData := []byte("Dados Sigilosos Para. Teste de criptografia com dados maiores e mais complexos! SerÃ¡ que funciona? Vamos testar com mais dados e ver se tudo estÃ¡ certo.")
	encryptedData, _, err := crp.NewCryptoService().Encrypt(originalData, key)
	if err != nil {
		t.Fatalf("Erro na criptografia: %v", err)
	}

	decryptedData, _, err := crp.NewCryptoService().Decrypt([]byte(encryptedData), key)
	if err != nil {
		t.Fatalf("Erro na descriptografia: %v", err)
	}

	if !bytes.Equal(originalData, []byte(decryptedData)) {
		t.Errorf("Dados nÃ£o correspondem apÃ³s descriptografia. Esperado: %s, Obtido: %s", originalData, decryptedData)
	}
}

// TestGenerateKey verifica se a chave gerada tem o tamanho correto
func TestGenerateKey(t *testing.T) {
	key, err := crp.NewCryptoService().GenerateKey()
	if err != nil {
		t.Fatalf("Erro ao gerar chave: %v", err)
	}

	if len(key) != chacha20poly1305.KeySize {
		t.Errorf("Tamanho da chave incorreto. Esperado: %d, Obtido: %d", chacha20poly1305.KeySize, len(key))
	}
}

/// tests/environment_test.go ///
package tests

// import (
// 	"context"
// 	"fmt"
// 	gb "github.com/kubex-ecosystem/gobe"
// 	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
// 	at "github.com/kubex-ecosystem/gobe/internal/types"
// 	gl "github.com/kubex-ecosystem/gobe/logger"
// 	l "github.com/kubex-ecosystem/logz"
// 	"os"
// 	"testing"
// 	"time"
// )

// var bgmErr error

// func getGoBEInstance(logFile, configFile string, isConfidential bool) (ci.IGoBE, error) {
// 	return gb.NewGoBE(
// 		"Test",
// 		"8666",
// 		"0.0.0.0",
// 		logFile,
// 		configFile,
// 		isConfidential,
// 		l.GetLogger("GoBE"),
// 		false,
// 	)
// }

// func TestLoadEnvFileWithValidFileLoadsSuccessfully(t *testing.T) {
// 	envFile := "/srv/apps/projects/gobe/tests/env/test.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"

// 	gbmT, bgmErr = getGoBEInstance(logFile, envFile, true)
// 	if bgmErr != nil {
// 		gl.Log("fatal", fmt.Sprintf("Failed to initialize GoBE: %v", bgmErr.Error()))
// 		return
// 	}

// 	if gbmT == nil {
// 		gl.Log("fatal", "GoBE instance is nil")
// 	}

// 	value := gbmT.Environment().Getenv("KEY")
// 	if value != "VALUE" {
// 		gl.Log("error", fmt.Sprintf("expected 'KEY' to be 'VALUE', got '%s'", value))
// 		t.Fatalf("expected 'KEY' to be 'VALUE', got '%s'", value)
// 	}
// }

// func TestLoadEnvFileWithValidEncryptedFileLoadsSuccessfully(t *testing.T) {
// 	envFile := "/srv/apps/projects/gobe/tests/env/go_kubex.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"

// 	gbmT, bgmErr = getGoBEInstance(logFile, envFile, true)
// 	if bgmErr != nil {
// 		gl.Log("fatal", fmt.Sprintf("Failed to initialize GoBE: %v", bgmErr.Error()))
// 		return
// 	}
// 	if gbmT == nil {
// 		gl.Log("fatal", "GoBE instance is nil")
// 	}

// 	expect := "faelmori@gmail.com"

// 	value := gbmT.Environment().Getenv("EMAIL_USR")

// 	gl.Log("notice", fmt.Sprintf("Expecting 'EMAIL_USR' to be '%s'", expect))
// 	gl.Log("notice", fmt.Sprintf("Config file: '%s'", gbmT.Environment().GetEnvFilePath()))
// 	gl.Log("notice", fmt.Sprintf("Is encrypted: '%t'", gbmT.Environment().IsEncrypted(gbmT.Environment().GetEnvFilePath())))
// 	gl.Log("notice", fmt.Sprintf("%d env vars loaded", len(gbmT.Environment().GetEnvCache())))
// 	gl.Log("notice", fmt.Sprintf("Env var 'EMAIL_USR': '%s'", value))

// 	if value != expect {
// 		gl.Log("warn", fmt.Sprintf("expected 'EMAIL_USR' to be '%s', got '%s'", expect, gbmT.Environment().Getenv("EMAIL_USR")))
// 		t.Fatalf("expected 'EMAIL_USR' to be '%s', got '%s'", expect, value)
// 	}
// }

// func TestLoadEnvFileWithInvalidFileReturnsError(t *testing.T) {
// 	envFile := "/srv/apps/projects/gobe/tests/nonexistent.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"
// 	configFile := envFile

// 	gbm, bgmErr := getGoBEInstance(logFile, configFile, false)
// 	if bgmErr != nil {
// 		if bgmErr.Error() != "environment is nil" {
// 			t.Fatalf("expected 'environment is nil', got '%v'", bgmErr.Error())
// 		} else {
// 			t.Logf("expected 'environment is nil', got '%v'", bgmErr.Error())
// 			return
// 		}
// 	}
// 	if err := gbm.Initialize(); err != nil {
// 		if err.Error() != "environment is nil" {
// 			t.Fatalf("expected 'environment is nil', got '%v'", err.Error())
// 		} else {
// 			t.Logf("expected 'environment is nil', got '%v'", err.Error())
// 			return
// 		}
// 	}

// 	err := gbm.Environment().LoadEnvFile(nil)

// 	if err == nil {
// 		t.Fatal("expected an error, got nil")
// 	}
// }

// func TestEncryptEnvFileWithUnencryptedFileEncryptsSuccessfully(t *testing.T) {
// 	envFile := "/srv/apps/projects/gobe/tests/env/unencrypted.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"
// 	configFile := envFile

// 	gbm, bgmErr := getGoBEInstance(logFile, configFile, true)
// 	if bgmErr != nil {
// 		gl.Log("fatal", fmt.Sprintf("Failed to initialize GoBE: %v", bgmErr.Error()))
// 		return
// 	}
// 	if err := gbm.Initialize(); err != nil {
// 		t.Fatalf("failed to initialize: %v", err)
// 	}

// 	writeErr := os.WriteFile(envFile, []byte("KEY=VALUE\n"), 0644)
// 	if writeErr != nil {
// 		t.Fatalf("failed to write test file: %v", writeErr)
// 		return
// 	}
// 	defer func(name string) {
// 		_ = os.Remove(name)
// 	}(envFile)

// 	err := gbm.Environment().EncryptEnvFile()
// 	if err != nil {
// 		t.Fatalf("unexpected error: %v", err)
// 	}

// 	if !gbm.Environment().IsEncrypted(envFile) {
// 		t.Errorf("expected file to be encrypted")
// 	}
// }

// func TestEncryptEnvFileWithAlreadyEncryptedFileDoesNothing(t *testing.T) {
// 	envFile := "encrypted.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"
// 	configFile := envFile

// 	gbm, bgmErr := getGoBEInstance(logFile, configFile, true)
// 	if bgmErr != nil {
// 		gl.Log("fatal", fmt.Sprintf("Failed to initialize GoBE: %v", bgmErr.Error()))
// 		return
// 	}
// 	if err := gbm.Initialize(); err != nil {
// 		t.Fatalf("failed to initialize: %v", err)
// 	}

// 	writeErr := os.WriteFile(envFile, []byte("KEY=VALUE\n"), 0644)
// 	if writeErr != nil {
// 		t.Fatalf("failed to write test file: %v", writeErr)
// 		return
// 	}
// 	defer func(name string) {
// 		_ = os.Remove(name)
// 	}(envFile)

// 	encryptErr := gbm.Environment().EncryptEnvFile()
// 	if encryptErr != nil {
// 		t.Fatalf("unexpected error: %v", encryptErr)
// 		return
// 	} // Encrypt once
// 	err := gbm.Environment().EncryptEnvFile() // Encrypt again
// 	if err != nil {
// 		t.Fatalf("unexpected error: %v", err)
// 	}

// 	if !gbm.Environment().IsEncrypted(envFile) {
// 		t.Errorf("expected file to remain encrypted")
// 	}
// }

// func TestDecryptEnvWithValidEncryptedValueReturnsOriginalValue(t *testing.T) {
// 	envFile := "/srv/apps/projects/gobe/tests/env/go_kubex.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"
// 	configFile := envFile

// 	gbm, bgmErr := getGoBEInstance(logFile, configFile, true)
// 	if bgmErr != nil {
// 		gl.Log("fatal", fmt.Sprintf("Failed to initialize GoBE: %v", bgmErr.Error()))
// 		return
// 	}
// 	if err := gbm.Initialize(); err != nil {
// 		t.Fatalf("failed to initialize: %v", err)
// 	}
// 	originalValue := "VALUE"
// 	encryptedValue, err := gbm.Environment().EncryptEnv(originalValue)
// 	if err != nil {
// 		t.Fatalf("unexpected error: %v", err)
// 	}

// 	decryptedValue, err := gbm.Environment().DecryptEnv(encryptedValue)
// 	if err != nil {
// 		t.Fatalf("unexpected error: %v", err)
// 	}

// 	if decryptedValue != originalValue {
// 		t.Errorf("expected '%s', got '%s'", originalValue, decryptedValue)
// 	}
// }

// func TestDecryptEnvWithInvalidEncryptedValueReturnsError(t *testing.T) {
// 	envFile := "/srv/apps/projects/gobe/tests/env/go_kubex.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"
// 	configFile := envFile

// 	gbm, bgmErr := getGoBEInstance(logFile, configFile, true)
// 	if bgmErr != nil {
// 		gl.Log("fatal", fmt.Sprintf("Failed to initialize GoBE: %v", bgmErr.Error()))
// 		return
// 	}
// 	if err := gbm.Initialize(); err != nil {
// 		t.Fatalf("failed to initialize: %v", err)
// 	}
// 	_, err := gbm.Environment().DecryptEnv("invalid-encrypted-value")
// 	if err == nil {
// 		t.Fatal("expected an error, got nil")
// 	}
// }

// func TestLoadEnvFromShellLoadsEnvironmentVariables(t *testing.T) {
// 	envFile := "/srv/apps/projects/gobe/tests/env/go_kubex.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"
// 	configFile := envFile

// 	gbm, bgmErr := getGoBEInstance(logFile, configFile, true)
// 	if bgmErr != nil {
// 		gl.Log("fatal", fmt.Sprintf("Failed to initialize GoBE: %v", bgmErr.Error()))
// 		return
// 	}
// 	if err := gbm.Initialize(); err != nil {
// 		t.Fatalf("failed to initialize: %v", err)
// 	}
// 	env, err := at.NewEnvironment("", false, nil)
// 	if err != nil {
// 		t.Fatalf("failed to create environment: %v", err)
// 	}
// 	err = env.LoadEnvFromShell()

// 	if err != nil {
// 		t.Fatalf("unexpected error: %v", err)
// 	}

// 	if env.Getenv("PATH") == "" {
// 		t.Errorf("expected 'PATH' to be set, got empty value")
// 	}
// }

// func TestBackupEnvFileCreatesBackupSuccessfully(t *testing.T) {
// 	envFile := "test.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"
// 	configFile := envFile

// 	gbm, bgmErr := getGoBEInstance(logFile, configFile, true)
// 	if bgmErr != nil {
// 		gl.Log("fatal", fmt.Sprintf("Failed to initialize GoBE: %v", bgmErr.Error()))
// 		return
// 	}
// 	if err := gbm.Initialize(); err != nil {
// 		t.Fatalf("failed to initialize: %v", err)
// 	}

// 	writeErr := os.WriteFile(envFile, []byte("KEY=VALUE\n"), 0644)
// 	if writeErr != nil {
// 		t.Fatalf("failed to write test file: %v", writeErr)
// 		return
// 	}
// 	defer func(name string) {
// 		_ = os.Remove(name)
// 	}(envFile)

// 	err := gbm.Environment().BackupEnvFile()
// 	if err != nil {
// 		t.Fatalf("unexpected error: %v", err)
// 	}

// 	backupFile := envFile + ".backup"
// 	defer func(name string) {
// 		_ = os.Remove(name)
// 	}(backupFile)

// 	if _, err := os.Stat(backupFile); os.IsNotExist(err) {
// 		t.Errorf("expected backup file to exist")
// 	}
// }

// func TestLoadEnvFileWithTimeoutReturnsError(t *testing.T) {
// 	envFile := "test.env"
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"
// 	configFile := envFile

// 	gbm, bgmErr := getGoBEInstance(logFile, configFile, true)
// 	if bgmErr != nil {
// 		gl.Log("fatal", fmt.Sprintf("Failed to initialize GoBE: %v", bgmErr.Error()))
// 		return
// 	}
// 	if err := gbm.Initialize(); err != nil {
// 		t.Fatalf("failed to initialize: %v", err)
// 	}

// 	writeErr := os.WriteFile(envFile, []byte("KEY=VALUE\n"), 0644)
// 	if writeErr != nil {
// 		t.Fatalf("failed to write test file: %v", writeErr)
// 		return
// 	}
// 	defer func(name string) {
// 		_ = os.Remove(name)
// 	}(envFile)

// 	env, err := at.NewEnvironment(envFile, false, nil)
// 	_, cancel := context.WithTimeout(context.Background(), 1*time.Millisecond)
// 	defer cancel()

// 	err = env.LoadEnvFile(func(ctx context.Context, chanCbArg chan any) <-chan any {
// 		time.Sleep(2 * time.Millisecond)
// 		return nil
// 	})

// 	if err == nil {
// 		t.Fatal("expected an error, got nil")
// 	}
// }

/// tests/keyring_service_test.go ///
package tests

import (
	"testing"

	krs "github.com/kubex-ecosystem/gobe/internal/security/external"
	"github.com/stretchr/testify/require"
)

var (
	keyringService = ""
	keyringName    = ""
)

func TestStorePasswordStoresPasswordSuccessfully(t *testing.T) {
	certService := krs.NewKeyringService(keyringName, keyringService)
	err := certService.StorePassword("test-password")
	require.NoError(t, err)
}

func TestRetrievePasswordReturnsStoredPassword(t *testing.T) {
	certService := krs.NewKeyringService(keyringName, keyringService)
	_ = certService.StorePassword("test-password")
	password, err := certService.RetrievePassword()
	require.NoError(t, err)
	require.Equal(t, "test-password", password)
}

/// tests/log/test_request_tracer.json ///
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-04-30T23:58:18.590012235-03:00"],"count":1}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-04-30T23:58:18.590012235-03:00","2025-04-30T23:58:18.590265673-03:00"],"count":2}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T02:45:33.542216793-03:00"],"count":1}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T02:45:33.542216793-03:00","2025-05-01T02:45:33.54259158-03:00"],"count":2}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T09:08:22.10247621-03:00"],"count":1}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T09:08:22.10247621-03:00","2025-05-01T09:08:22.103077038-03:00"],"count":2}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T09:09:44.913277788-03:00"],"count":1}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T09:09:44.913277788-03:00","2025-05-01T09:09:44.913514974-03:00"],"count":2}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:13:59.202567039-03:00"],"count":1}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:13:59.202567039-03:00","2025-05-01T15:13:59.204087474-03:00"],"count":2}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:14:05.622341721-03:00"],"count":1}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:14:05.622341721-03:00","2025-05-01T15:14:05.622569821-03:00"],"count":2}
{"ip":"192.168.1.10","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:18.464324199-03:00"],"count":1}
{"ip":"192.168.1.10","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:18.464324199-03:00","2025-05-01T15:17:18.464714562-03:00"],"count":2}
{"ip":"192.168.1.10","port":"12345","last_user_agent":"","user_agents":["","",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:18.464324199-03:00","2025-05-01T15:17:18.464714562-03:00","2025-05-01T15:17:18.46483854-03:00"],"count":3}
{"ip":"192.168.1.20","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:18.464923283-03:00"],"count":1}
{"ip":"192.168.1.20","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:18.464923283-03:00","2025-05-01T15:17:18.464969664-03:00"],"count":2}
{"ip":"192.168.1.20","port":"12345","last_user_agent":"","user_agents":["","",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:18.464923283-03:00","2025-05-01T15:17:18.464969664-03:00","2025-05-01T15:17:18.465062175-03:00"],"count":3}
{"ip":"192.168.1.30","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:18.465156372-03:00"],"count":1}
{"ip":"192.168.1.30","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:18.465156372-03:00","2025-05-01T15:17:18.465207727-03:00"],"count":2}
{"ip":"192.168.1.30","port":"12345","last_user_agent":"","user_agents":["","",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:18.465156372-03:00","2025-05-01T15:17:18.465207727-03:00","2025-05-01T15:17:18.465291348-03:00"],"count":3}
{"ip":"127.0.0.1","port":"8080","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:17:25.515381986-03:00"],"count":1}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":[""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:18:52.72611027-03:00"],"count":1}
{"ip":"192.168.1.1","port":"12345","last_user_agent":"","user_agents":["",""],"endpoint":"/test","method":"GET","time_list":["2025-05-01T15:18:52.72611027-03:00","2025-05-01T15:18:52.726251379-03:00"],"count":2}

/// tests/mapper_test.go ///
package tests

import (
	"fmt"
	"testing"

	at "github.com/kubex-ecosystem/gobe/internal/types"
	atc "github.com/kubex-ecosystem/gobe/internal/types"
	gl "github.com/kubex-ecosystem/gobe/logger"
)

func TestEncodeJSONInputProducesJSONOutput(t *testing.T) {
	input := map[string]string{"key": "value"}
	expected := `{"key":"value"}`

	output, err := atc.AutoEncode[map[string]string](input, "json", "./TestEncodeJSONInputProducesJSONOutput.json")
	if err != nil {
		gl.Log("error", fmt.Sprintf("unexpected error: %v", err))
		t.Fatalf("unexpected error: %v", err)
	}

	if string(output) != expected {
		gl.Log("error", fmt.Sprintf("expected '%s', got '%s'", expected, string(output)))
		t.Errorf("expected %s, got %s", expected, string(output))
	}
}

func TestDecodeJSONInputProducesCorrectStruct(t *testing.T) {
	input := []byte(`{"key":"value"}`)
	var obj map[string]string

	mapper := at.NewMapperPtr[map[string]string](&obj, "")
	out, err := mapper.Deserialize(input, "json")
	if err != nil {
		gl.Log("error", fmt.Sprintf("unexpected error: %v", err))
		t.Fatalf("unexpected error: %v", err)
	}
	if out == nil {
		gl.Log("error", "expected non-nil output, got nil")
		t.Fatalf("expected non-nil output, got nil")
	}

	outA := *out
	output := *outA

	if output != nil && output["key"] != "value" {
		gl.Log("error", fmt.Sprintf("expected value to be 'value', got '%s'", (output)["key"]))
		t.Errorf("expected value to be 'value', got '%s'", (output)["key"])
	}
	gl.Log("info", fmt.Sprintf("expected value to be 'value', got '%s'", (output)["key"]))
}

func TestEncodeUnsupportedTypeReturnsError(t *testing.T) {
	input := make(chan int)

	_, err := atc.AutoEncode[chan int](input, "json", "./TestEncodeUnsupportedTypeReturnsError.json")
	if err == nil {
		t.Fatal("expected an error, got nil")
	}
}

func TestDecodeUnsupportedTypeReturnsError(t *testing.T) {
	input := []byte(`{"key":"value"}`)
	var output chan int

	err := atc.AutoDecode[chan int](input, &output, "json")
	if err == nil {
		t.Fatal("expected an error, got nil")
	}
}

func TestEncodeTOMLInputProducesTOMLOutput(t *testing.T) {
	input := map[string]string{"key": "value"}
	expected := "key = 'value'\n"

	output, err := atc.AutoEncode[map[string]string](input, "toml", "./TestEncodeTOMLInputProducesTOMLOutput.toml")
	if err != nil {
		t.Fatalf("unexpected error: %v", err)
	}

	if string(output) != expected {
		gl.Log("error", fmt.Sprintf("expected %s, got %s", expected, string(output)))
		t.Errorf("expected %s, got '%s'", expected, string(output))
	}
}

func TestEncodeTOMLInputProducesTOMLOutputB(t *testing.T) {
	input := map[string]string{"key": "value"}
	expected := "key = \"value\"\n"

	output, err := atc.AutoEncode[map[string]string](input, "env", "./TestEncodeTOMLInputProducesTOMLOutput.toml")
	if err != nil {
		t.Fatalf("unexpected error: %v", err)
	}

	if !at.IsEqual(string(output), expected) {
		gl.Log("error", fmt.Sprintf("expected %s, got %s", expected, string(output)))
		t.Errorf("expected %s, got '%s'", expected, string(output))
	} else {
		gl.Log("info", fmt.Sprintf("expected %s, got %s", expected, string(output)))
	}
}

func TestDecodeTOMLInputProducesCorrectStruct(t *testing.T) {
	input := []byte(`key = "value"`)
	var output map[string]string

	err := atc.AutoDecode[map[string]string](input, &output, "toml")
	if err != nil {
		t.Fatalf("unexpected error: %v", err)
	}

	if !at.IsEqual(output["key"], "value") {
		gl.Log("error", fmt.Sprintf("expected value to be 'value', got '%s'", output["key"]))
		t.Errorf("expected value to be 'value', got '%v'", output["key"])
	}
}

func TestEncodeYAMLInputProducesYAMLOutput(t *testing.T) {
	input := map[string]string{"key": "value"}
	expected := "key: value\n"

	output, err := atc.AutoEncode[map[string]string](input, "yaml", "./TestEncodeYAMLInputProducesYAMLOutput.yaml")
	if err != nil {
		t.Fatalf("unexpected error: %v", err)
	}

	if string(output) != expected {
		t.Errorf("expected %s, got %s", expected, string(output))
	}
}

func TestDecodeYAMLInputProducesCorrectStruct(t *testing.T) {
	input := []byte("key: value\n\n")
	var output = make(map[string]string)

	err := atc.AutoDecode[map[string]string](input, &output, "yaml")
	if err != nil {
		t.Fatalf("unexpected error: %v", err)
	}

	if output["key"] != "value" {
		t.Errorf("expected value to be 'value', got %s", output["key"])
	}
}

func TestEncodeXMLInputProducesXMLOutput(t *testing.T) {
	input := struct {
		XMLName struct{} `xml:"root"`
		Key     string   `xml:"key"`
	}{Key: "value"}
	expected := `<root><key>value</key></root>`

	output, err := atc.AutoEncode[struct {
		XMLName struct{} `xml:"root"`
		Key     string   `xml:"key"`
	}](input, "xml", "./TestEncodeXMLInputProducesXMLOutput.xml")
	if err != nil {
		t.Fatalf("unexpected error: %v", err)
	}

	if string(output) != expected {
		t.Errorf("expected %s, got %s", expected, string(output))
	}
}

func TestEncodeXMLInputProducesXMLOutputB(t *testing.T) {
	input := struct {
		XMLName struct{} `xml:"root"`
		Key     string   `xml:"key"`
	}{Key: "value"}
	expected := `<root><key>value</key></root>`

	output, err := atc.AutoEncode[struct {
		XMLName struct{} `xml:"root"`
		Key     string   `xml:"key"`
	}](input, "xml", "./TestEncodeXMLInputProducesXMLOutputB.xml")
	if err != nil {
		t.Fatalf("unexpected error: %v", err)
	}

	if string(output) != expected {
		t.Errorf("expected %s, got %s", expected, string(output))
	}
}

func TestDecodeXMLInputProducesCorrectStruct(t *testing.T) {
	input := []byte(`<root><key>value</key></root>`)
	var output struct {
		Key string `xml:"key"`
	}

	err := atc.AutoDecode[struct {
		Key string `xml:"key"`
	}](input, &output, "xml")
	if err != nil {
		t.Fatalf("unexpected error: %v", err)
	}

	if output.Key != "value" {
		t.Errorf("expected value to be 'value', got %s", output.Key)
	}
}

/// tests/request_tracer_test.go ///
package tests

// import (
// 	"fmt"
// 	gb "github.com/kubex-ecosystem/gobe"
// 	ci "github.com/kubex-ecosystem/gobe/internal/interfaces"
// 	at "github.com/kubex-ecosystem/gobe/internal/types"
// 	gl "github.com/kubex-ecosystem/gobe/logger"
// 	l "github.com/kubex-ecosystem/logz"
// 	"path/filepath"
// 	"strings"
// 	"sync"

// 	"bytes"
// 	"encoding/json"
// 	"net/http"
// 	"net/http/httptest"
// 	"os"
// 	"testing"
// 	"time"
// )

// var (
// 	gbmT    ci.IGoBE
// 	gbmTErr error
// )

// func getGoBEInstanceTest(logFile, configFile string, isConfidential bool) (ci.IGoBE, error) {
// 	return gb.NewGoBE(
// 		"Test",
// 		"8666",
// 		"0.0.0.0",
// 		logFile,
// 		configFile,
// 		isConfidential,
// 		l.GetLogger("GoBE"),
// 		false,
// 	)
// }

// func init() {
// 	logFile := "/srv/apps/projects/gobe/tests/log/test_request_tracer.json"
// 	configFile := "/srv/apps/projects/gobe/tests/env/go_kubex.env"
// 	gbmT, gbmTErr = getGoBEInstance(logFile, configFile, true)
// }

// func unsetTestToken() {
// 	if os.Getenv("SECRET_TOKEN") == "valid_token" || os.Getenv("SECRET_TOKEN") == "invalid_token" {
// 		if err := os.Unsetenv("SECRET_TOKEN"); err != nil {
// 			gl.Log("error", fmt.Sprintf("Failed to unset environment variable: %v", err))
// 		}
// 	}
// }

// func TestRateLimit(t *testing.T) {
// 	defer unsetTestToken()

// 	var rr *httptest.ResponseRecorder
// 	req, err := http.NewRequest("GET", "/test", nil)
// 	if err != nil {
// 		t.Fatal(err)
// 	}
// 	req.RemoteAddr = "192.168.1.1:12345"

// 	for i := 0; i < gbmT.GetRequestLimit()+2; i++ {
// 		// New instance of ResponseRecorder for each request
// 		rr = httptest.NewRecorder()
// 		gbmT.RateLimit(rr, req)

// 		resp := rr.Result()
// 		if resp.StatusCode == http.StatusOK {
// 			gl.Log("info", fmt.Sprintf("Request %d allowed", i+1))
// 		} else {
// 			if resp.StatusCode == http.StatusTooManyRequests {
// 				gl.Log("info", "Rate limit exceeded")
// 				t.Logf("Rate limit exceeded for IP: %s", req.RemoteAddr)
// 				break
// 			} else {
// 				gl.Log("info", fmt.Sprintf("Request %d blocked", i+1))
// 				t.Errorf("Request %d blocked, expected %d, got %d", i+1, http.StatusOK, resp.StatusCode)
// 			}
// 		}
// 		gl.Log("info", fmt.Sprintf("Request response code: %d", resp.StatusCode))
// 	}

// 	if rr == nil || rr.Result().StatusCode != http.StatusTooManyRequests {
// 		if rr == nil {
// 			t.Errorf("ResponseRecorder is nil")
// 		} else {
// 			t.Errorf("Expected %d, got %d", http.StatusTooManyRequests, rr.Result().StatusCode)
// 		}
// 	} else {
// 		t.Log("info", "Rate limit test passed")
// 		err = nil
// 		return
// 	}
// }

// func TestRateLimitMultipleIPs(t *testing.T) {
// 	ips := []string{"192.168.1.10", "192.168.1.20", "192.168.1.30"}
// 	ports := []string{"12345", "54321", "67890"}

// 	for _, ip := range ips {
// 		for _, port := range ports {
// 			req, err := http.NewRequest("GET", "/test", nil)
// 			if err != nil {
// 				t.Fatal(err)
// 			}
// 			req.RemoteAddr = fmt.Sprintf("%s:%s", ip, port)

// 			rr := httptest.NewRecorder()
// 			gbmT.RateLimit(rr, req)

// 			resp := rr.Result()
// 			if resp.StatusCode == http.StatusTooManyRequests {
// 				t.Logf("Rate limit exceeded for IP: %s Port: %s", ip, port)
// 			} else {
// 				t.Logf("Request allowed for IP: %s Port: %s", ip, port)
// 			}
// 		}
// 	}
// }

// func TestHandleValidate(t *testing.T) {
// 	// simulate a ip and port
// 	ip := "127.0.0.1"
// 	port := "8080"
// 	// create a new request
// 	req, err := http.NewRequest("GET", "/test", nil)
// 	if err != nil {
// 		t.Fatal(err)
// 	}
// 	req.RemoteAddr = ip + ":" + port

// 	// set an invalid token
// 	req.Header.Set("Authorization Bearer", "invalid_token")
// 	rr := httptest.NewRecorder()
// 	gbmT.HandleValidate(rr, req)

// 	if rr.Code != http.StatusForbidden {
// 		t.Errorf("Token invÃ¡lido deveria retornar %d, mas retornou %d", http.StatusForbidden, rr.Code)
// 	}
// 	if strings.TrimSpace(rr.Body.String()) != "Invalid token" {
// 		t.Errorf("Esperado 'Invalid token', obtido '%s'", rr.Body.String())
// 	}
// }

// func TestPersistRequest(t *testing.T) {
// 	wg := sync.WaitGroup{}
// 	newLogFileTest := filepath.Join(filepath.Dir(gbmT.GetLogFilePath()), "TEST"+filepath.Base(gbmT.GetLogFilePath()))

// 	defer func() {
// 		if statFile, err := os.Stat(newLogFileTest); err == nil && !statFile.IsDir() {
// 			if err := os.Remove(newLogFileTest); err != nil {
// 				t.Errorf("Erro ao remover arquivo de teste: %v", err)
// 			}
// 		}
// 	}()
// 	defer wg.Wait()

// 	_ = at.NewRequestsTracer("192.168.1.14", "8666", "/validate", "GET", "Mozilla/5.0", newLogFileTest)

// 	if _, err := os.Stat(newLogFileTest); os.IsNotExist(err) {
// 		t.Errorf("PersistÃªncia de requests falhou, arquivo '%s' nÃ£o foi criado", newLogFileTest)
// 	}
// }

// func TestLoadRequestTracers(t *testing.T) {
// 	wg := sync.WaitGroup{}

// 	chTimeout := make(chan bool, 1)
// 	chDone := make(chan bool, 1)
// 	ch := make(chan any, 1)

// 	gl.Log("info", "Starting TestLoadRequestTracers")
// 	requestsTracer := make(map[string]ci.IRequestsTracer)

// 	wg.Add(1)
// 	go func(rqt map[string]ci.IRequestsTracer, gbm ci.IGoBE, wg *sync.WaitGroup, ch chan any) {
// 		defer wg.Done()
// 		gl.Log("info", "Loading request tracers from file")
// 		rqtMap, rqtErr := at.LoadRequestsTracerFromFile(gbm)
// 		if rqtErr != nil {
// 			t.Errorf("Erro ao carregar request tracers: %v", rqtErr)
// 		}
// 		if len(rqtMap) == 0 {
// 			absPath, absPathErr := filepath.Abs(gbmT.GetLogFilePath())
// 			gl.Log("error", fmt.Sprintf("Erro ao carregar request tracers do arquivo, mapa vazio: %s", absPath))
// 			if absPathErr != nil {
// 				t.Errorf("Erro ao obter o caminho absoluto do arquivo: %v", absPathErr)
// 			}
// 			if len(at.RequestTracers) == 0 {
// 				gl.Log("error", fmt.Sprintf("Erro ao carregar request tracers do arquivo, mapa vazio: %s", absPath))
// 				t.Errorf("Erro ao carregar request tracers do arquivo, mapa vazio")
// 			} else {
// 				gl.Log("info", "Request tracers loaded successfully")
// 				gl.Log("info", fmt.Sprintf("Loaded %d request tracers", len(at.RequestTracers)))
// 				t.Logf("Loaded %d request tracers", len(at.RequestTracers))
// 				for ip, tracer := range at.RequestTracers {
// 					gl.Log("info", fmt.Sprintf("IP: %s, Count: %d, LastUserAgent: %s", ip, tracer.GetCount(), tracer.GetLastUserAgent()))
// 					t.Logf("IP: %s, Count: %d, LastUserAgent: %s", ip, tracer.GetCount(), tracer.GetLastUserAgent())
// 				}
// 			}
// 		} else {
// 			gl.Log("info", "Request tracers loaded successfully")
// 			gl.Log("info", fmt.Sprintf("Loaded %d request tracers", len(rqtMap)))
// 			t.Logf("Loaded %d request tracers", len(rqtMap))
// 			for ip, tracer := range rqtMap {
// 				gl.Log("info", fmt.Sprintf("IP: %s, Count: %d, LastUserAgent: %s", ip, tracer.GetCount(), tracer.GetLastUserAgent()))
// 				t.Logf("IP: %s, Count: %d, LastUserAgent: %s", ip, tracer.GetCount(), tracer.GetLastUserAgent())
// 			}
// 		}
// 		rqt = rqtMap
// 		ch <- rqt
// 	}(requestsTracer, gbmT, &wg, ch)

// 	go func(chTimeout chan bool) {
// 		time.Sleep(10 * time.Second)
// 		if chTimeout != nil {
// 			chTimeout <- true
// 		}
// 	}(chTimeout)

// 	t.Log("info", "Waiting for request tracers to load...")
// 	gl.Log("info", "Waiting for request tracers to load...")
// 	wg.Wait()

// 	for {
// 		select {
// 		case <-chDone:
// 			t.Log("info", "Request tracers loaded successfully")
// 			gl.Log("info", "Request tracers loaded successfully")
// 			t.Log("info", fmt.Sprintf("Loaded %d request tracers", len(requestsTracer)))
// 			gl.Log("info", fmt.Sprintf("Loaded %d request tracers", len(requestsTracer)))
// 			for ip, tracer := range requestsTracer {
// 				gl.Log("info", fmt.Sprintf("IP: %s, Count: %d, LastUserAgent: %s", ip, tracer.GetCount(), tracer.GetLastUserAgent()))
// 				t.Logf("IP: %s, Count: %d, LastUserAgent: %s", ip, tracer.GetCount(), tracer.GetLastUserAgent())
// 			}
// 			return
// 		case rqt := <-ch:
// 			t.Log("info", "Request tracers loaded successfully")
// 			gl.Log("info", "Request tracers loaded successfully")
// 			t.Log("info", fmt.Sprintf("Loaded %d request tracers", len(rqt.(map[string]ci.IRequestsTracer))))
// 			gl.Log("info", fmt.Sprintf("Loaded %d request tracers", len(rqt.(map[string]ci.IRequestsTracer))))
// 			for ip, tracer := range rqt.(map[string]ci.IRequestsTracer) {
// 				gl.Log("info", fmt.Sprintf("IP: %s, Count: %d, LastUserAgent: %s", ip, tracer.GetCount(), tracer.GetLastUserAgent()))
// 				t.Logf("IP: %s, Count: %d, LastUserAgent: %s", ip, tracer.GetCount(), tracer.GetLastUserAgent())
// 			}
// 			requestsTracer = rqt.(map[string]ci.IRequestsTracer)
// 			chDone <- true
// 		case <-chTimeout:
// 			gl.Log("info", "Timeout reached while waiting for request tracers to load")
// 			t.Errorf("Timeout reached while waiting for request tracers to load")
// 			chDone <- true
// 		default:
// 			continue
// 		}
// 	}
// }

// func TestHandleValidateWithValidTokenReturnsStatusOK(t *testing.T) {
// 	defer unsetTestToken()

// 	g := gbmT
// 	req := httptest.NewRequest(http.MethodGet, "/validate", nil)
// 	req.Header.Set("Authorization", "Bearer valid_token")
// 	w := httptest.NewRecorder()

// 	g.HandleValidate(w, req)

// 	resp := w.Result()
// 	if resp.StatusCode != http.StatusOK {
// 		t.Errorf("expected status %d, got %d", http.StatusOK, resp.StatusCode)
// 	}
// }

// func TestHandleValidateWithInvalidTokenReturnsForbidden(t *testing.T) {
// 	defer unsetTestToken()

// 	g := gbmT
// 	req := httptest.NewRequest(http.MethodGet, "/validate", nil)
// 	req.Header.Set("Authorization", "Bearer invalid_token")
// 	w := httptest.NewRecorder()

// 	g.HandleValidate(w, req)

// 	resp := w.Result()
// 	if resp.StatusCode != http.StatusForbidden {
// 		t.Errorf("expected status %d, got %d", http.StatusForbidden, resp.StatusCode)
// 	}
// }

// func TestHandleContactWithValidDataReturnsStatusOK(t *testing.T) {
// 	defer unsetTestToken()

// 	g := gbmT
// 	form := at.ContactForm{
// 		Name:    "Test User A",
// 		Email:   "faelmori@gmail.com",
// 		Message: "Hello World",
// 		Token:   "valid_token",
// 	}
// 	body, _ := json.Marshal(form)
// 	req := httptest.NewRequest(http.MethodPost, "/contact", bytes.NewReader(body))
// 	w := httptest.NewRecorder()

// 	g.HandleContact(w, req)

// 	resp := w.Result()
// 	if resp.StatusCode != http.StatusOK {
// 		gl.Log("error", fmt.Sprintf("HandleContact failed with status: %d", resp.StatusCode))
// 		t.Errorf("expected status %d, got %d", http.StatusOK, resp.StatusCode)
// 	}
// }

// func TestHandleContactWithInvalidTokenReturnsForbidden(t *testing.T) {
// 	defer unsetTestToken()

// 	g := gbmT
// 	form := at.ContactForm{
// 		Name:    "Test User",
// 		Email:   "test@example.com",
// 		Message: "Hello",
// 		Token:   "invalid_token",
// 	}
// 	body, _ := json.Marshal(form)
// 	req := httptest.NewRequest(http.MethodPost, "/contact", bytes.NewReader(body))
// 	w := httptest.NewRecorder()

// 	g.HandleContact(w, req)

// 	resp := w.Result()
// 	if resp.StatusCode != http.StatusForbidden {
// 		t.Errorf("expected status %d, got %d", http.StatusForbidden, resp.StatusCode)
// 	}
// }

// func TestRateLimitExceededReturnsTooManyRequests(t *testing.T) {
// 	defer unsetTestToken()

// 	g := gbmT
// 	req := httptest.NewRequest(http.MethodGet, "/validate", nil)
// 	req.RemoteAddr = "127.0.0.1:12345"
// 	w := httptest.NewRecorder()

// 	for i := 0; i < gbmT.GetRequestLimit()+1; i++ {
// 		g.RateLimit(w, req)
// 	}

// 	resp := w.Result()
// 	if resp.StatusCode != http.StatusTooManyRequests {
// 		t.Errorf("expected status %d, got %d", http.StatusTooManyRequests, resp.StatusCode)
// 	}
// }

// func TestInitializeWithInvalidEnvironmentFileLogsError(t *testing.T) {
// 	defer unsetTestToken()

// 	bgmT, bgmTErr := gb.NewGoBE("test", "8080", "127.0.0.1", "", "invalid_config.json", false, nil, false)
// 	if bgmTErr == nil {
// 		t.Errorf("expected error, got nil")
// 		return
// 	}
// 	done := make(chan bool)
// 	defer close(done)

// 	go func(bgmT ci.IGoBE, done chan bool) {
// 		if bgmT != nil {
// 			err := bgmT.Initialize()
// 			if err != nil {
// 				gl.Log("error", fmt.Sprintf("Initialize failed: %v", err))
// 				t.Errorf("Initialize failed: %v", err)
// 				return
// 			}
// 			done <- true
// 		} else {
// 			gl.Log("debug", "GoBE instance is nil")
// 			done <- false
// 		}
// 	}(bgmT, done)

// 	select {
// 	case <-done:
// 	case <-time.After(5 * time.Second):
// 		t.Fatal("Initialize did not complete within the expected time")
// 	}
// }

/// tests/scripts/binary_management.sh ///
#!/usr/bin/env bash

# Manage binary files
compress_binary() {
    local binary_path="$1"
    local compressed_path="${binary_path}.gz"

    if [[ -f "$binary_path" ]]; then
        gzip -c "$binary_path" > "$compressed_path"
        echo "Binary compressed to $compressed_path"
    else
        echo "Error: Binary file $binary_path not found."
        return 1
    fi
}

install_binary() {
    local binary_path="$1"
    local install_dir="$2"

    if [[ -f "$binary_path" ]]; then
        mkdir -p "$install_dir"
        cp "$binary_path" "$install_dir"
        chmod +x "$install_dir/$(basename "$binary_path")"
        echo "Binary installed to $install_dir"
    else
        echo "Error: Binary file $binary_path not found."
        return 1
    fi
}

/// tests/scripts/configure.sh ///
#!/usr/bin/env bash
# shellcheck disable=SC2065

# This script is used to configure the environment for the project.
set -euo pipefail
IFS=$'\n\t'

# Source modular scripts
# shellcheck source=/dev/null
test -z "$(declare -f kbx_die)" >/dev/null && source "$(dirname "${0}")/utils.sh"

_PROJECT_ROOT=${_PROJECT_ROOT:-""}

add_to_path() {
    target_path="$1"
    shell_rc_file=$(detect_shell_rc)
    if [ -z "$shell_rc_file" ]; then
        kbx_log "error" "Could not determine shell configuration file."
        return 1
    fi

    if grep -q "export PATH=.*$target_path" "$shell_rc_file" 2>/dev/null; then
        kbx_log "success" "$target_path is already in $shell_rc_file."
        return 0
    fi

    echo "export PATH=$target_path:\$PATH" >> "$shell_rc_file"
    kbx_log "success" "Added $target_path to PATH in $shell_rc_file."
    kbx_log "success" "Run 'source $shell_rc_file' to apply changes."
}

__main() {
  local _project_root=""
  local _is_real_project_root=""

  # shellcheck source=/dev/null
  _is_real_project_root="$(git rev-parse --is-inside-work-tree 2>/dev/null || true)"
  if [[ "${_is_real_project_root}" == "true" ]]; then
    _project_root="$(git rev-parse --show-toplevel 2>/dev/null || true)"
  else
    kbx_die 1 "This script must be run from within a Git repository."
  fi

  if [[ -z "${_project_root}" ]]; then
    kbx_die 1 "Failed to determine the project root directory."
  fi

  if [[ ! -f "${_project_root}/Makefile" ]]; then
    ln -s "${_project_root}/support/scripts/Makefile" "${_project_root}/Makefile"
    if [[ $? -ne 0 ]]; then
      kbx_die 1 "Failed to create symlink for Makefile in the project root directory."
    else
      echo "Created symlink for Makefile in the project root directory: ${_project_root}/Makefile"
    fi
  fi

  # test if make cmd will work with symlink created
  cd "${_project_root}" || exit 1

  _PROJECT_ROOT=${_project_root:-"$(pwd)../.."}
  export _PROJECT_ROOT

  if ! make --version >/dev/null 2>&1; then
    echo "Make command failed. Please ensure that Make is installed and available in your PATH."
    exit 1
  else
    echo "Everything is set up correctly. To build/install the project, run 'make' in this directory (${_project_root})."
    echo "You can also use 'make build' or 'make install' to build or install the project respectively."
  fi
}

# Execute the main function
# shellcheck disable=SC2317
__main "$@" || {
  echo "An error occurred while configuring the project. Please check the logs for details."
}

/// tests/scripts/dependency_management.sh ///
#!/usr/bin/env bash

# Manage dependencies
validate_versions() {
    local required_version="$1"
    local current_version="$2"

    if [[ "$current_version" == "$required_version" ]]; then
        echo "Version $current_version is valid."
    else
        echo "Error: Required version is $required_version, but found $current_version."
        return 1
    fi
}

check_dependencies() {
    local dependencies=("git" "make" "gzip")

    for dep in "${dependencies[@]}"; do
        if ! command -v "$dep" >/dev/null 2>&1; then
            echo "Error: Dependency $dep is not installed."
            return 1
        fi
    done

    echo "All dependencies are installed."
}

/// tests/scripts/install.sh ///
#!/usr/bin/env bash

# This script is used to install the project binary and manage its dependencies.
set -euo pipefail
set -o errtrace
set -o functrace
set -o posix

IFS=$'\n\t'

_DEBUG=${DEBUG:-false}

_HIDE_ABOUT=${HIDE_ABOUT:-false}

# This variable are used to customize the script behavior, like repository url and owner
_OWNER="rafa-mori"

# This function is used to get the release URL for the binary.
# It can be customized to change the URL format or add additional parameters.
# Actually im using the default logic to construct the URL with the release version, the platform and the architecture
# with the format .tar.gz or .zip (for windows). Sweet yourself.
get_release_url() {
    # Default logic for constructing the release URL
    local os="${_PLATFORM%%-*}"
    local arch="${_PLATFORM##*-}"
    # If os is windows, set the format to .zip, otherwise .tar.gz
    local format="${os:zip=tar.gz}"

    echo "https://github.com/${_OWNER}/${_PROJECT_NAME}/releases/download/${_VERSION}/${_PROJECT_NAME}_.${format}"
}

# The _REPO_ROOT variable is set to the root directory of the repository. One above the script directory.
_REPO_ROOT="${ROOT_DIR:-$(dirname "$(dirname "$(dirname "$(realpath "$0")")")")}"

# The _APP_NAME variable is set to the name of the repository. It is used to identify the application.
_APP_NAME="${APP_NAME:-$(basename "$_REPO_ROOT")}"

# The _PROJECT_NAME variable is set to the name of the project. It is used for display purposes.
_PROJECT_NAME="$_APP_NAME"

# The _VERSION variable is set to the version of the project. It is used for display purposes.
_VERSION=$(cat "$_REPO_ROOT/version/CLI_VERSION" 2>/dev/null || echo "v0.0.0")

# The _VERSION_GO variable is set to the version of the Go required by the project.
_VERSION_GO=$(grep '^go ' go.mod | awk '{print $2}')

# The _VERSION variable is set to the version of the project. It is used for display purposes.
_LICENSE="MIT"

# The _ABOUT variable contains information about the script and its usage.
_ABOUT="################################################################################
  This Script is used to install ${_PROJECT_NAME} project, version ${_VERSION}.
  Supported OS: Linux, MacOS, Windows
  Supported Architecture: amd64, arm64, 386
  Source: https://github.com/${_OWNER}/${_PROJECT_NAME}
  Binary Release: https://github.com/${_OWNER}/${_PROJECT_NAME}/releases/latest
  License: ${_LICENSE}
  Notes:
    - [version] is optional; if omitted, the latest version will be used.
    - If the script is run locally, it will try to resolve the version from the
      repo tags if no version is provided.
    - The script will install the binary in the ~/.local/bin directory if the
      user is not root. Otherwise, it will install in /usr/local/bin.
    - The script will add the installation directory to the PATH in the shell
      configuration file.
    - The script will also install UPX if it is not already installed.
    - The script will build the binary if the build option is provided.
    - The script will download the binary from the release URL
    - The script will clean up build artifacts if the clean option is provided.
    - The script will check if the required dependencies are installed.
    - The script will validate the Go version before building the binary.
    - The script will check if the installation directory is in the PATH.
################################################################################"

_BANNER="################################################################################

               â–ˆâ–ˆ   â–ˆâ–ˆ â–ˆâ–ˆ     â–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ     â–ˆâ–ˆ
              â–‘â–ˆâ–ˆ  â–ˆâ–ˆ â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–ˆ â–‘â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ â–‘â–‘â–ˆâ–ˆ   â–ˆâ–ˆ
              â–‘â–ˆâ–ˆ â–ˆâ–ˆ  â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆ   â–‘â–ˆâ–ˆ â–‘â–ˆâ–ˆ       â–‘â–‘â–ˆâ–ˆ â–ˆâ–ˆ
              â–‘â–ˆâ–ˆâ–ˆâ–ˆ   â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–‘â–‘â–ˆâ–ˆâ–ˆ
              â–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆ  â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–‘â–‘â–‘â–‘ â–ˆâ–ˆâ–‘â–ˆâ–ˆâ–‘â–‘â–‘â–‘     â–ˆâ–ˆâ–‘â–ˆâ–ˆ
              â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆ â–‘â–ˆâ–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆ    â–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆ        â–ˆâ–ˆ â–‘â–‘â–ˆâ–ˆ
              â–‘â–ˆâ–ˆ â–‘â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ   â–‘â–‘â–ˆâ–ˆ
              â–‘â–‘   â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â–‘â–‘     â–‘â–‘"

# Variable to store the current running shell
_CURRENT_SHELL=""

# The _CMD_PATH variable is set to the path of the cmd directory. It is used to
# identify the location of the main application code.
_CMD_PATH="${_REPO_ROOT}/cmd"

# The _BUILD_PATH variable is set to the path of the build directory. It is used
# to identify the location of the build artifacts.
_BUILD_PATH="$(dirname "${_CMD_PATH}")"

# The _BINARY variable is set to the path of the binary file. It is used to
# identify the location of the binary file.
_BINARY="${_BUILD_PATH}/${_APP_NAME}"

# The _LOCAL_BIN variable is set to the path of the local bin directory. It is
# used to identify the location of the local bin directory.
_LOCAL_BIN="${HOME:-"~"}/.local/bin"

# The _GLOBAL_BIN variable is set to the path of the global bin directory. It is
# used to identify the location of the global bin directory.
_GLOBAL_BIN="/usr/local/bin"

# Color codes for logging
_SUCCESS="\033[0;32m"
_WARN="\033[0;33m"
_ERROR="\033[0;31m"
_INFO="\033[0;36m"
_NC="\033[0m"

# For internal use only
__PLATFORMS=( "windows" "darwin" "linux" )
__ARCHs=( "amd64" "386" "arm64" )

# The _PLATFORM variable is set to the platform name. It is used to identify the
# platform on which the script is running.
_PLATFORM_WITH_ARCH=""
_PLATFORM=""
_ARCH=""


# kbx_log messages with different levels
# Arguments:
#   $1 - kbx_log level (info, warn, error, success)
#   $2 - message to log
log() {
  local type=
  type=${1:-info}
  local message=
  message=${2:-}
  local debug=${3:-${_DEBUG:-false}}

  # With colors
  case $type in
    info|_INFO|-i|-I)
      if [[ "$debug" == true ]]; then
        printf '%b[_INFO]%b â„¹ï¸  %s\n' "$_INFO" "$_NC" "$message"
      fi
      ;;
    warn|_WARN|-w|-W)
      if [[ "$debug" == true ]]; then
        printf '%b[_WARN]%b âš ï¸  %s\n' "$_WARN" "$_NC" "$message"
      fi
      ;;
    error|_ERROR|-e|-E)
      printf '%b[_ERROR]%b âŒ  %s\n' "$_ERROR" "$_NC" "$message"
      ;;
    success|_SUCCESS|-s|-S)
      printf '%b[_SUCCESS]%b âœ…  %s\n' "$_SUCCESS" "$_NC" "$message"
      ;;
    *)
      if [[ "$debug" == true ]]; then
        kbx_log "info" "$message"
      fi
      ;;
  esac
}

# Create a temporary directory for script cache
_TEMP_DIR="$(mktemp -d)"

# DiretÃ³rio temporÃ¡rio para baixar o arquivo
if [[ -d "${_TEMP_DIR}" ]]; then
    kbx_log "info" "Temporary directory created: ${_TEMP_DIR}"
else
    kbx_log "error" "Failed to create temporary directory."
fi

clear_screen() {
  printf "\033[H\033[2J" || return 1
  return 0
}

# Function to clear the script cache
clear_script_cache() {
  # Disable the trap for cleanup
  trap - EXIT HUP INT QUIT ABRT ALRM TERM

  # Check if the temporary directory exists, if not, return
  if [[ ! -d "${_TEMP_DIR}" ]]; then
    exit 0
  fi

  # Remove the temporary directory
  rm -rf "${_TEMP_DIR}" || true
  if [[ -d "${_TEMP_DIR}" && $(sudo -v 2>/dev/null) ]]; then
    sudo rm -rf "${_TEMP_DIR}"
    if [[ -d "${_TEMP_DIR}" ]]; then
      printf '%b[_ERROR]%b âŒ  %s\n' "$_ERROR" "$_NC" "Failed to remove temporary directory: ${_TEMP_DIR}"
    else
      printf '%b[_SUCCESS]%b âœ…  %s\n' "$_SUCCESS" "$_NC" "Temporary directory removed: ${_TEMP_DIR}"
    fi
  fi
  exit 0
}

# Function to get the current shell
get_current_shell() {
  _CURRENT_SHELL="$(cat /proc/$$/comm)"

  case "${0##*/}" in
    ${_CURRENT_SHELL}*)
      shebang="$(head -1 "${0}")"
      _CURRENT_SHELL="${shebang##*/}"
      ;;
  esac

  return 0
}

# Set a trap to clean up the temporary directory on exit
set_trap(){
  # Get the current shell
  get_current_shell

  # Set the trap for the current shell and enable error handling, if applicable
  case "${_CURRENT_SHELL}" in
    *ksh|*zsh|*bash)

      # Collect all arguments passed to the script into an array without modifying or running them
      # shellcheck disable=SC2124
      declare -a _FULL_SCRIPT_ARGS=$@

      # Check if the script is being run in debug mode, if so, enable debug mode on the script output
      if [[ ${_FULL_SCRIPT_ARGS[*]} =~ ^.*-d.*$ ]]; then
          set -x
      fi

      # Set for the current shell error handling and some other options
      if [[ "${_CURRENT_SHELL}" == "bash" ]]; then
        set -o errexit
        set -o pipefail
        set -o errtrace
        set -o functrace
        shopt -s inherit_errexit
      fi

      # Set the trap to clear the script cache on exit.
      # It will handle the following situations: command line exit, hangup, interrupt, quit, abort, alarm, and termination.
      trap 'clear_script_cache' EXIT HUP INT QUIT ABRT ALRM TERM
      ;;
  esac

  return 0
}

# Call the set_trap function to set up the trap
set_trap "$@"

# Clear the screen. If the script gets here, it means the script passed the
# initial checks and the temporary directory was created successfully.
clear_screen

# Detect the platform
what_platform() {
  local _platform=""
  _platform="$(uname -o 2>/dev/null || echo "")"

  local _os=""
  _os="$(uname -s)"

  local _arch=""
  _arch="$(uname -m)"

  # Detect the platform and architecture
  case "${_os}" in
  *inux|*nix)
    _os="linux"
    case "${_arch}" in
    "x86_64")
      _arch="amd64"
      ;;
    "armv6")
      _arch="armv6l"
      ;;
    "armv8" | "aarch64")
      _arch="arm64"
      ;;
    .*386.*)
      _arch="386"
      ;;
    esac
    _platform="linux-${_arch}"
    ;;
  *arwin*)
    _os="darwin"
    case "${_arch}" in
    "x86_64")
      _arch="amd64"
      ;;
    "arm64")
      _arch="arm64"
      ;;
    esac
    _platform="darwin-${_arch}"
    ;;
  MINGW|MSYS|CYGWIN|Win*)
    _os="windows"
    case "${_arch}" in
    "x86_64")
      _arch="amd64"
      ;;
    "arm64")
      _arch="arm64"
      ;;
    esac
    _platform="windows-${_arch}"
    ;;
  *)
    _os=""
    _arch=""
    _platform=""
    ;;
  esac

  if [[ -z "${_platform}" ]]; then
    kbx_log "error" "Unsupported platform: ${_os} ${_arch}"
    kbx_log "error" "Please report this issue to the project maintainers."
    return 1
  fi

  # Normalize the platform string
  _PLATFORM_WITH_ARCH="${_platform//\-/\_}"
  _PLATFORM="${_os//\ /}"
  _ARCH="${_arch//\ /}"

  return 0
}

_get_os_arr_from_args() {
  local _PLATFORM_ARG=$1
  local _PLATFORM_ARR=()

  if [[ "${_PLATFORM_ARG}" == "all" ]]; then
    _PLATFORM_ARR=( "${__PLATFORMS[@]}" )
  else
    _PLATFORM_ARR=( "${_PLATFORM_ARG}" )
  fi

  for _platform_pos in "${_PLATFORM_ARR[@]}"; do
    echo "${_platform_pos} "
  done

  return 0
}
_get_arch_arr_from_args() {
  local _ARCH_ARG=$1
  local _ARCH_ARR=()

  if [[ "${_ARCH_ARG}" == "all" ]]; then
    _ARCH_ARR=( "${__ARCHs[@]}" )
  else
    _ARCH_ARR=( "${_ARCH_ARG}" )
  fi

  echo "${_ARCH_ARR[@]}"

  return 0
}
_get_os_from_args() {
  local _PLATFORM_ARG=$1
  case "${_PLATFORM_ARG}" in
    all|ALL|a|A|-a|-A)
      echo "all"
      ;;
    win|WIN|windows|WINDOWS|w|W|-w|-W)
      echo "windows"
      ;;
    linux|LINUX|l|L|-l|-L)
      echo "linux"
      ;;
    darwin|DARWIN|macOS|MACOS|m|M|-m|-M)
      echo "darwin"
      ;;
    *)
      kbx_log "error" "build_and_validate: Unsupported platform: '${_PLATFORM_ARG}'."
      kbx_log "error" "Please specify a valid platform (windows, linux, darwin, all)."
      exit 1
      ;;
  esac
  return 0
}
_get_arch_from_args() {
  local _ARCH_ARG=$1
  case "${_ARCH_ARG}" in
    all|ALL|a|A|-a|-A)
      echo "all"
      ;;
    amd64|AMD64|x86_64|X86_64|x64|X64)
      echo "amd64"
      ;;
    arm64|ARM64|aarch64|AARCH64)
      echo "arm64"
      ;;
    386|i386|I386)
      echo "386"
      ;;
    *)
      kbx_log "error" "build_and_validate: Unsupported architecture: '${_ARCH_ARG}'. Please specify a valid architecture (amd64, arm64, 386)."
      exit 1
      ;;
  esac
  return 0
}

# Detect the shell configuration file
# Returns:
#   Shell configuration file path
detect_shell_rc() {
    shell_rc_file=""
    user_shell=$(basename "$SHELL")
    case "$user_shell" in
        bash) shell_rc_file="$HOME/.bashrc" ;;
        zsh) shell_rc_file="$HOME/.zshrc" ;;
        sh) shell_rc_file="$HOME/.profile" ;;
        fish) shell_rc_file="$HOME/.config/fish/config.fish" ;;
        *)
            kbx_log "warn" "Unsupported shell, modify PATH manually."
            return 1
            ;;
    esac
    kbx_log "info" "$shell_rc_file"
    if [ ! -f "$shell_rc_file" ]; then
        kbx_log "error" "Shell configuration file not found: $shell_rc_file"
        return 1
    fi
    echo "$shell_rc_file"
    return 0
}

# Add a directory to the PATH in the shell configuration file
# Arguments:
#   $1 - target path to add to PATH
add_to_path() {
    target_path="$1"
    shell_rc_file=$(detect_shell_rc)
    if [ -z "$shell_rc_file" ]; then
        kbx_log "error" "Could not determine shell configuration file."
        return 1
    fi

    if grep -q "export PATH=.*$target_path" "$shell_rc_file" 2>/dev/null; then
        kbx_log "success" "$target_path is already in $shell_rc_file."
        return 0
    fi

    echo "export PATH=$target_path:\$PATH" >> "$shell_rc_file"
    kbx_log "success" "Added $target_path to PATH in $shell_rc_file."
    kbx_log "success" "Run 'source $shell_rc_file' to apply changes."
}

# Clean up build artifacts
clean() {
    kbx_log "info" "Cleaning up build artifacts..."
    local _platforms=( "windows" "darwin" "linux" )
    local _archS=( "amd64" "386" "arm64" )
    for _platform in "${_platforms[@]}"; do
        for _arch in "${_archS[@]}"; do
            local _OUTPUT_NAME="${_BINARY}_${_platform}_${_arch}"
            if [ "${_platform}" != "windows" ]; then
                _COMPRESS_NAME="${_OUTPUT_NAME}.tar.gz"
            else
                _OUTPUT_NAME+=".exe"
                _COMPRESS_NAME="${_BINARY}_${_platform}_${_arch}.zip"
            fi
            rm -f "${_OUTPUT_NAME}" || true
            rm -f "${_COMPRESS_NAME}" || true
            if [ -f "${_OUTPUT_NAME}" ]; then
                if sudo -v; then
                    sudo rm -f "${_OUTPUT_NAME}" || true
                else
                    kbx_log "error" "Failed to remove build artifact: ${_OUTPUT_NAME}"
                    kbx_log "error" "Please remove it manually with 'sudo rm -f \"${_OUTPUT_NAME}\"'"
                fi
            fi
            if [ -f "${_COMPRESS_NAME}" ]; then
                if sudo -v; then
                    sudo rm -f "${_COMPRESS_NAME}" || true
                else
                    kbx_log "error" "Failed to remove build artifact: ${_COMPRESS_NAME}"
                    kbx_log "error" "Please remove it manually with 'sudo rm -f \"${_COMPRESS_NAME}\"'"
                fi
            fi
        done
    done
    kbx_log "success" "Cleaned up build artifacts."
    return 0
}

# Install the binary to the appropriate directory
install_binary() {
    local _SUFFIX="${_PLATFORM_WITH_ARCH}"
    local _BINARY_TO_INSTALL="${_BINARY}${_SUFFIX:+_${_SUFFIX}}"
    kbx_log "info" "Installing binary: '$_BINARY_TO_INSTALL' like '$_APP_NAME'"

    if [ "$(id -u)" -ne 0 ]; then
        kbx_log "info" "You are not root. Installing in $_LOCAL_BIN..."
        mkdir -p "$_LOCAL_BIN"
        cp "$_BINARY_TO_INSTALL" "$_LOCAL_BIN/$_APP_NAME" || exit 1
        add_to_path "$_LOCAL_BIN"
    else
        kbx_log "info" "Root detected. Installing in $_GLOBAL_BIN..."
        cp "$_BINARY_TO_INSTALL" "$_GLOBAL_BIN/$_APP_NAME" || exit 1
        add_to_path "$_GLOBAL_BIN"
    fi
    clean
}

# Install UPX if it is not already installed
install_upx() {
    if ! command -v upx > /dev/null; then
        kbx_log "info" "Installing UPX..."
        if [ "$(uname)" = "Darwin" ]; then
            brew install upx
        elif command -v apt-get > /dev/null; then
            sudo apt-get install -y upx
        else
            kbx_log "error" 'Install UPX manually from https://upx.github.io/'
            exit 1
        fi
    else
        kbx_log "success" ' UPX is already installed.'
    fi
}

# Check if the required dependencies are installed
# Arguments:
#   $@ - list of dependencies to check
check_dependencies() {
    # shellcheck disable=SC2317
    for dep in "$@"; do
        if ! command -v "$dep" > /dev/null; then
            kbx_log "error" "$dep is not installed."
            exit 1
        else
            kbx_log "success" "$dep is installed."
        fi
    done
}

# Build the binary
# shellcheck disable=SC2207,SC2116,SC2091,SC2155,SC2005
build_binary() {
  declare -a __platform_arr="$(echo "$(_get_os_arr_from_args "$1")")"
  declare -a _platform_arr=()
  eval _platform_arr="( $(echo "${__platform_arr[@]}") )"
  kbx_log "info" "Qty OS's: ${#_platform_arr[@]}"

  declare -a __arch_arr="$(echo "$(_get_arch_arr_from_args "$2")")"
  declare -a _arch_arr=()
  eval _arch_arr="( $(echo "${__arch_arr[@]}") )"
  kbx_log "info" "Qty Arch's: ${#_arch_arr[@]}"

  for _platform_pos in "${_platform_arr[@]}"; do
    if test -z "${_platform_pos}"; then
      continue
    fi
    for _arch_pos in "${_arch_arr[@]}"; do
      if test -z "${_arch_pos}"; then
        continue
      fi
      if [[ "${_platform_pos}" != "darwin" && "${_arch_pos}" == "arm64" ]]; then
        continue
      fi
      if [[ "${_platform_pos}" != "windows" && "${_arch_pos}" == "386" ]]; then
        continue
      fi
      local _OUTPUT_NAME="$(printf '%s_%s_%s' "${_BINARY}" "${_platform_pos}" "${_arch_pos}")"
      if [[ "${_platform_pos}" == "windows" ]]; then
        _OUTPUT_NAME="$(printf '%s.exe' "${_OUTPUT_NAME}")"
      fi

      local _build_env=(
        "GOOS=${_platform_pos}"
        "GOARCH=${_arch_pos}"
      )
      local _build_args=(
        "-ldflags '-s -w -X main.version=$(git describe --tags) -X main.commit=$(git rev-parse HEAD) -X main.date=$(date +%Y-%m-%d)' "
        "-trimpath -o \"${_OUTPUT_NAME}\" \"${_CMD_PATH}\""
      )

      local _build_cmd=( "${_build_env[@]}" "go build " "${_build_args[*]}" )
      local _build_cmd_str="$(echo "$(printf "%s" "${_build_cmd[*]//\ / }")")"
      _build_cmd_str="$(printf '%s\n' "${_build_cmd_str//\ _/_}")"
      kbx_log "info" "$(printf '%s %s/%s' "Building the binary for" "${_platform_pos}" "${_arch_pos}")"
      kbx_log "info" "Command: ${_build_cmd_str}"

      local _cmdExec=$(bash -c "${_build_cmd_str}" 2>&1 && echo "true" || echo "false")

      # Build the binary using the environment variables and arguments
      if [[ "${_cmdExec}" == "false" ]]; then
        kbx_log "error" "Failed to build the binary for ${_platform_pos} ${_arch_pos}"
        kbx_log "error" "Command: ${_build_cmd_str}"
        return 1
      else
        # If the build was successful, check if UPX is installed and compress the binary (if not Windows)
        if [[ "${_platform_pos}" != "windows" ]]; then
            install_upx
            kbx_log "info" "Packing/compressing the binary with UPX..."
            upx "${_OUTPUT_NAME}" --force-overwrite --lzma --no-progress --no-color -qqq || true
            kbx_log "success" "Binary packed/compressed successfully: ${_OUTPUT_NAME}"
        fi
        # Check if the binary was created successfully (if not Windows)
        if [[ ! -f "${_OUTPUT_NAME}" ]]; then
          kbx_log "error" "Binary not found after build: ${_OUTPUT_NAME}"
          kbx_log "error" "Command: ${_build_cmd_str}"
          return 1
        else
          local compress_vars=( "${_platform_pos}" "${_arch_pos}" )
          compress_binary "${compress_vars[@]}" || return 1
          kbx_log "success" "Binary created successfully: ${_OUTPUT_NAME}"
        fi
      fi
    done
  done

  echo ""
  kbx_log "success" "All builds completed successfully!"
  echo ""

  return 0
}

# Compress the binary into a single tar.gz/zip file
# shellcheck disable=SC2207,SC2116,SC2091,SC2155,SC2005
compress_binary() {
  declare -a __platform_arr="$(echo $(_get_os_arr_from_args "$1"))"
  declare -a _platform_arr=()
  eval _platform_arr="( $(echo "${__platform_arr[@]}") )"
  kbx_log "info" "Qty OS's: ${#_platform_arr[@]}"

  declare -a __arch_arr="$(echo $(_get_arch_arr_from_args "$2"))"
  declare -a _arch_arr=()
  eval _arch_arr="( $(echo "${__arch_arr[@]}") )"
  kbx_log "info" "Qty Arch's: ${#_arch_arr[@]}"

  for _platform_pos in "${_platform_arr[@]}"; do
    if [[ -z "${_platform_pos}" ]]; then
      continue
    fi
    for _arch_pos in "${_arch_arr[@]}"; do
      if [[ -z "${_arch_pos}" ]]; then
        continue
      fi
      if [[ "${_platform_pos}" != "darwin" && "${_arch_pos}" == "arm64" ]]; then
        continue
      fi
      if [[ "${_platform_pos}" == "linux" && "${_arch_pos}" == "386" ]]; then
        continue
      fi

      local _BINARY_NAME="$(printf '%s_%s_%s' "${_BINARY}" "${_platform_pos}" "${_arch_pos}")"
      if [[ "${_platform_pos}" == "windows" ]]; then
        _BINARY_NAME="$(printf '%s.exe' "${_BINARY_NAME}")"
      fi

      local _OUTPUT_NAME="${_BINARY_NAME//\.exe/}"
      local _compress_cmd_exec=""
      if [[ "${_platform_pos}" != "windows" ]]; then
        _OUTPUT_NAME="${_OUTPUT_NAME}.tar.gz"
        kbx_log "info" "Compressing the binary for ${_platform_pos} ${_arch_pos} into ${_OUTPUT_NAME}..."
        _compress_cmd_exec=$(tar -czf "${_OUTPUT_NAME}" "${_BINARY_NAME}" 2>&1 && echo "true" || echo "false")
      else
        _OUTPUT_NAME="${_OUTPUT_NAME}.zip"
        kbx_log "info" "Compressing the binary for ${_platform_pos} ${_arch_pos} into ${_OUTPUT_NAME}..."
        _compress_cmd_exec=$(zip -r -9 "${_OUTPUT_NAME}" "${_BINARY_NAME}" 2>&1 && echo "true" || echo "false")
      fi
      if [[ "${_compress_cmd_exec}" == "false" ]]; then
        kbx_log "error" "Failed to compress the binary for ${_platform_pos} ${_arch_pos}"
        kbx_log "error" "Command: ${_compress_cmd_exec}"
        return 1
      else
        kbx_log "success" "Binary compressed successfully: ${_OUTPUT_NAME}"
      fi
    done
  done

  kbx_log "success" "All binaries compressed successfully!"

  return 0
}

# Validate the Go version
validate_versions() {
    REQUIRED_GO_VERSION="${_VERSION_GO:-1.20.0}"
    GO_VERSION=$(go version | awk '{print $3}' | sed 's/go//')
    if [[ "$(printf '%s\n' "$REQUIRED_GO_VERSION" "$GO_VERSION" | sort -V | head -n1)" != "$REQUIRED_GO_VERSION" ]]; then
        kbx_log "error" "Go version must be >= $REQUIRED_GO_VERSION. Detected: $GO_VERSION"
        exit 1
    fi
    kbx_log "success" "Go version is valid: $GO_VERSION"
    go mod tidy || return 1
}

# Print a summary of the installation
summary() {
    install_dir="$_BINARY"
    kbx_log "success" "Build and installation complete!"
    kbx_log "success" "Binary: $_BINARY"
    kbx_log "success" "Installed in: $install_dir"
    check_path "$install_dir"
}

# Build the binary and validate the Go version
build_and_validate() {
    # Check if the Go version is valid
    validate_versions

    local _PLATFORM_ARG="$1"
    # _PLATFORM_ARG="$(_get_os_from_args "${1:-${_PLATFORM}}")"
    local _ARCH_ARG="$2"
    # _ARCH_ARG="$(_get_arch_from_args "${2:-${_ARCH}}")"

    kbx_log "info" "Building for platform: ${_PLATFORM_ARG}, architecture: ${_ARCH_ARG}" true
    local _WHICH_COMPILE_ARG=( "${_PLATFORM_ARG}" "${_ARCH_ARG}" )

    # Call the build function with the platform and architecture arguments
    build_binary "${_WHICH_COMPILE_ARG[@]}" || exit 1

    return 0
}

# Check if the installation directory is in the PATH
# Arguments:
#   $1 - installation directory
check_path() {
    kbx_log "info" "Checking if the installation directory is in the PATH..."
    if ! echo "$PATH" | grep -q "$1"; then
        kbx_log "warn" "$1 is not in the PATH."
        kbx_log "warn" "Add the following to your ~/.bashrc, ~/.zshrc, or equivalent file:"
        kbx_log "warn" "export PATH=$1:\$PATH"
    else
        kbx_log "success" "$1 is already in the PATH."
    fi
}

# Download the binary from the release URL
download_binary() {
    # Obtem o sistema operacional e a arquitetura
    if ! what_platform > /dev/null; then
        kbx_log "error" "Failed to detect platform."
        return 1
    fi

    # ValidaÃ§Ã£o: Verificar se o sistema operacional ou a arquitetura sÃ£o suportados
    if [[ -z "${_PLATFORM}" ]]; then
        kbx_log "error" "Unsupported platform: ${_PLATFORM}"
        return 1
    fi

    # Obter a versÃ£o mais recente de forma robusta (fallback para "latest")
    version=$(curl -s "https://api.github.com/repos/${_OWNER}/${_PROJECT_NAME}/releases/latest" | \
        grep "tag_name" | cut -d '"' -f 4 || echo "latest")

    if [ -z "$version" ]; then
        kbx_log "error" "Failed to determine the latest version."
        return 1
    fi

    # Construir a URL de download usando a funÃ§Ã£o customizÃ¡vel
    release_url=$(get_release_url)
    kbx_log "info" "Downloading ${_APP_NAME} binary for OS=$os, ARCH=$arch, Version=$version..."
    kbx_log "info" "Release URL: ${release_url}"

    archive_path="${_TEMP_DIR}/${_APP_NAME}.tar.gz"

    # Realizar o download e validar sucesso
    if ! curl -L -o "${archive_path}" "${release_url}"; then
        kbx_log "error" "Failed to download the binary from: ${release_url}"
        return 1
    fi
    kbx_log "success" "Binary downloaded successfully."

    # ExtraÃ§Ã£o do arquivo para o diretÃ³rio binÃ¡rio
    kbx_log "info" "Extracting binary to: $(dirname "${_BINARY}")"
    if ! tar -xzf "${archive_path}" -C "$(dirname "${_BINARY}")"; then
        kbx_log "error" "Failed to extract the binary from: ${archive_path}"
        rm -rf "${_TEMP_DIR}"
        exit 1
    fi

    # Limpar artefatos temporÃ¡rios
    rm -rf "${_TEMP_DIR}"
    kbx_log "success" "Binary extracted successfully."

    # Verificar se o binÃ¡rio foi extraÃ­do com sucesso
    if [ ! -f "$_BINARY" ]; then
        kbx_log "error" "Binary not found after extraction: $_BINARY"
        exit 1
    fi

    kbx_log "success" "Download and extraction of ${_APP_NAME} completed!"
}

# Install the binary from the release URL
install_from_release() {
    download_binary
    install_binary
}

# Show about information
show_about() {
    # Print the ABOUT message
    printf '%s\n\n' "${_ABOUT:-}"
}

# Show banner information
show_banner() {
    # Print the ABOUT message
    printf '\n%s\n\n' "${_BANNER:-}"
}

# Show headers information
show_headers() {
    # Print the BANNER message
    show_banner || return 1
    # Print the ABOUT message
    show_about || return 1
}

# Source modular scripts
source "$(dirname "$0")/binary_management.sh"
source "$(dirname "$0")/platform_detection.sh"
source "$(dirname "$0")/dependency_management.sh"
source "$(dirname "$0")/utils.sh"

# Ensure modular scripts are loaded
if ! declare -f compress_binary >/dev/null; then
    log error "Failed to load binary_management.sh"
    exit 1
fi
if ! declare -f what_platform >/dev/null; then
    log error "Failed to load platform_detection.sh"
    exit 1
fi
if ! declare -f validate_versions >/dev/null; then
    log error "Failed to load dependency_management.sh"
    exit 1
fi
if ! declare -f log >/dev/null; then
    log error "Failed to load utils.sh"
    exit 1
fi

# Main function to handle command line arguments
main() {
  # Detect the platform
  what_platform || exit 1

  # Show headers
  log "info" "Starting installation..."

  # Parse arguments
  local _PLATFORM_ARG=""
  _PLATFORM_ARG=$(_get_os_from_args "${1:-${_PLATFORM}}")
  local _ARCH_ARG=""
  _ARCH_ARG=$(_get_arch_from_args "${2:-${_ARCH}}")

  case "${1:-}" in
    build)
      compress_binary "$_PLATFORM_ARG" "$_ARCH_ARG" || exit 1
      ;;
    install)
      install_binary "$_PLATFORM_ARG" "$_ARCH_ARG" || exit 1
      ;;
    clean)
      clear_script_cache || exit 1
      ;;
    *)
      echo "Usage: $0 {build|install|clean}"
      exit 1
      ;;
  esac
}

# Execute the main function
main "$@"

/// tests/scripts/platform_detection.sh ///
#!/usr/bin/env bash

# Detect platform and architecture
what_platform() {
    local os
    os="$(uname -s | tr '[:upper:]' '[:lower:]')"
    local arch
    arch="$(uname -m)"

    case "$os" in
        linux|darwin|windows)
            echo "Platform detected: $os-$arch"
            ;;
        *)
            echo "Error: Unsupported platform $os-$arch"
            return 1
            ;;
    esac
}

_get_os_from_args() {
    local args="$1"
    if [[ "$args" =~ linux|darwin|windows ]]; then
        echo "$args"
    else
        echo "Error: Invalid OS argument $args"
        return 1
    fi
}

_get_arch_from_args() {
    local args="$1"
    if [[ "$args" =~ amd64|386|arm64 ]]; then
        echo "$args"
    else
        echo "Error: Invalid architecture argument $args"
        return 1
    fi
}

/// tests/scripts/utils.sh ///
#!/usr/bin/env bash

# Utility functions
log() {
    local type=${1:-info}
    local message=${2:-}
    local debug=${3:-false}

    case $type in
        info)
            [[ "$debug" == true ]] && echo "[INFO] $message"
            ;;
        warn)
            [[ "$debug" == true ]] && echo "[WARN] $message"
            ;;
        error)
            echo "[ERROR] $message"
            ;;
        success)
            echo "[SUCCESS] $message"
            ;;
    esac
}

create_temp_dir() {
    # Logic for creating temporary directory
    echo "Creating temporary directory..."
}

clear_script_cache() {
    # Logic for clearing script cache
    echo "Clearing script cache..."
}

/// tests/secure_mapper_test.go ///
package tests

import (
	fsc "github.com/kubex-ecosystem/gobe/factory/security"
	//at "github.com/kubex-ecosystem/gobe/internal/types"
	"testing"

	"github.com/stretchr/testify/mock"
	"github.com/stretchr/testify/require"
)

type MockCryptoService struct {
	mock.Mock
}

func (m *MockCryptoService) GenerateKeyWithLength(length int) ([]byte, error) {
	args := m.Called(length)
	return args.Get(0).([]byte), args.Error(1)
}

func (m *MockCryptoService) IsEncrypted(data []byte) bool {
	args := m.Called(data)
	return args.Bool(0)
}

func (m *MockCryptoService) Encrypt(data []byte, key []byte) ([]byte, error) {
	args := m.Called(data, key)
	return args.Get(0).([]byte), args.Error(1)
}

func (m *MockCryptoService) Decrypt(encryptedData []byte, key []byte) ([]byte, error) {
	args := m.Called(encryptedData, key)
	return args.Get(0).([]byte), args.Error(1)
}

func (m *MockCryptoService) GenerateKey() ([]byte, error) {
	args := m.Called()
	return args.Get(0).([]byte), args.Error(1)
}

// MockKeyringService para simular armazenamento de chaves
type MockKeyringService struct {
	mock.Mock
}

func (m *MockKeyringService) StorePassword(password string) error {
	args := m.Called(password)
	return args.Error(0)
}

func (m *MockKeyringService) RetrievePassword() (string, error) {
	args := m.Called()
	return args.String(0), args.Error(1)
}

// Teste do SecureMapper usando mocks

func TestNewSecureMapperWithValidInputsInitializesSuccessfully(t *testing.T) {
	name := "test-mapper"
	mapperObject := "test-value"
	key := []byte("test-key")
	filePath := "test-path"

	secureMapper := fsc.NewSecureMapper(name, &mapperObject, key, filePath)

	loadedKey, err := secureMapper.LoadOrGenerateKey(name)
	if err != nil {
		t.Fatalf("Failed to load or generate key: %v", err)
	}

	require.NotNil(t, secureMapper)
	require.Equal(t, name, secureMapper.Reference.Name)
	require.Equal(t, key, loadedKey)
	require.Equal(t, filePath, secureMapper.GetFilePath())
	require.NotNil(t, secureMapper.GetValue())

	// This is not possible to test because these properties are not exported
	// or accessible from outside the struct
	// require.NotNil(t, secureMapper.cryptoService)
	// require.NotNil(t, secureMapper.keyring)

}

func TestNewSecureMapperWithNilKeyGeneratesKey(t *testing.T) {
	name := "test-mapper"
	mapperObject := "test-value"
	filePath := "test-path"

	secureMapper := fsc.NewSecureMapper(name, &mapperObject, nil, filePath)

	loadedKey, err := secureMapper.LoadOrGenerateKey(name)
	if err != nil {
		t.Fatalf("Failed to load or generate key: %v", err)
	}

	require.NotNil(t, secureMapper)
	require.NotNil(t, loadedKey)
	require.NotEmpty(t, loadedKey)
}

//func TestNewSecureMapperWithMocks(t *testing.T) {
//	// Criando mocks
//	mockCrypto := new(MockCryptoService)
//	mockKeyring := new(MockKeyringService)
//
//	// Definindo comportamento esperado dos mocks
//	mockCrypto.On("GenerateKey").Return([]byte("mocked-key"), nil)
//	mockKeyring.On("StorePassword", "mocked-key").Return(nil)
//	mockKeyring.On("RetrievePassword").Return("mocked-key", nil)
//
//	// InicializaÃ§Ã£o com os mocks
//	name := "test-mapper"
//	mapperObject := "test-value"
//	filePath := "test-path"
//
//	secureMapper := &SecureMapper[string]{
//		Reference:     at.NewReference(name).GetReference(),
//		key:           []byte("mocked-key"),
//		keyring:       mockKeyring,
//		filePath:      filePath,
//		cryptoService: mockCrypto,
//		object:        at.NewProperty[string](name, &mapperObject, false, nil),
//	}
//
//	loadedKey, err := secureMapper.LoadOrGenerateKey(name)
//	require.NoError(t, err)
//	require.Equal(t, []byte("mocked-key"), loadedKey)
//	require.Equal(t, name, secureMapper.Reference.Name)
//
//	mockKeyring.AssertExpectations(t)
//	mockCrypto.AssertExpectations(t)
//}

/// tests/token_service_test.go ///
package tests

// import (
// 	"crypto/rand"
// 	"crypto/rsa"
// 	"testing"
// 	"time"

// 	"github.com/golang-jwt/jwt/v4"
// 	"github.com/kubex-ecosystem/gobe/internal/security/authentication"
// 	"github.com/stretchr/testify/assert"
// )

// func TestValidateIDToken(t *testing.T) {
// 	// Generate RSA keys for testing
// 	privKey, err := rsa.GenerateKey(rand.Reader, 2048)
// 	assert.NoError(t, err)
// 	pubKey := &privKey.PublicKey

// 	// Create a valid token
// 	expiresAt := time.Now().Add(time.Hour).Unix()
// 	claims := &authentication.idTokenCustomClaims{
// 		User: &authentication.UserModelType{
// 			ID:       "123",
// 			Username: "testuser",
// 			Email:    "test@example.com",
// 		},
// 		RegisteredClaims: jwt.RegisteredClaims{
// 			ExpiresAt: expiresAt,
// 			IssuedAt:  time.Now().Unix(),
// 		},
// 	}
// 	token := jwt.NewWithClaims(jwt.SigningMethodRS256, claims)
// 	tokenString, err := token.SignedString(privKey)
// 	assert.NoError(t, err)

// 	// Validate the token
// 	validatedClaims, err := authentication.validateIDToken(tokenString, pubKey)
// 	assert.NoError(t, err)
// 	assert.NotNil(t, validatedClaims)
// 	assert.Equal(t, "123", validatedClaims.User.GetID())
// 	assert.Equal(t, "testuser", validatedClaims.User.GetUsername())
// 	assert.Equal(t, "test@example.com", validatedClaims.User.GetEmail())

// 	// Test with an expired token
// 	expiredClaims := &authentication.idTokenCustomClaims{
// 		User: &authentication.UserModelType{
// 			ID:       "123",
// 			Username: "testuser",
// 			Email:    "test@example.com",
// 		},
// 		RegisteredClaims: jwt.RegisteredClaims{
// 			ExpiresAt: time.Now().Add(-time.Hour).Unix(),
// 			IssuedAt:  time.Now().Add(-2 * time.Hour).Unix(),
// 		},
// 	}
// 	expiredToken := jwt.NewWithClaims(jwt.SigningMethodRS256, expiredClaims)
// 	expiredTokenString, err := expiredToken.SignedString(privKey)
// 	assert.NoError(t, err)

// 	_, err = authentication.validateIDToken(expiredTokenString, pubKey)
// 	assert.Error(t, err)
// 	assert.Contains(t, err.Error(), "token has expired")

// 	// Test with an invalid token
// 	invalidTokenString := "invalid.token.string"
// 	_, err = authentication.validateIDToken(invalidTokenString, pubKey)
// 	assert.Error(t, err)
// 	assert.Contains(t, err.Error(), "invalid token format")
// }

/// tests/virus_total.go ///
package tests

import (
	"flag"
	"fmt"
	"log"
	"os"

	vt "github.com/VirusTotal/vt-go"
)

var apikey = flag.String("apikey", "", "VirusTotal API key")
var sha256 = flag.String("sha256", "", "SHA-256 of some file")

func main() {

	flag.Parse()

	if *apikey == "" || *sha256 == "" {
		fmt.Println("Must pass both the --apikey and --sha256 arguments.")
		os.Exit(0)
	}

	client := vt.NewClient(*apikey)

	file, err := client.GetObject(vt.URL("files/%s", *sha256))
	if err != nil {
		log.Fatal(err)
	}

	ls, err := file.GetTime("last_submission_date")
	if err != nil {
		log.Fatal(err)
	}

	fmt.Printf("File %s was submitted for the last time on %v\n", file.ID(), ls)
}

/// utils/embed.go ///
package utils

import (
	"embed"
	"html/template"
	"net/http"
)

//go:embed views/error/*
var ErrorTemplates embed.FS

func pageNotFound(rw http.ResponseWriter, r *http.Request) {

	rw.WriteHeader(http.StatusNotFound)
	tmpl, _ := template.ParseFS(ErrorTemplates, "../views/error/404.html")
	tmpl.Execute(rw, nil)
}

func internalServerError(rw http.ResponseWriter, r *http.Request) {
	rw.WriteHeader(http.StatusInternalServerError)
	tmpl, _ := template.ParseFS(ErrorTemplates, "views/error/500.html")
	tmpl.Execute(rw, nil)
}

/// utils/pagination.go ///
package utils

import (
	"github.com/gin-gonic/gin"

	"strconv"
)

func GetPaginationParams(c *gin.Context) (int, int) {
	page, _ := strconv.Atoi(c.DefaultQuery("page", "1"))
	limit, _ := strconv.Atoi(c.DefaultQuery("limit", "10"))
	if page < 1 {
		page = 1
	}
	if limit < 1 {
		limit = 10
	}
	return page, limit
}

/// utils/validator.go ///
package utils

import (
	"github.com/go-playground/validator/v10"

	"regexp"
)

var validate *validator.Validate

func init() {
	validate = validator.New()
}

func ValidateStruct(s interface{}) error {
	return validate.Struct(s)
}

func SanitizeInput(input string) string {
	re := regexp.MustCompile(`[^\w\s]`)
	return re.ReplaceAllString(input, "")
}

/// utils/views/error/404.html ///
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Page Not Found</title>
</head>
<body>
<h1>404 - Page Not Found</h1>
<p>Desculpe, a pÃ¡gina que vocÃª estÃ¡ procurando nÃ£o existe.</p>
</body>
</html>

/// utils/views/error/500.html ///
 <!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Internal Server Error</title>
</head>
<body>
<h1>500 - Internal Server Error</h1>
<p>Ocorreu um erro interno no servidor. Por favor, tente novamente mais tarde.</p>
</body>
</html>

/// version/semantic.go ///
package version

import (
	gl "github.com/kubex-ecosystem/gobe/logger"
	l "github.com/kubex-ecosystem/logz"

	"github.com/spf13/cobra"

	_ "embed"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strconv"
	"strings"
	"time"
)

const moduleAlias = "GoBE"
const moduleName = "gobe"
const gitModelUrl = "https://github.com/kubex-ecosystem/" + moduleName + ".git"
const currentVersionFallback = "v1.1.0" // First version with the version file

type Service interface {
	GetLatestVersion() (string, error)
	GetCurrentVersion() string
	IsLatestVersion() (bool, error)
}
type ServiceImpl struct {
	gitModelUrl    string
	latestVersion  string
	currentVersion string
}
type Tag struct {
	Name string `json:"name"`
}

func init() {
	l.GetLogger(moduleAlias)
}

func getLatestTag(repoURL string) (string, error) {
	apiURL := fmt.Sprintf("%s/tags", repoURL)
	resp, err := http.Get(apiURL)
	if err != nil {
		return "", err
	}
	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("failed to fetch tags: %s", resp.Status)
	}

	var tags []Tag
	if err := json.NewDecoder(resp.Body).Decode(&tags); err != nil {
		return "", err
	}

	if len(tags) == 0 {
		return "", fmt.Errorf("no tags found")
	}

	return tags[0].Name, nil
}

func (v *ServiceImpl) updateLatestVersion() error {
	repoURL := strings.TrimSuffix(v.gitModelUrl, ".git")
	tag, err := getLatestTag(repoURL)
	if err != nil {
		return err
	}
	v.latestVersion = tag
	return nil
}
func (v *ServiceImpl) vrsCompare(v1, v2 []int) (int, error) {
	if len(v1) != len(v2) {
		return 0, fmt.Errorf("version length mismatch")
	}

	for idx, v2S := range v2 {
		v1S := v1[idx]
		if v1S > v2S {
			return 1, nil
		}

		if v1S < v2S {
			return -1, nil
		}
	}
	return 0, nil
}
func (v *ServiceImpl) versionAtMost(versionAtMostArg, max []int) (bool, error) {
	if comp, err := v.vrsCompare(versionAtMostArg, max); err != nil {
		return false, err
	} else if comp == 1 {
		return false, nil
	}
	return true, nil
}
func (v *ServiceImpl) parseVersion(versionToParse string) []int {
	version := make([]int, 3)
	for idx, vStr := range strings.Split(versionToParse, ".") {
		vS, err := strconv.Atoi(vStr)
		if err != nil {
			return nil
		}
		version[idx] = vS
	}
	return version
}

func (v *ServiceImpl) IsLatestVersion() (bool, error) {
	if v.latestVersion == "" {
		if err := v.updateLatestVersion(); err != nil {
			return false, err
		}
	}

	curr := v.parseVersion(v.currentVersion)
	latest := v.parseVersion(v.latestVersion)

	if curr == nil || latest == nil {
		return false, fmt.Errorf("error parsing versions")
	}

	if isLatest, err := v.versionAtMost(curr, latest); err != nil {
		return false, err
	} else if isLatest {
		return true, nil
	}
	return false, nil
}
func (v *ServiceImpl) GetLatestVersion() (string, error) {
	if v.latestVersion == "" {
		if err := v.updateLatestVersion(); err != nil {
			return "", err
		}
	}

	return v.latestVersion, nil
}
func (v *ServiceImpl) GetCurrentVersion() string { return v.currentVersion }

func NewVersionService() Service {
	return &ServiceImpl{
		gitModelUrl:    gitModelUrl,
		currentVersion: currentVersion,
		latestVersion:  "",
	}
}

var (
	versionCmd = &cobra.Command{
		Use:   "version",
		Short: "Print the version number of " + moduleAlias,
		Long:  "Print the version number of " + moduleAlias,
		Run: func(cmd *cobra.Command, args []string) {
			GetVersionInfo()
		},
	}
	subLatestCmd = &cobra.Command{
		Use:   "latest",
		Short: "Print the latest version number of " + moduleAlias,
		Long:  "Print the latest version number of " + moduleAlias,
		Run: func(cmd *cobra.Command, args []string) {
			GetLatestVersionInfo()
		},
	}
	subCmdCheck = &cobra.Command{
		Use:   "check",
		Short: "Check if the current version is the latest version of " + moduleAlias,
		Long:  "Check if the current version is the latest version of " + moduleAlias,
		Run: func(cmd *cobra.Command, args []string) {
			GetVersionInfoWithLatestAndCheck()
		},
	}
)

//go:embed CLI_VERSION
var currentVersion string

func GetVersion() string {
	if currentVersion == "" {
		return currentVersionFallback
	}
	return currentVersion
}

func GetGitModelUrl() string {
	return gitModelUrl
}

func GetVersionInfo() string {
	gl.Log("info", "Version: "+GetVersion())
	gl.Log("info", "Git repository: "+GetGitModelUrl())
	return fmt.Sprintf("Version: %s\nGit repository: %s", GetVersion(), GetGitModelUrl())
}

func GetLatestVersionFromGit() string {
	netClient := &http.Client{
		Timeout: time.Second * 10,
	}

	gitUrlWithoutGit := strings.TrimSuffix(gitModelUrl, ".git")

	response, err := netClient.Get(gitUrlWithoutGit + "/releases/latest")
	if err != nil {
		gl.Log("error", "ErrorCtx fetching latest version: "+err.Error())
		gl.Log("error", gitUrlWithoutGit+"/releases/latest")
		return err.Error()
	}

	if response.StatusCode != 200 {
		gl.Log("error", "ErrorCtx fetching latest version: "+response.Status)
		gl.Log("error", "Url: "+gitUrlWithoutGit+"/releases/latest")
		body, _ := io.ReadAll(response.Body)
		return fmt.Sprintf("ErrorCtx: %s\nResponse: %s", response.Status, string(body))
	}

	tag := strings.Split(response.Request.URL.Path, "/")

	return tag[len(tag)-1]
}

func GetLatestVersionInfo() string {
	gl.Log("info", "Latest version: "+GetLatestVersionFromGit())
	return "Latest version: " + GetLatestVersionFromGit()
}

func GetVersionInfoWithLatestAndCheck() string {
	if GetVersion() == GetLatestVersionFromGit() {
		gl.Log("info", "You are using the latest version.")
		return fmt.Sprintf("You are using the latest version.\n%s\n%s", GetVersionInfo(), GetLatestVersionInfo())
	} else {
		gl.Log("warn", "You are using an outdated version.")
		return fmt.Sprintf("You are using an outdated version.\n%s\n%s", GetVersionInfo(), GetLatestVersionInfo())
	}
}

func CliCommand() *cobra.Command {
	versionCmd.AddCommand(subLatestCmd)
	versionCmd.AddCommand(subCmdCheck)
	return versionCmd
}
